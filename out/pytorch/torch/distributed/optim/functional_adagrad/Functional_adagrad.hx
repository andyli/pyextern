/* This file is generated, do not edit! */
package torch.distributed.optim.functional_adagrad;
typedef Functional_adagrad = torch.distributed.optim.functional_adagrad.Functional_adagrad_Module;