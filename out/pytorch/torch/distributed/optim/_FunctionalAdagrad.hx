/* This file is generated, do not edit! */
package torch.distributed.optim;
typedef _FunctionalAdagrad = torch.distributed.optim.functional_adagrad._FunctionalAdagrad;