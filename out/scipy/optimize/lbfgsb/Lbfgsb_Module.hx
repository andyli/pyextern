/* This file is generated, do not edit! */
package scipy.optimize.lbfgsb;
@:pythonImport("scipy.optimize.lbfgsb") extern class Lbfgsb_Module {
	static public var __all__ : Dynamic;
	static public var __builtins__ : Dynamic;
	static public var __cached__ : Dynamic;
	static public var __doc__ : Dynamic;
	static public var __file__ : Dynamic;
	static public var __loader__ : Dynamic;
	static public var __name__ : Dynamic;
	static public var __package__ : Dynamic;
	static public var __spec__ : Dynamic;
	/**
		See ``approx_fprime``.  An optional initial function value arg is added.
	**/
	static public function _approx_fprime_helper(xk:Dynamic, f:Dynamic, epsilon:Dynamic, ?args:Dynamic, ?f0:Dynamic):Dynamic;
	static public function _check_unknown_options(unknown_options:Dynamic):Dynamic;
	/**
		Minimize a scalar function of one or more variables using the L-BFGS-B
		algorithm.
		
		Options
		-------
		disp : bool
		   Set to True to print convergence messages.
		maxcor : int
		    The maximum number of variable metric corrections used to
		    define the limited memory matrix. (The limited memory BFGS
		    method does not store the full hessian but uses this many terms
		    in an approximation to it.)
		factr : float
		    The iteration stops when ``(f^k -
		    f^{k+1})/max{|f^k|,|f^{k+1}|,1} <= factr * eps``, where ``eps``
		    is the machine precision, which is automatically generated by
		    the code. Typical values for `factr` are: 1e12 for low
		    accuracy; 1e7 for moderate accuracy; 10.0 for extremely high
		    accuracy.
		ftol : float
		    The iteration stops when ``(f^k -
		    f^{k+1})/max{|f^k|,|f^{k+1}|,1} <= ftol``.
		gtol : float
		    The iteration will stop when ``max{|proj g_i | i = 1, ..., n}
		    <= gtol`` where ``pg_i`` is the i-th component of the
		    projected gradient.
		eps : float
		    Step size used for numerical approximation of the jacobian.
		disp : int
		    Set to True to print convergence messages.
		maxfun : int
		    Maximum number of function evaluations.
		maxiter : int
		    Maximum number of iterations.
	**/
	static public function _minimize_lbfgsb(fun:Dynamic, x0:Dynamic, ?args:Dynamic, ?jac:Dynamic, ?bounds:Dynamic, ?disp:Dynamic, ?maxcor:Dynamic, ?ftol:Dynamic, ?gtol:Dynamic, ?eps:Dynamic, ?maxfun:Dynamic, ?maxiter:Dynamic, ?iprint:Dynamic, ?callback:Dynamic, ?unknown_options:python.KwArgs<Dynamic>):Dynamic;
	static public var absolute_import : Dynamic;
	/**
		Finite-difference approximation of the gradient of a scalar function.
		
		Parameters
		----------
		xk : array_like
		    The coordinate vector at which to determine the gradient of `f`.
		f : callable
		    The function of which to determine the gradient (partial derivatives).
		    Should take `xk` as first argument, other arguments to `f` can be
		    supplied in ``*args``.  Should return a scalar, the value of the
		    function at `xk`.
		epsilon : array_like
		    Increment to `xk` to use for determining the function gradient.
		    If a scalar, uses the same finite difference delta for all partial
		    derivatives.  If an array, should contain one value per element of
		    `xk`.
		\*args : args, optional
		    Any other arguments that are to be passed to `f`.
		
		Returns
		-------
		grad : ndarray
		    The partial derivatives of `f` to `xk`.
		
		See Also
		--------
		check_grad : Check correctness of gradient function against approx_fprime.
		
		Notes
		-----
		The function gradient is determined by the forward finite difference
		formula::
		
		             f(xk[i] + epsilon[i]) - f(xk[i])
		    f'[i] = ---------------------------------
		                        epsilon[i]
		
		The main use of `approx_fprime` is in scalar function optimizers like
		`fmin_bfgs`, to determine numerically the Jacobian of a function.
		
		Examples
		--------
		>>> from scipy import optimize
		>>> def func(x, c0, c1):
		...     "Coordinate vector `x` should be an array of size two."
		...     return c0 * x[0]**2 + c1*x[1]**2
		
		>>> x = np.ones(2)
		>>> c0, c1 = (1, 200)
		>>> eps = np.sqrt(np.finfo(np.float).eps)
		>>> optimize.approx_fprime(x, func, [eps, np.sqrt(200) * eps], c0, c1)
		array([   2.        ,  400.00004198])
	**/
	static public function approx_fprime(xk:Dynamic, f:Dynamic, epsilon:Dynamic, ?args:python.VarArgs<Dynamic>):Dynamic;
	/**
		array(object, dtype=None, copy=True, order=None, subok=False, ndmin=0)
		
		Create an array.
		
		Parameters
		----------
		object : array_like
		    An array, any object exposing the array interface, an
		    object whose __array__ method returns an array, or any
		    (nested) sequence.
		dtype : data-type, optional
		    The desired data-type for the array.  If not given, then
		    the type will be determined as the minimum type required
		    to hold the objects in the sequence.  This argument can only
		    be used to 'upcast' the array.  For downcasting, use the
		    .astype(t) method.
		copy : bool, optional
		    If true (default), then the object is copied.  Otherwise, a copy
		    will only be made if __array__ returns a copy, if obj is a
		    nested sequence, or if a copy is needed to satisfy any of the other
		    requirements (`dtype`, `order`, etc.).
		order : {'C', 'F', 'A'}, optional
		    Specify the order of the array.  If order is 'C', then the array
		    will be in C-contiguous order (last-index varies the fastest).
		    If order is 'F', then the returned array will be in
		    Fortran-contiguous order (first-index varies the fastest).
		    If order is 'A' (default), then the returned array may be
		    in any order (either C-, Fortran-contiguous, or even discontiguous),
		    unless a copy is required, in which case it will be C-contiguous.
		subok : bool, optional
		    If True, then sub-classes will be passed-through, otherwise
		    the returned array will be forced to be a base-class array (default).
		ndmin : int, optional
		    Specifies the minimum number of dimensions that the resulting
		    array should have.  Ones will be pre-pended to the shape as
		    needed to meet this requirement.
		
		Returns
		-------
		out : ndarray
		    An array object satisfying the specified requirements.
		
		See Also
		--------
		empty, empty_like, zeros, zeros_like, ones, ones_like, fill
		
		Examples
		--------
		>>> np.array([1, 2, 3])
		array([1, 2, 3])
		
		Upcasting:
		
		>>> np.array([1, 2, 3.0])
		array([ 1.,  2.,  3.])
		
		More than one dimension:
		
		>>> np.array([[1, 2], [3, 4]])
		array([[1, 2],
		       [3, 4]])
		
		Minimum dimensions 2:
		
		>>> np.array([1, 2, 3], ndmin=2)
		array([[1, 2, 3]])
		
		Type provided:
		
		>>> np.array([1, 2, 3], dtype=complex)
		array([ 1.+0.j,  2.+0.j,  3.+0.j])
		
		Data-type consisting of more than one element:
		
		>>> x = np.array([(1,2),(3,4)],dtype=[('a','<i4'),('b','<i4')])
		>>> x['a']
		array([1, 3])
		
		Creating an array from sub-classes:
		
		>>> np.array(np.mat('1 2; 3 4'))
		array([[1, 2],
		       [3, 4]])
		
		>>> np.array(np.mat('1 2; 3 4'), subok=True)
		matrix([[1, 2],
		        [3, 4]])
	**/
	static public function array(args:haxe.extern.Rest<Dynamic>):Dynamic;
	/**
		Convert the input to an array.
		
		Parameters
		----------
		a : array_like
		    Input data, in any form that can be converted to an array.  This
		    includes lists, lists of tuples, tuples, tuples of tuples, tuples
		    of lists and ndarrays.
		dtype : data-type, optional
		    By default, the data-type is inferred from the input data.
		order : {'C', 'F'}, optional
		    Whether to use row-major (C-style) or
		    column-major (Fortran-style) memory representation.
		    Defaults to 'C'.
		
		Returns
		-------
		out : ndarray
		    Array interpretation of `a`.  No copy is performed if the input
		    is already an ndarray.  If `a` is a subclass of ndarray, a base
		    class ndarray is returned.
		
		See Also
		--------
		asanyarray : Similar function which passes through subclasses.
		ascontiguousarray : Convert input to a contiguous array.
		asfarray : Convert input to a floating point ndarray.
		asfortranarray : Convert input to an ndarray with column-major
		                 memory order.
		asarray_chkfinite : Similar function which checks input for NaNs and Infs.
		fromiter : Create an array from an iterator.
		fromfunction : Construct an array by executing a function on grid
		               positions.
		
		Examples
		--------
		Convert a list into an array:
		
		>>> a = [1, 2]
		>>> np.asarray(a)
		array([1, 2])
		
		Existing arrays are not copied:
		
		>>> a = np.array([1, 2])
		>>> np.asarray(a) is a
		True
		
		If `dtype` is set, array is copied only if dtype does not match:
		
		>>> a = np.array([1, 2], dtype=np.float32)
		>>> np.asarray(a, dtype=np.float32) is a
		True
		>>> np.asarray(a, dtype=np.float64) is a
		False
		
		Contrary to `asanyarray`, ndarray subclasses are not passed through:
		
		>>> issubclass(np.matrix, np.ndarray)
		True
		>>> a = np.matrix([[1, 2]])
		>>> np.asarray(a) is a
		False
		>>> np.asanyarray(a) is a
		True
	**/
	static public function asarray(a:Dynamic, ?dtype:Dynamic, ?order:Dynamic):Dynamic;
	static public var division : Dynamic;
	/**
		Minimize a function func using the L-BFGS-B algorithm.
		
		Parameters
		----------
		func : callable f(x,*args)
		    Function to minimise.
		x0 : ndarray
		    Initial guess.
		fprime : callable fprime(x,*args), optional
		    The gradient of `func`.  If None, then `func` returns the function
		    value and the gradient (``f, g = func(x, *args)``), unless
		    `approx_grad` is True in which case `func` returns only ``f``.
		args : sequence, optional
		    Arguments to pass to `func` and `fprime`.
		approx_grad : bool, optional
		    Whether to approximate the gradient numerically (in which case
		    `func` returns only the function value).
		bounds : list, optional
		    ``(min, max)`` pairs for each element in ``x``, defining
		    the bounds on that parameter. Use None or +-inf for one of ``min`` or
		    ``max`` when there is no bound in that direction.
		m : int, optional
		    The maximum number of variable metric corrections
		    used to define the limited memory matrix. (The limited memory BFGS
		    method does not store the full hessian but uses this many terms in an
		    approximation to it.)
		factr : float, optional
		    The iteration stops when
		    ``(f^k - f^{k+1})/max{|f^k|,|f^{k+1}|,1} <= factr * eps``,
		    where ``eps`` is the machine precision, which is automatically
		    generated by the code. Typical values for `factr` are: 1e12 for
		    low accuracy; 1e7 for moderate accuracy; 10.0 for extremely
		    high accuracy.
		pgtol : float, optional
		    The iteration will stop when
		    ``max{|proj g_i | i = 1, ..., n} <= pgtol``
		    where ``pg_i`` is the i-th component of the projected gradient.
		epsilon : float, optional
		    Step size used when `approx_grad` is True, for numerically
		    calculating the gradient
		iprint : int, optional
		    Controls the frequency of output. ``iprint < 0`` means no output;
		    ``iprint == 0`` means write messages to stdout; ``iprint > 1`` in
		    addition means write logging information to a file named
		    ``iterate.dat`` in the current working directory.
		disp : int, optional
		    If zero, then no output.  If a positive number, then this over-rides
		    `iprint` (i.e., `iprint` gets the value of `disp`).
		maxfun : int, optional
		    Maximum number of function evaluations.
		maxiter : int, optional
		    Maximum number of iterations.
		callback : callable, optional
		    Called after each iteration, as ``callback(xk)``, where ``xk`` is the
		    current parameter vector.
		
		Returns
		-------
		x : array_like
		    Estimated position of the minimum.
		f : float
		    Value of `func` at the minimum.
		d : dict
		    Information dictionary.
		
		    * d['warnflag'] is
		
		      - 0 if converged,
		      - 1 if too many function evaluations or too many iterations,
		      - 2 if stopped for another reason, given in d['task']
		
		    * d['grad'] is the gradient at the minimum (should be 0 ish)
		    * d['funcalls'] is the number of function calls made.
		    * d['nit'] is the number of iterations.
		
		See also
		--------
		minimize: Interface to minimization algorithms for multivariate
		    functions. See the 'L-BFGS-B' `method` in particular.
		
		Notes
		-----
		License of L-BFGS-B (FORTRAN code):
		
		The version included here (in fortran code) is 3.0
		(released April 25, 2011).  It was written by Ciyou Zhu, Richard Byrd,
		and Jorge Nocedal <nocedal@ece.nwu.edu>. It carries the following
		condition for use:
		
		This software is freely available, but we expect that all publications
		describing work using this software, or all commercial products using it,
		quote at least one of the references given below. This software is released
		under the BSD License.
		
		References
		----------
		* R. H. Byrd, P. Lu and J. Nocedal. A Limited Memory Algorithm for Bound
		  Constrained Optimization, (1995), SIAM Journal on Scientific and
		  Statistical Computing, 16, 5, pp. 1190-1208.
		* C. Zhu, R. H. Byrd and J. Nocedal. L-BFGS-B: Algorithm 778: L-BFGS-B,
		  FORTRAN routines for large scale bound constrained optimization (1997),
		  ACM Transactions on Mathematical Software, 23, 4, pp. 550 - 560.
		* J.L. Morales and J. Nocedal. L-BFGS-B: Remark on Algorithm 778: L-BFGS-B,
		  FORTRAN routines for large scale bound constrained optimization (2011),
		  ACM Transactions on Mathematical Software, 38, 1.
	**/
	static public function fmin_l_bfgs_b(func:Dynamic, x0:Dynamic, ?fprime:Dynamic, ?args:Dynamic, ?approx_grad:Dynamic, ?bounds:Dynamic, ?m:Dynamic, ?factr:Dynamic, ?pgtol:Dynamic, ?epsilon:Dynamic, ?iprint:Dynamic, ?maxfun:Dynamic, ?maxiter:Dynamic, ?disp:Dynamic, ?callback:Dynamic):Dynamic;
	static public var print_function : Dynamic;
	static public function wrap_function(_function:Dynamic, args:Dynamic):Dynamic;
	/**
		zeros(shape, dtype=float, order='C')
		
		Return a new array of given shape and type, filled with zeros.
		
		Parameters
		----------
		shape : int or sequence of ints
		    Shape of the new array, e.g., ``(2, 3)`` or ``2``.
		dtype : data-type, optional
		    The desired data-type for the array, e.g., `numpy.int8`.  Default is
		    `numpy.float64`.
		order : {'C', 'F'}, optional
		    Whether to store multidimensional data in C- or Fortran-contiguous
		    (row- or column-wise) order in memory.
		
		Returns
		-------
		out : ndarray
		    Array of zeros with the given shape, dtype, and order.
		
		See Also
		--------
		zeros_like : Return an array of zeros with shape and type of input.
		ones_like : Return an array of ones with shape and type of input.
		empty_like : Return an empty array with shape and type of input.
		ones : Return a new array setting values to one.
		empty : Return a new uninitialized array.
		
		Examples
		--------
		>>> np.zeros(5)
		array([ 0.,  0.,  0.,  0.,  0.])
		
		>>> np.zeros((5,), dtype=np.int)
		array([0, 0, 0, 0, 0])
		
		>>> np.zeros((2, 1))
		array([[ 0.],
		       [ 0.]])
		
		>>> s = (2,2)
		>>> np.zeros(s)
		array([[ 0.,  0.],
		       [ 0.,  0.]])
		
		>>> np.zeros((2,), dtype=[('x', 'i4'), ('y', 'i4')]) # custom dtype
		array([(0, 0), (0, 0)],
		      dtype=[('x', '<i4'), ('y', '<i4')])
	**/
	static public function zeros(args:haxe.extern.Rest<Dynamic>):Dynamic;
}