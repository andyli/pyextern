/* This file is generated, do not edit! */
package tensorflow.compat.v1.keras.layers;
@:pythonImport("tensorflow.compat.v1.keras.layers") extern class Layers_Module {
	/**
		`Input()` is used to instantiate a Keras tensor.
		
		A Keras tensor is a symbolic tensor-like object,
		which we augment with certain attributes that allow us to build a Keras model
		just by knowing the inputs and outputs of the model.
		
		For instance, if `a`, `b` and `c` are Keras tensors,
		it becomes possible to do:
		`model = Model(input=[a, b], output=c)`
		
		Args:
		    shape: A shape tuple (integers), not including the batch size.
		        For instance, `shape=(32,)` indicates that the expected input
		        will be batches of 32-dimensional vectors. Elements of this tuple
		        can be None; 'None' elements represent dimensions where the shape is
		        not known.
		    batch_size: optional static batch size (integer).
		    name: An optional name string for the layer.
		        Should be unique in a model (do not reuse the same name twice).
		        It will be autogenerated if it isn't provided.
		    dtype: The data type expected by the input, as a string
		        (`float32`, `float64`, `int32`...)
		    sparse: A boolean specifying whether the placeholder to be created is
		        sparse. Only one of 'ragged' and 'sparse' can be True. Note that,
		        if `sparse` is False, sparse tensors can still be passed into the
		        input - they will be densified with a default value of 0.
		    tensor: Optional existing tensor to wrap into the `Input` layer.
		        If set, the layer will use the `tf.TypeSpec` of this tensor rather
		        than creating a new placeholder tensor.
		    ragged: A boolean specifying whether the placeholder to be created is
		        ragged. Only one of 'ragged' and 'sparse' can be True. In this case,
		        values of 'None' in the 'shape' argument represent ragged dimensions.
		        For more information about RaggedTensors, see
		        [this guide](https://www.tensorflow.org/guide/ragged_tensors).
		    type_spec: A `tf.TypeSpec` object to create the input placeholder from.
		        When provided, all other args except name must be None.
		    **kwargs: deprecated arguments support. Supports `batch_shape` and
		        `batch_input_shape`.
		
		Returns:
		  A `tensor`.
		
		Example:
		
		```python
		# this is a logistic regression in Keras
		x = Input(shape=(32,))
		y = Dense(16, activation='softmax')(x)
		model = Model(x, y)
		```
		
		Note that even if eager execution is enabled,
		`Input` produces a symbolic tensor-like object (i.e. a placeholder).
		This symbolic tensor-like object can be used with lower-level
		TensorFlow ops that take tensors as inputs, as such:
		
		```python
		x = Input(shape=(32,))
		y = tf.square(x)  # This op will be treated like a layer
		model = Model(x, y)
		```
		
		(This behavior does not work for higher-order TensorFlow APIs such as
		control flow and being directly watched by a `tf.GradientTape`).
		
		However, the resulting model will not track any variables that were
		used as inputs to TensorFlow ops. All variable usages must happen within
		Keras layers to make sure they will be tracked by the model's weights.
		
		The Keras Input can also create a placeholder from an arbitrary `tf.TypeSpec`,
		e.g:
		
		```python
		x = Input(type_spec=tf.RaggedTensorSpec(shape=[None, None],
		                                        dtype=tf.float32, ragged_rank=1))
		y = x.values
		model = Model(x, y)
		```
		When passing an arbitrary `tf.TypeSpec`, it must represent the signature of an
		entire batch instead of just one example.
		
		Raises:
		  ValueError: If both `sparse` and `ragged` are provided.
		  ValueError: If both `shape` and (`batch_input_shape` or `batch_shape`) are
		    provided.
		  ValueError: If `shape`, `tensor` and `type_spec` are None.
		  ValueError: If arguments besides `type_spec` are non-None while `type_spec`
		              is passed.
		  ValueError: if any unrecognized parameters are provided.
	**/
	static public function Input(?shape:Dynamic, ?batch_size:Dynamic, ?name:Dynamic, ?dtype:Dynamic, ?sparse:Dynamic, ?tensor:Dynamic, ?ragged:Dynamic, ?type_spec:Dynamic, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	static public var __all__ : Dynamic;
	static public var __builtins__ : Dynamic;
	static public var __cached__ : Dynamic;
	static public var __doc__ : Dynamic;
	static public var __file__ : Dynamic;
	static public var __loader__ : Dynamic;
	static public var __name__ : Dynamic;
	static public var __package__ : Dynamic;
	static public var __path__ : Dynamic;
	static public var __spec__ : Dynamic;
	/**
		Functional interface to the `tf.keras.layers.Add` layer.
		
		Args:
		    inputs: A list of input tensors (at least 2) with the same shape.
		    **kwargs: Standard layer keyword arguments.
		
		Returns:
		    A tensor as the sum of the inputs. It has the same shape as the inputs.
		
		Examples:
		
		>>> input_shape = (2, 3, 4)
		>>> x1 = tf.random.normal(input_shape)
		>>> x2 = tf.random.normal(input_shape)
		>>> y = tf.keras.layers.add([x1, x2])
		>>> print(y.shape)
		(2, 3, 4)
		
		Used in a functional model:
		
		>>> input1 = tf.keras.layers.Input(shape=(16,))
		>>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)
		>>> input2 = tf.keras.layers.Input(shape=(32,))
		>>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2)
		>>> added = tf.keras.layers.add([x1, x2])
		>>> out = tf.keras.layers.Dense(4)(added)
		>>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)
	**/
	static public function add(inputs:Dynamic, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	/**
		Functional interface to the `tf.keras.layers.Average` layer.
		
		Example:
		
		>>> x1 = np.ones((2, 2))
		>>> x2 = np.zeros((2, 2))
		>>> y = tf.keras.layers.Average()([x1, x2])
		>>> y.numpy().tolist()
		[[0.5, 0.5], [0.5, 0.5]]
		
		Usage in a functional model:
		
		>>> input1 = tf.keras.layers.Input(shape=(16,))
		>>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)
		>>> input2 = tf.keras.layers.Input(shape=(32,))
		>>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2)
		>>> avg = tf.keras.layers.Average()([x1, x2])
		>>> out = tf.keras.layers.Dense(4)(avg)
		>>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)
		
		Args:
		    inputs: A list of input tensors (at least 2).
		    **kwargs: Standard layer keyword arguments.
		
		Returns:
		    A tensor, the average of the inputs.
		
		Raises:
		  ValueError: If there is a shape mismatch between the inputs and the shapes
		    cannot be broadcasted to match.
	**/
	static public function average(inputs:Dynamic, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	/**
		Functional interface to the `Concatenate` layer.
		
		>>> x = np.arange(20).reshape(2, 2, 5)
		>>> print(x)
		[[[ 0  1  2  3  4]
		  [ 5  6  7  8  9]]
		 [[10 11 12 13 14]
		  [15 16 17 18 19]]]
		>>> y = np.arange(20, 30).reshape(2, 1, 5)
		>>> print(y)
		[[[20 21 22 23 24]]
		 [[25 26 27 28 29]]]
		>>> tf.keras.layers.concatenate([x, y],
		...                             axis=1)
		<tf.Tensor: shape=(2, 3, 5), dtype=int64, numpy=
		array([[[ 0,  1,  2,  3,  4],
		      [ 5,  6,  7,  8,  9],
		      [20, 21, 22, 23, 24]],
		     [[10, 11, 12, 13, 14],
		      [15, 16, 17, 18, 19],
		      [25, 26, 27, 28, 29]]])>
		
		Args:
		    inputs: A list of input tensors (at least 2).
		    axis: Concatenation axis.
		    **kwargs: Standard layer keyword arguments.
		
		Returns:
		    A tensor, the concatenation of the inputs alongside axis `axis`.
	**/
	static public function concatenate(inputs:Dynamic, ?axis:Dynamic, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	/**
		Instantiates a layer from a config dictionary.
		
		Args:
		    config: dict of the form {'class_name': str, 'config': dict}
		    custom_objects: dict mapping class names (or function names) of custom
		      (non-Keras) objects to class/functions
		
		Returns:
		    Layer instance (may be Model, Sequential, Network, Layer...)
		
		Example:
		
		```python
		# Configuration of Dense(32, activation='relu')
		config = {
		  'class_name': 'Dense',
		  'config': {
		    'activation': 'relu',
		    'activity_regularizer': None,
		    'bias_constraint': None,
		    'bias_initializer': {'class_name': 'Zeros', 'config': {}},
		    'bias_regularizer': None,
		    'dtype': 'float32',
		    'kernel_constraint': None,
		    'kernel_initializer': {'class_name': 'GlorotUniform',
		                           'config': {'seed': None}},
		    'kernel_regularizer': None,
		    'name': 'dense',
		    'trainable': True,
		    'units': 32,
		    'use_bias': True
		  }
		}
		dense_layer = tf.keras.layers.deserialize(config)
		```
	**/
	static public function deserialize(config:Dynamic, ?custom_objects:Dynamic):Dynamic;
	/**
		Disables the V2 dtype behavior for Keras layers.
		
		See `tf.compat.v1.keras.layers.enable_v2_dtype_behavior`.
	**/
	static public function disable_v2_dtype_behavior():Dynamic;
	/**
		Functional interface to the `Dot` layer.
		
		Args:
		    inputs: A list of input tensors (at least 2).
		    axes: Integer or tuple of integers,
		        axis or axes along which to take the dot product.
		    normalize: Whether to L2-normalize samples along the
		        dot product axis before taking the dot product.
		        If set to True, then the output of the dot product
		        is the cosine proximity between the two samples.
		    **kwargs: Standard layer keyword arguments.
		
		Returns:
		    A tensor, the dot product of the samples from the inputs.
	**/
	static public function dot(inputs:Dynamic, axes:Dynamic, ?normalize:Dynamic, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	/**
		Enable the V2 dtype behavior for Keras layers.
		
		By default, the V2 dtype behavior is enabled in TensorFlow 2, so this function
		is only useful if `tf.compat.v1.disable_v2_behavior` has been called. Since
		mixed precision requires V2 dtype behavior to be enabled, this function allows
		you to use mixed precision in Keras layers if `disable_v2_behavior` has been
		called.
		
		When enabled, the dtype of Keras layers defaults to floatx (which is typically
		float32) instead of None. In addition, layers will automatically cast
		floating-point inputs to the layer's dtype.
		
		>>> x = tf.ones((4, 4, 4, 4), dtype='float64')
		>>> layer = tf.keras.layers.Conv2D(filters=4, kernel_size=2)
		>>> print(layer.dtype)  # float32 since V2 dtype behavior is enabled
		float32
		>>> y = layer(x)  # Layer casts inputs since V2 dtype behavior is enabled
		>>> print(y.dtype.name)
		float32
		
		A layer author can opt-out their layer from the automatic input casting by
		passing `autocast=False` to the base Layer's constructor. This disables the
		autocasting part of the V2 behavior for that layer, but not the defaulting to
		floatx part of the V2 behavior.
		
		When a global `tf.keras.mixed_precision.Policy` is set, a Keras layer's dtype
		will default to the global policy instead of floatx. Layers will automatically
		cast inputs to the policy's compute_dtype.
	**/
	static public function enable_v2_dtype_behavior():Dynamic;
	/**
		Functional interface to compute maximum (element-wise) list of `inputs`.
		
		This is equivalent to the `tf.keras.layers.Maximum` layer.
		
		For example:
		
		```python
		input1 = tf.keras.layers.Input(shape=(16,))
		x1 = tf.keras.layers.Dense(8, activation='relu')(input1) #shape=(None, 8)
		input2 = tf.keras.layers.Input(shape=(32,))
		x2 = tf.keras.layers.Dense(8, activation='relu')(input2) #shape=(None, 8)
		max_inp=tf.keras.layers.maximum([x1,x2]) #shape=(None, 8)
		out = tf.keras.layers.Dense(4)(max_inp)
		model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)
		```
		
		Args:
		    inputs: A list of input tensors (at least 2) of same shape.
		    **kwargs: Standard layer keyword arguments.
		
		Returns:
		    A tensor (of same shape as input tensor) with the element-wise
		    maximum of the inputs.
		
		Raises:
		    ValueError: If input tensors are of different shape.
	**/
	static public function maximum(inputs:Dynamic, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	/**
		Functional interface to the `Minimum` layer.
		
		Args:
		    inputs: A list of input tensors (at least 2).
		    **kwargs: Standard layer keyword arguments.
		
		Returns:
		    A tensor, the element-wise minimum of the inputs.
	**/
	static public function minimum(inputs:Dynamic, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	/**
		Functional interface to the `Multiply` layer.
		
		Example:
		
		>>> x1 = np.arange(3.0)
		>>> x2 = np.arange(3.0)
		>>> tf.keras.layers.multiply([x1, x2])
		<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 1., 4.], ...)>
		
		Usage in a functional model:
		
		>>> input1 = tf.keras.layers.Input(shape=(16,))
		>>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1) #shape=(None, 8)
		>>> input2 = tf.keras.layers.Input(shape=(32,))
		>>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2) #shape=(None, 8)
		>>> out = tf.keras.layers.multiply([x1,x2]) #shape=(None, 8)
		>>> out = tf.keras.layers.Dense(4)(out)
		>>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)
		
		Args:
		    inputs: A list of input tensors (at least 2).
		    **kwargs: Standard layer keyword arguments.
		
		Returns:
		    A tensor, the element-wise product of the inputs.
	**/
	static public function multiply(inputs:Dynamic, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
	/**
		Serializes a `Layer` object into a JSON-compatible representation.
		
		Args:
		  layer: The `Layer` object to serialize.
		
		Returns:
		  A JSON-serializable dict representing the object's config.
		
		Example:
		
		```python
		from pprint import pprint
		model = tf.keras.models.Sequential()
		model.add(tf.keras.Input(shape=(16,)))
		model.add(tf.keras.layers.Dense(32, activation='relu'))
		
		pprint(tf.keras.layers.serialize(model))
		# prints the configuration of the model, as a dict.
	**/
	static public function serialize(layer:Dynamic):Dynamic;
	/**
		Functional interface to the `Subtract` layer.
		
		Args:
		    inputs: A list of input tensors (exactly 2).
		    **kwargs: Standard layer keyword arguments.
		
		Returns:
		    A tensor, the difference of the inputs.
		
		Examples:
		
		```python
		    import keras
		
		    input1 = keras.layers.Input(shape=(16,))
		    x1 = keras.layers.Dense(8, activation='relu')(input1)
		    input2 = keras.layers.Input(shape=(32,))
		    x2 = keras.layers.Dense(8, activation='relu')(input2)
		    subtracted = keras.layers.subtract([x1, x2])
		
		    out = keras.layers.Dense(4)(subtracted)
		    model = keras.models.Model(inputs=[input1, input2], outputs=out)
		```
	**/
	static public function subtract(inputs:Dynamic, ?kwargs:python.KwArgs<Dynamic>):Dynamic;
}