/* This file is generated, do not edit! */
package tensorflow.compat.v2.raw_ops;
@:pythonImport("tensorflow.compat.v2.raw_ops") extern class Raw_ops_Module {
	/**
		Raise a exception to abort the process when called.
		
		If exit_without_error is true, the process will exit normally,
		otherwise it will exit with a SIGABORT signal.
		
		Returns nothing but an exception.
		
		Args:
		  error_msg: An optional `string`. Defaults to `""`.
		    A string which is the message associated with the exception.
		  exit_without_error: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function Abort(?error_msg:Dynamic, ?exit_without_error:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the absolute value of a tensor.
		
		Given a tensor `x`, this operation returns a tensor containing the absolute
		value of each element in `x`. For example, if x is an input element and y is
		an output element, this operation computes \\(y = |x|\\).
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Abs(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the element-wise sum of a list of tensors.
		
		`tf.accumulate_n_v2` performs the same operation as `tf.add_n`, but does not
		wait for all of its inputs to be ready before beginning to sum. This can
		save memory if inputs are ready at different times, since minimum temporary
		storage is proportional to the output size rather than the inputs size.
		
		Unlike the original `accumulate_n`, `accumulate_n_v2` is differentiable.
		
		Returns a `Tensor` of same shape and type as the elements of `inputs`.
		
		Args:
		  inputs: A list of at least 1 `Tensor` objects with the same type in: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A list of `Tensor` objects, each with same shape and type.
		  shape: A `tf.TensorShape` or list of `ints`.
		    Shape of elements of `inputs`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `inputs`.
	**/
	static public function AccumulateNV2(inputs:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies a gradient to a given accumulator.
		
		Does not add if local_step is lesser than the accumulator's global_step.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a accumulator.
		  local_step: A `Tensor` of type `int64`.
		    The local_step value at which the gradient was computed.
		  gradient: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A tensor of the gradient to be accumulated.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function AccumulatorApplyGradient(handle:Dynamic, local_step:Dynamic, gradient:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the number of gradients aggregated in the given accumulators.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to an accumulator.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function AccumulatorNumAccumulated(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Updates the accumulator with a new value for global_step.
		
		Logs warning if the accumulator's value is already higher than
		new_global_step.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to an accumulator.
		  new_global_step: A `Tensor` of type `int64`.
		    The new global_step value to set.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function AccumulatorSetGlobalStep(handle:Dynamic, new_global_step:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Extracts the average gradient in the given ConditionalAccumulator.
		
		The op blocks until sufficient (i.e., more than num_required)
		gradients have been accumulated.  If the accumulator has already
		aggregated more than num_required gradients, it returns the average of
		the accumulated gradients.  Also automatically increments the recorded
		global_step in the accumulator by 1, and resets the aggregate to 0.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to an accumulator.
		  num_required: A `Tensor` of type `int32`.
		    Number of gradients required before we return an aggregate.
		  dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
		    The data type of accumulated gradients. Needs to correspond to the type
		    of the accumulator.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function AccumulatorTakeGradient(handle:Dynamic, num_required:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes acos of x element-wise.
		
		
		  Provided an input tensor, the `tf.math.acos` operation returns the inverse cosine of each element of the tensor. If `y = tf.math.cos(x)` then, `x = tf.math.acos(y)`.
		
		  Input range is `[-1, 1]` and the output has a range of `[0, pi]`.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Acos(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes inverse hyperbolic cosine of x element-wise.
		
		Given an input tensor, the function computes inverse hyperbolic cosine of every element.
		Input range is `[1, inf]`. It returns `nan` if the input lies outside the range.
		
		```python
		x = tf.constant([-2, -0.5, 1, 1.2, 200, 10000, float("inf")])
		tf.math.acosh(x) ==> [nan nan 0. 0.62236255 5.9914584 9.903487 inf]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Acosh(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x + y element-wise.
		
		*NOTE*: `Add` supports broadcasting. `AddN` does not. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Given two input tensors, the `tf.add` operation computes the sum for every element in the tensor.
		
		Both input and output have a range `(-inf, inf)`.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `string`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Add(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Add an `N`-minibatch `SparseTensor` to a `SparseTensorsMap`, return `N` handles.
		
		A `SparseTensor` of rank `R` is represented by three tensors: `sparse_indices`,
		`sparse_values`, and `sparse_shape`, where
		
		```sparse_indices.shape[1] == sparse_shape.shape[0] == R```
		
		An `N`-minibatch of `SparseTensor` objects is represented as a `SparseTensor`
		having a first `sparse_indices` column taking values between `[0, N)`, where
		the minibatch size `N == sparse_shape[0]`.
		
		The input `SparseTensor` must have rank `R` greater than 1, and the first
		dimension is treated as the minibatch dimension.  Elements of the `SparseTensor`
		must be sorted in increasing order of this first dimension.  The stored
		`SparseTensor` objects pointed to by each row of the output `sparse_handles`
		will have rank `R-1`.
		
		The `SparseTensor` values can then be read out as part of a minibatch by passing
		the given keys as vector elements to `TakeManySparseFromTensorsMap`.  To ensure
		the correct `SparseTensorsMap` is accessed, ensure that the same
		`container` and `shared_name` are passed to that Op.  If no `shared_name`
		is provided here, instead use the *name* of the Operation created by calling
		`AddManySparseToTensorsMap` as the `shared_name` passed to
		`TakeManySparseFromTensorsMap`.  Ensure the Operations are colocated.
		
		Args:
		  sparse_indices: A `Tensor` of type `int64`.
		    2-D.  The `indices` of the minibatch `SparseTensor`.
		    `sparse_indices[:, 0]` must be ordered values in `[0, N)`.
		  sparse_values: A `Tensor`.
		    1-D.  The `values` of the minibatch `SparseTensor`.
		  sparse_shape: A `Tensor` of type `int64`.
		    1-D.  The `shape` of the minibatch `SparseTensor`.
		    The minibatch size `N == sparse_shape[0]`.
		  container: An optional `string`. Defaults to `""`.
		    The container name for the `SparseTensorsMap` created by this op.
		  shared_name: An optional `string`. Defaults to `""`.
		    The shared name for the `SparseTensorsMap` created by this op.
		    If blank, the new Operation's unique name is used.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function AddManySparseToTensorsMap(sparse_indices:Dynamic, sparse_values:Dynamic, sparse_shape:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Add all input tensors element wise.
		
		  Inputs must be of same size and shape.
		
		  ```python
		  x = [9, 7, 10]
		  tf.math.add_n(x) ==> 26
		  ```
		
		Args:
		  inputs: A list of at least 1 `Tensor` objects with the same type in: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`, `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `inputs`.
	**/
	static public function AddN(inputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Add a `SparseTensor` to a `SparseTensorsMap` return its handle.
		
		A `SparseTensor` is represented by three tensors: `sparse_indices`,
		`sparse_values`, and `sparse_shape`.
		
		This operator takes the given `SparseTensor` and adds it to a container
		object (a `SparseTensorsMap`).  A unique key within this container is generated
		in the form of an `int64`, and this is the value that is returned.
		
		The `SparseTensor` can then be read out as part of a minibatch by passing
		the key as a vector element to `TakeManySparseFromTensorsMap`.  To ensure
		the correct `SparseTensorsMap` is accessed, ensure that the same
		`container` and `shared_name` are passed to that Op.  If no `shared_name`
		is provided here, instead use the *name* of the Operation created by calling
		`AddSparseToTensorsMap` as the `shared_name` passed to
		`TakeManySparseFromTensorsMap`.  Ensure the Operations are colocated.
		
		Args:
		  sparse_indices: A `Tensor` of type `int64`.
		    2-D.  The `indices` of the `SparseTensor`.
		  sparse_values: A `Tensor`. 1-D.  The `values` of the `SparseTensor`.
		  sparse_shape: A `Tensor` of type `int64`.
		    1-D.  The `shape` of the `SparseTensor`.
		  container: An optional `string`. Defaults to `""`.
		    The container name for the `SparseTensorsMap` created by this op.
		  shared_name: An optional `string`. Defaults to `""`.
		    The shared name for the `SparseTensorsMap` created by this op.
		    If blank, the new Operation's unique name is used.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function AddSparseToTensorsMap(sparse_indices:Dynamic, sparse_values:Dynamic, sparse_shape:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x + y element-wise.
		
		*NOTE*: `Add` supports broadcasting. `AddN` does not. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function AddV2(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Disallowed in GraphDef version >= 2.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `int16`, `int32`, `int64`, `float32`, `float64`.
		  contrast_factor: A `Tensor` of type `float32`.
		  min_value: A `Tensor` of type `float32`.
		  max_value: A `Tensor` of type `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function AdjustContrast(images:Dynamic, contrast_factor:Dynamic, min_value:Dynamic, max_value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adjust the contrast of one or more images.
		
		`images` is a tensor of at least 3 dimensions.  The last 3 dimensions are
		interpreted as `[height, width, channels]`.  The other dimensions only
		represent a collection of images, such as `[batch, height, width, channels].`
		
		Contrast is adjusted independently for each channel of each image.
		
		For each channel, the Op first computes the mean of the image pixels in the
		channel and then adjusts each component of each pixel to
		`(x - mean) * contrast_factor + mean`.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    Images to adjust.  At least 3-D.
		  contrast_factor: A `Tensor` of type `float32`.
		    A float multiplier for adjusting contrast.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `images`.
	**/
	static public function AdjustContrastv2(images:Dynamic, contrast_factor:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adjust the hue of one or more images.
		
		`images` is a tensor of at least 3 dimensions.  The last dimension is
		interpreted as channels, and must be three.
		
		The input image is considered in the RGB colorspace. Conceptually, the RGB
		colors are first mapped into HSV. A delta is then applied all the hue values,
		and then remapped back to RGB colorspace.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    Images to adjust.  At least 3-D.
		  delta: A `Tensor` of type `float32`. A float delta to add to the hue.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `images`.
	**/
	static public function AdjustHue(images:Dynamic, delta:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adjust the saturation of one or more images.
		
		`images` is a tensor of at least 3 dimensions.  The last dimension is
		interpreted as channels, and must be three.
		
		The input image is considered in the RGB colorspace. Conceptually, the RGB
		colors are first mapped into HSV. A scale is then applied all the saturation
		values, and then remapped back to RGB colorspace.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    Images to adjust.  At least 3-D.
		  scale: A `Tensor` of type `float32`.
		    A float scale to add to the saturation.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `images`.
	**/
	static public function AdjustSaturation(images:Dynamic, scale:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the "logical and" of elements across dimensions of a tensor.
		
		Reduces `input` along the dimensions given in `axis`. Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`axis`. If `keep_dims` is true, the reduced dimensions are
		retained with length 1.
		
		Args:
		  input: A `Tensor` of type `bool`. The tensor to reduce.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The dimensions to reduce. Must be in the range
		    `[-rank(input), rank(input))`.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function All(input:Dynamic, axis:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates labels for candidate sampling with a learned unigram distribution.
		
		See explanations of candidate sampling and the data formats at
		go/candidate-sampling.
		
		For each batch, this op picks a single set of sampled candidate labels.
		
		The advantages of sampling candidates per-batch are simplicity and the
		possibility of efficient dense matrix multiplication. The disadvantage is that
		the sampled candidates must be chosen independently of the context and of the
		true labels.
		
		Args:
		  true_classes: A `Tensor` of type `int64`.
		    A batch_size * num_true matrix, in which each row contains the
		    IDs of the num_true target_classes in the corresponding original label.
		  num_true: An `int` that is `>= 1`. Number of true labels per context.
		  num_sampled: An `int` that is `>= 1`. Number of candidates to produce.
		  unique: A `bool`.
		    If unique is true, we sample with rejection, so that all sampled
		    candidates in a batch are unique. This requires some approximation to
		    estimate the post-rejection sampling probabilities.
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    An second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sampled_candidates, true_expected_count, sampled_expected_count).
		
		  sampled_candidates: A `Tensor` of type `int64`.
		  true_expected_count: A `Tensor` of type `float32`.
		  sampled_expected_count: A `Tensor` of type `float32`.
	**/
	static public function AllCandidateSampler(true_classes:Dynamic, num_true:Dynamic, num_sampled:Dynamic, unique:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An Op to exchange data across TPU replicas.
		
		On each replica, the input is split into `split_count` blocks along
		`split_dimension` and send to the other replicas given group_assignment. After
		receiving `split_count` - 1 blocks from other replicas, we concatenate the
		blocks along `concat_dimension` as the output.
		
		For example, suppose there are 2 TPU replicas:
		replica 0 receives input: `[[A, B]]`
		replica 1 receives input: `[[C, D]]`
		
		group_assignment=`[[0, 1]]`
		concat_dimension=0
		split_dimension=1
		split_count=2
		
		replica 0's output: `[[A], [C]]`
		replica 1's output: `[[B], [D]]`
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`, `bool`.
		    The local input to the sum.
		  group_assignment: A `Tensor` of type `int32`. An int32 tensor with shape
		    [num_groups, num_replicas_per_group]. `group_assignment[i]` represents the
		    replica ids in the ith subgroup.
		  concat_dimension: An `int`. The dimension number to concatenate.
		  split_dimension: An `int`. The dimension number to split.
		  split_count: An `int`.
		    The number of splits, this number must equal to the sub-group
		    size(group_assignment.get_shape()[1])
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function AllToAll(input:Dynamic, group_assignment:Dynamic, concat_dimension:Dynamic, split_dimension:Dynamic, split_count:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the argument of a complex number.
		
		Given a tensor `input` of complex numbers, this operation returns a tensor of
		type `float` that is the argument of each element in `input`. All elements in
		`input` must be complex numbers of the form \\(a + bj\\), where *a*
		is the real part and *b* is the imaginary part.
		
		The argument returned by this operation is of the form \\(atan2(b, a)\\).
		
		For example:
		
		```
		# tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
		tf.angle(input) ==> [2.0132, 1.056]
		```
		
		@compatibility(numpy)
		Equivalent to np.angle.
		@end_compatibility
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		  Tout: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Tout`.
	**/
	static public function Angle(input:Dynamic, ?Tout:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a uninitialized anonymous hash table.
		
		This op creates a new anonymous hash table (as a resource) everytime
		it is executed, with the specified dtype of its keys and values,
		returning the resource handle.  Before using the table you will have
		to initialize it.  After initialization the table will be
		immutable. The table is anonymous in the sense that it can only be
		accessed by the returned resource handle (e.g. it cannot be looked up
		by a name in a resource manager). The table will be automatically
		deleted when all resource handles pointing to it are gone.
		
		Args:
		  key_dtype: A `tf.DType`. Type of the table keys.
		  value_dtype: A `tf.DType`. Type of the table values.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function AnonymousHashTable(key_dtype:Dynamic, value_dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A container for an iterator resource.
		
		Args:
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function AnonymousIterator(output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A container for an iterator resource.
		
		Args:
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (handle, deleter).
		
		  handle: A `Tensor` of type `resource`.
		  deleter: A `Tensor` of type `variant`.
	**/
	static public function AnonymousIteratorV2(output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (handle, deleter).
		
		  handle: A `Tensor` of type `resource`.
		  deleter: A `Tensor` of type `variant`.
	**/
	static public function AnonymousMemoryCache(?name:Dynamic):Dynamic;
	/**
		A container for a multi device iterator resource.
		
		Args:
		  devices: A list of `strings` that has length `>= 1`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (handle, deleter).
		
		  handle: A `Tensor` of type `resource`.
		  deleter: A `Tensor` of type `variant`.
	**/
	static public function AnonymousMultiDeviceIterator(devices:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  seed: A `Tensor` of type `int64`.
		  seed2: A `Tensor` of type `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (handle, deleter).
		
		  handle: A `Tensor` of type `resource`.
		  deleter: A `Tensor` of type `variant`.
	**/
	static public function AnonymousRandomSeedGenerator(seed:Dynamic, seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  seed: A `Tensor` of type `int64`.
		  seed2: A `Tensor` of type `int64`.
		  reshuffle: A `Tensor` of type `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (handle, deleter).
		
		  handle: A `Tensor` of type `resource`.
		  deleter: A `Tensor` of type `variant`.
	**/
	static public function AnonymousSeedGenerator(seed:Dynamic, seed2:Dynamic, reshuffle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the "logical or" of elements across dimensions of a tensor.
		
		Reduces `input` along the dimensions given in `axis`. Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`axis`. If `keep_dims` is true, the reduced dimensions are
		retained with length 1.
		
		Args:
		  input: A `Tensor` of type `bool`. The tensor to reduce.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The dimensions to reduce. Must be in the range
		    `[-rank(input), rank(input))`.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function Any(input:Dynamic, axis:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the AdaMax algorithm.
		
		m_t <- beta1 * m_{t-1} + (1 - beta1) * g
		v_t <- max(beta2 * v_{t-1}, abs(g))
		variable <- variable - learning_rate / (1 - beta1^t) * m_t / (v_t + epsilon)
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  m: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  v: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  beta1_power: A `Tensor`. Must have the same type as `var`.
		    Must be a scalar.
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  beta1: A `Tensor`. Must have the same type as `var`.
		    Momentum factor. Must be a scalar.
		  beta2: A `Tensor`. Must have the same type as `var`.
		    Momentum factor. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `var`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, m, and v tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyAdaMax(_var:Dynamic, m:Dynamic, v:Dynamic, beta1_power:Dynamic, lr:Dynamic, beta1:Dynamic, beta2:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the adadelta scheme.
		
		accum = rho() * accum + (1 - rho()) * grad.square();
		update = (update_accum + epsilon).sqrt() * (accum + epsilon()).rsqrt() * grad;
		update_accum = rho() * update_accum + (1 - rho()) * update.square();
		var -= update;
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  accum_update: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `var`.
		    Decay factor. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `var`.
		    Constant factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var, accum and update_accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyAdadelta(_var:Dynamic, accum:Dynamic, accum_update:Dynamic, lr:Dynamic, rho:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the adagrad scheme.
		
		accum += grad * grad
		var -= lr * grad * (1 / sqrt(accum))
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  update_slots: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyAdagrad(_var:Dynamic, accum:Dynamic, lr:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?update_slots:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the proximal adagrad scheme.
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  gradient_accumulator: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  gradient_squared_accumulator: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `var`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `var`.
		    L2 regularization. Must be a scalar.
		  global_step: A `Tensor` of type `int64`.
		    Training step number. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var and accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyAdagradDA(_var:Dynamic, gradient_accumulator:Dynamic, gradient_squared_accumulator:Dynamic, grad:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, global_step:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the adagrad scheme.
		
		accum += grad * grad
		var -= lr * grad * (1 / sqrt(accum))
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `var`.
		    Constant factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  update_slots: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyAdagradV2(_var:Dynamic, accum:Dynamic, lr:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?update_slots:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the Adam algorithm.
		
		$$\text{lr}_t := \mathrm{lr} \cdot \frac{\sqrt{1 - \beta_2^t}}{1 - \beta_1^t}$$
		$$m_t := \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g$$
		$$v_t := \beta_2 \cdot v_{t-1} + (1 - \beta_2) \cdot g^2$$
		$$\text{var} := \begin{cases} \text{var} - (m_t \beta_1 + g \cdot (1 - \beta_1))\cdot\text{lr}_t/(\sqrt{v_t} + \epsilon), &\text{if use_nesterov}\\\\  \text{var} - m_t \cdot \text{lr}_t /(\sqrt{v_t} + \epsilon), &\text{otherwise} \end{cases}$$
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  m: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  v: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  beta1_power: A `Tensor`. Must have the same type as `var`.
		    Must be a scalar.
		  beta2_power: A `Tensor`. Must have the same type as `var`.
		    Must be a scalar.
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  beta1: A `Tensor`. Must have the same type as `var`.
		    Momentum factor. Must be a scalar.
		  beta2: A `Tensor`. Must have the same type as `var`.
		    Momentum factor. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `var`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, m, and v tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  use_nesterov: An optional `bool`. Defaults to `False`.
		    If `True`, uses the nesterov update.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyAdam(_var:Dynamic, m:Dynamic, v:Dynamic, beta1_power:Dynamic, beta2_power:Dynamic, lr:Dynamic, beta1:Dynamic, beta2:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?use_nesterov:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the AddSign update.
		
		m_t <- beta1 * m_{t-1} + (1 - beta1) * g
		update <- (alpha + sign_decay * sign(g) *sign(m)) * g
		variable <- variable - lr_t * update
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  m: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  alpha: A `Tensor`. Must have the same type as `var`. Must be a scalar.
		  sign_decay: A `Tensor`. Must have the same type as `var`.
		    Must be a scalar.
		  beta: A `Tensor`. Must have the same type as `var`. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and m tensors is
		    protected by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyAddSign(_var:Dynamic, m:Dynamic, lr:Dynamic, alpha:Dynamic, sign_decay:Dynamic, beta:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the centered RMSProp algorithm.
		
		The centered RMSProp algorithm uses an estimate of the centered second moment
		(i.e., the variance) for normalization, as opposed to regular RMSProp, which
		uses the (uncentered) second moment. This often helps with training, but is
		slightly more expensive in terms of computation and memory.
		
		Note that in dense implementation of this algorithm, mg, ms, and mom will
		update even if the grad is zero, but in this sparse implementation, mg, ms,
		and mom will not update in iterations during which the grad is zero.
		
		mean_square = decay * mean_square + (1-decay) * gradient ** 2
		mean_grad = decay * mean_grad + (1-decay) * gradient
		
		Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
		
		mg <- rho * mg_{t-1} + (1-rho) * grad
		ms <- rho * ms_{t-1} + (1-rho) * grad * grad
		mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms - mg * mg + epsilon)
		var <- var - mom
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  mg: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  ms: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  mom: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `var`.
		    Decay rate. Must be a scalar.
		  momentum: A `Tensor`. Must have the same type as `var`.
		    Momentum Scale. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `var`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, mg, ms, and mom tensors is
		    protected by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyCenteredRMSProp(_var:Dynamic, mg:Dynamic, ms:Dynamic, mom:Dynamic, lr:Dynamic, rho:Dynamic, momentum:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the Ftrl-proximal scheme.
		
		accum_new = accum + grad * grad
		linear += grad - (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
		quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
		var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
		accum = accum_new
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  linear: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `var`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `var`.
		    L2 regularization. Must be a scalar.
		  lr_power: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  multiply_linear_by_lr: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyFtrl(_var:Dynamic, accum:Dynamic, linear:Dynamic, grad:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, lr_power:Dynamic, ?use_locking:Dynamic, ?multiply_linear_by_lr:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the Ftrl-proximal scheme.
		
		grad_with_shrinkage = grad + 2 * l2_shrinkage * var
		accum_new = accum + grad * grad
		linear += grad_with_shrinkage -
		    (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
		quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
		var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
		accum = accum_new
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  linear: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `var`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `var`.
		    L2 shrinkage regularization. Must be a scalar.
		  l2_shrinkage: A `Tensor`. Must have the same type as `var`.
		  lr_power: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  multiply_linear_by_lr: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyFtrlV2(_var:Dynamic, accum:Dynamic, linear:Dynamic, grad:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, l2_shrinkage:Dynamic, lr_power:Dynamic, ?use_locking:Dynamic, ?multiply_linear_by_lr:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' by subtracting 'alpha' * 'delta' from it.
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  alpha: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  delta: A `Tensor`. Must have the same type as `var`. The change.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, the subtraction will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyGradientDescent(_var:Dynamic, alpha:Dynamic, delta:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the momentum scheme.
		
		Set use_nesterov = True if you want to use Nesterov momentum.
		
		accum = accum * momentum + grad
		var -= lr * accum
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  momentum: A `Tensor`. Must have the same type as `var`.
		    Momentum. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  use_nesterov: An optional `bool`. Defaults to `False`.
		    If `True`, the tensor passed to compute grad will be
		    var - lr * momentum * accum, so in the end, the var you get is actually
		    var - lr * momentum * accum.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyMomentum(_var:Dynamic, accum:Dynamic, lr:Dynamic, grad:Dynamic, momentum:Dynamic, ?use_locking:Dynamic, ?use_nesterov:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the AddSign update.
		
		m_t <- beta1 * m_{t-1} + (1 - beta1) * g
		update <- exp(logbase * sign_decay * sign(g) * sign(m_t)) * g
		variable <- variable - lr_t * update
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  m: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  logbase: A `Tensor`. Must have the same type as `var`. Must be a scalar.
		  sign_decay: A `Tensor`. Must have the same type as `var`.
		    Must be a scalar.
		  beta: A `Tensor`. Must have the same type as `var`. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and m tensors is
		    protected by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyPowerSign(_var:Dynamic, m:Dynamic, lr:Dynamic, logbase:Dynamic, sign_decay:Dynamic, beta:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' and '*accum' according to FOBOS with Adagrad learning rate.
		
		accum += grad * grad
		prox_v = var - lr * grad * (1 / sqrt(accum))
		var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `var`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `var`.
		    L2 regularization. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var and accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyProximalAdagrad(_var:Dynamic, accum:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' as FOBOS algorithm with fixed learning rate.
		
		prox_v = var - alpha * delta
		var = sign(prox_v)/(1+alpha*l2) * max{|prox_v|-alpha*l1,0}
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  alpha: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `var`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `var`.
		    L2 regularization. Must be a scalar.
		  delta: A `Tensor`. Must have the same type as `var`. The change.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the subtraction will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyProximalGradientDescent(_var:Dynamic, alpha:Dynamic, l1:Dynamic, l2:Dynamic, delta:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the RMSProp algorithm.
		
		Note that in dense implementation of this algorithm, ms and mom will
		update even if the grad is zero, but in this sparse implementation, ms
		and mom will not update in iterations during which the grad is zero.
		
		mean_square = decay * mean_square + (1-decay) * gradient ** 2
		Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
		
		ms <- rho * ms_{t-1} + (1-rho) * grad * grad
		mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
		var <- var - mom
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  ms: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  mom: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `var`.
		    Decay rate. Must be a scalar.
		  momentum: A `Tensor`. Must have the same type as `var`.
		  epsilon: A `Tensor`. Must have the same type as `var`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, ms, and mom tensors is protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function ApplyRMSProp(_var:Dynamic, ms:Dynamic, mom:Dynamic, lr:Dynamic, rho:Dynamic, momentum:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of abs(x-y) < tolerance element-wise.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  tolerance: An optional `float`. Defaults to `1e-05`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function ApproximateEqual(x:Dynamic, y:Dynamic, ?tolerance:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the index with the largest value across dimensions of a tensor.
		
		Note that in case of ties the identity of the return value is not guaranteed.
		
		Usage:
		  ```python
		  import tensorflow as tf
		  a = [1, 10, 26.9, 2.8, 166.32, 62.3]
		  b = tf.math.argmax(input = a)
		  c = tf.keras.backend.eval(b)
		  # c = 4
		  # here a[4] = 166.32 which is the largest element of a across axis 0
		  ```
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`, `bool`.
		  dimension: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    int32 or int64, must be in the range `[-rank(input), rank(input))`.
		    Describes which dimension of the input Tensor to reduce across. For vectors,
		    use dimension = 0.
		  output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `output_type`.
	**/
	static public function ArgMax(input:Dynamic, dimension:Dynamic, ?output_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the index with the smallest value across dimensions of a tensor.
		
		Note that in case of ties the identity of the return value is not guaranteed.
		
		Usage:
		  ```python
		  import tensorflow as tf
		  a = [1, 10, 26.9, 2.8, 166.32, 62.3]
		  b = tf.math.argmin(input = a)
		  c = tf.keras.backend.eval(b)
		  # c = 0
		  # here a[0] = 1 which is the smallest element of a across axis 0
		  ```
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`, `bool`.
		  dimension: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    int32 or int64, must be in the range `[-rank(input), rank(input))`.
		    Describes which dimension of the input Tensor to reduce across. For vectors,
		    use dimension = 0.
		  output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `output_type`.
	**/
	static public function ArgMin(input:Dynamic, dimension:Dynamic, ?output_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts each entry in the given tensor to strings.
		
		Supports many numeric types and boolean.
		
		For Unicode, see the
		[https://www.tensorflow.org/tutorials/representation/unicode](Working with Unicode text)
		tutorial.
		
		Examples:
		
		>>> tf.strings.as_string([3, 2])
		<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'3', b'2'], dtype=object)>
		>>> tf.strings.as_string([3.1415926, 2.71828], precision=2).numpy()
		array([b'3.14', b'2.72'], dtype=object)
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `complex64`, `complex128`, `bool`, `variant`.
		  precision: An optional `int`. Defaults to `-1`.
		    The post-decimal precision to use for floating point numbers.
		    Only used if precision > -1.
		  scientific: An optional `bool`. Defaults to `False`.
		    Use scientific notation for floating point numbers.
		  shortest: An optional `bool`. Defaults to `False`.
		    Use shortest representation (either scientific or standard) for
		    floating point numbers.
		  width: An optional `int`. Defaults to `-1`.
		    Pad pre-decimal numbers to this width.
		    Applies to both floating point and integer numbers.
		    Only used if width > -1.
		  fill: An optional `string`. Defaults to `""`.
		    The value to pad if width > -1.  If empty, pads with spaces.
		    Another typical value is '0'.  String cannot be longer than 1 character.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function AsString(input:Dynamic, ?precision:Dynamic, ?scientific:Dynamic, ?shortest:Dynamic, ?width:Dynamic, ?fill:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the trignometric inverse sine of x element-wise.
		
		The `tf.math.asin` operation returns the inverse of `tf.math.sin`, such that
		if `y = tf.math.sin(x)` then, `x = tf.math.asin(y)`.
		
		**Note**: The output of `tf.math.asin` will lie within the invertible range
		of sine, i.e [-pi/2, pi/2].
		
		For example:
		
		```python
		# Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]
		x = tf.constant([1.047, 0.785])
		y = tf.math.sin(x) # [0.8659266, 0.7068252]
		
		tf.math.asin(y) # [1.047, 0.785] = x
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Asin(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes inverse hyperbolic sine of x element-wise.
		
		  Given an input tensor, this function computes inverse hyperbolic sine
		  for every element in the tensor. Both input and output has a range of
		  `[-inf, inf]`.
		
		  ```python
		  x = tf.constant([-float("inf"), -2, -0.5, 1, 1.2, 200, 10000, float("inf")])
		  tf.math.asinh(x) ==> [-inf -1.4436355 -0.4812118 0.8813736 1.0159732 5.991471 9.903487 inf]
		  ```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Asinh(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Asserts that the given condition is true.
		
		If `condition` evaluates to false, print the list of tensors in `data`.
		`summarize` determines how many entries of the tensors to print.
		
		Args:
		  condition: A `Tensor` of type `bool`. The condition to evaluate.
		  data: A list of `Tensor` objects.
		    The tensors to print out when condition is false.
		  summarize: An optional `int`. Defaults to `3`.
		    Print this many entries of each tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function Assert(condition:Dynamic, data:Dynamic, ?summarize:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  cardinality: A `Tensor` of type `int64`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function AssertCardinalityDataset(input_dataset:Dynamic, cardinality:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A transformation that asserts which transformations happen next.
		
		This transformation checks whether the camel-case names (i.e. "FlatMap", not
		"flat_map") of the transformations following this transformation match the list
		of names in the `transformations` argument. If there is a mismatch, the
		transformation raises an exception.
		
		The check occurs when iterating over the contents of the dataset, which
		means that the check happens *after* any static optimizations are applied
		to the dataset graph.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		    `AssertNextDataset` passes through the outputs of its input dataset.
		  transformations: A `Tensor` of type `string`.
		    A `tf.string` vector `tf.Tensor` identifying the transformations that are
		    expected to happen next.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function AssertNextDataset(input_dataset:Dynamic, transformations:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update 'ref' by assigning 'value' to it.
		
		This operation outputs "ref" after the assignment is done.
		This makes it easier to chain operations that need to use the reset value.
		
		Args:
		  ref: A mutable `Tensor`.
		    Should be from a `Variable` node. May be uninitialized.
		  value: A `Tensor`. Must have the same type as `ref`.
		    The value to be assigned to the variable.
		  validate_shape: An optional `bool`. Defaults to `True`.
		    If true, the operation will validate that the shape
		    of 'value' matches the shape of the Tensor being assigned to.  If false,
		    'ref' will take on the shape of 'value'.
		  use_locking: An optional `bool`. Defaults to `True`.
		    If True, the assignment will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function Assign(ref:Dynamic, value:Dynamic, ?validate_shape:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update 'ref' by adding 'value' to it.
		
		This operation outputs "ref" after the update is done.
		This makes it easier to chain operations that need to use the reset value.
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a `Variable` node.
		  value: A `Tensor`. Must have the same type as `ref`.
		    The value to be added to the variable.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the addition will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function AssignAdd(ref:Dynamic, value:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adds a value to the current value of a variable.
		
		Any ReadVariableOp with a control dependency on this op is guaranteed to
		see the incremented value or a subsequent newer one.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    handle to the resource in which to store the variable.
		  value: A `Tensor`. the value by which the variable will be incremented.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function AssignAddVariableOp(resource:Dynamic, value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update 'ref' by subtracting 'value' from it.
		
		This operation outputs "ref" after the update is done.
		This makes it easier to chain operations that need to use the reset value.
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a `Variable` node.
		  value: A `Tensor`. Must have the same type as `ref`.
		    The value to be subtracted to the variable.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the subtraction will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function AssignSub(ref:Dynamic, value:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Subtracts a value from the current value of a variable.
		
		Any ReadVariableOp with a control dependency on this op is guaranteed to
		see the decremented value or a subsequent newer one.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    handle to the resource in which to store the variable.
		  value: A `Tensor`. the value by which the variable will be incremented.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function AssignSubVariableOp(resource:Dynamic, value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Assigns a new value to a variable.
		
		Any ReadVariableOp with a control dependency on this op is guaranteed to return
		this value or a subsequent newer value of the variable.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    handle to the resource in which to store the variable.
		  value: A `Tensor`. the value to set the new tensor to use.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function AssignVariableOp(resource:Dynamic, value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Concats input tensor across all dimensions.
		
		An op which merges slices the input tensor based on the given num_splits
		attribute, strips paddings optionally, and writes the merged tensor without
		paddings to the resource variable.
		
		This op may be generated via the TPU bridge.
		
		For example, with `input` tensor:
		```
		[[0, 1],
		 [4, 5]]
		[[2, 3],
		 [6, 7]]
		[[8, 9],
		 [12, 13]]
		[[10, 11],
		 [14, 15]]
		```
		`num_splits`:
		```
		[2, 2]
		```
		and `paddings`:
		```
		[1, 1]
		```
		the expected `outputs` is:
		```
		[[0, 1, 2],
		 [4, 5, 6],
		 [8, 9, 10]]
		```
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    Resource variable for concatenated input tensors across all dimensions.
		      }
		      in_arg {
		        name: "inputs"
		        description: <<END
		    Input tensor slices in row-major order to merge across all dimensions. All
		    inputs must have the same shape.
		      }
		      out_arg {
		        name: "output"
		        description: <<END
		    Output tensor formed from merging input slices based on num_concats defined.
		  inputs: A list of at least 1 `Tensor` objects with the same type.
		  num_concats: A list of `ints`. Number of ways to merge per dimension.
		  paddings: An optional list of `ints`. Defaults to `[]`.
		    Optional list of right paddings per dimension to strip from the final merged
		    tensor. These paddings must not exceed the dimension size of the merged result
		    prior to stripping paddings.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function AssignVariableXlaConcatND(resource:Dynamic, inputs:Dynamic, num_concats:Dynamic, ?paddings:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the trignometric inverse tangent of x element-wise.
		
		The `tf.math.atan` operation returns the inverse of `tf.math.tan`, such that
		if `y = tf.math.tan(x)` then, `x = tf.math.atan(y)`.
		
		**Note**: The output of `tf.math.atan` will lie within the invertible range
		of tan, i.e (-pi/2, pi/2).
		
		For example:
		
		```python
		# Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]
		x = tf.constant([1.047, 0.785])
		y = tf.math.tan(x) # [1.731261, 0.99920404]
		
		tf.math.atan(y) # [1.047, 0.785] = x
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Atan(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes arctangent of `y/x` element-wise, respecting signs of the arguments.
		
		This is the angle \\( \theta \in [-\pi, \pi] \\) such that
		\\[ x = r \cos(\theta) \\]
		and
		\\[ y = r \sin(\theta) \\]
		where \\(r = \sqrt{x^2 + y^2} \\).
		
		For example:
		
		>>> x = [1., 1.]
		>>> y = [1., -1.]
		>>> print((tf.math.atan2(y,x) * (180 / np.pi)).numpy())
		[ 45. -45.]
		
		Args:
		  y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  x: A `Tensor`. Must have the same type as `y`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `y`.
	**/
	static public function Atan2(y:Dynamic, x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes inverse hyperbolic tangent of x element-wise.
		
		  Given an input tensor, this function computes inverse hyperbolic tangent
		  for every element in the tensor. Input range is `[-1,1]` and output range is
		  `[-inf, inf]`. If input is `-1`, output will be `-inf` and if the
		  input is `1`, output will be `inf`. Values outside the range will have
		  `nan` as output.
		
		  ```python
		  x = tf.constant([-float("inf"), -1, -0.5, 1, 0, 0.5, 10, float("inf")])
		  tf.math.atanh(x) ==> [nan -inf -0.54930615 inf  0. 0.54930615 nan nan]
		  ```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Atanh(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Produces a visualization of audio data over time.
		
		Spectrograms are a standard way of representing audio information as a series of
		slices of frequency information, one slice for each window of time. By joining
		these together into a sequence, they form a distinctive fingerprint of the sound
		over time.
		
		This op expects to receive audio data as an input, stored as floats in the range
		-1 to 1, together with a window width in samples, and a stride specifying how
		far to move the window between slices. From this it generates a three
		dimensional output. The first dimension is for the channels in the input, so a
		stereo audio input would have two here for example. The second dimension is time,
		with successive frequency slices. The third dimension has an amplitude value for
		each frequency during that time slice.
		
		This means the layout when converted and saved as an image is rotated 90 degrees
		clockwise from a typical spectrogram. Time is descending down the Y axis, and
		the frequency decreases from left to right.
		
		Each value in the result represents the square root of the sum of the real and
		imaginary parts of an FFT on the current window of samples. In this way, the
		lowest dimension represents the power of each frequency in the current window,
		and adjacent windows are concatenated in the next dimension.
		
		To get a more intuitive and visual look at what this operation does, you can run
		tensorflow/examples/wav_to_spectrogram to read in an audio file and save out the
		resulting spectrogram as a PNG image.
		
		Args:
		  input: A `Tensor` of type `float32`. Float representation of audio data.
		  window_size: An `int`.
		    How wide the input window is in samples. For the highest efficiency
		    this should be a power of two, but other values are accepted.
		  stride: An `int`.
		    How widely apart the center of adjacent sample windows should be.
		  magnitude_squared: An optional `bool`. Defaults to `False`.
		    Whether to return the squared magnitude or just the
		    magnitude. Using squared magnitude can avoid extra calculations.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function AudioSpectrogram(input:Dynamic, window_size:Dynamic, stride:Dynamic, ?magnitude_squared:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs a `Summary` protocol buffer with audio.
		
		The summary has up to `max_outputs` summary values containing audio. The
		audio is built from `tensor` which must be 3-D with shape `[batch_size,
		frames, channels]` or 2-D with shape `[batch_size, frames]`. The values are
		assumed to be in the range of `[-1.0, 1.0]` with a sample rate of `sample_rate`.
		
		The `tag` argument is a scalar `Tensor` of type `string`.  It is used to
		build the `tag` of the summary values:
		
		*  If `max_outputs` is 1, the summary value tag is '*tag* /audio'.
		*  If `max_outputs` is greater than 1, the summary value tags are
		   generated sequentially as '*tag* /audio/0', '*tag* /audio/1', etc.
		
		Args:
		  tag: A `Tensor` of type `string`.
		    Scalar. Used to build the `tag` attribute of the summary values.
		  tensor: A `Tensor` of type `float32`. 2-D of shape `[batch_size, frames]`.
		  sample_rate: A `float`. The sample rate of the signal in hertz.
		  max_outputs: An optional `int` that is `>= 1`. Defaults to `3`.
		    Max number of batch elements to generate audio for.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function AudioSummary(tag:Dynamic, tensor:Dynamic, sample_rate:Dynamic, ?max_outputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs a `Summary` protocol buffer with audio.
		
		The summary has up to `max_outputs` summary values containing audio. The
		audio is built from `tensor` which must be 3-D with shape `[batch_size,
		frames, channels]` or 2-D with shape `[batch_size, frames]`. The values are
		assumed to be in the range of `[-1.0, 1.0]` with a sample rate of `sample_rate`.
		
		The `tag` argument is a scalar `Tensor` of type `string`.  It is used to
		build the `tag` of the summary values:
		
		*  If `max_outputs` is 1, the summary value tag is '*tag* /audio'.
		*  If `max_outputs` is greater than 1, the summary value tags are
		   generated sequentially as '*tag* /audio/0', '*tag* /audio/1', etc.
		
		Args:
		  tag: A `Tensor` of type `string`.
		    Scalar. Used to build the `tag` attribute of the summary values.
		  tensor: A `Tensor` of type `float32`. 2-D of shape `[batch_size, frames]`.
		  sample_rate: A `Tensor` of type `float32`.
		    The sample rate of the signal in hertz.
		  max_outputs: An optional `int` that is `>= 1`. Defaults to `3`.
		    Max number of batch elements to generate audio for.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function AudioSummaryV2(tag:Dynamic, tensor:Dynamic, sample_rate:Dynamic, ?max_outputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that shards the input dataset.
		
		Creates a dataset that shards the input dataset by num_workers, returning a
		sharded dataset for the index-th worker. This attempts to automatically shard
		a dataset by examining the Dataset graph and inserting a shard op before the
		inputs to a reader Dataset (e.g. CSVDataset, TFRecordDataset).
		
		This dataset will throw a NotFound error if we cannot shard the dataset
		automatically.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  num_workers: A `Tensor` of type `int64`.
		    A scalar representing the number of workers to distribute this dataset across.
		  index: A `Tensor` of type `int64`.
		    A scalar representing the index of the current worker out of num_workers.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  auto_shard_policy: An optional `int`. Defaults to `0`.
		  num_replicas: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function AutoShardDataset(input_dataset:Dynamic, num_workers:Dynamic, index:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?auto_shard_policy:Dynamic, ?num_replicas:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs average pooling on the input.
		
		Each entry in `output` is the mean of the corresponding size `ksize`
		window in `value`.
		
		Args:
		  value: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    4-D with shape `[batch, height, width, channels]`.
		  ksize: A list of `ints` that has length `>= 4`.
		    The size of the sliding window for each dimension of `value`.
		  strides: A list of `ints` that has length `>= 4`.
		    The stride of the sliding window for each dimension of `value`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `value`.
	**/
	static public function AvgPool(value:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs 3D average pooling on the input.
		
		Each entry in `output` is the mean of the corresponding size `ksize` window in
		`value`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    Shape `[batch, depth, rows, cols, channels]` tensor to pool over.
		  ksize: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The size of the window for each dimension of
		    the input tensor. Must have `ksize[0] = ksize[4] = 1`.
		  strides: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The stride of the sliding window for each
		    dimension of `input`. Must have `strides[0] = strides[4] = 1`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
		    The data format of the input and output data. With the
		    default format "NDHWC", the data is stored in the order of:
		        [batch, in_depth, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCDHW", the data storage order is:
		        [batch, in_channels, in_depth, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function AvgPool3D(input:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradients of average pooling function.
		
		Args:
		  orig_input_shape: A `Tensor` of type `int32`.
		    The original input dimensions.
		  grad: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    Output backprop of shape `[batch, depth, rows, cols, channels]`.
		  ksize: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The size of the window for each dimension of
		    the input tensor. Must have `ksize[0] = ksize[4] = 1`.
		  strides: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The stride of the sliding window for each
		    dimension of `input`. Must have `strides[0] = strides[4] = 1`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
		    The data format of the input and output data. With the
		    default format "NDHWC", the data is stored in the order of:
		        [batch, in_depth, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCDHW", the data storage order is:
		        [batch, in_channels, in_depth, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `grad`.
	**/
	static public function AvgPool3DGrad(orig_input_shape:Dynamic, grad:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradients of the average pooling function.
		
		Args:
		  orig_input_shape: A `Tensor` of type `int32`.
		    1-D.  Shape of the original input to `avg_pool`.
		  grad: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    4-D with shape `[batch, height, width, channels]`.  Gradients w.r.t.
		    the output of `avg_pool`.
		  ksize: A list of `ints` that has length `>= 4`.
		    The size of the sliding window for each dimension of the input.
		  strides: A list of `ints` that has length `>= 4`.
		    The stride of the sliding window for each dimension of the input.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `grad`.
	**/
	static public function AvgPoolGrad(orig_input_shape:Dynamic, grad:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  matrix: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		  rhs: A `Tensor`. Must have the same type as `matrix`.
		  lower: An optional `bool`. Defaults to `True`.
		  adjoint: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `matrix`.
	**/
	static public function BandedTriangularSolve(matrix:Dynamic, rhs:Dynamic, ?lower:Dynamic, ?adjoint:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Defines a barrier that persists across different graph executions.
		
		A barrier represents a key-value map, where each key is a string, and
		each value is a tuple of tensors.
		
		At runtime, the barrier contains 'complete' and 'incomplete'
		elements. A complete element has defined tensors for all components of
		its value tuple, and may be accessed using BarrierTakeMany. An
		incomplete element has some undefined components in its value tuple,
		and may be updated using BarrierInsertMany.
		
		Args:
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a value.
		  shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    The shape of each component in a value. Each shape must be 1 in the
		    first dimension. The length of this attr must be the same as the length of
		    component_types.
		  capacity: An optional `int`. Defaults to `-1`.
		    The capacity of the barrier.  The default capacity is MAX_INT32,
		    which is the largest capacity of the underlying queue.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this barrier is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this barrier will be shared under the given name
		    across multiple sessions.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function Barrier(component_types:Dynamic, ?shapes:Dynamic, ?capacity:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Closes the given barrier.
		
		This operation signals that no more new elements will be inserted in the
		given barrier. Subsequent InsertMany that try to introduce a new key will fail.
		Subsequent InsertMany operations that just add missing components to already
		existing elements will continue to succeed. Subsequent TakeMany operations will
		continue to succeed if sufficient completed elements remain in the barrier.
		Subsequent TakeMany operations that would block will fail immediately.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a barrier.
		  cancel_pending_enqueues: An optional `bool`. Defaults to `False`.
		    If true, all pending enqueue requests that are
		    blocked on the barrier's queue will be canceled. InsertMany will fail, even
		    if no new key is introduced.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function BarrierClose(handle:Dynamic, ?cancel_pending_enqueues:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the number of incomplete elements in the given barrier.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a barrier.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function BarrierIncompleteSize(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		For each key, assigns the respective value to the specified component.
		
		If a key is not found in the barrier, this operation will create a new
		incomplete element. If a key is found in the barrier, and the element
		already has a value at component_index, this operation will fail with
		INVALID_ARGUMENT, and leave the barrier in an undefined state.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a barrier.
		  keys: A `Tensor` of type `string`.
		    A one-dimensional tensor of keys, with length n.
		  values: A `Tensor`.
		    An any-dimensional tensor of values, which are associated with the
		    respective keys. The 0th dimension must have length n.
		  component_index: An `int`.
		    The component of the barrier elements that is being assigned.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function BarrierInsertMany(handle:Dynamic, keys:Dynamic, values:Dynamic, component_index:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the number of complete elements in the given barrier.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a barrier.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function BarrierReadySize(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Takes the given number of completed elements from a barrier.
		
		This operation concatenates completed-element component tensors along
		the 0th dimension to make a single component tensor.
		
		Elements come out of the barrier when they are complete, and in the order
		in which they were placed into the barrier.  The indices output provides
		information about the batch in which each element was originally inserted
		into the barrier.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a barrier.
		  num_elements: A `Tensor` of type `int32`.
		    A single-element tensor containing the number of elements to
		    take.
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a value.
		  allow_small_batch: An optional `bool`. Defaults to `False`.
		    Allow to return less than num_elements items if barrier is
		    already closed.
		  wait_for_incomplete: An optional `bool`. Defaults to `False`.
		  timeout_ms: An optional `int`. Defaults to `-1`.
		    If the queue is empty, this operation will block for up to
		    timeout_ms milliseconds.
		    Note: This option is not supported yet.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (indices, keys, values).
		
		  indices: A `Tensor` of type `int64`.
		  keys: A `Tensor` of type `string`.
		  values: A list of `Tensor` objects of type `component_types`.
	**/
	static public function BarrierTakeMany(handle:Dynamic, num_elements:Dynamic, component_types:Dynamic, ?allow_small_batch:Dynamic, ?wait_for_incomplete:Dynamic, ?timeout_ms:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Batches all input tensors nondeterministically.
		
		When many instances of this Op are being run concurrently with the same
		container/shared_name in the same device, some will output zero-shaped Tensors
		and others will output Tensors of size up to max_batch_size.
		
		All Tensors in in_tensors are batched together (so, for example, labels and
		features should be batched with a single instance of this operation.
		
		Each invocation of batch emits an `id` scalar which will be used to identify
		this particular invocation when doing unbatch or its gradient.
		
		Each op which emits a non-empty batch will also emit a non-empty batch_index
		Tensor, which, is a [K, 3] matrix where each row contains the invocation's id,
		start, and length of elements of each set of Tensors present in batched_tensors.
		
		Batched tensors are concatenated along the first dimension, and all tensors in
		in_tensors must have the first dimension of the same size.
		
		in_tensors: The tensors to be batched.
		num_batch_threads: Number of scheduling threads for processing batches of work.
		 Determines the number of batches processed in parallel.
		max_batch_size: Batch sizes will never be bigger than this.
		batch_timeout_micros: Maximum number of microseconds to wait before outputting
		 an incomplete batch.
		allowed_batch_sizes: Optional list of allowed batch sizes. If left empty, does
		 nothing. Otherwise, supplies a list of batch sizes, causing the op to pad
		 batches up to one of those sizes. The entries must increase monotonically, and
		 the final entry must equal max_batch_size.
		grad_timeout_micros: The timeout to use for the gradient. See Unbatch.
		batched_tensors: Either empty tensors or a batch of concatenated Tensors.
		batch_index: If out_tensors is non-empty, has information to invert it.
		container: Controls the scope of sharing of this batch.
		id: always contains a scalar with a unique ID for this invocation of Batch.
		shared_name: Concurrently running instances of batch in the same device with the
		 same container and shared_name will batch their elements together. If left
		 empty, the op name will be used as the shared name.
		T: the types of tensors to be batched.
		
		Args:
		  in_tensors: A list of `Tensor` objects.
		  num_batch_threads: An `int`.
		  max_batch_size: An `int`.
		  batch_timeout_micros: An `int`.
		  grad_timeout_micros: An `int`.
		  max_enqueued_batches: An optional `int`. Defaults to `10`.
		  allowed_batch_sizes: An optional list of `ints`. Defaults to `[]`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  batching_queue: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (batched_tensors, batch_index, id).
		
		  batched_tensors: A list of `Tensor` objects. Has the same type as `in_tensors`.
		  batch_index: A `Tensor` of type `int64`.
		  id: A `Tensor` of type `int64`.
	**/
	static public function Batch(in_tensors:Dynamic, num_batch_threads:Dynamic, max_batch_size:Dynamic, batch_timeout_micros:Dynamic, grad_timeout_micros:Dynamic, ?max_enqueued_batches:Dynamic, ?allowed_batch_sizes:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?batching_queue:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function BatchCholesky(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  l: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		  grad: A `Tensor`. Must have the same type as `l`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `l`.
	**/
	static public function BatchCholeskyGrad(l:Dynamic, grad:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that batches `batch_size` elements from `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  batch_size: A `Tensor` of type `int64`.
		    A scalar representing the number of elements to accumulate in a
		    batch.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function BatchDataset(input_dataset:Dynamic, batch_size:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that batches `batch_size` elements from `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  batch_size: A `Tensor` of type `int64`.
		    A scalar representing the number of elements to accumulate in a batch.
		  drop_remainder: A `Tensor` of type `bool`.
		    A scalar representing whether the last batch should be dropped in case its size
		    is smaller than desired.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  parallel_copy: An optional `bool`. Defaults to `False`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function BatchDatasetV2(input_dataset:Dynamic, batch_size:Dynamic, drop_remainder:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?parallel_copy:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor` of type `complex64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `complex64`.
	**/
	static public function BatchFFT(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor` of type `complex64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `complex64`.
	**/
	static public function BatchFFT2D(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor` of type `complex64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `complex64`.
	**/
	static public function BatchFFT3D(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Batches all the inputs tensors to the computation done by the function.
		
		So, for example, in the following code
		
		  ```python
		
		  # This input will be captured.
		  y = tf.placeholder_with_default(1.0, shape=[])
		
		  @tf.Defun(tf.float32)
		  def computation(a):
		    return tf.matmul(a, a) + y
		
		  b = gen_batch_ops.batch_function(
		          f=computation
		          in_tensors=[a],
		          captured_tensors=computation.captured_inputs,
		          Tout=[o.type for o in computation.definition.signature.output_arg],
		          num_batch_threads=1,
		          max_batch_size=10,
		          batch_timeout_micros=100000,  # 100ms
		          allowed_batch_sizes=[3, 10],
		          batching_queue="")
		  ```
		
		If more than one session.run call is simultaneously trying to compute `b`
		the values of `a` will be gathered, non-deterministically concatenated
		along the first axis, and only one thread will run the computation.
		
		Assumes that all arguments of the function are Tensors which will be batched
		along their first dimension.
		
		Arguments that are captured, are not batched. The session.run call which does
		the concatenation, will use the values of the captured tensors available to it.
		Therefore, typical uses of captured tensors should involve values which remain
		unchanged across session.run calls. Inference is a good example of this.
		
		SparseTensor is not supported. The return value of the decorated function
		must be a Tensor or a list/tuple of Tensors.
		
		Args:
		  in_tensors: A list of `Tensor` objects. The tensors to be batched.
		  captured_tensors: A list of `Tensor` objects.
		    The tensors which are captured in the function, and don't need
		    to be batched.
		  f: A function decorated with @Defun.
		  num_batch_threads: An `int`.
		    Number of scheduling threads for processing batches of work.
		    Determines the number of batches processed in parallel.
		  max_batch_size: An `int`. Batch sizes will never be bigger than this.
		  batch_timeout_micros: An `int`.
		    Maximum number of microseconds to wait before outputting
		    an incomplete batch.
		  Tout: A list of `tf.DTypes` that has length `>= 1`.
		    the types of the output tensors.
		  max_enqueued_batches: An optional `int`. Defaults to `10`.
		    Maximum number of batches enqueued. Default: 10.
		  allowed_batch_sizes: An optional list of `ints`. Defaults to `[]`.
		    Optional list of allowed batch sizes. If left empty, does
		    nothing. Otherwise, supplies a list of batch sizes, causing the op to pad
		    batches up to one of those sizes. The entries must increase monotonically.
		    If enable_large_batch_splitting is false (i.e., large-input-split is not
		    enabled) the final entry must equal max_batch_size.
		  container: An optional `string`. Defaults to `""`.
		    Controls the scope of sharing of this batch.
		  shared_name: An optional `string`. Defaults to `""`.
		    Concurrently running instances of batch in the same device with the
		    same container and shared_name will batch their elements together. If left
		    empty, the op name will be used as the shared name.
		  batching_queue: An optional `string`. Defaults to `""`.
		  enable_large_batch_splitting: An optional `bool`. Defaults to `False`.
		    input with a large size (i.e., larger than the largest value of
		    `allowed_batch_sizes`) will be splitted into multiple batches with batch size.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function BatchFunction(in_tensors:Dynamic, captured_tensors:Dynamic, f:Dynamic, num_batch_threads:Dynamic, max_batch_size:Dynamic, batch_timeout_micros:Dynamic, Tout:Dynamic, ?max_enqueued_batches:Dynamic, ?allowed_batch_sizes:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?batching_queue:Dynamic, ?enable_large_batch_splitting:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor` of type `complex64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `complex64`.
	**/
	static public function BatchIFFT(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor` of type `complex64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `complex64`.
	**/
	static public function BatchIFFT2D(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor` of type `complex64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `complex64`.
	**/
	static public function BatchIFFT3D(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Multiplies slices of two tensors in batches.
		
		Multiplies all slices of `Tensor` `x` and `y` (each slice can be
		viewed as an element of a batch), and arranges the individual results
		in a single output tensor of the same batch size. Each of the
		individual slices can optionally be adjointed (to adjoint a matrix
		means to transpose and conjugate it) before multiplication by setting
		the `adj_x` or `adj_y` flag to `True`, which are by default `False`.
		
		The input tensors `x` and `y` are 2-D or higher with shape `[..., r_x, c_x]`
		and `[..., r_y, c_y]`.
		
		The output tensor is 2-D or higher with shape `[..., r_o, c_o]`, where:
		
		    r_o = c_x if adj_x else r_x
		    c_o = r_y if adj_y else c_y
		
		It is computed as:
		
		    output[..., :, :] = matrix(x[..., :, :]) * matrix(y[..., :, :])
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.
		    2-D or higher with shape `[..., r_x, c_x]`.
		  y: A `Tensor`. Must have the same type as `x`.
		    2-D or higher with shape `[..., r_y, c_y]`.
		  adj_x: An optional `bool`. Defaults to `False`.
		    If `True`, adjoint the slices of `x`. Defaults to `False`.
		  adj_y: An optional `bool`. Defaults to `False`.
		    If `True`, adjoint the slices of `y`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BatchMatMul(x:Dynamic, y:Dynamic, ?adj_x:Dynamic, ?adj_y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Multiplies slices of two tensors in batches.
		
		Multiplies all slices of `Tensor` `x` and `y` (each slice can be
		viewed as an element of a batch), and arranges the individual results
		in a single output tensor of the same batch size. Each of the
		individual slices can optionally be adjointed (to adjoint a matrix
		means to transpose and conjugate it) before multiplication by setting
		the `adj_x` or `adj_y` flag to `True`, which are by default `False`.
		
		The input tensors `x` and `y` are 2-D or higher with shape `[..., r_x, c_x]`
		and `[..., r_y, c_y]`.
		
		The output tensor is 2-D or higher with shape `[..., r_o, c_o]`, where:
		
		    r_o = c_x if adj_x else r_x
		    c_o = r_y if adj_y else c_y
		
		It is computed as:
		
		    output[..., :, :] = matrix(x[..., :, :]) * matrix(y[..., :, :])
		
		*NOTE*: `BatchMatMulV2` supports broadcasting in the batch dimensions. More
		about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		    2-D or higher with shape `[..., r_x, c_x]`.
		  y: A `Tensor`. Must have the same type as `x`.
		    2-D or higher with shape `[..., r_y, c_y]`.
		  adj_x: An optional `bool`. Defaults to `False`.
		    If `True`, adjoint the slices of `x`. Defaults to `False`.
		  adj_y: An optional `bool`. Defaults to `False`.
		    If `True`, adjoint the slices of `y`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BatchMatMulV2(x:Dynamic, y:Dynamic, ?adj_x:Dynamic, ?adj_y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Multiplies slices of two tensors in batches.
		
		Multiplies all slices of `Tensor` `x` and `y` (each slice can be
		viewed as an element of a batch), and arranges the individual results
		in a single output tensor of the same batch size. Each of the
		individual slices can optionally be adjointed (to adjoint a matrix
		means to transpose and conjugate it) before multiplication by setting
		the `adj_x` or `adj_y` flag to `True`, which are by default `False`.
		
		The input tensors `x` and `y` are 2-D or higher with shape `[..., r_x, c_x]`
		and `[..., r_y, c_y]`.
		
		The output tensor is 2-D or higher with shape `[..., r_o, c_o]`, where:
		
		    r_o = c_x if adj_x else r_x
		    c_o = r_y if adj_y else c_y
		
		It is computed as:
		
		    output[..., :, :] = matrix(x[..., :, :]) * matrix(y[..., :, :])
		
		*NOTE*: `BatchMatMulV3` supports broadcasting in the batch dimensions. More
		about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		    2-D or higher with shape `[..., r_x, c_x]`.
		  y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		    2-D or higher with shape `[..., r_y, c_y]`.
		  Tout: A `tf.DType` from: `tf.bfloat16, tf.half, tf.float32, tf.float64, tf.int16, tf.int32, tf.int64, tf.complex64, tf.complex128`.
		    If not spcified, Tout is the same type to input type.
		  adj_x: An optional `bool`. Defaults to `False`.
		    If `True`, adjoint the slices of `x`. Defaults to `False`.
		  adj_y: An optional `bool`. Defaults to `False`.
		    If `True`, adjoint the slices of `y`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Tout`.
	**/
	static public function BatchMatMulV3(x:Dynamic, y:Dynamic, Tout:Dynamic, ?adj_x:Dynamic, ?adj_y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`.
		  num_lower: A `Tensor` of type `int64`.
		  num_upper: A `Tensor` of type `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function BatchMatrixBandPart(input:Dynamic, num_lower:Dynamic, num_upper:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function BatchMatrixDeterminant(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  diagonal: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `diagonal`.
	**/
	static public function BatchMatrixDiag(diagonal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function BatchMatrixDiagPart(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`.
		  adjoint: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function BatchMatrixInverse(input:Dynamic, ?adjoint:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`.
		  diagonal: A `Tensor`. Must have the same type as `input`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function BatchMatrixSetDiag(input:Dynamic, diagonal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  matrix: A `Tensor`. Must be one of the following types: `float64`, `float32`.
		  rhs: A `Tensor`. Must have the same type as `matrix`.
		  adjoint: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `matrix`.
	**/
	static public function BatchMatrixSolve(matrix:Dynamic, rhs:Dynamic, ?adjoint:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  matrix: A `Tensor`. Must be one of the following types: `float64`, `float32`.
		  rhs: A `Tensor`. Must have the same type as `matrix`.
		  l2_regularizer: A `Tensor` of type `float64`.
		  fast: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `matrix`.
	**/
	static public function BatchMatrixSolveLs(matrix:Dynamic, rhs:Dynamic, l2_regularizer:Dynamic, ?fast:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  matrix: A `Tensor`. Must be one of the following types: `float64`, `float32`.
		  rhs: A `Tensor`. Must have the same type as `matrix`.
		  lower: An optional `bool`. Defaults to `True`.
		  adjoint: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `matrix`.
	**/
	static public function BatchMatrixTriangularSolve(matrix:Dynamic, rhs:Dynamic, ?lower:Dynamic, ?adjoint:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Batch normalization.
		
		This op is deprecated. Prefer `tf.nn.batch_normalization`.
		
		Args:
		  t: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A 4D input Tensor.
		  m: A `Tensor`. Must have the same type as `t`.
		    A 1D mean Tensor with size matching the last dimension of t.
		    This is the first output from tf.nn.moments,
		    or a saved moving average thereof.
		  v: A `Tensor`. Must have the same type as `t`.
		    A 1D variance Tensor with size matching the last dimension of t.
		    This is the second output from tf.nn.moments,
		    or a saved moving average thereof.
		  beta: A `Tensor`. Must have the same type as `t`.
		    A 1D beta Tensor with size matching the last dimension of t.
		    An offset to be added to the normalized tensor.
		  gamma: A `Tensor`. Must have the same type as `t`.
		    A 1D gamma Tensor with size matching the last dimension of t.
		    If "scale_after_normalization" is true, this tensor will be multiplied
		    with the normalized tensor.
		  variance_epsilon: A `float`. A small float number to avoid dividing by 0.
		  scale_after_normalization: A `bool`.
		    A bool indicating whether the resulted tensor
		    needs to be multiplied with gamma.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `t`.
	**/
	static public function BatchNormWithGlobalNormalization(t:Dynamic, m:Dynamic, v:Dynamic, beta:Dynamic, gamma:Dynamic, variance_epsilon:Dynamic, scale_after_normalization:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gradients for batch normalization.
		
		This op is deprecated. See `tf.nn.batch_normalization`.
		
		Args:
		  t: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A 4D input Tensor.
		  m: A `Tensor`. Must have the same type as `t`.
		    A 1D mean Tensor with size matching the last dimension of t.
		    This is the first output from tf.nn.moments,
		    or a saved moving average thereof.
		  v: A `Tensor`. Must have the same type as `t`.
		    A 1D variance Tensor with size matching the last dimension of t.
		    This is the second output from tf.nn.moments,
		    or a saved moving average thereof.
		  gamma: A `Tensor`. Must have the same type as `t`.
		    A 1D gamma Tensor with size matching the last dimension of t.
		    If "scale_after_normalization" is true, this Tensor will be multiplied
		    with the normalized Tensor.
		  backprop: A `Tensor`. Must have the same type as `t`. 4D backprop Tensor.
		  variance_epsilon: A `float`. A small float number to avoid dividing by 0.
		  scale_after_normalization: A `bool`.
		    A bool indicating whether the resulted tensor
		    needs to be multiplied with gamma.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (dx, dm, dv, db, dg).
		
		  dx: A `Tensor`. Has the same type as `t`.
		  dm: A `Tensor`. Has the same type as `t`.
		  dv: A `Tensor`. Has the same type as `t`.
		  db: A `Tensor`. Has the same type as `t`.
		  dg: A `Tensor`. Has the same type as `t`.
	**/
	static public function BatchNormWithGlobalNormalizationGrad(t:Dynamic, m:Dynamic, v:Dynamic, gamma:Dynamic, backprop:Dynamic, variance_epsilon:Dynamic, scale_after_normalization:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function BatchSelfAdjointEig(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`.
		  compute_v: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (e, v).
		
		  e: A `Tensor`. Has the same type as `input`.
		  v: A `Tensor`. Has the same type as `input`.
	**/
	static public function BatchSelfAdjointEigV2(input:Dynamic, ?compute_v:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `complex64`, `complex128`.
		  compute_uv: An optional `bool`. Defaults to `True`.
		  full_matrices: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (s, u, v).
		
		  s: A `Tensor`. Has the same type as `input`.
		  u: A `Tensor`. Has the same type as `input`.
		  v: A `Tensor`. Has the same type as `input`.
	**/
	static public function BatchSvd(input:Dynamic, ?compute_uv:Dynamic, ?full_matrices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		BatchToSpace for 4-D tensors of type T.
		
		This is a legacy version of the more general BatchToSpaceND.
		
		Rearranges (permutes) data from batch into blocks of spatial data, followed by
		cropping. This is the reverse transformation of SpaceToBatch. More specifically,
		this op outputs a copy of the input tensor where values from the `batch`
		dimension are moved in spatial blocks to the `height` and `width` dimensions,
		followed by cropping along the `height` and `width` dimensions.
		
		Args:
		  input: A `Tensor`. 4-D tensor with shape
		    `[batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
		      depth]`. Note that the batch size of the input tensor must be divisible by
		    `block_size * block_size`.
		  crops: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2-D tensor of non-negative integers with shape `[2, 2]`. It specifies
		    how many elements to crop from the intermediate result across the spatial
		    dimensions as follows:
		
		        crops = [[crop_top, crop_bottom], [crop_left, crop_right]]
		  block_size: An `int` that is `>= 2`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function BatchToSpace(input:Dynamic, crops:Dynamic, block_size:Dynamic, ?name:Dynamic):Dynamic;
	/**
		BatchToSpace for N-D tensors of type T.
		
		This operation reshapes the "batch" dimension 0 into `M + 1` dimensions of shape
		`block_shape + [batch]`, interleaves these blocks back into the grid defined by
		the spatial dimensions `[1, ..., M]`, to obtain a result with the same rank as
		the input.  The spatial dimensions of this intermediate result are then
		optionally cropped according to `crops` to produce the output.  This is the
		reverse of SpaceToBatch.  See below for a precise description.
		
		Args:
		  input: A `Tensor`.
		    N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,
		    where spatial_shape has M dimensions.
		  block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    1-D with shape `[M]`, all values must be >= 1.
		  crops: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2-D with shape `[M, 2]`, all values must be >= 0.
		      `crops[i] = [crop_start, crop_end]` specifies the amount to crop from input
		      dimension `i + 1`, which corresponds to spatial dimension `i`.  It is
		      required that
		      `crop_start[i] + crop_end[i] <= block_shape[i] * input_shape[i + 1]`.
		
		    This operation is equivalent to the following steps:
		
		    1. Reshape `input` to `reshaped` of shape:
		         [block_shape[0], ..., block_shape[M-1],
		          batch / prod(block_shape),
		          input_shape[1], ..., input_shape[N-1]]
		
		    2. Permute dimensions of `reshaped` to produce `permuted` of shape
		         [batch / prod(block_shape),
		
		          input_shape[1], block_shape[0],
		          ...,
		          input_shape[M], block_shape[M-1],
		
		          input_shape[M+1], ..., input_shape[N-1]]
		
		    3. Reshape `permuted` to produce `reshaped_permuted` of shape
		         [batch / prod(block_shape),
		
		          input_shape[1] * block_shape[0],
		          ...,
		          input_shape[M] * block_shape[M-1],
		
		          input_shape[M+1],
		          ...,
		          input_shape[N-1]]
		
		    4. Crop the start and end of dimensions `[1, ..., M]` of
		       `reshaped_permuted` according to `crops` to produce the output of shape:
		         [batch / prod(block_shape),
		
		          input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1],
		          ...,
		          input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],
		
		          input_shape[M+1], ..., input_shape[N-1]]
		
		    Some examples:
		
		    (1) For the following input of shape `[4, 1, 1, 1]`, `block_shape = [2, 2]`, and
		        `crops = [[0, 0], [0, 0]]`:
		
		    ```
		    [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
		    ```
		
		    The output tensor has shape `[1, 2, 2, 1]` and value:
		
		    ```
		    x = [[[[1], [2]], [[3], [4]]]]
		    ```
		
		    (2) For the following input of shape `[4, 1, 1, 3]`, `block_shape = [2, 2]`, and
		        `crops = [[0, 0], [0, 0]]`:
		
		    ```
		    [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]
		    ```
		
		    The output tensor has shape `[1, 2, 2, 3]` and value:
		
		    ```
		    x = [[[[1, 2, 3], [4, 5, 6]],
		          [[7, 8, 9], [10, 11, 12]]]]
		    ```
		
		    (3) For the following input of shape `[4, 2, 2, 1]`, `block_shape = [2, 2]`, and
		        `crops = [[0, 0], [0, 0]]`:
		
		    ```
		    x = [[[[1], [3]], [[9], [11]]],
		         [[[2], [4]], [[10], [12]]],
		         [[[5], [7]], [[13], [15]]],
		         [[[6], [8]], [[14], [16]]]]
		    ```
		
		    The output tensor has shape `[1, 4, 4, 1]` and value:
		
		    ```
		    x = [[[[1],   [2],  [3],  [4]],
		         [[5],   [6],  [7],  [8]],
		         [[9],  [10], [11],  [12]],
		         [[13], [14], [15],  [16]]]]
		    ```
		
		    (4) For the following input of shape `[8, 1, 3, 1]`, `block_shape = [2, 2]`, and
		        `crops = [[0, 0], [2, 0]]`:
		
		    ```
		    x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
		         [[[0], [2], [4]]], [[[0], [10], [12]]],
		         [[[0], [5], [7]]], [[[0], [13], [15]]],
		         [[[0], [6], [8]]], [[[0], [14], [16]]]]
		    ```
		
		    The output tensor has shape `[2, 2, 4, 1]` and value:
		
		    ```
		    x = [[[[1],   [2],  [3],  [4]],
		          [[5],   [6],  [7],  [8]]],
		         [[[9],  [10], [11],  [12]],
		          [[13], [14], [15],  [16]]]]
		    ```
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function BatchToSpaceND(input:Dynamic, block_shape:Dynamic, crops:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselI0(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselI0e(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselI1(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselI1e(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselJ0(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselJ1(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselK0(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselK0e(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselK1(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselK1e(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselY0(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BesselY1(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute the regularized incomplete beta integral \\(I_x(a, b)\\).
		
		The regularized incomplete beta integral is defined as:
		
		
		\\(I_x(a, b) = \frac{B(x; a, b)}{B(a, b)}\\)
		
		where
		
		
		\\(B(x; a, b) = \int_0^x t^{a-1} (1 - t)^{b-1} dt\\)
		
		
		is the incomplete beta function and \\(B(a, b)\\) is the *complete*
		beta function.
		
		Args:
		  a: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		  b: A `Tensor`. Must have the same type as `a`.
		  x: A `Tensor`. Must have the same type as `a`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `a`.
	**/
	static public function Betainc(a:Dynamic, b:Dynamic, x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adds `bias` to `value`.
		
		This is a special case of `tf.add` where `bias` is restricted to be 1-D.
		Broadcasting is supported, so `value` may have any number of dimensions.
		
		Args:
		  value: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Any number of dimensions.
		  bias: A `Tensor`. Must have the same type as `value`.
		    1-D with size the last dimension of `value`.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the bias tensor will be added to the last dimension
		    of the value tensor.
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		    The tensor will be added to "in_channels", the third-to-the-last
		        dimension.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `value`.
	**/
	static public function BiasAdd(value:Dynamic, bias:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		The backward operation for "BiasAdd" on the "bias" tensor.
		
		It accumulates all the values from out_backprop into the feature dimension.
		For NHWC data format, the feature dimension is the last. For NCHW data format,
		the feature dimension is the third-to-last.
		
		Args:
		  out_backprop: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Any number of dimensions.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the bias tensor will be added to the last dimension
		    of the value tensor.
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		    The tensor will be added to "in_channels", the third-to-the-last
		        dimension.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `out_backprop`.
	**/
	static public function BiasAddGrad(out_backprop:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adds `bias` to `value`.
		
		This is a deprecated version of BiasAdd and will be soon removed.
		
		This is a special case of `tf.add` where `bias` is restricted to be 1-D.
		Broadcasting is supported, so `value` may have any number of dimensions.
		
		Args:
		  value: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Any number of dimensions.
		  bias: A `Tensor`. Must have the same type as `value`.
		    1-D with size the last dimension of `value`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `value`.
	**/
	static public function BiasAddV1(value:Dynamic, bias:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Counts the number of occurrences of each value in an integer array.
		
		Outputs a vector with length `size` and the same dtype as `weights`. If
		`weights` are empty, then index `i` stores the number of times the value `i` is
		counted in `arr`. If `weights` are non-empty, then index `i` stores the sum of
		the value in `weights` at each index where the corresponding value in `arr` is
		`i`.
		
		Values in `arr` outside of the range [0, size) are ignored.
		
		Args:
		  arr: A `Tensor` of type `int32`. int32 `Tensor`.
		  size: A `Tensor` of type `int32`. non-negative int32 scalar `Tensor`.
		  weights: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.
		    is an int32, int64, float32, or float64 `Tensor` with the same
		    shape as `arr`, or a length-0 `Tensor`, in which case it acts as all weights
		    equal to 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `weights`.
	**/
	static public function Bincount(arr:Dynamic, size:Dynamic, weights:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Bitcasts a tensor from one type to another without copying data.
		
		Given a tensor `input`, this operation returns a tensor that has the same buffer
		data as `input` with datatype `type`.
		
		If the input datatype `T` is larger than the output datatype `type` then the
		shape changes from [...] to [..., sizeof(`T`)/sizeof(`type`)].
		
		If `T` is smaller than `type`, the operator requires that the rightmost
		dimension be equal to sizeof(`type`)/sizeof(`T`). The shape then goes from
		[..., sizeof(`type`)/sizeof(`T`)] to [...].
		
		tf.bitcast() and tf.cast() work differently when real dtype is casted as a complex dtype
		(e.g. tf.complex64 or tf.complex128) as tf.cast() make imaginary part 0 while tf.bitcast()
		gives module error.
		For example,
		
		Example 1:
		
		>>> a = [1., 2., 3.]
		>>> equality_bitcast = tf.bitcast(a, tf.complex128)
		Traceback (most recent call last):
		...
		InvalidArgumentError: Cannot bitcast from 1 to 18 [Op:Bitcast]
		>>> equality_cast = tf.cast(a, tf.complex128)
		>>> print(equality_cast)
		tf.Tensor([1.+0.j 2.+0.j 3.+0.j], shape=(3,), dtype=complex128)
		
		Example 2:
		
		>>> tf.bitcast(tf.constant(0xffffffff, dtype=tf.uint32), tf.uint8)
		<tf.Tensor: shape=(4,), dtype=uint8, numpy=array([255, 255, 255, 255], dtype=uint8)>
		
		Example 3:
		
		>>> x = [1., 2., 3.]
		>>> y = [0., 2., 3.]
		>>> equality= tf.equal(x,y)
		>>> equality_cast = tf.cast(equality,tf.float32)
		>>> equality_bitcast = tf.bitcast(equality_cast,tf.uint8)
		>>> print(equality)
		tf.Tensor([False True True], shape=(3,), dtype=bool)
		>>> print(equality_cast)
		tf.Tensor([0. 1. 1.], shape=(3,), dtype=float32)
		>>> print(equality_bitcast)
		tf.Tensor(
		    [[  0   0   0   0]
		     [  0   0 128  63]
		     [  0   0 128  63]], shape=(3, 4), dtype=uint8)
		
		*NOTE*: Bitcast is implemented as a low-level cast, so machines with different
		endian orderings will give different results.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int64`, `int32`, `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `complex64`, `complex128`, `qint8`, `quint8`, `qint16`, `quint16`, `qint32`.
		  type: A `tf.DType` from: `tf.bfloat16, tf.half, tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.uint32, tf.uint64, tf.int8, tf.int16, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint16, tf.quint16, tf.qint32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `type`.
	**/
	static public function Bitcast(input:Dynamic, type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Elementwise computes the bitwise AND of `x` and `y`.
		
		The result will have those bits set, that are set in both `x` and `y`. The
		computation is performed on the underlying representations of `x` and `y`.
		
		For example:
		
		```python
		import tensorflow as tf
		from tensorflow.python.ops import bitwise_ops
		dtype_list = [tf.int8, tf.int16, tf.int32, tf.int64,
		              tf.uint8, tf.uint16, tf.uint32, tf.uint64]
		
		for dtype in dtype_list:
		  lhs = tf.constant([0, 5, 3, 14], dtype=dtype)
		  rhs = tf.constant([5, 0, 7, 11], dtype=dtype)
		  exp = tf.constant([0, 0, 3, 10], dtype=tf.float32)
		
		  res = bitwise_ops.bitwise_and(lhs, rhs)
		  tf.assert_equal(tf.cast(res, tf.float32), exp) # TRUE
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BitwiseAnd(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Elementwise computes the bitwise OR of `x` and `y`.
		
		The result will have those bits set, that are set in `x`, `y` or both. The
		computation is performed on the underlying representations of `x` and `y`.
		
		For example:
		
		```python
		import tensorflow as tf
		from tensorflow.python.ops import bitwise_ops
		dtype_list = [tf.int8, tf.int16, tf.int32, tf.int64,
		              tf.uint8, tf.uint16, tf.uint32, tf.uint64]
		
		for dtype in dtype_list:
		  lhs = tf.constant([0, 5, 3, 14], dtype=dtype)
		  rhs = tf.constant([5, 0, 7, 11], dtype=dtype)
		  exp = tf.constant([5, 5, 7, 15], dtype=tf.float32)
		
		  res = bitwise_ops.bitwise_or(lhs, rhs)
		  tf.assert_equal(tf.cast(res,  tf.float32), exp)  # TRUE
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BitwiseOr(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Elementwise computes the bitwise XOR of `x` and `y`.
		
		The result will have those bits set, that are different in `x` and `y`. The
		computation is performed on the underlying representations of `x` and `y`.
		
		For example:
		
		```python
		import tensorflow as tf
		from tensorflow.python.ops import bitwise_ops
		dtype_list = [tf.int8, tf.int16, tf.int32, tf.int64,
		              tf.uint8, tf.uint16, tf.uint32, tf.uint64]
		
		for dtype in dtype_list:
		  lhs = tf.constant([0, 5, 3, 14], dtype=dtype)
		  rhs = tf.constant([5, 0, 7, 11], dtype=dtype)
		  exp = tf.constant([5, 5, 4, 5],  dtype=tf.float32)
		
		  res = bitwise_ops.bitwise_xor(lhs, rhs)
		  tf.assert_equal(tf.cast(res, tf.float32), exp) # TRUE
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function BitwiseXor(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the LSTM cell forward propagation for all the time steps.
		
		This is equivalent to applying LSTMBlockCell in a loop, like so:
		
		```python
		for x1 in unpack(x):
		  i1, cs1, f1, o1, ci1, co1, h1 = LSTMBlock(
		    x1, cs_prev, h_prev, w, wci, wcf, wco, b)
		  cs_prev = cs1
		  h_prev = h1
		  i.append(i1)
		  cs.append(cs1)
		  f.append(f1)
		  o.append(o1)
		  ci.append(ci1)
		  co.append(co1)
		  h.append(h1)
		return pack(i), pack(cs), pack(f), pack(o), pack(ci), pack(ch), pack(h)
		```
		
		Args:
		  seq_len_max: A `Tensor` of type `int64`.
		    Maximum time length actually used by this input. Outputs are padded
		    with zeros beyond this length.
		  x: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    The sequence input to the LSTM, shape (timelen, batch_size, num_inputs).
		  cs_prev: A `Tensor`. Must have the same type as `x`.
		    Value of the initial cell state.
		  h_prev: A `Tensor`. Must have the same type as `x`.
		    Initial output of cell (to be used for peephole).
		  w: A `Tensor`. Must have the same type as `x`. The weight matrix.
		  wci: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for input gate peephole connection.
		  wcf: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for forget gate peephole connection.
		  wco: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for output gate peephole connection.
		  b: A `Tensor`. Must have the same type as `x`. The bias vector.
		  forget_bias: An optional `float`. Defaults to `1`. The forget gate bias.
		  cell_clip: An optional `float`. Defaults to `3`.
		    Value to clip the 'cs' value to.
		  use_peephole: An optional `bool`. Defaults to `False`.
		    Whether to use peephole weights.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (i, cs, f, o, ci, co, h).
		
		  i: A `Tensor`. Has the same type as `x`.
		  cs: A `Tensor`. Has the same type as `x`.
		  f: A `Tensor`. Has the same type as `x`.
		  o: A `Tensor`. Has the same type as `x`.
		  ci: A `Tensor`. Has the same type as `x`.
		  co: A `Tensor`. Has the same type as `x`.
		  h: A `Tensor`. Has the same type as `x`.
	**/
	static public function BlockLSTM(seq_len_max:Dynamic, x:Dynamic, cs_prev:Dynamic, h_prev:Dynamic, w:Dynamic, wci:Dynamic, wcf:Dynamic, wco:Dynamic, b:Dynamic, ?forget_bias:Dynamic, ?cell_clip:Dynamic, ?use_peephole:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the LSTM cell backward propagation for the entire time sequence.
		
		This implementation is to be used in conjunction of LSTMBlock.
		
		Args:
		  seq_len_max: A `Tensor` of type `int64`.
		    Maximum time length actually used by this input. Outputs are padded
		    with zeros beyond this length.
		  x: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    The sequence input to the LSTM, shape (timelen, batch_size, num_inputs).
		  cs_prev: A `Tensor`. Must have the same type as `x`.
		    Value of the initial cell state.
		  h_prev: A `Tensor`. Must have the same type as `x`.
		    Initial output of cell (to be used for peephole).
		  w: A `Tensor`. Must have the same type as `x`. The weight matrix.
		  wci: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for input gate peephole connection.
		  wcf: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for forget gate peephole connection.
		  wco: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for output gate peephole connection.
		  b: A `Tensor`. Must have the same type as `x`. The bias vector.
		  i: A `Tensor`. Must have the same type as `x`.
		    The input gate over the whole time sequence.
		  cs: A `Tensor`. Must have the same type as `x`.
		    The cell state before the tanh over the whole time sequence.
		  f: A `Tensor`. Must have the same type as `x`.
		    The forget gate over the whole time sequence.
		  o: A `Tensor`. Must have the same type as `x`.
		    The output gate over the whole time sequence.
		  ci: A `Tensor`. Must have the same type as `x`.
		    The cell input over the whole time sequence.
		  co: A `Tensor`. Must have the same type as `x`.
		    The cell after the tanh over the whole time sequence.
		  h: A `Tensor`. Must have the same type as `x`.
		    The output h vector over the whole time sequence.
		  cs_grad: A `Tensor`. Must have the same type as `x`.
		    The current gradient of cs.
		  h_grad: A `Tensor`. Must have the same type as `x`.
		    The gradient of h vector.
		  use_peephole: A `bool`. Whether to use peephole weights.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (x_grad, cs_prev_grad, h_prev_grad, w_grad, wci_grad, wcf_grad, wco_grad, b_grad).
		
		  x_grad: A `Tensor`. Has the same type as `x`.
		  cs_prev_grad: A `Tensor`. Has the same type as `x`.
		  h_prev_grad: A `Tensor`. Has the same type as `x`.
		  w_grad: A `Tensor`. Has the same type as `x`.
		  wci_grad: A `Tensor`. Has the same type as `x`.
		  wcf_grad: A `Tensor`. Has the same type as `x`.
		  wco_grad: A `Tensor`. Has the same type as `x`.
		  b_grad: A `Tensor`. Has the same type as `x`.
	**/
	static public function BlockLSTMGrad(seq_len_max:Dynamic, x:Dynamic, cs_prev:Dynamic, h_prev:Dynamic, w:Dynamic, wci:Dynamic, wcf:Dynamic, wco:Dynamic, b:Dynamic, i:Dynamic, cs:Dynamic, f:Dynamic, o:Dynamic, ci:Dynamic, co:Dynamic, h:Dynamic, cs_grad:Dynamic, h_grad:Dynamic, use_peephole:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the LSTM cell backward propagation for the entire time sequence.
		
		This implementation is to be used in conjunction of BlockLSTMV2.
		
		Args:
		  seq_len_max: A `Tensor` of type `int64`.
		    Maximum time length actually used by this input. Outputs are padded
		    with zeros beyond this length.
		  x: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    The sequence input to the LSTM, shape (timelen, batch_size, num_inputs).
		  cs_prev: A `Tensor`. Must have the same type as `x`.
		    Value of the initial cell state.
		  h_prev: A `Tensor`. Must have the same type as `x`.
		    Initial output of cell (to be used for peephole).
		  w: A `Tensor`. Must have the same type as `x`. The weight matrix.
		  wci: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for input gate peephole connection.
		  wcf: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for forget gate peephole connection.
		  wco: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for output gate peephole connection.
		  b: A `Tensor`. Must have the same type as `x`. The bias vector.
		  i: A `Tensor`. Must have the same type as `x`.
		    The input gate over the whole time sequence.
		  cs: A `Tensor`. Must have the same type as `x`.
		    The cell state before the tanh over the whole time sequence.
		  f: A `Tensor`. Must have the same type as `x`.
		    The forget gate over the whole time sequence.
		  o: A `Tensor`. Must have the same type as `x`.
		    The output gate over the whole time sequence.
		  ci: A `Tensor`. Must have the same type as `x`.
		    The cell input over the whole time sequence.
		  co: A `Tensor`. Must have the same type as `x`.
		    The cell after the tanh over the whole time sequence.
		  h: A `Tensor`. Must have the same type as `x`.
		    The output h vector over the whole time sequence.
		  cs_grad: A `Tensor`. Must have the same type as `x`.
		    The current gradient of cs.
		  h_grad: A `Tensor`. Must have the same type as `x`.
		    The gradient of h vector.
		  use_peephole: A `bool`. Whether to use peephole weights.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (x_grad, cs_prev_grad, h_prev_grad, w_grad, wci_grad, wcf_grad, wco_grad, b_grad).
		
		  x_grad: A `Tensor`. Has the same type as `x`.
		  cs_prev_grad: A `Tensor`. Has the same type as `x`.
		  h_prev_grad: A `Tensor`. Has the same type as `x`.
		  w_grad: A `Tensor`. Has the same type as `x`.
		  wci_grad: A `Tensor`. Has the same type as `x`.
		  wcf_grad: A `Tensor`. Has the same type as `x`.
		  wco_grad: A `Tensor`. Has the same type as `x`.
		  b_grad: A `Tensor`. Has the same type as `x`.
	**/
	static public function BlockLSTMGradV2(seq_len_max:Dynamic, x:Dynamic, cs_prev:Dynamic, h_prev:Dynamic, w:Dynamic, wci:Dynamic, wcf:Dynamic, wco:Dynamic, b:Dynamic, i:Dynamic, cs:Dynamic, f:Dynamic, o:Dynamic, ci:Dynamic, co:Dynamic, h:Dynamic, cs_grad:Dynamic, h_grad:Dynamic, use_peephole:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the LSTM cell forward propagation for all the time steps.
		
		This is equivalent to applying LSTMBlockCell in a loop, like so:
		
		```python
		for x1 in unpack(x):
		  i1, cs1, f1, o1, ci1, co1, h1 = LSTMBlock(
		    x1, cs_prev, h_prev, w, wci, wcf, wco, b)
		  cs_prev = cs1
		  h_prev = h1
		  i.append(i1)
		  cs.append(cs1)
		  f.append(f1)
		  o.append(o1)
		  ci.append(ci1)
		  co.append(co1)
		  h.append(h1)
		return pack(i), pack(cs), pack(f), pack(o), pack(ci), pack(ch), pack(h)
		
		Note that unlike LSTMBlockCell (and BlockLSTM) which uses ICFO gate layout,
		this op uses IFCO. So in order for the following snippet to be equivalent
		all gate-related outputs should be reordered.
		```
		
		Args:
		  seq_len_max: A `Tensor` of type `int64`.
		    Maximum time length actually used by this input. Outputs are padded
		    with zeros beyond this length.
		  x: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    The sequence input to the LSTM, shape (timelen, batch_size, num_inputs).
		  cs_prev: A `Tensor`. Must have the same type as `x`.
		    Value of the initial cell state.
		  h_prev: A `Tensor`. Must have the same type as `x`.
		    Initial output of cell (to be used for peephole).
		  w: A `Tensor`. Must have the same type as `x`. The weight matrix.
		  wci: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for input gate peephole connection.
		  wcf: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for forget gate peephole connection.
		  wco: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for output gate peephole connection.
		  b: A `Tensor`. Must have the same type as `x`. The bias vector.
		  cell_clip: An optional `float`. Defaults to `0`.
		    Value to clip the 'cs' value to.
		  use_peephole: An optional `bool`. Defaults to `False`.
		    Whether to use peephole weights.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (i, cs, f, o, ci, co, h).
		
		  i: A `Tensor`. Has the same type as `x`.
		  cs: A `Tensor`. Has the same type as `x`.
		  f: A `Tensor`. Has the same type as `x`.
		  o: A `Tensor`. Has the same type as `x`.
		  ci: A `Tensor`. Has the same type as `x`.
		  co: A `Tensor`. Has the same type as `x`.
		  h: A `Tensor`. Has the same type as `x`.
	**/
	static public function BlockLSTMV2(seq_len_max:Dynamic, x:Dynamic, cs_prev:Dynamic, h_prev:Dynamic, w:Dynamic, wci:Dynamic, wcf:Dynamic, wco:Dynamic, b:Dynamic, ?cell_clip:Dynamic, ?use_peephole:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Aggregates the summary of accumulated stats for the batch.
		
		The summary stats contains gradients and hessians accumulated for each node, feature dimension id and bucket.
		
		Args:
		  node_ids: A `Tensor` of type `int32`.
		    int32; Rank 1 Tensor containing node ids for each example, shape [batch_size].
		  gradients: A `Tensor` of type `float32`.
		    float32; Rank 2 Tensor (shape=[batch_size, logits_dimension]) with gradients for each example.
		  hessians: A `Tensor` of type `float32`.
		    float32; Rank 2 Tensor (shape=[batch_size, hessian_dimension]) with hessians for each example.
		  feature: A `Tensor` of type `int32`.
		    int32; Rank 2 feature Tensors (shape=[batch_size, feature_dimension]).
		  max_splits: An `int` that is `>= 1`.
		    int; the maximum number of splits possible in the whole tree.
		  num_buckets: An `int` that is `>= 1`.
		    int; equals to the maximum possible value of bucketized feature.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function BoostedTreesAggregateStats(node_ids:Dynamic, gradients:Dynamic, hessians:Dynamic, feature:Dynamic, max_splits:Dynamic, num_buckets:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Bucketize each feature based on bucket boundaries.
		
		An op that returns a list of float tensors, where each tensor represents the
		bucketized values for a single feature.
		
		Args:
		  float_values: A list of `Tensor` objects with type `float32`.
		    float; List of Rank 1 Tensor each containing float values for a single feature.
		  bucket_boundaries: A list with the same length as `float_values` of `Tensor` objects with type `float32`.
		    float; List of Rank 1 Tensors each containing the bucket boundaries for a single
		    feature.
		  name: A name for the operation (optional).
		
		Returns:
		  A list with the same length as `float_values` of `Tensor` objects with type `int32`.
	**/
	static public function BoostedTreesBucketize(float_values:Dynamic, bucket_boundaries:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Calculates gains for each feature and returns the best possible split information for the feature.
		
		The split information is the best threshold (bucket id), gains and left/right node contributions per node for each feature.
		
		It is possible that not all nodes can be split on each feature. Hence, the list of possible nodes can differ between the features. Therefore, we return `node_ids_list` for each feature, containing the list of nodes that this feature can be used to split.
		
		In this manner, the output is the best split per features and per node, so that it needs to be combined later to produce the best split for each node (among all possible features).
		
		The output shapes are compatible in a way that the first dimension of all tensors are the same and equal to the number of possible split nodes for each feature.
		
		Args:
		  node_id_range: A `Tensor` of type `int32`.
		    A Rank 1 tensor (shape=[2]) to specify the range [first, last) of node ids to process within `stats_summary_list`. The nodes are iterated between the two nodes specified by the tensor, as like `for node_id in range(node_id_range[0], node_id_range[1])` (Note that the last index node_id_range[1] is exclusive).
		  stats_summary: A `Tensor` of type `float32`.
		    A Rank 4 tensor (#shape=[max_splits, feature_dims, bucket, stats_dims]) for accumulated stats summary (gradient/hessian) per node, per dimension, per buckets for each feature.
		    The first dimension of the tensor is the maximum number of splits, and thus not all elements of it will be used, but only the indexes specified by node_ids will be used.
		  l1: A `Tensor` of type `float32`.
		    l1 regularization factor on leaf weights, per instance based.
		  l2: A `Tensor` of type `float32`.
		    l2 regularization factor on leaf weights, per instance based.
		  tree_complexity: A `Tensor` of type `float32`.
		    adjustment to the gain, per leaf based.
		  min_node_weight: A `Tensor` of type `float32`.
		    minimum avg of hessians in a node before required for the node to be considered for splitting.
		  logits_dimension: An `int` that is `>= 1`.
		    The dimension of logit, i.e., number of classes.
		  split_type: An optional `string` from: `"inequality", "equality"`. Defaults to `"inequality"`.
		    A string indicating if this Op should perform inequality split or equality split.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (node_ids, gains, feature_dimensions, thresholds, left_node_contribs, right_node_contribs, split_with_default_directions).
		
		  node_ids: A `Tensor` of type `int32`.
		  gains: A `Tensor` of type `float32`.
		  feature_dimensions: A `Tensor` of type `int32`.
		  thresholds: A `Tensor` of type `int32`.
		  left_node_contribs: A `Tensor` of type `float32`.
		  right_node_contribs: A `Tensor` of type `float32`.
		  split_with_default_directions: A `Tensor` of type `string`.
	**/
	static public function BoostedTreesCalculateBestFeatureSplit(node_id_range:Dynamic, stats_summary:Dynamic, l1:Dynamic, l2:Dynamic, tree_complexity:Dynamic, min_node_weight:Dynamic, logits_dimension:Dynamic, ?split_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Calculates gains for each feature and returns the best possible split information for each node. However, if no split is found, then no split information is returned for that node.
		
		The split information is the best threshold (bucket id), gains and left/right node contributions per node for each feature.
		
		It is possible that not all nodes can be split on each feature. Hence, the list of possible nodes can differ between the features. Therefore, we return `node_ids_list` for each feature, containing the list of nodes that this feature can be used to split.
		
		In this manner, the output is the best split per features and per node, so that it needs to be combined later to produce the best split for each node (among all possible features).
		
		The output shapes are compatible in a way that the first dimension of all tensors are the same and equal to the number of possible split nodes for each feature.
		
		Args:
		  node_id_range: A `Tensor` of type `int32`.
		    A Rank 1 tensor (shape=[2]) to specify the range [first, last) of node ids to process within `stats_summary_list`. The nodes are iterated between the two nodes specified by the tensor, as like `for node_id in range(node_id_range[0], node_id_range[1])` (Note that the last index node_id_range[1] is exclusive).
		  stats_summaries_list: A list of at least 1 `Tensor` objects with type `float32`.
		    A list of Rank 4 tensor (#shape=[max_splits, feature_dims, bucket, stats_dims]) for accumulated stats summary (gradient/hessian) per node, per dimension, per buckets for each feature.
		    The first dimension of the tensor is the maximum number of splits, and thus not all elements of it will be used, but only the indexes specified by node_ids will be used.
		  split_types: A `Tensor` of type `string`.
		    A Rank 1 tensor indicating if this Op should perform inequality split or equality split per feature.
		  candidate_feature_ids: A `Tensor` of type `int32`.
		    Rank 1 tensor with ids for each feature. This is the real id of the feature.
		  l1: A `Tensor` of type `float32`.
		    l1 regularization factor on leaf weights, per instance based.
		  l2: A `Tensor` of type `float32`.
		    l2 regularization factor on leaf weights, per instance based.
		  tree_complexity: A `Tensor` of type `float32`.
		    adjustment to the gain, per leaf based.
		  min_node_weight: A `Tensor` of type `float32`.
		    minimum avg of hessians in a node before required for the node to be considered for splitting.
		  logits_dimension: An `int` that is `>= 1`.
		    The dimension of logit, i.e., number of classes.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (node_ids, gains, feature_ids, feature_dimensions, thresholds, left_node_contribs, right_node_contribs, split_with_default_directions).
		
		  node_ids: A `Tensor` of type `int32`.
		  gains: A `Tensor` of type `float32`.
		  feature_ids: A `Tensor` of type `int32`.
		  feature_dimensions: A `Tensor` of type `int32`.
		  thresholds: A `Tensor` of type `int32`.
		  left_node_contribs: A `Tensor` of type `float32`.
		  right_node_contribs: A `Tensor` of type `float32`.
		  split_with_default_directions: A `Tensor` of type `string`.
	**/
	static public function BoostedTreesCalculateBestFeatureSplitV2(node_id_range:Dynamic, stats_summaries_list:Dynamic, split_types:Dynamic, candidate_feature_ids:Dynamic, l1:Dynamic, l2:Dynamic, tree_complexity:Dynamic, min_node_weight:Dynamic, logits_dimension:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Calculates gains for each feature and returns the best possible split information for the feature.
		
		The split information is the best threshold (bucket id), gains and left/right node contributions per node for each feature.
		
		It is possible that not all nodes can be split on each feature. Hence, the list of possible nodes can differ between the features. Therefore, we return `node_ids_list` for each feature, containing the list of nodes that this feature can be used to split.
		
		In this manner, the output is the best split per features and per node, so that it needs to be combined later to produce the best split for each node (among all possible features).
		
		The length of output lists are all of the same length, `num_features`.
		The output shapes are compatible in a way that the first dimension of all tensors of all lists are the same and equal to the number of possible split nodes for each feature.
		
		Args:
		  node_id_range: A `Tensor` of type `int32`.
		    A Rank 1 tensor (shape=[2]) to specify the range [first, last) of node ids to process within `stats_summary_list`. The nodes are iterated between the two nodes specified by the tensor, as like `for node_id in range(node_id_range[0], node_id_range[1])` (Note that the last index node_id_range[1] is exclusive).
		  stats_summary_list: A list of at least 1 `Tensor` objects with type `float32`.
		    A list of Rank 3 tensor (#shape=[max_splits, bucket, 2]) for accumulated stats summary (gradient/hessian) per node per buckets for each feature. The first dimension of the tensor is the maximum number of splits, and thus not all elements of it will be used, but only the indexes specified by node_ids will be used.
		  l1: A `Tensor` of type `float32`.
		    l1 regularization factor on leaf weights, per instance based.
		  l2: A `Tensor` of type `float32`.
		    l2 regularization factor on leaf weights, per instance based.
		  tree_complexity: A `Tensor` of type `float32`.
		    adjustment to the gain, per leaf based.
		  min_node_weight: A `Tensor` of type `float32`.
		    minimum avg of hessians in a node before required for the node to be considered for splitting.
		  max_splits: An `int` that is `>= 1`.
		    the number of nodes that can be split in the whole tree. Used as a dimension of output tensors.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (node_ids_list, gains_list, thresholds_list, left_node_contribs_list, right_node_contribs_list).
		
		  node_ids_list: A list with the same length as `stats_summary_list` of `Tensor` objects with type `int32`.
		  gains_list: A list with the same length as `stats_summary_list` of `Tensor` objects with type `float32`.
		  thresholds_list: A list with the same length as `stats_summary_list` of `Tensor` objects with type `int32`.
		  left_node_contribs_list: A list with the same length as `stats_summary_list` of `Tensor` objects with type `float32`.
		  right_node_contribs_list: A list with the same length as `stats_summary_list` of `Tensor` objects with type `float32`.
	**/
	static public function BoostedTreesCalculateBestGainsPerFeature(node_id_range:Dynamic, stats_summary_list:Dynamic, l1:Dynamic, l2:Dynamic, tree_complexity:Dynamic, min_node_weight:Dynamic, max_splits:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Calculates the prior from the training data (the bias) and fills in the first node with the logits' prior. Returns a boolean indicating whether to continue centering.
		
		Args:
		  tree_ensemble_handle: A `Tensor` of type `resource`.
		    Handle to the tree ensemble.
		  mean_gradients: A `Tensor` of type `float32`.
		    A tensor with shape=[logits_dimension] with mean of gradients for a first node.
		  mean_hessians: A `Tensor` of type `float32`.
		    A tensor with shape=[logits_dimension] mean of hessians for a first node.
		  l1: A `Tensor` of type `float32`.
		    l1 regularization factor on leaf weights, per instance based.
		  l2: A `Tensor` of type `float32`.
		    l2 regularization factor on leaf weights, per instance based.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function BoostedTreesCenterBias(tree_ensemble_handle:Dynamic, mean_gradients:Dynamic, mean_hessians:Dynamic, l1:Dynamic, l2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a tree ensemble model and returns a handle to it.
		
		Args:
		  tree_ensemble_handle: A `Tensor` of type `resource`.
		    Handle to the tree ensemble resource to be created.
		  stamp_token: A `Tensor` of type `int64`.
		    Token to use as the initial value of the resource stamp.
		  tree_ensemble_serialized: A `Tensor` of type `string`.
		    Serialized proto of the tree ensemble.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function BoostedTreesCreateEnsemble(tree_ensemble_handle:Dynamic, stamp_token:Dynamic, tree_ensemble_serialized:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Create the Resource for Quantile Streams.
		
		Args:
		  quantile_stream_resource_handle: A `Tensor` of type `resource`.
		    resource; Handle to quantile stream resource.
		  epsilon: A `Tensor` of type `float32`.
		    float; The required approximation error of the stream resource.
		  num_streams: A `Tensor` of type `int64`.
		    int; The number of streams managed by the resource that shares the same epsilon.
		  max_elements: An optional `int`. Defaults to `1099511627776`.
		    int; The maximum number of data points that can be fed to the stream.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function BoostedTreesCreateQuantileStreamResource(quantile_stream_resource_handle:Dynamic, epsilon:Dynamic, num_streams:Dynamic, ?max_elements:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deserializes a serialized tree ensemble config and replaces current tree
		
		ensemble.
		
		Args:
		  tree_ensemble_handle: A `Tensor` of type `resource`.
		    Handle to the tree ensemble.
		  stamp_token: A `Tensor` of type `int64`.
		    Token to use as the new value of the resource stamp.
		  tree_ensemble_serialized: A `Tensor` of type `string`.
		    Serialized proto of the ensemble.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function BoostedTreesDeserializeEnsemble(tree_ensemble_handle:Dynamic, stamp_token:Dynamic, tree_ensemble_serialized:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a handle to a BoostedTreesEnsembleResource
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function BoostedTreesEnsembleResourceHandleOp(?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Debugging/model interpretability outputs for each example.
		
		It traverses all the trees and computes debug metrics for individual examples,
		such as getting split feature ids and logits after each split along the decision
		path used to compute directional feature contributions.
		
		Args:
		  tree_ensemble_handle: A `Tensor` of type `resource`.
		  bucketized_features: A list of at least 1 `Tensor` objects with type `int32`.
		    A list of rank 1 Tensors containing bucket id for each
		    feature.
		  logits_dimension: An `int`.
		    scalar, dimension of the logits, to be used for constructing the protos in
		    examples_debug_outputs_serialized.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function BoostedTreesExampleDebugOutputs(tree_ensemble_handle:Dynamic, bucketized_features:Dynamic, logits_dimension:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Flush the quantile summaries from each quantile stream resource.
		
		An op that outputs a list of quantile summaries of a quantile stream resource.
		Each summary Tensor is rank 2, containing summaries (value, weight, min_rank,
		max_rank) for a single feature.
		
		Args:
		  quantile_stream_resource_handle: A `Tensor` of type `resource`.
		    resource handle referring to a QuantileStreamResource.
		  num_features: An `int` that is `>= 0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `num_features` `Tensor` objects with type `float32`.
	**/
	static public function BoostedTreesFlushQuantileSummaries(quantile_stream_resource_handle:Dynamic, num_features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieves the tree ensemble resource stamp token, number of trees and growing statistics.
		
		Args:
		  tree_ensemble_handle: A `Tensor` of type `resource`.
		    Handle to the tree ensemble.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (stamp_token, num_trees, num_finalized_trees, num_attempted_layers, last_layer_nodes_range).
		
		  stamp_token: A `Tensor` of type `int64`.
		  num_trees: A `Tensor` of type `int32`.
		  num_finalized_trees: A `Tensor` of type `int32`.
		  num_attempted_layers: A `Tensor` of type `int32`.
		  last_layer_nodes_range: A `Tensor` of type `int32`.
	**/
	static public function BoostedTreesGetEnsembleStates(tree_ensemble_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Makes the summary of quantiles for the batch.
		
		An op that takes a list of tensors (one tensor per feature) and outputs the
		quantile summaries for each tensor.
		
		Args:
		  float_values: A list of `Tensor` objects with type `float32`.
		    float; List of Rank 1 Tensors each containing values for a single feature.
		  example_weights: A `Tensor` of type `float32`.
		    float; Rank 1 Tensor with weights per instance.
		  epsilon: A `Tensor` of type `float32`.
		    float; The required maximum approximation error.
		  name: A name for the operation (optional).
		
		Returns:
		  A list with the same length as `float_values` of `Tensor` objects with type `float32`.
	**/
	static public function BoostedTreesMakeQuantileSummaries(float_values:Dynamic, example_weights:Dynamic, epsilon:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Makes the summary of accumulated stats for the batch.
		
		The summary stats contains gradients and hessians accumulated into the corresponding node and bucket for each example.
		
		Args:
		  node_ids: A `Tensor` of type `int32`.
		    int32 Rank 1 Tensor containing node ids, which each example falls into for the requested layer.
		  gradients: A `Tensor` of type `float32`.
		    float32; Rank 2 Tensor (shape=[#examples, 1]) for gradients.
		  hessians: A `Tensor` of type `float32`.
		    float32; Rank 2 Tensor (shape=[#examples, 1]) for hessians.
		  bucketized_features_list: A list of at least 1 `Tensor` objects with type `int32`.
		    int32 list of Rank 1 Tensors, each containing the bucketized feature (for each feature column).
		  max_splits: An `int` that is `>= 1`.
		    int; the maximum number of splits possible in the whole tree.
		  num_buckets: An `int` that is `>= 1`.
		    int; equals to the maximum possible value of bucketized feature.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function BoostedTreesMakeStatsSummary(node_ids:Dynamic, gradients:Dynamic, hessians:Dynamic, bucketized_features_list:Dynamic, max_splits:Dynamic, num_buckets:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Runs multiple additive regression ensemble predictors on input instances and
		
		computes the logits. It is designed to be used during prediction.
		It traverses all the trees and calculates the final score for each instance.
		
		Args:
		  tree_ensemble_handle: A `Tensor` of type `resource`.
		  bucketized_features: A list of at least 1 `Tensor` objects with type `int32`.
		    A list of rank 1 Tensors containing bucket id for each
		    feature.
		  logits_dimension: An `int`.
		    scalar, dimension of the logits, to be used for partial logits
		    shape.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function BoostedTreesPredict(tree_ensemble_handle:Dynamic, bucketized_features:Dynamic, logits_dimension:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Add the quantile summaries to each quantile stream resource.
		
		An op that adds a list of quantile summaries to a quantile stream resource. Each
		summary Tensor is rank 2, containing summaries (value, weight, min_rank, max_rank)
		for a single feature.
		
		Args:
		  quantile_stream_resource_handle: A `Tensor` of type `resource`.
		    resource handle referring to a QuantileStreamResource.
		  summaries: A list of `Tensor` objects with type `float32`.
		    string; List of Rank 2 Tensor each containing the summaries for a single feature.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function BoostedTreesQuantileStreamResourceAddSummaries(quantile_stream_resource_handle:Dynamic, summaries:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deserialize bucket boundaries and ready flag into current QuantileAccumulator.
		
		An op that deserializes bucket boundaries and are boundaries ready flag into current QuantileAccumulator.
		
		Args:
		  quantile_stream_resource_handle: A `Tensor` of type `resource`.
		    resource handle referring to a QuantileStreamResource.
		  bucket_boundaries: A list of at least 1 `Tensor` objects with type `float32`.
		    float; List of Rank 1 Tensors each containing the bucket boundaries for a feature.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function BoostedTreesQuantileStreamResourceDeserialize(quantile_stream_resource_handle:Dynamic, bucket_boundaries:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Flush the summaries for a quantile stream resource.
		
		An op that flushes the summaries for a quantile stream resource.
		
		Args:
		  quantile_stream_resource_handle: A `Tensor` of type `resource`.
		    resource handle referring to a QuantileStreamResource.
		  num_buckets: A `Tensor` of type `int64`.
		    int; approximate number of buckets unless using generate_quantiles.
		  generate_quantiles: An optional `bool`. Defaults to `False`.
		    bool; If True, the output will be the num_quantiles for each stream where the ith
		    entry is the ith quantile of the input with an approximation error of epsilon.
		    Duplicate values may be present.
		    If False, the output will be the points in the histogram that we got which roughly
		    translates to 1/epsilon boundaries and without any duplicates.
		    Default to False.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function BoostedTreesQuantileStreamResourceFlush(quantile_stream_resource_handle:Dynamic, num_buckets:Dynamic, ?generate_quantiles:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generate the bucket boundaries for each feature based on accumulated summaries.
		
		An op that returns a list of float tensors for a quantile stream resource. Each
		tensor is Rank 1 containing bucket boundaries for a single feature.
		
		Args:
		  quantile_stream_resource_handle: A `Tensor` of type `resource`.
		    resource handle referring to a QuantileStreamResource.
		  num_features: An `int` that is `>= 0`.
		    inferred int; number of features to get bucket boundaries for.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `num_features` `Tensor` objects with type `float32`.
	**/
	static public function BoostedTreesQuantileStreamResourceGetBucketBoundaries(quantile_stream_resource_handle:Dynamic, num_features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a handle to a BoostedTreesQuantileStreamResource.
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function BoostedTreesQuantileStreamResourceHandleOp(?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Serializes the tree ensemble to a proto.
		
		Args:
		  tree_ensemble_handle: A `Tensor` of type `resource`.
		    Handle to the tree ensemble.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (stamp_token, tree_ensemble_serialized).
		
		  stamp_token: A `Tensor` of type `int64`.
		  tree_ensemble_serialized: A `Tensor` of type `string`.
	**/
	static public function BoostedTreesSerializeEnsemble(tree_ensemble_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Aggregates the summary of accumulated stats for the batch.
		
		The summary stats contains gradients and hessians accumulated for each node, bucket and dimension id.
		
		Args:
		  node_ids: A `Tensor` of type `int32`.
		    int32; Rank 1 Tensor containing node ids for each example, shape [batch_size].
		  gradients: A `Tensor` of type `float32`.
		    float32; Rank 2 Tensor (shape=[batch_size, logits_dimension]) with gradients for each example.
		  hessians: A `Tensor` of type `float32`.
		    float32; Rank 2 Tensor (shape=[batch_size, hessian_dimension]) with hessians for each example.
		  feature_indices: A `Tensor` of type `int32`.
		    int32; Rank 2 indices of feature sparse Tensors (shape=[number of sparse entries, 2]).
		    Number of sparse entries across all instances from the batch. The first value is
		    the index of the instance, the second is dimension of the feature. The second axis
		    can only have 2 values, i.e., the input dense version of Tensor can only be matrix.
		  feature_values: A `Tensor` of type `int32`.
		    int32; Rank 1 values of feature sparse Tensors (shape=[number of sparse entries]).
		    Number of sparse entries across all instances from the batch. The first value is
		    the index of the instance, the second is dimension of the feature.
		  feature_shape: A `Tensor` of type `int32`.
		    int32; Rank 1 dense shape of feature sparse Tensors (shape=[2]).
		    The first axis can only have 2 values, [batch_size, feature_dimension].
		  max_splits: An `int` that is `>= 1`.
		    int; the maximum number of splits possible in the whole tree.
		  num_buckets: An `int` that is `>= 1`.
		    int; equals to the maximum possible value of bucketized feature + 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (stats_summary_indices, stats_summary_values, stats_summary_shape).
		
		  stats_summary_indices: A `Tensor` of type `int32`.
		  stats_summary_values: A `Tensor` of type `float32`.
		  stats_summary_shape: A `Tensor` of type `int32`.
	**/
	static public function BoostedTreesSparseAggregateStats(node_ids:Dynamic, gradients:Dynamic, hessians:Dynamic, feature_indices:Dynamic, feature_values:Dynamic, feature_shape:Dynamic, max_splits:Dynamic, num_buckets:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Calculates gains for each feature and returns the best possible split information for the feature.
		
		The split information is the best threshold (bucket id), gains and left/right node contributions per node for each feature.
		
		It is possible that not all nodes can be split on each feature. Hence, the list of possible nodes can differ between the features. Therefore, we return `node_ids_list` for each feature, containing the list of nodes that this feature can be used to split.
		
		In this manner, the output is the best split per features and per node, so that it needs to be combined later to produce the best split for each node (among all possible features).
		
		The output shapes are compatible in a way that the first dimension of all tensors are the same and equal to the number of possible split nodes for each feature.
		
		Args:
		  node_id_range: A `Tensor` of type `int32`.
		    A Rank 1 tensor (shape=[2]) to specify the range [first, last) of node ids to process within `stats_summary_list`. The nodes are iterated between the two nodes specified by the tensor, as like `for node_id in range(node_id_range[0], node_id_range[1])` (Note that the last index node_id_range[1] is exclusive).
		  stats_summary_indices: A `Tensor` of type `int32`.
		    A Rank 2 int64 tensor of dense shape [N, 4] (N specifies the number of non-zero values) for accumulated stats summary (gradient/hessian) per node per bucket for each feature. The second dimension contains node id, feature dimension, bucket id, and stats dim.
		    stats dim is the sum of logits dimension and hessian dimension, hessian dimension can either be logits dimension if diagonal hessian is used, or logits dimension^2 if full hessian is used.
		  stats_summary_values: A `Tensor` of type `float32`.
		    A Rank 1 float tensor of dense shape [N] (N specifies the number of non-zero values), which supplies the values for each element in summary_indices.
		  stats_summary_shape: A `Tensor` of type `int32`.
		    A Rank 1 float tensor of dense shape [4], which specifies the dense shape of the sparse tensor, which is [num tree nodes, feature dimensions, num buckets, stats dim].
		  l1: A `Tensor` of type `float32`.
		    l1 regularization factor on leaf weights, per instance based.
		  l2: A `Tensor` of type `float32`.
		    l2 regularization factor on leaf weights, per instance based.
		  tree_complexity: A `Tensor` of type `float32`.
		    adjustment to the gain, per leaf based.
		  min_node_weight: A `Tensor` of type `float32`.
		    minimum avg of hessians in a node before required for the node to be considered for splitting.
		  logits_dimension: An `int` that is `>= 1`.
		    The dimension of logit, i.e., number of classes.
		  split_type: An optional `string` from: `"inequality"`. Defaults to `"inequality"`.
		    A string indicating if this Op should perform inequality split or equality split.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (node_ids, gains, feature_dimensions, thresholds, left_node_contribs, right_node_contribs, split_with_default_directions).
		
		  node_ids: A `Tensor` of type `int32`.
		  gains: A `Tensor` of type `float32`.
		  feature_dimensions: A `Tensor` of type `int32`.
		  thresholds: A `Tensor` of type `int32`.
		  left_node_contribs: A `Tensor` of type `float32`.
		  right_node_contribs: A `Tensor` of type `float32`.
		  split_with_default_directions: A `Tensor` of type `string`.
	**/
	static public function BoostedTreesSparseCalculateBestFeatureSplit(node_id_range:Dynamic, stats_summary_indices:Dynamic, stats_summary_values:Dynamic, stats_summary_shape:Dynamic, l1:Dynamic, l2:Dynamic, tree_complexity:Dynamic, min_node_weight:Dynamic, logits_dimension:Dynamic, ?split_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Runs multiple additive regression ensemble predictors on input instances and
		
		computes the update to cached logits. It is designed to be used during training.
		It traverses the trees starting from cached tree id and cached node id and
		calculates the updates to be pushed to the cache.
		
		Args:
		  tree_ensemble_handle: A `Tensor` of type `resource`.
		  cached_tree_ids: A `Tensor` of type `int32`.
		    Rank 1 Tensor containing cached tree ids which is the starting
		    tree of prediction.
		  cached_node_ids: A `Tensor` of type `int32`.
		    Rank 1 Tensor containing cached node id which is the starting
		    node of prediction.
		  bucketized_features: A list of at least 1 `Tensor` objects with type `int32`.
		    A list of rank 1 Tensors containing bucket id for each
		    feature.
		  logits_dimension: An `int`.
		    scalar, dimension of the logits, to be used for partial logits
		    shape.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (partial_logits, tree_ids, node_ids).
		
		  partial_logits: A `Tensor` of type `float32`.
		  tree_ids: A `Tensor` of type `int32`.
		  node_ids: A `Tensor` of type `int32`.
	**/
	static public function BoostedTreesTrainingPredict(tree_ensemble_handle:Dynamic, cached_tree_ids:Dynamic, cached_node_ids:Dynamic, bucketized_features:Dynamic, logits_dimension:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Updates the tree ensemble by either adding a layer to the last tree being grown
		
		or by starting a new tree.
		
		Args:
		  tree_ensemble_handle: A `Tensor` of type `resource`.
		    Handle to the ensemble variable.
		  feature_ids: A `Tensor` of type `int32`.
		    Rank 1 tensor with ids for each feature. This is the real id of
		    the feature that will be used in the split.
		  node_ids: A list of `Tensor` objects with type `int32`.
		    List of rank 1 tensors representing the nodes for which this feature
		    has a split.
		  gains: A list with the same length as `node_ids` of `Tensor` objects with type `float32`.
		    List of rank 1 tensors representing the gains for each of the feature's
		    split.
		  thresholds: A list with the same length as `node_ids` of `Tensor` objects with type `int32`.
		    List of rank 1 tensors representing the thesholds for each of the
		    feature's split.
		  left_node_contribs: A list with the same length as `node_ids` of `Tensor` objects with type `float32`.
		    List of rank 2 tensors with left leaf contribs for each of
		    the feature's splits. Will be added to the previous node values to constitute
		    the values of the left nodes.
		  right_node_contribs: A list with the same length as `node_ids` of `Tensor` objects with type `float32`.
		    List of rank 2 tensors with right leaf contribs for each
		    of the feature's splits. Will be added to the previous node values to constitute
		    the values of the right nodes.
		  max_depth: A `Tensor` of type `int32`. Max depth of the tree to build.
		  learning_rate: A `Tensor` of type `float32`.
		    shrinkage const for each new tree.
		  pruning_mode: An `int` that is `>= 0`.
		    0-No pruning, 1-Pre-pruning, 2-Post-pruning.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function BoostedTreesUpdateEnsemble(tree_ensemble_handle:Dynamic, feature_ids:Dynamic, node_ids:Dynamic, gains:Dynamic, thresholds:Dynamic, left_node_contribs:Dynamic, right_node_contribs:Dynamic, max_depth:Dynamic, learning_rate:Dynamic, pruning_mode:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Updates the tree ensemble by adding a layer to the last tree being grown
		
		or by starting a new tree.
		
		Args:
		  tree_ensemble_handle: A `Tensor` of type `resource`.
		    Handle to the ensemble variable.
		  feature_ids: A list of at least 1 `Tensor` objects with type `int32`.
		    Rank 1 tensor with ids for each feature. This is the real id of
		    the feature that will be used in the split.
		  dimension_ids: A list of `Tensor` objects with type `int32`.
		    List of rank 1 tensors representing the dimension in each feature.
		  node_ids: A list with the same length as `dimension_ids` of `Tensor` objects with type `int32`.
		    List of rank 1 tensors representing the nodes for which this feature
		    has a split.
		  gains: A list with the same length as `dimension_ids` of `Tensor` objects with type `float32`.
		    List of rank 1 tensors representing the gains for each of the feature's
		    split.
		  thresholds: A list with the same length as `dimension_ids` of `Tensor` objects with type `int32`.
		    List of rank 1 tensors representing the thesholds for each of the
		    feature's split.
		  left_node_contribs: A list with the same length as `dimension_ids` of `Tensor` objects with type `float32`.
		    List of rank 2 tensors with left leaf contribs for each of
		    the feature's splits. Will be added to the previous node values to constitute
		    the values of the left nodes.
		  right_node_contribs: A list with the same length as `dimension_ids` of `Tensor` objects with type `float32`.
		    List of rank 2 tensors with right leaf contribs for each
		    of the feature's splits. Will be added to the previous node values to constitute
		    the values of the right nodes.
		  split_types: A list with the same length as `dimension_ids` of `Tensor` objects with type `string`.
		    List of rank 1 tensors representing the split type for each feature.
		  max_depth: A `Tensor` of type `int32`. Max depth of the tree to build.
		  learning_rate: A `Tensor` of type `float32`.
		    shrinkage const for each new tree.
		  pruning_mode: A `Tensor` of type `int32`.
		    0-No pruning, 1-Pre-pruning, 2-Post-pruning.
		  logits_dimension: An optional `int`. Defaults to `1`.
		    scalar, dimension of the logits
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function BoostedTreesUpdateEnsembleV2(tree_ensemble_handle:Dynamic, feature_ids:Dynamic, dimension_ids:Dynamic, node_ids:Dynamic, gains:Dynamic, thresholds:Dynamic, left_node_contribs:Dynamic, right_node_contribs:Dynamic, split_types:Dynamic, max_depth:Dynamic, learning_rate:Dynamic, pruning_mode:Dynamic, ?logits_dimension:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return the shape of s0 op s1 with broadcast.
		
		Given `s0` and `s1`, tensors that represent shapes, compute `r0`, the
		broadcasted shape. `s0`, `s1` and `r0` are all integer vectors.
		
		Args:
		  s0: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  s1: A `Tensor`. Must have the same type as `s0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `s0`.
	**/
	static public function BroadcastArgs(s0:Dynamic, s1:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return the reduction indices for computing gradients of s0 op s1 with broadcast.
		
		This is typically used by gradient computations for a broadcasting operation.
		
		Args:
		  s0: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  s1: A `Tensor`. Must have the same type as `s0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (r0, r1).
		
		  r0: A `Tensor`. Has the same type as `s0`.
		  r1: A `Tensor`. Has the same type as `s0`.
	**/
	static public function BroadcastGradientArgs(s0:Dynamic, s1:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Broadcast an array for a compatible shape.
		
		Broadcasting is the process of making arrays to have compatible shapes
		for arithmetic operations. Two shapes are compatible if for each
		dimension pair they are either equal or one of them is one. When trying
		to broadcast a Tensor to a shape, it starts with the trailing dimensions,
		and works its way forward.
		
		For example,
		
		>>> x = tf.constant([1, 2, 3])
		>>> y = tf.broadcast_to(x, [3, 3])
		>>> print(y)
		tf.Tensor(
		    [[1 2 3]
		     [1 2 3]
		     [1 2 3]], shape=(3, 3), dtype=int32)
		
		In the above example, the input Tensor with the shape of `[1, 3]`
		is broadcasted to output Tensor with shape of `[3, 3]`.
		
		When doing broadcasted operations such as multiplying a tensor
		by a scalar, broadcasting (usually) confers some time or space
		benefit, as the broadcasted tensor is never materialized.
		
		However, `broadcast_to` does not carry with it any such benefits.
		The newly-created tensor takes the full memory of the broadcasted
		shape. (In a graph context, `broadcast_to` might be fused to
		subsequent operation and then be optimized away, however.)
		
		Args:
		  input: A `Tensor`. A Tensor to broadcast.
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    An 1-D `int` Tensor. The shape of the desired output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function BroadcastTo(input:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Bucketizes 'input' based on 'boundaries'.
		
		For example, if the inputs are
		    boundaries = [0, 10, 100]
		    input = [[-5, 10000]
		             [150,   10]
		             [5,    100]]
		
		then the output will be
		    output = [[0, 3]
		              [3, 2]
		              [1, 3]]
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.
		    Any shape of Tensor contains with int or float type.
		  boundaries: A list of `floats`.
		    A sorted list of floats gives the boundary of the buckets.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function Bucketize(input:Dynamic, boundaries:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Records the bytes size of each element of `input_dataset` in a StatsAggregator.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  tag: A `Tensor` of type `string`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function BytesProducedStatsDataset(input_dataset:Dynamic, tag:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reads out the CSR components at batch `index`.
		
		This op is meant only for debugging / testing, and its interface is not expected
		to be stable.
		
		Args:
		  csr_sparse_matrix: A `Tensor` of type `variant`.
		    A batched CSRSparseMatrix.
		  index: A `Tensor` of type `int32`.
		    The index in `csr_sparse_matrix`'s batch.
		  type: A `tf.DType` from: `tf.float32, tf.float64, tf.complex64, tf.complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (row_ptrs, col_inds, values).
		
		  row_ptrs: A `Tensor` of type `int32`.
		  col_inds: A `Tensor` of type `int32`.
		  values: A `Tensor` of type `type`.
	**/
	static public function CSRSparseMatrixComponents(csr_sparse_matrix:Dynamic, index:Dynamic, type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Convert a (possibly batched) CSRSparseMatrix to dense.
		
		Args:
		  sparse_input: A `Tensor` of type `variant`. A batched CSRSparseMatrix.
		  type: A `tf.DType` from: `tf.float32, tf.float64, tf.complex64, tf.complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `type`.
	**/
	static public function CSRSparseMatrixToDense(sparse_input:Dynamic, type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts a (possibly batched) CSRSparesMatrix to a SparseTensor.
		
		Args:
		  sparse_matrix: A `Tensor` of type `variant`.
		    A (possibly batched) CSRSparseMatrix.
		  type: A `tf.DType` from: `tf.float32, tf.float64, tf.complex64, tf.complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (indices, values, dense_shape).
		
		  indices: A `Tensor` of type `int64`.
		  values: A `Tensor` of type `type`.
		  dense_shape: A `Tensor` of type `int64`.
	**/
	static public function CSRSparseMatrixToSparseTensor(sparse_matrix:Dynamic, type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  filenames: A `Tensor` of type `string`.
		  compression_type: A `Tensor` of type `string`.
		  buffer_size: A `Tensor` of type `int64`.
		  header: A `Tensor` of type `bool`.
		  field_delim: A `Tensor` of type `string`.
		  use_quote_delim: A `Tensor` of type `bool`.
		  na_value: A `Tensor` of type `string`.
		  select_cols: A `Tensor` of type `int64`.
		  record_defaults: A list of `Tensor` objects with types from: `float32`, `float64`, `int32`, `int64`, `string`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function CSVDataset(filenames:Dynamic, compression_type:Dynamic, buffer_size:Dynamic, header:Dynamic, field_delim:Dynamic, use_quote_delim:Dynamic, na_value:Dynamic, select_cols:Dynamic, record_defaults:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  filenames: A `Tensor` of type `string`.
		  compression_type: A `Tensor` of type `string`.
		  buffer_size: A `Tensor` of type `int64`.
		  header: A `Tensor` of type `bool`.
		  field_delim: A `Tensor` of type `string`.
		  use_quote_delim: A `Tensor` of type `bool`.
		  na_value: A `Tensor` of type `string`.
		  select_cols: A `Tensor` of type `int64`.
		  record_defaults: A list of `Tensor` objects with types from: `float32`, `float64`, `int32`, `int64`, `string`.
		  exclude_cols: A `Tensor` of type `int64`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function CSVDatasetV2(filenames:Dynamic, compression_type:Dynamic, buffer_size:Dynamic, header:Dynamic, field_delim:Dynamic, use_quote_delim:Dynamic, na_value:Dynamic, select_cols:Dynamic, record_defaults:Dynamic, exclude_cols:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs beam search decoding on the logits given in input.
		
		A note about the attribute merge_repeated: For the beam search decoder,
		this means that if consecutive entries in a beam are the same, only
		the first of these is emitted.  That is, when the top path is "A B B B B",
		"A B" is returned if merge_repeated = True but "A B B B B" is
		returned if merge_repeated = False.
		
		Args:
		  inputs: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		    3-D, shape: `(max_time x batch_size x num_classes)`, the logits.
		  sequence_length: A `Tensor` of type `int32`.
		    A vector containing sequence lengths, size `(batch)`.
		  beam_width: An `int` that is `>= 1`.
		    A scalar >= 0 (beam search beam width).
		  top_paths: An `int` that is `>= 1`.
		    A scalar >= 0, <= beam_width (controls output size).
		  merge_repeated: An optional `bool`. Defaults to `True`.
		    If true, merge repeated classes in output.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (decoded_indices, decoded_values, decoded_shape, log_probability).
		
		  decoded_indices: A list of `top_paths` `Tensor` objects with type `int64`.
		  decoded_values: A list of `top_paths` `Tensor` objects with type `int64`.
		  decoded_shape: A list of `top_paths` `Tensor` objects with type `int64`.
		  log_probability: A `Tensor`. Has the same type as `inputs`.
	**/
	static public function CTCBeamSearchDecoder(inputs:Dynamic, sequence_length:Dynamic, beam_width:Dynamic, top_paths:Dynamic, ?merge_repeated:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs greedy decoding on the logits given in inputs.
		
		A note about the attribute merge_repeated: if enabled, when
		consecutive logits' maximum indices are the same, only the first of
		these is emitted.  Labeling the blank '*', the sequence "A B B * B B"
		becomes "A B B" if merge_repeated = True and "A B B B B" if
		merge_repeated = False.
		
		Regardless of the value of merge_repeated, if the maximum index of a given
		time and batch corresponds to the blank, index `(num_classes - 1)`, no new
		element is emitted.
		
		Args:
		  inputs: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		    3-D, shape: `(max_time x batch_size x num_classes)`, the logits.
		  sequence_length: A `Tensor` of type `int32`.
		    A vector containing sequence lengths, size `(batch_size)`.
		  merge_repeated: An optional `bool`. Defaults to `False`.
		    If True, merge repeated classes in output.
		  blank_index: An optional `int`. Defaults to `-1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (decoded_indices, decoded_values, decoded_shape, log_probability).
		
		  decoded_indices: A `Tensor` of type `int64`.
		  decoded_values: A `Tensor` of type `int64`.
		  decoded_shape: A `Tensor` of type `int64`.
		  log_probability: A `Tensor`. Has the same type as `inputs`.
	**/
	static public function CTCGreedyDecoder(inputs:Dynamic, sequence_length:Dynamic, ?merge_repeated:Dynamic, ?blank_index:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Calculates the CTC Loss (log probability) for each batch entry.  Also calculates
		
		the gradient.  This class performs the softmax operation for you, so inputs
		should be e.g. linear projections of outputs by an LSTM.
		
		Args:
		  inputs: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		    3-D, shape: `(max_time x batch_size x num_classes)`, the logits.
		  labels_indices: A `Tensor` of type `int64`.
		    The indices of a `SparseTensor<int32, 2>`.
		    `labels_indices(i, :) == [b, t]` means `labels_values(i)` stores the id for
		    `(batch b, time t)`.
		  labels_values: A `Tensor` of type `int32`.
		    The values (labels) associated with the given batch and time.
		  sequence_length: A `Tensor` of type `int32`.
		    A vector containing sequence lengths (batch).
		  preprocess_collapse_repeated: An optional `bool`. Defaults to `False`.
		    Scalar, if true then repeated labels are
		    collapsed prior to the CTC calculation.
		  ctc_merge_repeated: An optional `bool`. Defaults to `True`.
		    Scalar.  If set to false, *during* CTC calculation
		    repeated non-blank labels will not be merged and are interpreted as
		    individual labels.  This is a simplified version of CTC.
		  ignore_longer_outputs_than_inputs: An optional `bool`. Defaults to `False`.
		    Scalar. If set to true, during CTC
		    calculation, items that have longer output sequences than input sequences
		    are skipped: they don't contribute to the loss term and have zero-gradient.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (loss, gradient).
		
		  loss: A `Tensor`. Has the same type as `inputs`.
		  gradient: A `Tensor`. Has the same type as `inputs`.
	**/
	static public function CTCLoss(inputs:Dynamic, labels_indices:Dynamic, labels_values:Dynamic, sequence_length:Dynamic, ?preprocess_collapse_repeated:Dynamic, ?ctc_merge_repeated:Dynamic, ?ignore_longer_outputs_than_inputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Calculates the CTC Loss (log probability) for each batch entry.  Also calculates
		
		the gradient.  This class performs the softmax operation for you, so inputs
		should be e.g. linear projections of outputs by an LSTM.
		
		Args:
		  inputs: A `Tensor` of type `float32`.
		    3-D, shape: `(max_time x batch_size x num_classes)`, the logits. Default blank
		    label is 0 rather num_classes - 1.
		  labels_indices: A `Tensor` of type `int64`.
		    The indices of a `SparseTensor<int32, 2>`.
		    `labels_indices(i, :) == [b, t]` means `labels_values(i)` stores the id for
		    `(batch b, time t)`.
		  labels_values: A `Tensor` of type `int32`.
		    The values (labels) associated with the given batch and time.
		  sequence_length: A `Tensor` of type `int32`.
		    A vector containing sequence lengths (batch).
		  preprocess_collapse_repeated: An optional `bool`. Defaults to `False`.
		    Scalar, if true then repeated labels are
		    collapsed prior to the CTC calculation.
		  ctc_merge_repeated: An optional `bool`. Defaults to `True`.
		    Scalar.  If set to false, *during* CTC calculation
		    repeated non-blank labels will not be merged and are interpreted as
		    individual labels.  This is a simplified version of CTC.
		  ignore_longer_outputs_than_inputs: An optional `bool`. Defaults to `False`.
		    Scalar. If set to true, during CTC
		    calculation, items that have longer output sequences than input sequences
		    are skipped: they don't contribute to the loss term and have zero-gradient.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (loss, gradient).
		
		  loss: A `Tensor` of type `float32`.
		  gradient: A `Tensor` of type `float32`.
	**/
	static public function CTCLossV2(inputs:Dynamic, labels_indices:Dynamic, labels_values:Dynamic, sequence_length:Dynamic, ?preprocess_collapse_repeated:Dynamic, ?ctc_merge_repeated:Dynamic, ?ignore_longer_outputs_than_inputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that caches elements from `input_dataset`.
		
		A CacheDataset will iterate over the input_dataset, and store tensors. If the
		cache already exists, the cache will be used. If the cache is inappropriate
		(e.g. cannot be opened, contains tensors of the wrong shape / size), an error
		will the returned when used.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  filename: A `Tensor` of type `string`.
		    A path on the filesystem where we should cache the dataset. Note: this
		    will be a directory.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function CacheDataset(input_dataset:Dynamic, filename:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  filename: A `Tensor` of type `string`.
		  cache: A `Tensor` of type `resource`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function CacheDatasetV2(input_dataset:Dynamic, filename:Dynamic, cache:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An n-way switch statement which calls a single branch function.
		
		    An n-way switch statement, implementing the following:
		    ```
		    switch (branch_index) {
		      case 0:
		        output = branches[0](input);
		        break;
		      case 1:
		        output = branches[1](input);
		        break;
		      ...
		      case [[nbranches-1]]:
		      default:
		        output = branches[nbranches-1](input);
		        break;
		    }
		    ```
		
		Args:
		  branch_index: A `Tensor` of type `int32`.
		    The branch selector, an int32 Tensor.
		  input: A list of `Tensor` objects.
		    A list of input tensors passed to the branch function.
		  Tout: A list of `tf.DTypes`. A list of output types.
		  branches: A list of functions decorated with @Defun that has length `>= 1`.
		          A list of functions each of which takes 'inputs' and returns a list of
		          tensors, whose types are the same as what every other branch returns.
		  output_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function Case(branch_index:Dynamic, input:Dynamic, Tout:Dynamic, branches:Dynamic, ?output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Cast x of type SrcT to y of DstT.
		
		Args:
		  x: A `Tensor`.
		  DstT: A `tf.DType`.
		  Truncate: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `DstT`.
	**/
	static public function Cast(x:Dynamic, DstT:Dynamic, ?Truncate:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns element-wise smallest integer not less than x.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Ceil(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Checks a tensor for NaN and Inf values.
		
		When run, reports an `InvalidArgument` error if `tensor` has any values
		that are not a number (NaN) or infinity (Inf). Otherwise, returns the input
		tensor.
		
		Example usage:
		
		``` python
		a = tf.Variable(1.0)
		tf.debugging.check_numerics(a, message='')
		
		b = tf.Variable(np.nan)
		try:
		  tf.debugging.check_numerics(b, message='Checking b')
		except Exception as e:
		  assert "Checking b : Tensor had NaN values" in e.message
		
		c = tf.Variable(np.inf)
		try:
		  tf.debugging.check_numerics(c, message='Checking c')
		except Exception as e:
		  assert "Checking c : Tensor had Inf values" in e.message
		```
		
		Args:
		  tensor: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  message: A `string`. Prefix of the error message.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `tensor`.
	**/
	static public function CheckNumerics(tensor:Dynamic, message:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Checks a tensor for NaN, -Inf and +Inf values.
		
		When run, reports an `InvalidArgument` error if `tensor` has any values
		that are not a number (NaN) or infinity (Inf). Otherwise, returns the input
		tensor. Unlike CheckNumerics (V1), CheckNumericsV2 distinguishes -Inf and +Inf
		in the errors it throws.
		
		Args:
		  tensor: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  message: A `string`. Prefix of the error message.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `tensor`.
	**/
	static public function CheckNumericsV2(tensor:Dynamic, message:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the Cholesky decomposition of one or more square matrices.
		
		The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
		form square matrices.
		
		The input has to be symmetric and positive definite. Only the lower-triangular
		part of the input will be used for this operation. The upper-triangular part
		will not be read.
		
		The output is a tensor of the same shape as the input
		containing the Cholesky decompositions for all input submatrices `[..., :, :]`.
		
		**Note**: The gradient computation on GPU is faster for large matrices but
		not for large batch dimensions when the submatrices are small. In this
		case it might be faster to use the CPU.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		    Shape is `[..., M, M]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Cholesky(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the reverse mode backpropagated gradient of the Cholesky algorithm.
		
		For an explanation see "Differentiation of the Cholesky algorithm" by
		Iain Murray http://arxiv.org/abs/1602.07527.
		
		Args:
		  l: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		    Output of batch Cholesky algorithm l = cholesky(A). Shape is `[..., M, M]`.
		    Algorithm depends only on lower triangular part of the innermost matrices of
		    this tensor.
		  grad: A `Tensor`. Must have the same type as `l`.
		    df/dl where f is some scalar function. Shape is `[..., M, M]`.
		    Algorithm depends only on lower triangular part of the innermost matrices of
		    this tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `l`.
	**/
	static public function CholeskyGrad(l:Dynamic, grad:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  ratio_numerator: A `Tensor` of type `int64`.
		  ratio_denominator: A `Tensor` of type `int64`.
		  other_arguments: A list of `Tensor` objects.
		  num_elements_per_branch: An `int` that is `>= 1`.
		  branches: A list of functions decorated with @Defun that has length `>= 1`.
		  other_arguments_lengths: A list of `ints` that has length `>= 1`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ChooseFastestBranchDataset(input_dataset:Dynamic, ratio_numerator:Dynamic, ratio_denominator:Dynamic, other_arguments:Dynamic, num_elements_per_branch:Dynamic, branches:Dynamic, other_arguments_lengths:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_datasets: A list of at least 2 `Tensor` objects with type `variant`.
		  num_experiments: An `int`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ChooseFastestDataset(input_datasets:Dynamic, num_experiments:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Clips tensor values to a specified min and max.
		
		Given a tensor `t`, this operation returns a tensor of the same type and
		shape as `t` with its values clipped to `clip_value_min` and `clip_value_max`.
		Any values less than `clip_value_min` are set to `clip_value_min`. Any values
		greater than `clip_value_max` are set to `clip_value_max`.
		
		Args:
		  t: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A `Tensor`.
		  clip_value_min: A `Tensor`. Must have the same type as `t`.
		    A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape
		    as `t`. The minimum value to clip by.
		  clip_value_max: A `Tensor`. Must have the same type as `t`.
		    A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape
		    as `t`. The maximum value to clip by.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `t`.
	**/
	static public function ClipByValue(t:Dynamic, clip_value_min:Dynamic, clip_value_max:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function CloseSummaryWriter(writer:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Mutually exchanges multiple tensors of identical type and shape.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bfloat16`, `float32`, `half`, `float64`, `int32`, `int64`.
		  communicator: A `Tensor` of type `resource`.
		  group_assignment: A `Tensor` of type `int32`.
		  timeout_seconds: An optional `float`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function CollectiveAllToAllV3(input:Dynamic, communicator:Dynamic, group_assignment:Dynamic, ?timeout_seconds:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Receives a tensor value broadcast from another device.
		
		Args:
		  T: A `tf.DType` from: `tf.bool, tf.float32, tf.half, tf.float64, tf.int32, tf.int64`.
		  group_size: An `int`.
		  group_key: An `int`.
		  instance_key: An `int`.
		  shape: A `tf.TensorShape` or list of `ints`.
		  communication_hint: An optional `string`. Defaults to `"auto"`.
		  timeout_seconds: An optional `float`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `T`.
	**/
	static public function CollectiveBcastRecv(T:Dynamic, group_size:Dynamic, group_key:Dynamic, instance_key:Dynamic, shape:Dynamic, ?communication_hint:Dynamic, ?timeout_seconds:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Receives a tensor value broadcast from another device.
		
		Args:
		  group_size: A `Tensor` of type `int32`.
		  group_key: A `Tensor` of type `int32`.
		  instance_key: A `Tensor` of type `int32`.
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  T: A `tf.DType` from: `tf.bool, tf.float32, tf.half, tf.float64, tf.int32, tf.int64`.
		  communication_hint: An optional `string`. Defaults to `"auto"`.
		  timeout_seconds: An optional `float`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `T`.
	**/
	static public function CollectiveBcastRecvV2(group_size:Dynamic, group_key:Dynamic, instance_key:Dynamic, shape:Dynamic, T:Dynamic, ?communication_hint:Dynamic, ?timeout_seconds:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Broadcasts a tensor value to one or more other devices.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bool`, `float32`, `half`, `float64`, `int32`, `int64`.
		  group_size: An `int`.
		  group_key: An `int`.
		  instance_key: An `int`.
		  shape: A `tf.TensorShape` or list of `ints`.
		  communication_hint: An optional `string`. Defaults to `"auto"`.
		  timeout_seconds: An optional `float`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function CollectiveBcastSend(input:Dynamic, group_size:Dynamic, group_key:Dynamic, instance_key:Dynamic, shape:Dynamic, ?communication_hint:Dynamic, ?timeout_seconds:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Broadcasts a tensor value to one or more other devices.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bool`, `float32`, `half`, `float64`, `int32`, `int64`.
		  group_size: A `Tensor` of type `int32`.
		  group_key: A `Tensor` of type `int32`.
		  instance_key: A `Tensor` of type `int32`.
		  communication_hint: An optional `string`. Defaults to `"auto"`.
		  timeout_seconds: An optional `float`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function CollectiveBcastSendV2(input:Dynamic, group_size:Dynamic, group_key:Dynamic, instance_key:Dynamic, ?communication_hint:Dynamic, ?timeout_seconds:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Mutually accumulates multiple tensors of identical type and shape.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `half`, `float64`, `int32`, `int64`.
		  group_size: An `int`.
		  group_key: An `int`.
		  instance_key: An `int`.
		  shape: A `tf.TensorShape` or list of `ints`.
		  communication_hint: An optional `string`. Defaults to `"auto"`.
		  timeout_seconds: An optional `float`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function CollectiveGather(input:Dynamic, group_size:Dynamic, group_key:Dynamic, instance_key:Dynamic, shape:Dynamic, ?communication_hint:Dynamic, ?timeout_seconds:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Mutually accumulates multiple tensors of identical type and shape.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `half`, `float64`, `int32`, `int64`.
		  group_size: A `Tensor` of type `int32`.
		  group_key: A `Tensor` of type `int32`.
		  instance_key: A `Tensor` of type `int32`.
		  ordering_token: A list of `Tensor` objects with type `resource`.
		  communication_hint: An optional `string`. Defaults to `"auto"`.
		  timeout_seconds: An optional `float`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function CollectiveGatherV2(input:Dynamic, group_size:Dynamic, group_key:Dynamic, instance_key:Dynamic, ordering_token:Dynamic, ?communication_hint:Dynamic, ?timeout_seconds:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Initializes a group for collective operations.
		
		Args:
		  group_key: A `Tensor` of type `int32`.
		  rank: A `Tensor` of type `int32`.
		  group_size: A `Tensor` of type `int32`.
		  communication_hint: An optional `string`. Defaults to `"auto"`.
		  timeout_seconds: An optional `float`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function CollectiveInitializeCommunicator(group_key:Dynamic, rank:Dynamic, group_size:Dynamic, ?communication_hint:Dynamic, ?timeout_seconds:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An Op to permute tensors across replicated TPU instances.
		
		Each instance supplies its own input.
		
		For example, suppose there are 4 TPU instances: `[A, B, C, D]`. Passing
		source_target_pairs=`[[0,1],[1,2],[2,3],[3,0]]` gets the outputs:
		`[D, A, B, C]`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    The local input to be permuted. Currently only supports float and
		    bfloat16.
		  source_target_pairs: A `Tensor` of type `int32`.
		    A tensor with shape [num_pairs, 2].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function CollectivePermute(input:Dynamic, source_target_pairs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Mutually reduces multiple tensors of identical type and shape.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bfloat16`, `float32`, `half`, `float64`, `int32`, `int64`.
		  group_size: An `int`.
		  group_key: An `int`.
		  instance_key: An `int`.
		  merge_op: A `string` from: `"Min", "Max", "Mul", "Add"`.
		  final_op: A `string` from: `"Id", "Div"`.
		  subdiv_offsets: A list of `ints`.
		  wait_for: An optional list of `ints`. Defaults to `[]`.
		  communication_hint: An optional `string`. Defaults to `"auto"`.
		  timeout_seconds: An optional `float`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function CollectiveReduce(input:Dynamic, group_size:Dynamic, group_key:Dynamic, instance_key:Dynamic, merge_op:Dynamic, final_op:Dynamic, subdiv_offsets:Dynamic, ?wait_for:Dynamic, ?communication_hint:Dynamic, ?timeout_seconds:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Mutually reduces multiple tensors of identical type and shape.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bfloat16`, `float32`, `half`, `float64`, `int32`, `int64`.
		  group_size: A `Tensor` of type `int32`.
		  group_key: A `Tensor` of type `int32`.
		  instance_key: A `Tensor` of type `int32`.
		  ordering_token: A list of `Tensor` objects with type `resource`.
		  merge_op: A `string` from: `"Min", "Max", "Mul", "Add"`.
		  final_op: A `string` from: `"Id", "Div"`.
		  communication_hint: An optional `string`. Defaults to `"auto"`.
		  timeout_seconds: An optional `float`. Defaults to `0`.
		  max_subdivs_per_device: An optional `int`. Defaults to `-1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function CollectiveReduceV2(input:Dynamic, group_size:Dynamic, group_key:Dynamic, instance_key:Dynamic, ordering_token:Dynamic, merge_op:Dynamic, final_op:Dynamic, ?communication_hint:Dynamic, ?timeout_seconds:Dynamic, ?max_subdivs_per_device:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Mutually reduces multiple tensors of identical type and shape.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bfloat16`, `float32`, `half`, `float64`, `int32`, `int64`.
		  communicator: A `Tensor` of type `resource`.
		  group_assignment: A `Tensor` of type `int32`.
		  reduction: A `string` from: `"Min", "Max", "Mul", "Add"`.
		  timeout_seconds: An optional `float`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function CollectiveReduceV3(input:Dynamic, communicator:Dynamic, group_assignment:Dynamic, reduction:Dynamic, ?timeout_seconds:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Greedily selects a subset of bounding boxes in descending order of score,
		
		This operation performs non_max_suppression on the inputs per batch, across
		all classes.
		Prunes away boxes that have high intersection-over-union (IOU) overlap
		with previously selected boxes.  Bounding boxes are supplied as
		[y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
		diagonal pair of box corners and the coordinates can be provided as normalized
		(i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
		is agnostic to where the origin is in the coordinate system. Also note that
		this algorithm is invariant to orthogonal transformations and translations
		of the coordinate system; thus translating or reflections of the coordinate
		system result in the same boxes being selected by the algorithm.
		The output of this operation is the final boxes, scores and classes tensor
		returned after performing non_max_suppression.
		
		Args:
		  boxes: A `Tensor` of type `float32`.
		    A 4-D float tensor of shape `[batch_size, num_boxes, q, 4]`. If `q` is 1 then
		    same boxes are used for all classes otherwise, if `q` is equal to number of
		    classes, class-specific boxes are used.
		  scores: A `Tensor` of type `float32`.
		    A 3-D float tensor of shape `[batch_size, num_boxes, num_classes]`
		    representing a single score corresponding to each box (each row of boxes).
		  max_output_size_per_class: A `Tensor` of type `int32`.
		    A scalar integer tensor representing the maximum number of
		    boxes to be selected by non max suppression per class
		  max_total_size: A `Tensor` of type `int32`.
		    An int32 scalar representing the maximum number of boxes retained over all
		    classes. Note that setting this value to a large number may result in OOM error
		    depending on the system workload.
		  iou_threshold: A `Tensor` of type `float32`.
		    A 0-D float tensor representing the threshold for deciding whether
		    boxes overlap too much with respect to IOU.
		  score_threshold: A `Tensor` of type `float32`.
		    A 0-D float tensor representing the threshold for deciding when to remove
		    boxes based on score.
		  pad_per_class: An optional `bool`. Defaults to `False`.
		    If false, the output nmsed boxes, scores and classes
		    are padded/clipped to `max_total_size`. If true, the
		    output nmsed boxes, scores and classes are padded to be of length
		    `max_size_per_class`*`num_classes`, unless it exceeds `max_total_size` in
		    which case it is clipped to `max_total_size`. Defaults to false.
		  clip_boxes: An optional `bool`. Defaults to `True`.
		    If true, assume the box coordinates are between [0, 1] and clip the output boxes
		    if they fall beyond [0, 1]. If false, do not do clipping and output the box
		    coordinates as it is.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (nmsed_boxes, nmsed_scores, nmsed_classes, valid_detections).
		
		  nmsed_boxes: A `Tensor` of type `float32`.
		  nmsed_scores: A `Tensor` of type `float32`.
		  nmsed_classes: A `Tensor` of type `float32`.
		  valid_detections: A `Tensor` of type `int32`.
	**/
	static public function CombinedNonMaxSuppression(boxes:Dynamic, scores:Dynamic, max_output_size_per_class:Dynamic, max_total_size:Dynamic, iou_threshold:Dynamic, score_threshold:Dynamic, ?pad_per_class:Dynamic, ?clip_boxes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts two real numbers to a complex number.
		
		Given a tensor `real` representing the real part of a complex number, and a
		tensor `imag` representing the imaginary part of a complex number, this
		operation returns complex numbers elementwise of the form \\(a + bj\\), where
		*a* represents the `real` part and *b* represents the `imag` part.
		
		The input tensors `real` and `imag` must have the same shape.
		
		For example:
		
		```
		# tensor 'real' is [2.25, 3.25]
		# tensor `imag` is [4.75, 5.75]
		tf.complex(real, imag) ==> [[2.25 + 4.75j], [3.25 + 5.75j]]
		```
		
		Args:
		  real: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		  imag: A `Tensor`. Must have the same type as `real`.
		  Tout: An optional `tf.DType` from: `tf.complex64, tf.complex128`. Defaults to `tf.complex64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Tout`.
	**/
	static public function Complex(real:Dynamic, imag:Dynamic, ?Tout:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the complex absolute value of a tensor.
		
		Given a tensor `x` of complex numbers, this operation returns a tensor of type
		`float` or `double` that is the absolute value of each element in `x`. All
		elements in `x` must be complex numbers of the form \\(a + bj\\). The absolute
		value is computed as \\( \sqrt{a^2 + b^2}\\).
		
		For example:
		
		>>> x = tf.complex(3.0, 4.0)
		>>> print((tf.raw_ops.ComplexAbs(x=x, Tout=tf.dtypes.float32, name=None)).numpy())
		5.0
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		  Tout: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Tout`.
	**/
	static public function ComplexAbs(x:Dynamic, ?Tout:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Encodes an `ExtensionType` value into a `variant` scalar Tensor.
		
		Returns a scalar variant tensor containing a single `CompositeTensorVariant`
		with the specified Tensor components and TypeSpec.
		
		Args:
		  components: A list of `Tensor` objects.
		    The component tensors for the extension type value.
		  metadata: A `string`.
		    String serialization for the TypeSpec.  (Note: the encoding for the TypeSpec
		    may change in future versions of TensorFlow.)
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function CompositeTensorVariantFromComponents(components:Dynamic, metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decodes a `variant` scalar Tensor into an `ExtensionType` value.
		
		Returns the Tensor components encoded in a `CompositeTensorVariant`.
		
		Raises an error if `type_spec_proto` doesn't match the TypeSpec
		in `encoded`.
		
		Args:
		  encoded: A `Tensor` of type `variant`.
		    A scalar `variant` Tensor containing an encoded ExtensionType value.
		  metadata: A `string`.
		    String serialization for the TypeSpec.  Must be compatible with the
		    `TypeSpec` contained in `encoded`.  (Note: the encoding for the TypeSpec
		    may change in future versions of TensorFlow.)
		  Tcomponents: A list of `tf.DTypes`. Expected dtypes for components.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tcomponents`.
	**/
	static public function CompositeTensorVariantToComponents(encoded:Dynamic, metadata:Dynamic, Tcomponents:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compresses a dataset element.
		
		Args:
		  components: A list of `Tensor` objects.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function CompressElement(components:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the ids of the positions in sampled_candidates that match true_labels.
		
		When doing log-odds NCE, the result of this op should be passed through a
		SparseToDense op, then added to the logits of the sampled candidates. This has
		the effect of 'removing' the sampled labels that match the true labels by
		making the classifier sure that they are sampled labels.
		
		Args:
		  true_classes: A `Tensor` of type `int64`.
		    The true_classes output of UnpackSparseLabels.
		  sampled_candidates: A `Tensor` of type `int64`.
		    The sampled_candidates output of CandidateSampler.
		  num_true: An `int`. Number of true labels per context.
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    An second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (indices, ids, weights).
		
		  indices: A `Tensor` of type `int32`.
		  ids: A `Tensor` of type `int64`.
		  weights: A `Tensor` of type `float32`.
	**/
	static public function ComputeAccidentalHits(true_classes:Dynamic, sampled_candidates:Dynamic, num_true:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the static batch size of a dataset sans partial batches.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function ComputeBatchSize(input_dataset:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Concatenates tensors along one dimension.
		
		Args:
		  concat_dim: A `Tensor` of type `int32`.
		    0-D.  The dimension along which to concatenate.  Must be in the
		    range [0, rank(values)).
		  values: A list of at least 2 `Tensor` objects with the same type.
		    The `N` Tensors to concatenate. Their ranks and types must match,
		    and their sizes must match in all dimensions except `concat_dim`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `values`.
	**/
	static public function Concat(concat_dim:Dynamic, values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes offsets of concat inputs within its output.
		
		For example:
		
		```
		# 'x' is [2, 2, 7]
		# 'y' is [2, 3, 7]
		# 'z' is [2, 5, 7]
		concat_offset(2, [x, y, z]) => [0, 0, 0], [0, 2, 0], [0, 5, 0]
		```
		
		This is typically used by gradient computations for a concat operation.
		
		Args:
		  concat_dim: A `Tensor` of type `int32`.
		    The dimension along which to concatenate.
		  shape: A list of at least 2 `Tensor` objects with type `int32`.
		    The `N` int32 vectors representing shape of tensors being concatenated.
		  name: A name for the operation (optional).
		
		Returns:
		  A list with the same length as `shape` of `Tensor` objects with type `int32`.
	**/
	static public function ConcatOffset(concat_dim:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Concatenates tensors along one dimension.
		
		Args:
		  values: A list of at least 2 `Tensor` objects with the same type.
		    List of `N` Tensors to concatenate. Their ranks and types must match,
		    and their sizes must match in all dimensions except `concat_dim`.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    0-D.  The dimension along which to concatenate.  Must be in the
		    range [-rank(values), rank(values)).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `values`.
	**/
	static public function ConcatV2(values:Dynamic, axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that concatenates `input_dataset` with `another_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  another_dataset: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ConcatenateDataset(input_dataset:Dynamic, another_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A conditional accumulator for aggregating gradients.
		
		The accumulator accepts gradients marked with local_step greater or
		equal to the most recent global_step known to the accumulator. The
		average can be extracted from the accumulator, provided sufficient
		gradients have been accumulated. Extracting the average automatically
		resets the aggregate to 0, and increments the global_step recorded by
		the accumulator.
		
		Args:
		  dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
		    The type of the value being accumulated.
		  shape: A `tf.TensorShape` or list of `ints`.
		    The shape of the values, can be [], in which case shape is unknown.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this accumulator is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this accumulator will be shared under the
		    given name across multiple sessions.
		  reduction_type: An optional `string` from: `"MEAN", "SUM"`. Defaults to `"MEAN"`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function ConditionalAccumulator(dtype:Dynamic, shape:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?reduction_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Sets up the centralized structures for a distributed TPU system.
		
		Args:
		  embedding_config: An optional `string`. Defaults to `""`.
		    Reserved. Do not use.
		  tpu_embedding_config: An optional `string`. Defaults to `""`.
		    Serialized tensorflow.tpu.TPUEmbeddingConfiguration that
		    describes the embedding lookups of the program.
		  is_global_init: An optional `bool`. Defaults to `False`.
		    Reserved. Do not use.
		  enable_whole_mesh_compilations: An optional `bool`. Defaults to `False`.
		  compilation_failure_closes_chips: An optional `bool`. Defaults to `True`.
		  tpu_cancellation_closes_chips: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function ConfigureDistributedTPU(?embedding_config:Dynamic, ?tpu_embedding_config:Dynamic, ?is_global_init:Dynamic, ?enable_whole_mesh_compilations:Dynamic, ?compilation_failure_closes_chips:Dynamic, ?tpu_cancellation_closes_chips:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Sets up TPUEmbedding in a distributed TPU system.
		
		Args:
		  config: A `string`.
		    Serialized tensorflow.tpu.TPUEmbeddingConfiguration that
		    describes the embedding lookups of the program.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ConfigureTPUEmbedding(config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the complex conjugate of a complex number.
		
		Given a tensor `input` of complex numbers, this operation returns a tensor of
		complex numbers that are the complex conjugate of each element in `input`. The
		complex numbers in `input` must be of the form \\(a + bj\\), where *a* is the
		real part and *b* is the imaginary part.
		
		The complex conjugate returned by this operation is of the form \\(a - bj\\).
		
		For example:
		
		```
		# tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
		tf.conj(input) ==> [-2.25 - 4.75j, 3.25 - 5.75j]
		```
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`, `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Conj(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Shuffle dimensions of x according to a permutation and conjugate the result.
		
		The output `y` has the same rank as `x`. The shapes of `x` and `y` satisfy:
		  `y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]`
		  `y[i,j,k,...,s,t,u] == conj(x[perm[i], perm[j], perm[k],...,perm[s], perm[t], perm[u]])`
		
		Args:
		  x: A `Tensor`.
		  perm: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function ConjugateTranspose(x:Dynamic, perm:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a constant tensor.
		
		Args:
		  value: A `tf.TensorProto`. Attr `value` is the tensor to return.
		  dtype: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function Const(value:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		This op consumes a lock created by `MutexLock`.
		
		This op exists to consume a tensor created by `MutexLock` (other than
		direct control dependencies).  It should be the only that consumes the tensor,
		and will raise an error if it is not.  Its only purpose is to keep the
		mutex lock tensor alive until it is consumed by this op.
		
		**NOTE**: This operation must run on the same device as its input.  This may
		be enforced via the `colocate_with` mechanism.
		
		Args:
		  mutex_lock: A `Tensor` of type `variant`.
		    A tensor returned by `MutexLock`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ConsumeMutexLock(mutex_lock:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Does nothing. Serves as a control trigger for scheduling.
		
		Only useful as a placeholder for control edges.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ControlTrigger(?name:Dynamic):Dynamic;
	/**
		Computes a 2-D convolution given 4-D `input` and `filter` tensors.
		
		Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
		and a filter / kernel tensor of shape
		`[filter_height, filter_width, in_channels, out_channels]`, this op
		performs the following:
		
		1. Flattens the filter to a 2-D matrix with shape
		   `[filter_height * filter_width * in_channels, output_channels]`.
		2. Extracts image patches from the input tensor to form a *virtual*
		   tensor of shape `[batch, out_height, out_width,
		   filter_height * filter_width * in_channels]`.
		3. For each patch, right-multiplies the filter matrix and the image patch
		   vector.
		
		In detail, with the default NHWC format,
		
		    output[b, i, j, k] =
		        sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
		                        filter[di, dj, q, k]
		
		Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
		horizontal and vertices strides, `strides = [1, stride, stride, 1]`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`.
		    A 4-D tensor. The dimension order is interpreted according to the value
		    of `data_format`, see below for details.
		  filter: A `Tensor`. Must have the same type as `input`.
		    A 4-D tensor of shape
		    `[filter_height, filter_width, in_channels, out_channels]`
		  strides: A list of `ints`.
		    1-D tensor of length 4.  The stride of the sliding window for each
		    dimension of `input`. The dimension order is determined by the value of
		    `data_format`, see below for details.
		  padding: A `string` from: `"SAME", "VALID", "EXPLICIT"`.
		    The type of padding algorithm to use.
		  use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.
		  explicit_paddings: An optional list of `ints`. Defaults to `[]`.
		    If `padding` is `"EXPLICIT"`, the list of explicit padding amounts. For the ith
		    dimension, the amount of padding inserted before and after the dimension is
		    `explicit_paddings[2 * i]` and `explicit_paddings[2 * i + 1]`, respectively. If
		    `padding` is not `"EXPLICIT"`, `explicit_paddings` must be empty.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, height, width, channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, channels, height, width].
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    1-D tensor of length 4.  The dilation factor for each dimension of
		    `input`. If set to k > 1, there will be k-1 skipped cells between each
		    filter element on that dimension. The dimension order is determined by the
		    value of `data_format`, see above for details. Dilations in the batch and
		    depth dimensions must be 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Conv2D(input:Dynamic, filter:Dynamic, strides:Dynamic, padding:Dynamic, ?use_cudnn_on_gpu:Dynamic, ?explicit_paddings:Dynamic, ?data_format:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradients of convolution with respect to the filter.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    4-D with shape `[batch, in_height, in_width, in_channels]`.
		  filter_sizes: A `Tensor` of type `int32`.
		    An integer vector representing the tensor shape of `filter`,
		    where `filter` is a 4-D
		    `[filter_height, filter_width, in_channels, out_channels]` tensor.
		  out_backprop: A `Tensor`. Must have the same type as `input`.
		    4-D with shape `[batch, out_height, out_width, out_channels]`.
		    Gradients w.r.t. the output of the convolution.
		  strides: A list of `ints`.
		    The stride of the sliding window for each dimension of the input
		    of the convolution. Must be in the same order as the dimension specified with
		    format.
		  padding: A `string` from: `"SAME", "VALID", "EXPLICIT"`.
		    The type of padding algorithm to use.
		  use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.
		  explicit_paddings: An optional list of `ints`. Defaults to `[]`.
		    If `padding` is `"EXPLICIT"`, the list of explicit padding amounts. For the ith
		    dimension, the amount of padding inserted before and after the dimension is
		    `explicit_paddings[2 * i]` and `explicit_paddings[2 * i + 1]`, respectively. If
		    `padding` is not `"EXPLICIT"`, `explicit_paddings` must be empty.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    1-D tensor of length 4.  The dilation factor for each dimension of
		    `input`. If set to k > 1, there will be k-1 skipped cells between each filter
		    element on that dimension. The dimension order is determined by the value of
		    `data_format`, see above for details. Dilations in the batch and depth
		    dimensions must be 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Conv2DBackpropFilter(input:Dynamic, filter_sizes:Dynamic, out_backprop:Dynamic, strides:Dynamic, padding:Dynamic, ?use_cudnn_on_gpu:Dynamic, ?explicit_paddings:Dynamic, ?data_format:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradients of convolution with respect to the input.
		
		Args:
		  input_sizes: A `Tensor` of type `int32`.
		    An integer vector representing the shape of `input`,
		    where `input` is a 4-D `[batch, height, width, channels]` tensor.
		  filter: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`.
		    4-D with shape
		    `[filter_height, filter_width, in_channels, out_channels]`.
		  out_backprop: A `Tensor`. Must have the same type as `filter`.
		    4-D with shape `[batch, out_height, out_width, out_channels]`.
		    Gradients w.r.t. the output of the convolution.
		  strides: A list of `ints`.
		    The stride of the sliding window for each dimension of the input
		    of the convolution. Must be in the same order as the dimension specified with
		    format.
		  padding: A `string` from: `"SAME", "VALID", "EXPLICIT"`.
		    The type of padding algorithm to use.
		  use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.
		  explicit_paddings: An optional list of `ints`. Defaults to `[]`.
		    If `padding` is `"EXPLICIT"`, the list of explicit padding amounts. For the ith
		    dimension, the amount of padding inserted before and after the dimension is
		    `explicit_paddings[2 * i]` and `explicit_paddings[2 * i + 1]`, respectively. If
		    `padding` is not `"EXPLICIT"`, `explicit_paddings` must be empty.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    1-D tensor of length 4.  The dilation factor for each dimension of
		    `input`. If set to k > 1, there will be k-1 skipped cells between each filter
		    element on that dimension. The dimension order is determined by the value of
		    `data_format`, see above for details. Dilations in the batch and depth
		    dimensions must be 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `filter`.
	**/
	static public function Conv2DBackpropInput(input_sizes:Dynamic, filter:Dynamic, out_backprop:Dynamic, strides:Dynamic, padding:Dynamic, ?use_cudnn_on_gpu:Dynamic, ?explicit_paddings:Dynamic, ?data_format:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes a 3-D convolution given 5-D `input` and `filter` tensors.
		
		In signal processing, cross-correlation is a measure of similarity of
		two waveforms as a function of a time-lag applied to one of them. This
		is also known as a sliding dot product or sliding inner-product.
		
		Our Conv3D implements a form of cross-correlation.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    Shape `[batch, in_depth, in_height, in_width, in_channels]`.
		  filter: A `Tensor`. Must have the same type as `input`.
		    Shape `[filter_depth, filter_height, filter_width, in_channels,
		    out_channels]`. `in_channels` must match between `input` and `filter`.
		  strides: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The stride of the sliding window for each
		    dimension of `input`. Must have `strides[0] = strides[4] = 1`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
		    The data format of the input and output data. With the
		    default format "NDHWC", the data is stored in the order of:
		        [batch, in_depth, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCDHW", the data storage order is:
		        [batch, in_channels, in_depth, in_height, in_width].
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1, 1]`.
		    1-D tensor of length 5.  The dilation factor for each dimension of
		    `input`. If set to k > 1, there will be k-1 skipped cells between each
		    filter element on that dimension. The dimension order is determined by the
		    value of `data_format`, see above for details. Dilations in the batch and
		    depth dimensions must be 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Conv3D(input:Dynamic, filter:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradients of 3-D convolution with respect to the filter.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		    Shape `[batch, depth, rows, cols, in_channels]`.
		  filter: A `Tensor`. Must have the same type as `input`.
		    Shape `[depth, rows, cols, in_channels, out_channels]`.
		    `in_channels` must match between `input` and `filter`.
		  out_backprop: A `Tensor`. Must have the same type as `input`.
		    Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
		    out_channels]`.
		  strides: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The stride of the sliding window for each
		    dimension of `input`. Must have `strides[0] = strides[4] = 1`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1, 1]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Conv3DBackpropFilter(input:Dynamic, filter:Dynamic, out_backprop:Dynamic, strides:Dynamic, padding:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradients of 3-D convolution with respect to the filter.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    Shape `[batch, depth, rows, cols, in_channels]`.
		  filter_sizes: A `Tensor` of type `int32`.
		    An integer vector representing the tensor shape of `filter`,
		    where `filter` is a 5-D
		    `[filter_depth, filter_height, filter_width, in_channels, out_channels]`
		    tensor.
		  out_backprop: A `Tensor`. Must have the same type as `input`.
		    Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
		    out_channels]`.
		  strides: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The stride of the sliding window for each
		    dimension of `input`. Must have `strides[0] = strides[4] = 1`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
		    The data format of the input and output data. With the
		    default format "NDHWC", the data is stored in the order of:
		        [batch, in_depth, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCDHW", the data storage order is:
		        [batch, in_channels, in_depth, in_height, in_width].
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1, 1]`.
		    1-D tensor of length 5.  The dilation factor for each dimension of
		    `input`. If set to k > 1, there will be k-1 skipped cells between each
		    filter element on that dimension. The dimension order is determined by the
		    value of `data_format`, see above for details. Dilations in the batch and
		    depth dimensions must be 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Conv3DBackpropFilterV2(input:Dynamic, filter_sizes:Dynamic, out_backprop:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradients of 3-D convolution with respect to the input.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		    Shape `[batch, depth, rows, cols, in_channels]`.
		  filter: A `Tensor`. Must have the same type as `input`.
		    Shape `[depth, rows, cols, in_channels, out_channels]`.
		    `in_channels` must match between `input` and `filter`.
		  out_backprop: A `Tensor`. Must have the same type as `input`.
		    Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
		    out_channels]`.
		  strides: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The stride of the sliding window for each
		    dimension of `input`. Must have `strides[0] = strides[4] = 1`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1, 1]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Conv3DBackpropInput(input:Dynamic, filter:Dynamic, out_backprop:Dynamic, strides:Dynamic, padding:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradients of 3-D convolution with respect to the input.
		
		Args:
		  input_sizes: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    An integer vector representing the tensor shape of `input`,
		    where `input` is a 5-D
		    `[batch, depth, rows, cols, in_channels]` tensor.
		  filter: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    Shape `[depth, rows, cols, in_channels, out_channels]`.
		    `in_channels` must match between `input` and `filter`.
		  out_backprop: A `Tensor`. Must have the same type as `filter`.
		    Backprop signal of shape `[batch, out_depth, out_rows, out_cols,
		    out_channels]`.
		  strides: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The stride of the sliding window for each
		    dimension of `input`. Must have `strides[0] = strides[4] = 1`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
		    The data format of the input and output data. With the
		    default format "NDHWC", the data is stored in the order of:
		        [batch, in_depth, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCDHW", the data storage order is:
		        [batch, in_channels, in_depth, in_height, in_width].
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1, 1]`.
		    1-D tensor of length 5.  The dilation factor for each dimension of
		    `input`. If set to k > 1, there will be k-1 skipped cells between each
		    filter element on that dimension. The dimension order is determined by the
		    value of `data_format`, see above for details. Dilations in the batch and
		    depth dimensions must be 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `filter`.
	**/
	static public function Conv3DBackpropInputV2(input_sizes:Dynamic, filter:Dynamic, out_backprop:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Copy a tensor from CPU-to-CPU or GPU-to-GPU.
		
		Performs CPU-to-CPU or GPU-to-GPU deep-copying of tensor, depending on the
		device on which the tensor is allocated.
		N.B.: If the all downstream attached debug ops are disabled given the current
		gRPC gating status, the output will simply forward the input tensor without
		deep-copying. See the documentation of Debug* ops for more details.
		
		Unlike the CopyHost Op, this op does not have HostMemory constraint on its
		input or output.
		
		Args:
		  input: A `Tensor`. Input tensor.
		  tensor_name: An optional `string`. Defaults to `""`.
		    The name of the input tensor.
		  debug_ops_spec: An optional list of `strings`. Defaults to `[]`.
		    A list of debug op spec (op, url, gated_grpc) for attached debug
		    ops. Each element of the list has the format
		    <debug_op>;<grpc_url>;<gated_grpc>, wherein gated_grpc is boolean represented
		    as 0/1. E.g., "DebugIdentity;grpc://foo:3333;1",
		    "DebugIdentity;file:///tmp/tfdbg_1;0".
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Copy(input:Dynamic, ?tensor_name:Dynamic, ?debug_ops_spec:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Copy a tensor to host.
		
		Performs CPU-to-CPU deep-copying of tensor.
		N.B.: If the all downstream attached debug ops are disabled given the current
		gRPC gating status, the output will simply forward the input tensor without
		deep-copying. See the documentation of Debug* ops for more details.
		
		Unlike the Copy Op, this op has HostMemory constraint on its input or output.
		
		Args:
		  input: A `Tensor`. Input tensor.
		  tensor_name: An optional `string`. Defaults to `""`.
		    The name of the input tensor.
		  debug_ops_spec: An optional list of `strings`. Defaults to `[]`.
		    A list of debug op spec (op, url, gated_grpc) for attached debug
		    ops. Each element of the list has the format
		    <debug_op>;<grpc_url>;<gated_grpc>, wherein gated_grpc is boolean represented
		    as 0/1. E.g., "DebugIdentity;grpc://foo:3333;1",
		    "DebugIdentity;file:///tmp/tfdbg_1;0".
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function CopyHost(input:Dynamic, ?tensor_name:Dynamic, ?debug_ops_spec:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes cos of x element-wise.
		
		  Given an input tensor, this function computes cosine of every
		  element in the tensor. Input range is `(-inf, inf)` and
		  output range is `[-1,1]`. If input lies outside the boundary, `nan`
		  is returned.
		
		  ```python
		  x = tf.constant([-float("inf"), -9, -0.5, 1, 1.2, 200, 10000, float("inf")])
		  tf.math.cos(x) ==> [nan -0.91113025 0.87758255 0.5403023 0.36235774 0.48718765 -0.95215535 nan]
		  ```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Cos(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes hyperbolic cosine of x element-wise.
		
		  Given an input tensor, this function computes hyperbolic cosine of every
		  element in the tensor. Input range is `[-inf, inf]` and output range
		  is `[1, inf]`.
		
		  ```python
		  x = tf.constant([-float("inf"), -9, -0.5, 1, 1.2, 2, 10, float("inf")])
		  tf.math.cosh(x) ==> [inf 4.0515420e+03 1.1276259e+00 1.5430807e+00 1.8106556e+00 3.7621956e+00 1.1013233e+04 inf]
		  ```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Cosh(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Increments 'ref' until it reaches 'limit'.
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Should be from a scalar `Variable` node.
		  limit: An `int`.
		    If incrementing ref would bring it above limit, instead generates an
		    'OutOfRange' error.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `ref`.
	**/
	static public function CountUpTo(ref:Dynamic, limit:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  db_uri: A `Tensor` of type `string`.
		  experiment_name: A `Tensor` of type `string`.
		  run_name: A `Tensor` of type `string`.
		  user_name: A `Tensor` of type `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function CreateSummaryDbWriter(writer:Dynamic, db_uri:Dynamic, experiment_name:Dynamic, run_name:Dynamic, user_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  logdir: A `Tensor` of type `string`.
		  max_queue: A `Tensor` of type `int32`.
		  flush_millis: A `Tensor` of type `int32`.
		  filename_suffix: A `Tensor` of type `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function CreateSummaryFileWriter(writer:Dynamic, logdir:Dynamic, max_queue:Dynamic, flush_millis:Dynamic, filename_suffix:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Extracts crops from the input image tensor and resizes them.
		
		Extracts crops from the input image tensor and resizes them using bilinear
		sampling or nearest neighbor sampling (possibly with aspect ratio change) to a
		common output size specified by `crop_size`. This is more general than the
		`crop_to_bounding_box` op which extracts a fixed size slice from the input image
		and does not allow resizing or aspect ratio change.
		
		Returns a tensor with `crops` from the input `image` at positions defined at the
		bounding box locations in `boxes`. The cropped boxes are all resized (with
		bilinear or nearest neighbor interpolation) to a fixed
		`size = [crop_height, crop_width]`. The result is a 4-D tensor
		`[num_boxes, crop_height, crop_width, depth]`. The resizing is corner aligned.
		In particular, if `boxes = [[0, 0, 1, 1]]`, the method will give identical
		results to using `tf.image.resize_bilinear()` or
		`tf.image.resize_nearest_neighbor()`(depends on the `method` argument) with
		`align_corners=True`.
		
		Args:
		  image: A `Tensor`. Must be one of the following types: `uint8`, `uint16`, `int8`, `int16`, `int32`, `int64`, `half`, `float32`, `float64`.
		    A 4-D tensor of shape `[batch, image_height, image_width, depth]`.
		    Both `image_height` and `image_width` need to be positive.
		  boxes: A `Tensor` of type `float32`.
		    A 2-D tensor of shape `[num_boxes, 4]`. The `i`-th row of the tensor
		    specifies the coordinates of a box in the `box_ind[i]` image and is specified
		    in normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value of
		    `y` is mapped to the image coordinate at `y * (image_height - 1)`, so as the
		    `[0, 1]` interval of normalized image height is mapped to
		    `[0, image_height - 1]` in image height coordinates. We do allow `y1` > `y2`, in
		    which case the sampled crop is an up-down flipped version of the original
		    image. The width dimension is treated similarly. Normalized coordinates
		    outside the `[0, 1]` range are allowed, in which case we use
		    `extrapolation_value` to extrapolate the input image values.
		  box_ind: A `Tensor` of type `int32`.
		    A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`.
		    The value of `box_ind[i]` specifies the image that the `i`-th box refers to.
		  crop_size: A `Tensor` of type `int32`.
		    A 1-D tensor of 2 elements, `size = [crop_height, crop_width]`. All
		    cropped image patches are resized to this size. The aspect ratio of the image
		    content is not preserved. Both `crop_height` and `crop_width` need to be
		    positive.
		  method: An optional `string` from: `"bilinear", "nearest"`. Defaults to `"bilinear"`.
		    A string specifying the sampling method for resizing. It can be either
		    `"bilinear"` or `"nearest"` and default to `"bilinear"`. Currently two sampling
		    methods are supported: Bilinear and Nearest Neighbor.
		  extrapolation_value: An optional `float`. Defaults to `0`.
		    Value used for extrapolation, when applicable.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function CropAndResize(image:Dynamic, boxes:Dynamic, box_ind:Dynamic, crop_size:Dynamic, ?method:Dynamic, ?extrapolation_value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient of the crop_and_resize op wrt the input boxes tensor.
		
		Args:
		  grads: A `Tensor` of type `float32`.
		    A 4-D tensor of shape `[num_boxes, crop_height, crop_width, depth]`.
		  image: A `Tensor`. Must be one of the following types: `uint8`, `uint16`, `int8`, `int16`, `int32`, `int64`, `half`, `float32`, `float64`.
		    A 4-D tensor of shape `[batch, image_height, image_width, depth]`.
		    Both `image_height` and `image_width` need to be positive.
		  boxes: A `Tensor` of type `float32`.
		    A 2-D tensor of shape `[num_boxes, 4]`. The `i`-th row of the tensor
		    specifies the coordinates of a box in the `box_ind[i]` image and is specified
		    in normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value of
		    `y` is mapped to the image coordinate at `y * (image_height - 1)`, so as the
		    `[0, 1]` interval of normalized image height is mapped to
		    `[0, image_height - 1] in image height coordinates. We do allow y1 > y2, in
		    which case the sampled crop is an up-down flipped version of the original
		    image. The width dimension is treated similarly. Normalized coordinates
		    outside the `[0, 1]` range are allowed, in which case we use
		    `extrapolation_value` to extrapolate the input image values.
		  box_ind: A `Tensor` of type `int32`.
		    A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`.
		    The value of `box_ind[i]` specifies the image that the `i`-th box refers to.
		  method: An optional `string` from: `"bilinear"`. Defaults to `"bilinear"`.
		    A string specifying the interpolation method. Only 'bilinear' is
		    supported for now.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function CropAndResizeGradBoxes(grads:Dynamic, image:Dynamic, boxes:Dynamic, box_ind:Dynamic, ?method:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient of the crop_and_resize op wrt the input image tensor.
		
		Args:
		  grads: A `Tensor` of type `float32`.
		    A 4-D tensor of shape `[num_boxes, crop_height, crop_width, depth]`.
		  boxes: A `Tensor` of type `float32`.
		    A 2-D tensor of shape `[num_boxes, 4]`. The `i`-th row of the tensor
		    specifies the coordinates of a box in the `box_ind[i]` image and is specified
		    in normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value of
		    `y` is mapped to the image coordinate at `y * (image_height - 1)`, so as the
		    `[0, 1]` interval of normalized image height is mapped to
		    `[0, image_height - 1] in image height coordinates. We do allow y1 > y2, in
		    which case the sampled crop is an up-down flipped version of the original
		    image. The width dimension is treated similarly. Normalized coordinates
		    outside the `[0, 1]` range are allowed, in which case we use
		    `extrapolation_value` to extrapolate the input image values.
		  box_ind: A `Tensor` of type `int32`.
		    A 1-D tensor of shape `[num_boxes]` with int32 values in `[0, batch)`.
		    The value of `box_ind[i]` specifies the image that the `i`-th box refers to.
		  image_size: A `Tensor` of type `int32`.
		    A 1-D tensor with value `[batch, image_height, image_width, depth]`
		    containing the original image size. Both `image_height` and `image_width` need
		    to be positive.
		  T: A `tf.DType` from: `tf.float32, tf.half, tf.float64`.
		  method: An optional `string` from: `"bilinear", "nearest"`. Defaults to `"bilinear"`.
		    A string specifying the interpolation method. Only 'bilinear' is
		    supported for now.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `T`.
	**/
	static public function CropAndResizeGradImage(grads:Dynamic, boxes:Dynamic, box_ind:Dynamic, image_size:Dynamic, T:Dynamic, ?method:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute the pairwise cross product.
		
		`a` and `b` must be the same shape; they can either be simple 3-element vectors,
		or any shape where the innermost dimension is 3. In the latter case, each pair
		of corresponding 3-element vectors is cross-multiplied independently.
		
		Args:
		  a: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    A tensor containing 3-element vectors.
		  b: A `Tensor`. Must have the same type as `a`.
		    Another tensor, of same type and shape as `a`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `a`.
	**/
	static public function Cross(a:Dynamic, b:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An Op to sum inputs across replicated TPU instances.
		
		Each instance supplies its own input.
		
		For example, suppose there are 8 TPU instances: `[A, B, C, D, E, F, G, H]`.
		Passing group_assignment=`[[0,2,4,6],[1,3,5,7]]` sets `A, C, E, G` as group 0,
		and `B, D, F, H` as group 1. Thus we get the outputs:
		`[A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H, A+C+E+G, B+D+F+H]`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`, `uint32`.
		    The local input to the sum.
		  group_assignment: A `Tensor` of type `int32`. An int32 tensor with shape
		    [num_groups, num_replicas_per_group]. `group_assignment[i]` represents the
		    replica ids in the ith subgroup.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function CrossReplicaSum(input:Dynamic, group_assignment:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A RNN backed by cuDNN.
		
		Computes the RNN from the input and initial states, with respect to the params
		buffer.
		
		rnn_mode: Indicates the type of the RNN model.
		input_mode: Indicate whether there is a linear projection between the input and
		  the actual computation before the first layer. 'skip_input' is only allowed
		  when input_size == num_units; 'auto_select' implies 'skip_input' when
		  input_size == num_units; otherwise, it implies 'linear_input'.
		direction: Indicates whether a bidirectional model will be used. Should be
		  "unidirectional" or "bidirectional".
		dropout: Dropout probability. When set to 0., dropout is disabled.
		seed: The 1st part of a seed to initialize dropout.
		seed2: The 2nd part of a seed to initialize dropout.
		input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
		input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
		    num_units].
		input_c: For LSTM, a 3-D tensor with the shape of
		    [num_layer * dir, batch, num_units]. For other models, it is ignored.
		params: A 1-D tensor that contains the weights and biases in an opaque layout.
		    The size must be created through CudnnRNNParamsSize, and initialized
		    separately. Note that they might not be compatible across different
		    generations. So it is a good idea to save and restore
		output: A 3-D tensor with the shape of [seq_length, batch_size,
		    dir * num_units].
		output_h: The same shape has input_h.
		output_c: The same shape as input_c for LSTM. An empty tensor for other models.
		is_training: Indicates whether this operation is used for inference or
		  training.
		reserve_space: An opaque tensor that can be used in backprop calculation. It
		  is only produced if is_training is false.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		  input_h: A `Tensor`. Must have the same type as `input`.
		  input_c: A `Tensor`. Must have the same type as `input`.
		  params: A `Tensor`. Must have the same type as `input`.
		  rnn_mode: An optional `string` from: `"rnn_relu", "rnn_tanh", "lstm", "gru"`. Defaults to `"lstm"`.
		  input_mode: An optional `string` from: `"linear_input", "skip_input", "auto_select"`. Defaults to `"linear_input"`.
		  direction: An optional `string` from: `"unidirectional", "bidirectional"`. Defaults to `"unidirectional"`.
		  dropout: An optional `float`. Defaults to `0`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  is_training: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, output_h, output_c, reserve_space).
		
		  output: A `Tensor`. Has the same type as `input`.
		  output_h: A `Tensor`. Has the same type as `input`.
		  output_c: A `Tensor`. Has the same type as `input`.
		  reserve_space: A `Tensor`. Has the same type as `input`.
	**/
	static public function CudnnRNN(input:Dynamic, input_h:Dynamic, input_c:Dynamic, params:Dynamic, ?rnn_mode:Dynamic, ?input_mode:Dynamic, ?direction:Dynamic, ?dropout:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?is_training:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Backprop step of CudnnRNN.
		
		Compute the backprop of both data and weights in a RNN.
		
		rnn_mode: Indicates the type of the RNN model.
		input_mode: Indicate whether there is a linear projection between the input and
		    the actual computation before the first layer. 'skip_input' is only allowed
		    when input_size == num_units; 'auto_select' implies 'skip_input' when
		    input_size == num_units; otherwise, it implies 'linear_input'.
		direction: Indicates whether a bidirectional model will be used. Should be
		  "unidirectional" or "bidirectional".
		dropout: Dropout probability. When set to 0., dropout is disabled.
		seed: The 1st part of a seed to initialize dropout.
		seed2: The 2nd part of a seed to initialize dropout.
		input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
		input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
		    num_units].
		input_c: For LSTM, a 3-D tensor with the shape of
		    [num_layer * dir, batch, num_units]. For other models, it is ignored.
		params: A 1-D tensor that contains the weights and biases in an opaque layout.
		    The size must be created through CudnnRNNParamsSize, and initialized
		    separately. Note that they might not be compatible across different
		    generations. So it is a good idea to save and restore
		output: A 3-D tensor with the shape of [seq_length, batch_size,
		    dir * num_units].
		output_h: The same shape has input_h.
		output_c: The same shape as input_c for LSTM. An empty tensor for other models.
		output_backprop: A 3-D tensor with the same shape as output in the forward pass.
		output_h_backprop: A 3-D tensor with the same shape as output_h in the forward
		    pass.
		output_c_backprop: A 3-D tensor with the same shape as output_c in the forward
		    pass.
		reserve_space: The same reserve_space produced in for forward operation.
		input_backprop: The backprop to input in the forward pass. Has the same shape
		    as input.
		input_h_backprop: The backprop to input_h in the forward pass. Has the same
		    shape as input_h.
		input_c_backprop: The backprop to input_c in the forward pass. Has the same
		    shape as input_c.
		params_backprop: The backprop to the params buffer in the forward pass. Has the
		    same shape as params.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		  input_h: A `Tensor`. Must have the same type as `input`.
		  input_c: A `Tensor`. Must have the same type as `input`.
		  params: A `Tensor`. Must have the same type as `input`.
		  output: A `Tensor`. Must have the same type as `input`.
		  output_h: A `Tensor`. Must have the same type as `input`.
		  output_c: A `Tensor`. Must have the same type as `input`.
		  output_backprop: A `Tensor`. Must have the same type as `input`.
		  output_h_backprop: A `Tensor`. Must have the same type as `input`.
		  output_c_backprop: A `Tensor`. Must have the same type as `input`.
		  reserve_space: A `Tensor`. Must have the same type as `input`.
		  rnn_mode: An optional `string` from: `"rnn_relu", "rnn_tanh", "lstm", "gru"`. Defaults to `"lstm"`.
		  input_mode: An optional `string` from: `"linear_input", "skip_input", "auto_select"`. Defaults to `"linear_input"`.
		  direction: An optional `string` from: `"unidirectional", "bidirectional"`. Defaults to `"unidirectional"`.
		  dropout: An optional `float`. Defaults to `0`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (input_backprop, input_h_backprop, input_c_backprop, params_backprop).
		
		  input_backprop: A `Tensor`. Has the same type as `input`.
		  input_h_backprop: A `Tensor`. Has the same type as `input`.
		  input_c_backprop: A `Tensor`. Has the same type as `input`.
		  params_backprop: A `Tensor`. Has the same type as `input`.
	**/
	static public function CudnnRNNBackprop(input:Dynamic, input_h:Dynamic, input_c:Dynamic, params:Dynamic, output:Dynamic, output_h:Dynamic, output_c:Dynamic, output_backprop:Dynamic, output_h_backprop:Dynamic, output_c_backprop:Dynamic, reserve_space:Dynamic, ?rnn_mode:Dynamic, ?input_mode:Dynamic, ?direction:Dynamic, ?dropout:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Backprop step of CudnnRNN.
		
		Compute the backprop of both data and weights in a RNN. Takes an extra
		    "host_reserved" inupt than CudnnRNNBackprop, which is used to determine RNN
		    cudnnRNNAlgo_t and cudnnMathType_t.
		
		rnn_mode: Indicates the type of the RNN model.
		input_mode: Indicates whether there is a linear projection between the input and
		    the actual computation before the first layer. 'skip_input' is only allowed
		    when input_size == num_units; 'auto_select' implies 'skip_input' when
		    input_size == num_units; otherwise, it implies 'linear_input'.
		direction: Indicates whether a bidirectional model will be used. Should be
		  "unidirectional" or "bidirectional".
		dropout: Dropout probability. When set to 0., dropout is disabled.
		seed: The 1st part of a seed to initialize dropout.
		seed2: The 2nd part of a seed to initialize dropout.
		input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
		input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
		    num_units].
		input_c: For LSTM, a 3-D tensor with the shape of
		    [num_layer * dir, batch, num_units]. For other models, it is ignored.
		params: A 1-D tensor that contains the weights and biases in an opaque layout.
		    The size must be created through CudnnRNNParamsSize, and initialized
		    separately. Note that they might not be compatible across different
		    generations. So it is a good idea to save and restore
		output: A 3-D tensor with the shape of [seq_length, batch_size,
		    dir * num_units].
		output_h: The same shape has input_h.
		output_c: The same shape as input_c for LSTM. An empty tensor for other models.
		output_backprop: A 3-D tensor with the same shape as output in the forward pass.
		output_h_backprop: A 3-D tensor with the same shape as output_h in the forward
		    pass.
		output_c_backprop: A 3-D tensor with the same shape as output_c in the forward
		    pass.
		reserve_space: The same reserve_space produced in the forward operation.
		host_reserved: The same host_reserved produced in the forward operation.
		input_backprop: The backprop to input in the forward pass. Has the same shape
		    as input.
		input_h_backprop: The backprop to input_h in the forward pass. Has the same
		    shape as input_h.
		input_c_backprop: The backprop to input_c in the forward pass. Has the same
		    shape as input_c.
		params_backprop: The backprop to the params buffer in the forward pass. Has the
		    same shape as params.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		  input_h: A `Tensor`. Must have the same type as `input`.
		  input_c: A `Tensor`. Must have the same type as `input`.
		  params: A `Tensor`. Must have the same type as `input`.
		  output: A `Tensor`. Must have the same type as `input`.
		  output_h: A `Tensor`. Must have the same type as `input`.
		  output_c: A `Tensor`. Must have the same type as `input`.
		  output_backprop: A `Tensor`. Must have the same type as `input`.
		  output_h_backprop: A `Tensor`. Must have the same type as `input`.
		  output_c_backprop: A `Tensor`. Must have the same type as `input`.
		  reserve_space: A `Tensor`. Must have the same type as `input`.
		  host_reserved: A `Tensor` of type `int8`.
		  rnn_mode: An optional `string` from: `"rnn_relu", "rnn_tanh", "lstm", "gru"`. Defaults to `"lstm"`.
		  input_mode: An optional `string` from: `"linear_input", "skip_input", "auto_select"`. Defaults to `"linear_input"`.
		  direction: An optional `string` from: `"unidirectional", "bidirectional"`. Defaults to `"unidirectional"`.
		  dropout: An optional `float`. Defaults to `0`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (input_backprop, input_h_backprop, input_c_backprop, params_backprop).
		
		  input_backprop: A `Tensor`. Has the same type as `input`.
		  input_h_backprop: A `Tensor`. Has the same type as `input`.
		  input_c_backprop: A `Tensor`. Has the same type as `input`.
		  params_backprop: A `Tensor`. Has the same type as `input`.
	**/
	static public function CudnnRNNBackpropV2(input:Dynamic, input_h:Dynamic, input_c:Dynamic, params:Dynamic, output:Dynamic, output_h:Dynamic, output_c:Dynamic, output_backprop:Dynamic, output_h_backprop:Dynamic, output_c_backprop:Dynamic, reserve_space:Dynamic, host_reserved:Dynamic, ?rnn_mode:Dynamic, ?input_mode:Dynamic, ?direction:Dynamic, ?dropout:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Backprop step of CudnnRNNV3.
		
		Compute the backprop of both data and weights in a RNN. Takes an extra
		    "sequence_lengths" input than CudnnRNNBackprop.
		
		rnn_mode: Indicates the type of the RNN model.
		input_mode: Indicates whether there is a linear projection between the input and
		    the actual computation before the first layer. 'skip_input' is only allowed
		    when input_size == num_units; 'auto_select' implies 'skip_input' when
		    input_size == num_units; otherwise, it implies 'linear_input'.
		direction: Indicates whether a bidirectional model will be used. Should be
		  "unidirectional" or "bidirectional".
		dropout: Dropout probability. When set to 0., dropout is disabled.
		seed: The 1st part of a seed to initialize dropout.
		seed2: The 2nd part of a seed to initialize dropout.
		input: If time_major is true, this is a 3-D tensor with the shape of
		    [seq_length, batch_size, input_size]. If time_major is false, the shape is
		    [batch_size, seq_length, input_size].
		input_h: If time_major is true, this is a 3-D tensor with the shape of
		    [num_layer * dir, batch_size, num_units]. If time_major is false, the shape
		    is [batch_size, num_layer * dir, num_units].
		input_c: For LSTM, a 3-D tensor with the shape of
		    [num_layer * dir, batch, num_units]. For other models, it is ignored.
		params: A 1-D tensor that contains the weights and biases in an opaque layout.
		    The size must be created through CudnnRNNParamsSize, and initialized
		    separately. Note that they might not be compatible across different
		    generations. So it is a good idea to save and restore
		sequence_lengths: a vector of lengths of each input sequence.
		output: If time_major is true, this is a 3-D tensor with the shape of
		    [seq_length, batch_size, dir * num_units]. If time_major is false, the
		    shape is [batch_size, seq_length, dir * num_units].
		output_h: The same shape has input_h.
		output_c: The same shape as input_c for LSTM. An empty tensor for other models.
		output_backprop: A 3-D tensor with the same shape as output in the forward pass.
		output_h_backprop: A 3-D tensor with the same shape as output_h in the forward
		    pass.
		output_c_backprop: A 3-D tensor with the same shape as output_c in the forward
		    pass.
		time_major: Indicates whether the input/output format is time major or batch
		    major.
		reserve_space: The same reserve_space produced in the forward operation.
		input_backprop: The backprop to input in the forward pass. Has the same shape
		    as input.
		input_h_backprop: The backprop to input_h in the forward pass. Has the same
		    shape as input_h.
		input_c_backprop: The backprop to input_c in the forward pass. Has the same
		    shape as input_c.
		params_backprop: The backprop to the params buffer in the forward pass. Has the
		    same shape as params.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		  input_h: A `Tensor`. Must have the same type as `input`.
		  input_c: A `Tensor`. Must have the same type as `input`.
		  params: A `Tensor`. Must have the same type as `input`.
		  sequence_lengths: A `Tensor` of type `int32`.
		  output: A `Tensor`. Must have the same type as `input`.
		  output_h: A `Tensor`. Must have the same type as `input`.
		  output_c: A `Tensor`. Must have the same type as `input`.
		  output_backprop: A `Tensor`. Must have the same type as `input`.
		  output_h_backprop: A `Tensor`. Must have the same type as `input`.
		  output_c_backprop: A `Tensor`. Must have the same type as `input`.
		  reserve_space: A `Tensor`. Must have the same type as `input`.
		  host_reserved: A `Tensor` of type `int8`.
		  rnn_mode: An optional `string` from: `"rnn_relu", "rnn_tanh", "lstm", "gru"`. Defaults to `"lstm"`.
		  input_mode: An optional `string` from: `"linear_input", "skip_input", "auto_select"`. Defaults to `"linear_input"`.
		  direction: An optional `string` from: `"unidirectional", "bidirectional"`. Defaults to `"unidirectional"`.
		  dropout: An optional `float`. Defaults to `0`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  num_proj: An optional `int`. Defaults to `0`.
		  time_major: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (input_backprop, input_h_backprop, input_c_backprop, params_backprop).
		
		  input_backprop: A `Tensor`. Has the same type as `input`.
		  input_h_backprop: A `Tensor`. Has the same type as `input`.
		  input_c_backprop: A `Tensor`. Has the same type as `input`.
		  params_backprop: A `Tensor`. Has the same type as `input`.
	**/
	static public function CudnnRNNBackpropV3(input:Dynamic, input_h:Dynamic, input_c:Dynamic, params:Dynamic, sequence_lengths:Dynamic, output:Dynamic, output_h:Dynamic, output_c:Dynamic, output_backprop:Dynamic, output_h_backprop:Dynamic, output_c_backprop:Dynamic, reserve_space:Dynamic, host_reserved:Dynamic, ?rnn_mode:Dynamic, ?input_mode:Dynamic, ?direction:Dynamic, ?dropout:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?num_proj:Dynamic, ?time_major:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts CudnnRNN params from canonical form to usable form.
		
		Writes a set of weights into the opaque params buffer so they can be used in
		upcoming training or inferences.
		
		Note that the params buffer may not be compatible across different GPUs. So any
		save and restoration should be converted to and from the canonical weights and
		biases.
		
		num_layers: Specifies the number of layers in the RNN model.
		num_units: Specifies the size of the hidden state.
		input_size: Specifies the size of the input state.
		weights: the canonical form of weights that can be used for saving
		    and restoration. They are more likely to be compatible across different
		    generations.
		biases: the canonical form of biases that can be used for saving
		    and restoration. They are more likely to be compatible across different
		    generations.
		num_params: number of parameter sets for all layers.
		    Each layer may contain multiple parameter sets, with each set consisting of
		    a weight matrix and a bias vector.
		rnn_mode: Indicates the type of the RNN model.
		input_mode: Indicate whether there is a linear projection between the input and
		    The actual computation before the first layer. 'skip_input' is only allowed
		    when input_size == num_units; 'auto_select' implies 'skip_input' when
		    input_size == num_units; otherwise, it implies 'linear_input'.
		direction: Indicates whether a bidirectional model will be used.
		    dir = (direction == bidirectional) ? 2 : 1
		dropout: dropout probability. When set to 0., dropout is disabled.
		seed: the 1st part of a seed to initialize dropout.
		seed2: the 2nd part of a seed to initialize dropout.
		
		Args:
		  num_layers: A `Tensor` of type `int32`.
		  num_units: A `Tensor` of type `int32`.
		  input_size: A `Tensor` of type `int32`.
		  weights: A list of at least 1 `Tensor` objects with the same type in: `half`, `float32`, `float64`.
		  biases: A list with the same length as `weights` of `Tensor` objects with the same type as `weights`.
		  rnn_mode: An optional `string` from: `"rnn_relu", "rnn_tanh", "lstm", "gru"`. Defaults to `"lstm"`.
		  input_mode: An optional `string` from: `"linear_input", "skip_input", "auto_select"`. Defaults to `"linear_input"`.
		  direction: An optional `string` from: `"unidirectional", "bidirectional"`. Defaults to `"unidirectional"`.
		  dropout: An optional `float`. Defaults to `0`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `weights`.
	**/
	static public function CudnnRNNCanonicalToParams(num_layers:Dynamic, num_units:Dynamic, input_size:Dynamic, weights:Dynamic, biases:Dynamic, ?rnn_mode:Dynamic, ?input_mode:Dynamic, ?direction:Dynamic, ?dropout:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts CudnnRNN params from canonical form to usable form. It supports the projection in LSTM.
		
		Writes a set of weights into the opaque params buffer so they can be used in
		upcoming training or inferences.
		
		Note that the params buffer may not be compatible across different GPUs. So any
		save and restoration should be converted to and from the canonical weights and
		biases.
		
		num_layers: Specifies the number of layers in the RNN model.
		num_units: Specifies the size of the hidden state.
		input_size: Specifies the size of the input state.
		weights: the canonical form of weights that can be used for saving
		    and restoration. They are more likely to be compatible across different
		    generations.
		biases: the canonical form of biases that can be used for saving
		    and restoration. They are more likely to be compatible across different
		    generations.
		num_params_weights: number of weight parameter matrix for all layers.
		num_params_biases: number of bias parameter vector for all layers.
		rnn_mode: Indicates the type of the RNN model.
		input_mode: Indicate whether there is a linear projection between the input and
		    The actual computation before the first layer. 'skip_input' is only allowed
		    when input_size == num_units; 'auto_select' implies 'skip_input' when
		    input_size == num_units; otherwise, it implies 'linear_input'.
		direction: Indicates whether a bidirectional model will be used.
		    dir = (direction == bidirectional) ? 2 : 1
		dropout: dropout probability. When set to 0., dropout is disabled.
		seed: the 1st part of a seed to initialize dropout.
		seed2: the 2nd part of a seed to initialize dropout.
		num_proj: The output dimensionality for the projection matrices. If None or 0,
		    no projection is performed.
		
		Args:
		  num_layers: A `Tensor` of type `int32`.
		  num_units: A `Tensor` of type `int32`.
		  input_size: A `Tensor` of type `int32`.
		  weights: A list of at least 1 `Tensor` objects with the same type in: `half`, `float32`, `float64`.
		  biases: A list of at least 1 `Tensor` objects with the same type as `weights`.
		  rnn_mode: An optional `string` from: `"rnn_relu", "rnn_tanh", "lstm", "gru"`. Defaults to `"lstm"`.
		  input_mode: An optional `string` from: `"linear_input", "skip_input", "auto_select"`. Defaults to `"linear_input"`.
		  direction: An optional `string` from: `"unidirectional", "bidirectional"`. Defaults to `"unidirectional"`.
		  dropout: An optional `float`. Defaults to `0`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  num_proj: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `weights`.
	**/
	static public function CudnnRNNCanonicalToParamsV2(num_layers:Dynamic, num_units:Dynamic, input_size:Dynamic, weights:Dynamic, biases:Dynamic, ?rnn_mode:Dynamic, ?input_mode:Dynamic, ?direction:Dynamic, ?dropout:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?num_proj:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes size of weights that can be used by a Cudnn RNN model.
		
		Return the params size that can be used by the Cudnn RNN model. Subsequent
		weight allocation and initialization should use this size.
		
		num_layers: Specifies the number of layers in the RNN model.
		num_units: Specifies the size of the hidden state.
		input_size: Specifies the size of the input state.
		rnn_mode: Indicates the type of the RNN model.
		input_mode: Indicate whether there is a linear projection between the input and
		  The actual computation before the first layer. 'skip_input' is only allowed
		  when input_size == num_units; 'auto_select' implies 'skip_input' when
		  input_size == num_units; otherwise, it implies 'linear_input'.
		direction: Indicates whether a bidirectional model will be used.
		  dir = (direction == bidirectional) ? 2 : 1
		dropout: dropout probability. When set to 0., dropout is disabled.
		seed: the 1st part of a seed to initialize dropout.
		seed2: the 2nd part of a seed to initialize dropout.
		params_size: The size of the params buffer that should be allocated and
		  initialized for this RNN model. Note that this params buffer may not be
		  compatible across GPUs. Please use CudnnRNNParamsWeights and
		  CudnnRNNParamsBiases to save and restore them in a way that is compatible
		  across different runs.
		
		Args:
		  num_layers: A `Tensor` of type `int32`.
		  num_units: A `Tensor` of type `int32`.
		  input_size: A `Tensor` of type `int32`.
		  T: A `tf.DType` from: `tf.half, tf.float32, tf.float64`.
		  S: A `tf.DType` from: `tf.int32, tf.int64`.
		  rnn_mode: An optional `string` from: `"rnn_relu", "rnn_tanh", "lstm", "gru"`. Defaults to `"lstm"`.
		  input_mode: An optional `string` from: `"linear_input", "skip_input", "auto_select"`. Defaults to `"linear_input"`.
		  direction: An optional `string` from: `"unidirectional", "bidirectional"`. Defaults to `"unidirectional"`.
		  dropout: An optional `float`. Defaults to `0`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  num_proj: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `S`.
	**/
	static public function CudnnRNNParamsSize(num_layers:Dynamic, num_units:Dynamic, input_size:Dynamic, T:Dynamic, S:Dynamic, ?rnn_mode:Dynamic, ?input_mode:Dynamic, ?direction:Dynamic, ?dropout:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?num_proj:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieves CudnnRNN params in canonical form.
		
		Retrieves a set of weights from the opaque params buffer that can be saved and
		restored in a way compatible with future runs.
		
		Note that the params buffer may not be compatible across different GPUs. So any
		save and restoration should be converted to and from the canonical weights and
		biases.
		
		num_layers: Specifies the number of layers in the RNN model.
		num_units: Specifies the size of the hidden state.
		input_size: Specifies the size of the input state.
		num_params: number of parameter sets for all layers.
		    Each layer may contain multiple parameter sets, with each set consisting of
		    a weight matrix and a bias vector.
		weights: the canonical form of weights that can be used for saving
		    and restoration. They are more likely to be compatible across different
		    generations.
		biases: the canonical form of biases that can be used for saving
		    and restoration. They are more likely to be compatible across different
		    generations.
		rnn_mode: Indicates the type of the RNN model.
		input_mode: Indicate whether there is a linear projection between the input and
		    The actual computation before the first layer. 'skip_input' is only allowed
		    when input_size == num_units; 'auto_select' implies 'skip_input' when
		    input_size == num_units; otherwise, it implies 'linear_input'.
		direction: Indicates whether a bidirectional model will be used.
		    dir = (direction == bidirectional) ? 2 : 1
		dropout: dropout probability. When set to 0., dropout is disabled.
		seed: the 1st part of a seed to initialize dropout.
		seed2: the 2nd part of a seed to initialize dropout.
		
		Args:
		  num_layers: A `Tensor` of type `int32`.
		  num_units: A `Tensor` of type `int32`.
		  input_size: A `Tensor` of type `int32`.
		  params: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		  num_params: An `int` that is `>= 1`.
		  rnn_mode: An optional `string` from: `"rnn_relu", "rnn_tanh", "lstm", "gru"`. Defaults to `"lstm"`.
		  input_mode: An optional `string` from: `"linear_input", "skip_input", "auto_select"`. Defaults to `"linear_input"`.
		  direction: An optional `string` from: `"unidirectional", "bidirectional"`. Defaults to `"unidirectional"`.
		  dropout: An optional `float`. Defaults to `0`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (weights, biases).
		
		  weights: A list of `num_params` `Tensor` objects with the same type as `params`.
		  biases: A list of `num_params` `Tensor` objects with the same type as `params`.
	**/
	static public function CudnnRNNParamsToCanonical(num_layers:Dynamic, num_units:Dynamic, input_size:Dynamic, params:Dynamic, num_params:Dynamic, ?rnn_mode:Dynamic, ?input_mode:Dynamic, ?direction:Dynamic, ?dropout:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieves CudnnRNN params in canonical form. It supports the projection in LSTM.
		
		Retrieves a set of weights from the opaque params buffer that can be saved and
		restored in a way compatible with future runs.
		
		Note that the params buffer may not be compatible across different GPUs. So any
		save and restoration should be converted to and from the canonical weights and
		biases.
		
		num_layers: Specifies the number of layers in the RNN model.
		num_units: Specifies the size of the hidden state.
		input_size: Specifies the size of the input state.
		num_params_weights: number of weight parameter matrix for all layers.
		num_params_biases: number of bias parameter vector for all layers.
		weights: the canonical form of weights that can be used for saving
		    and restoration. They are more likely to be compatible across different
		    generations.
		biases: the canonical form of biases that can be used for saving
		    and restoration. They are more likely to be compatible across different
		    generations.
		rnn_mode: Indicates the type of the RNN model.
		input_mode: Indicate whether there is a linear projection between the input and
		    The actual computation before the first layer. 'skip_input' is only allowed
		    when input_size == num_units; 'auto_select' implies 'skip_input' when
		    input_size == num_units; otherwise, it implies 'linear_input'.
		direction: Indicates whether a bidirectional model will be used.
		    dir = (direction == bidirectional) ? 2 : 1
		dropout: dropout probability. When set to 0., dropout is disabled.
		seed: the 1st part of a seed to initialize dropout.
		seed2: the 2nd part of a seed to initialize dropout.
		num_proj: The output dimensionality for the projection matrices. If None or 0,
		    no projection is performed.
		
		Args:
		  num_layers: A `Tensor` of type `int32`.
		  num_units: A `Tensor` of type `int32`.
		  input_size: A `Tensor` of type `int32`.
		  params: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		  num_params_weights: An `int` that is `>= 1`.
		  num_params_biases: An `int` that is `>= 1`.
		  rnn_mode: An optional `string` from: `"rnn_relu", "rnn_tanh", "lstm", "gru"`. Defaults to `"lstm"`.
		  input_mode: An optional `string` from: `"linear_input", "skip_input", "auto_select"`. Defaults to `"linear_input"`.
		  direction: An optional `string` from: `"unidirectional", "bidirectional"`. Defaults to `"unidirectional"`.
		  dropout: An optional `float`. Defaults to `0`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  num_proj: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (weights, biases).
		
		  weights: A list of `num_params_weights` `Tensor` objects with the same type as `params`.
		  biases: A list of `num_params_biases` `Tensor` objects with the same type as `params`.
	**/
	static public function CudnnRNNParamsToCanonicalV2(num_layers:Dynamic, num_units:Dynamic, input_size:Dynamic, params:Dynamic, num_params_weights:Dynamic, num_params_biases:Dynamic, ?rnn_mode:Dynamic, ?input_mode:Dynamic, ?direction:Dynamic, ?dropout:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?num_proj:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A RNN backed by cuDNN.
		
		Computes the RNN from the input and initial states, with respect to the params
		buffer. Produces one extra output "host_reserved" than CudnnRNN.
		
		rnn_mode: Indicates the type of the RNN model.
		input_mode: Indicates whether there is a linear projection between the input and
		  the actual computation before the first layer. 'skip_input' is only allowed
		  when input_size == num_units; 'auto_select' implies 'skip_input' when
		  input_size == num_units; otherwise, it implies 'linear_input'.
		direction: Indicates whether a bidirectional model will be used. Should be
		  "unidirectional" or "bidirectional".
		dropout: Dropout probability. When set to 0., dropout is disabled.
		seed: The 1st part of a seed to initialize dropout.
		seed2: The 2nd part of a seed to initialize dropout.
		input: A 3-D tensor with the shape of [seq_length, batch_size, input_size].
		input_h: A 3-D tensor with the shape of [num_layer * dir, batch_size,
		    num_units].
		input_c: For LSTM, a 3-D tensor with the shape of
		    [num_layer * dir, batch, num_units]. For other models, it is ignored.
		params: A 1-D tensor that contains the weights and biases in an opaque layout.
		    The size must be created through CudnnRNNParamsSize, and initialized
		    separately. Note that they might not be compatible across different
		    generations. So it is a good idea to save and restore
		output: A 3-D tensor with the shape of [seq_length, batch_size,
		    dir * num_units].
		output_h: The same shape has input_h.
		output_c: The same shape as input_c for LSTM. An empty tensor for other models.
		is_training: Indicates whether this operation is used for inference or
		  training.
		reserve_space: An opaque tensor that can be used in backprop calculation. It
		  is only produced if is_training is true.
		host_reserved: An opaque tensor that can be used in backprop calculation. It is
		  only produced if is_training is true. It is output on host memory rather than
		  device memory.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		  input_h: A `Tensor`. Must have the same type as `input`.
		  input_c: A `Tensor`. Must have the same type as `input`.
		  params: A `Tensor`. Must have the same type as `input`.
		  rnn_mode: An optional `string` from: `"rnn_relu", "rnn_tanh", "lstm", "gru"`. Defaults to `"lstm"`.
		  input_mode: An optional `string` from: `"linear_input", "skip_input", "auto_select"`. Defaults to `"linear_input"`.
		  direction: An optional `string` from: `"unidirectional", "bidirectional"`. Defaults to `"unidirectional"`.
		  dropout: An optional `float`. Defaults to `0`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  is_training: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, output_h, output_c, reserve_space, host_reserved).
		
		  output: A `Tensor`. Has the same type as `input`.
		  output_h: A `Tensor`. Has the same type as `input`.
		  output_c: A `Tensor`. Has the same type as `input`.
		  reserve_space: A `Tensor`. Has the same type as `input`.
		  host_reserved: A `Tensor` of type `int8`.
	**/
	static public function CudnnRNNV2(input:Dynamic, input_h:Dynamic, input_c:Dynamic, params:Dynamic, ?rnn_mode:Dynamic, ?input_mode:Dynamic, ?direction:Dynamic, ?dropout:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?is_training:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A RNN backed by cuDNN.
		
		Computes the RNN from the input and initial states, with respect to the params
		buffer. Accepts one extra input "sequence_lengths" than CudnnRNN.
		
		rnn_mode: Indicates the type of the RNN model.
		input_mode: Indicates whether there is a linear projection between the input and
		  the actual computation before the first layer. 'skip_input' is only allowed
		  when input_size == num_units; 'auto_select' implies 'skip_input' when
		  input_size == num_units; otherwise, it implies 'linear_input'.
		direction: Indicates whether a bidirectional model will be used. Should be
		  "unidirectional" or "bidirectional".
		dropout: Dropout probability. When set to 0., dropout is disabled.
		seed: The 1st part of a seed to initialize dropout.
		seed2: The 2nd part of a seed to initialize dropout.
		input: If time_major is true, this is a 3-D tensor with the shape of
		    [seq_length, batch_size, input_size]. If time_major is false, the shape is
		    [batch_size, seq_length, input_size].
		input_h: If time_major is true, this is a 3-D tensor with the shape of
		    [num_layer * dir, batch_size, num_units]. If time_major is false, the shape
		    is [batch_size, num_layer * dir, num_units].
		input_c: For LSTM, a 3-D tensor with the shape of
		    [num_layer * dir, batch, num_units]. For other models, it is ignored.
		params: A 1-D tensor that contains the weights and biases in an opaque layout.
		    The size must be created through CudnnRNNParamsSize, and initialized
		    separately. Note that they might not be compatible across different
		    generations. So it is a good idea to save and restore
		sequence_lengths: a vector of lengths of each input sequence.
		output: If time_major is true, this is a 3-D tensor with the shape of
		    [seq_length, batch_size, dir * num_units]. If time_major is false, the
		    shape is [batch_size, seq_length, dir * num_units].
		output_h: The same shape has input_h.
		output_c: The same shape as input_c for LSTM. An empty tensor for other models.
		is_training: Indicates whether this operation is used for inference or
		  training.
		time_major: Indicates whether the input/output format is time major or batch
		    major.
		reserve_space: An opaque tensor that can be used in backprop calculation. It
		  is only produced if is_training is true.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		  input_h: A `Tensor`. Must have the same type as `input`.
		  input_c: A `Tensor`. Must have the same type as `input`.
		  params: A `Tensor`. Must have the same type as `input`.
		  sequence_lengths: A `Tensor` of type `int32`.
		  rnn_mode: An optional `string` from: `"rnn_relu", "rnn_tanh", "lstm", "gru"`. Defaults to `"lstm"`.
		  input_mode: An optional `string` from: `"linear_input", "skip_input", "auto_select"`. Defaults to `"linear_input"`.
		  direction: An optional `string` from: `"unidirectional", "bidirectional"`. Defaults to `"unidirectional"`.
		  dropout: An optional `float`. Defaults to `0`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  num_proj: An optional `int`. Defaults to `0`.
		  is_training: An optional `bool`. Defaults to `True`.
		  time_major: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, output_h, output_c, reserve_space, host_reserved).
		
		  output: A `Tensor`. Has the same type as `input`.
		  output_h: A `Tensor`. Has the same type as `input`.
		  output_c: A `Tensor`. Has the same type as `input`.
		  reserve_space: A `Tensor`. Has the same type as `input`.
		  host_reserved: A `Tensor` of type `int8`.
	**/
	static public function CudnnRNNV3(input:Dynamic, input_h:Dynamic, input_c:Dynamic, params:Dynamic, sequence_lengths:Dynamic, ?rnn_mode:Dynamic, ?input_mode:Dynamic, ?direction:Dynamic, ?dropout:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?num_proj:Dynamic, ?is_training:Dynamic, ?time_major:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute the cumulative product of the tensor `x` along `axis`.
		
		By default, this op performs an inclusive cumprod, which means that the first
		element of the input is identical to the first element of the output:
		
		```python
		tf.cumprod([a, b, c])  # => [a, a * b, a * b * c]
		```
		
		By setting the `exclusive` kwarg to `True`, an exclusive cumprod is
		performed instead:
		
		```python
		tf.cumprod([a, b, c], exclusive=True)  # => [1, a, a * b]
		```
		
		By setting the `reverse` kwarg to `True`, the cumprod is performed in the
		opposite direction:
		
		```python
		tf.cumprod([a, b, c], reverse=True)  # => [a * b * c, b * c, c]
		```
		
		This is more efficient than using separate `tf.reverse` ops.
		
		The `reverse` and `exclusive` kwargs can also be combined:
		
		```python
		tf.cumprod([a, b, c], exclusive=True, reverse=True)  # => [b * c, c, 1]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A `Tensor`. Must be one of the following types: `float32`, `float64`,
		    `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,
		    `complex128`, `qint8`, `quint8`, `qint32`, `half`.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A `Tensor` of type `int32` (default: 0). Must be in the range
		    `[-rank(x), rank(x))`.
		  exclusive: An optional `bool`. Defaults to `False`.
		    If `True`, perform exclusive cumprod.
		  reverse: An optional `bool`. Defaults to `False`.
		    A `bool` (default: False).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Cumprod(x:Dynamic, axis:Dynamic, ?exclusive:Dynamic, ?reverse:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute the cumulative sum of the tensor `x` along `axis`.
		
		By default, this op performs an inclusive cumsum, which means that the first
		element of the input is identical to the first element of the output:
		
		```python
		tf.cumsum([a, b, c])  # => [a, a + b, a + b + c]
		```
		
		By setting the `exclusive` kwarg to `True`, an exclusive cumsum is
		performed instead:
		
		```python
		tf.cumsum([a, b, c], exclusive=True)  # => [0, a, a + b]
		```
		
		By setting the `reverse` kwarg to `True`, the cumsum is performed in the
		opposite direction:
		
		```python
		tf.cumsum([a, b, c], reverse=True)  # => [a + b + c, b + c, c]
		```
		
		This is more efficient than using separate `tf.reverse` ops.
		
		The `reverse` and `exclusive` kwargs can also be combined:
		
		```python
		tf.cumsum([a, b, c], exclusive=True, reverse=True)  # => [b + c, c, 0]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A `Tensor`. Must be one of the following types: `float32`, `float64`,
		    `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,
		    `complex128`, `qint8`, `quint8`, `qint32`, `half`.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A `Tensor` of type `int32` (default: 0). Must be in the range
		    `[-rank(x), rank(x))`.
		  exclusive: An optional `bool`. Defaults to `False`.
		    If `True`, perform exclusive cumsum.
		  reverse: An optional `bool`. Defaults to `False`.
		    A `bool` (default: False).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Cumsum(x:Dynamic, axis:Dynamic, ?exclusive:Dynamic, ?reverse:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute the cumulative product of the tensor `x` along `axis`.
		
		By default, this op performs an inclusive cumulative log-sum-exp,
		which means that the first
		element of the input is identical to the first element of the output:
		```python
		tf.math.cumulative_logsumexp([a, b, c])  # => [a, log(exp(a) + exp(b)), log(exp(a) + exp(b) + exp(c))]
		```
		
		By setting the `exclusive` kwarg to `True`, an exclusive cumulative log-sum-exp is
		performed instead:
		```python
		tf.cumulative_logsumexp([a, b, c], exclusive=True)  # => [-inf, a, log(exp(a) * exp(b))]
		```
		Note that the neutral element of the log-sum-exp operation is `-inf`,
		however, for performance reasons, the minimal value representable by the
		floating point type is used instead.
		
		By setting the `reverse` kwarg to `True`, the cumulative log-sum-exp is performed in the
		opposite direction.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		    A `Tensor`. Must be one of the following types: `float16`, `float32`, `float64`.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A `Tensor` of type `int32` (default: 0). Must be in the range
		    `[-rank(x), rank(x))`.
		  exclusive: An optional `bool`. Defaults to `False`.
		    If `True`, perform exclusive cumulative log-sum-exp.
		  reverse: An optional `bool`. Defaults to `False`.
		    A `bool` (default: False).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function CumulativeLogsumexp(x:Dynamic, axis:Dynamic, ?exclusive:Dynamic, ?reverse:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the dimension index in the destination data format given the one in
		
		the source data format.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor with each element as a dimension index in source data format.
		    Must be in the range [-4, 4).
		  src_format: An optional `string`. Defaults to `"NHWC"`.
		    source data format.
		  dst_format: An optional `string`. Defaults to `"NCHW"`.
		    destination data format.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function DataFormatDimMap(x:Dynamic, ?src_format:Dynamic, ?dst_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Permute input tensor from `src_format` to `dst_format`.
		
		Input tensor must be a vector of size 4, or a 4x2 tensor.
		
		For example, with `src_format` of `NHWC`, `dst_format` of `NCHW`, and inputs:
		```
		[1, 2, 3, 4]
		```
		and
		```
		[[1, 2, 3, 4],
		 [5, 6, 7, 8]]
		```
		, the outputs will be (respectively):
		```
		[1, 4, 2, 3]
		```
		and
		```
		[[1, 4, 2, 3],
		 [5, 8, 6, 7]]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Vector of size 4 or Tensor of shape (4, 2) in source data format.
		  src_format: An optional `string`. Defaults to `"NHWC"`.
		    source data format.
		  dst_format: An optional `string`. Defaults to `"NCHW"`.
		    destination data format.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function DataFormatVecPermute(x:Dynamic, ?src_format:Dynamic, ?dst_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that reads data from the tf.data service.
		
		Args:
		  dataset_id: A `Tensor` of type `int64`.
		  processing_mode: A `Tensor` of type `string`.
		  address: A `Tensor` of type `string`.
		  protocol: A `Tensor` of type `string`.
		  job_name: A `Tensor` of type `string`.
		  max_outstanding_requests: A `Tensor` of type `int64`.
		  iteration_counter: A `Tensor` of type `resource`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  task_refresh_interval_hint_ms: An optional `int`. Defaults to `-1`.
		  data_transfer_protocol: An optional `string`. Defaults to `""`.
		  target_workers: An optional `string`. Defaults to `"AUTO"`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function DataServiceDataset(dataset_id:Dynamic, processing_mode:Dynamic, address:Dynamic, protocol:Dynamic, job_name:Dynamic, max_outstanding_requests:Dynamic, iteration_counter:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?task_refresh_interval_hint_ms:Dynamic, ?data_transfer_protocol:Dynamic, ?target_workers:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that reads data from the tf.data service.
		
		Args:
		  dataset_id: A `Tensor` of type `int64`.
		  processing_mode: A `Tensor` of type `string`.
		  address: A `Tensor` of type `string`.
		  protocol: A `Tensor` of type `string`.
		  job_name: A `Tensor` of type `string`.
		  consumer_index: A `Tensor` of type `int64`.
		  num_consumers: A `Tensor` of type `int64`.
		  max_outstanding_requests: A `Tensor` of type `int64`.
		  iteration_counter: A `Tensor` of type `resource`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  task_refresh_interval_hint_ms: An optional `int`. Defaults to `-1`.
		  data_transfer_protocol: An optional `string`. Defaults to `""`.
		  target_workers: An optional `string`. Defaults to `"AUTO"`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function DataServiceDatasetV2(dataset_id:Dynamic, processing_mode:Dynamic, address:Dynamic, protocol:Dynamic, job_name:Dynamic, consumer_index:Dynamic, num_consumers:Dynamic, max_outstanding_requests:Dynamic, iteration_counter:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?task_refresh_interval_hint_ms:Dynamic, ?data_transfer_protocol:Dynamic, ?target_workers:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the cardinality of `input_dataset`.
		
		Returns the cardinality of `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the dataset to return cardinality for.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function DatasetCardinality(input_dataset:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset from the given `graph_def`.
		
		Creates a dataset from the provided `graph_def`.
		
		Args:
		  graph_def: A `Tensor` of type `string`.
		    The graph representation of the dataset (as serialized GraphDef).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function DatasetFromGraph(graph_def:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a serialized GraphDef representing `input_dataset`.
		
		Returns a graph representation for `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the dataset to return the graph representation for.
		  stateful_whitelist: An optional list of `strings`. Defaults to `[]`.
		  allow_stateful: An optional `bool`. Defaults to `False`.
		  strip_device_assignment: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function DatasetToGraph(input_dataset:Dynamic, ?stateful_whitelist:Dynamic, ?allow_stateful:Dynamic, ?strip_device_assignment:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a serialized GraphDef representing `input_dataset`.
		
		Returns a graph representation for `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the dataset to return the graph representation for.
		  external_state_policy: An optional `int`. Defaults to `0`.
		  strip_device_assignment: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function DatasetToGraphV2(input_dataset:Dynamic, ?external_state_policy:Dynamic, ?strip_device_assignment:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs the single element from the given dataset.
		
		Args:
		  dataset: A `Tensor` of type `variant`.
		    A handle to a dataset that contains a single element.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `output_types`.
	**/
	static public function DatasetToSingleElement(dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Writes the given dataset to the given file using the TFRecord format.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the dataset to write.
		  filename: A `Tensor` of type `string`.
		    A scalar string tensor representing the filename to use.
		  compression_type: A `Tensor` of type `string`.
		    A scalar string tensor containing either (i) the empty string (no
		    compression), (ii) "ZLIB", or (iii) "GZIP".
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function DatasetToTFRecord(input_dataset:Dynamic, filename:Dynamic, compression_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Dawsn(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Identity op for gradient debugging.
		
		This op is hidden from public in Python. It is used by TensorFlow Debugger to
		register gradient tensors for gradient debugging.
		This op operates on non-reference-type tensors.
		
		Args:
		  input: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function DebugGradientIdentity(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Identity op for gradient debugging.
		
		This op is hidden from public in Python. It is used by TensorFlow Debugger to
		register gradient tensors for gradient debugging.
		This op operates on reference-type tensors.
		
		Args:
		  input: A mutable `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `input`.
	**/
	static public function DebugGradientRefIdentity(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Provides an identity mapping of the non-Ref type input tensor for debugging.
		
		Provides an identity mapping of the non-Ref type input tensor for debugging.
		
		Args:
		  input: A `Tensor`. Input tensor, non-Reference type
		  device_name: An optional `string`. Defaults to `""`.
		    Name of the device on which the tensor resides.
		  tensor_name: An optional `string`. Defaults to `""`.
		    Name of the input tensor.
		  debug_urls: An optional list of `strings`. Defaults to `[]`.
		    List of URLs to debug targets, e.g.,
		      file:///foo/tfdbg_dump, grpc:://localhost:11011
		  gated_grpc: An optional `bool`. Defaults to `False`.
		    Whether this op will be gated. If any of the debug_urls of this
		      debug node is of the grpc:// scheme, when the value of this attribute is set
		      to True, the data will not actually be sent via the grpc stream unless this
		      debug op has been enabled at the debug_url. If all of the debug_urls of this
		      debug node are of the grpc:// scheme and the debug op is enabled at none of
		      them, the output will be an empty Tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function DebugIdentity(input:Dynamic, ?device_name:Dynamic, ?tensor_name:Dynamic, ?debug_urls:Dynamic, ?gated_grpc:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Debug Identity V2 Op.
		
		Provides an identity mapping from input to output, while writing the content of
		the input tensor by calling DebugEventsWriter.
		
		The semantics of the input tensor depends on tensor_debug_mode. In typical
		usage, the input tensor comes directly from the user computation only when
		graph_debug_mode is FULL_TENSOR (see protobuf/debug_event.proto for a
		list of all the possible values of graph_debug_mode). For the other debug modes,
		the input tensor should be produced by an additional op or subgraph that
		computes summary information about one or more tensors.
		
		Args:
		  input: A `Tensor`. Input tensor, non-Reference type
		  tfdbg_context_id: An optional `string`. Defaults to `""`.
		    A tfdbg-generated ID for the context that the op belongs to,
		      e.g., a concrete compiled tf.function.
		  op_name: An optional `string`. Defaults to `""`.
		    Optional. Name of the op that the debug op is concerned with.
		      Used only for single-tensor trace.
		  output_slot: An optional `int`. Defaults to `-1`.
		    Optional. Output slot index of the tensor that the debug op
		      is concerned with. Used only for single-tensor trace.
		  tensor_debug_mode: An optional `int`. Defaults to `-1`.
		    TensorDebugMode enum value. See debug_event.proto for details.
		  debug_urls: An optional list of `strings`. Defaults to `[]`.
		    List of URLs to debug targets, e.g., file:///foo/tfdbg_dump.
		  circular_buffer_size: An optional `int`. Defaults to `1000`.
		  tfdbg_run_id: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function DebugIdentityV2(input:Dynamic, ?tfdbg_context_id:Dynamic, ?op_name:Dynamic, ?output_slot:Dynamic, ?tensor_debug_mode:Dynamic, ?debug_urls:Dynamic, ?circular_buffer_size:Dynamic, ?tfdbg_run_id:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Debug NaN Value Counter Op.
		
		Counts number of NaNs in the input tensor, for debugging.
		
		Args:
		  input: A `Tensor`. Input tensor, non-Reference type.
		  device_name: An optional `string`. Defaults to `""`.
		  tensor_name: An optional `string`. Defaults to `""`.
		    Name of the input tensor.
		  debug_urls: An optional list of `strings`. Defaults to `[]`.
		    List of URLs to debug targets, e.g.,
		      file:///foo/tfdbg_dump, grpc:://localhost:11011.
		  gated_grpc: An optional `bool`. Defaults to `False`.
		     Whether this op will be gated. If any of the debug_urls of this
		      debug node is of the grpc:// scheme, when the value of this attribute is set
		      to True, the data will not actually be sent via the grpc stream unless this
		      debug op has been enabled at the debug_url. If all of the debug_urls of this
		      debug node are of the grpc:// scheme and the debug op is enabled at none of
		      them, the output will be an empty Tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function DebugNanCount(input:Dynamic, ?device_name:Dynamic, ?tensor_name:Dynamic, ?debug_urls:Dynamic, ?gated_grpc:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Debug Numeric Summary Op.
		
		Provide a basic summary of numeric value types, range and distribution.
		
		output: A double tensor of shape [14 + nDimensions], where nDimensions is the
		  number of dimensions of the tensor's shape. The elements of output are:
		  [0]: is initialized (1.0) or not (0.0).
		  [1]: total number of elements
		  [2]: NaN element count
		  [3]: generalized -inf count: elements <= lower_bound. lower_bound is -inf by
		    default.
		  [4]: negative element count (excluding -inf), if lower_bound is the default
		    -inf. Otherwise, this is the count of elements > lower_bound and < 0.
		  [5]: zero element count
		  [6]: positive element count (excluding +inf), if upper_bound is the default
		    +inf. Otherwise, this is the count of elements < upper_bound and > 0.
		  [7]: generalized +inf count, elements >= upper_bound. upper_bound is +inf by
		    default.
		Output elements [1:8] are all zero, if the tensor is uninitialized.
		  [8]: minimum of all non-inf and non-NaN elements.
		       If uninitialized or no such element exists: +inf.
		  [9]: maximum of all non-inf and non-NaN elements.
		       If uninitialized or no such element exists: -inf.
		  [10]: mean of all non-inf and non-NaN elements.
		        If uninitialized or no such element exists: NaN.
		  [11]: variance of all non-inf and non-NaN elements.
		        If uninitialized or no such element exists: NaN.
		  [12]: Data type of the tensor encoded as an enum integer. See the DataType
		        proto for more details.
		  [13]: Number of dimensions of the tensor (ndims).
		  [14+]: Sizes of the dimensions.
		
		Args:
		  input: A `Tensor`. Input tensor, non-Reference type.
		  device_name: An optional `string`. Defaults to `""`.
		  tensor_name: An optional `string`. Defaults to `""`.
		    Name of the input tensor.
		  debug_urls: An optional list of `strings`. Defaults to `[]`.
		    List of URLs to debug targets, e.g.,
		      file:///foo/tfdbg_dump, grpc:://localhost:11011.
		  lower_bound: An optional `float`. Defaults to `float('-inf')`.
		    (float) The lower bound <= which values will be included in the
		      generalized -inf count. Default: -inf.
		  upper_bound: An optional `float`. Defaults to `float('inf')`.
		    (float) The upper bound >= which values will be included in the
		      generalized +inf count. Default: +inf.
		  mute_if_healthy: An optional `bool`. Defaults to `False`.
		    (bool) Do not send data to the debug URLs unless at least one
		      of elements [2], [3] and [7] (i.e., the nan count and the generalized -inf and
		      inf counts) is non-zero.
		  gated_grpc: An optional `bool`. Defaults to `False`.
		    Whether this op will be gated. If any of the debug_urls of this
		      debug node is of the grpc:// scheme, when the value of this attribute is set
		      to True, the data will not actually be sent via the grpc stream unless this
		      debug op has been enabled at the debug_url. If all of the debug_urls of this
		      debug node are of the grpc:// scheme and the debug op is enabled at none of
		      them, the output will be an empty Tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float64`.
	**/
	static public function DebugNumericSummary(input:Dynamic, ?device_name:Dynamic, ?tensor_name:Dynamic, ?debug_urls:Dynamic, ?lower_bound:Dynamic, ?upper_bound:Dynamic, ?mute_if_healthy:Dynamic, ?gated_grpc:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Debug Numeric Summary V2 Op.
		
		Computes a numeric summary of the input tensor. The shape of the output
		depends on the tensor_debug_mode attribute.
		This op is used internally by TensorFlow Debugger (tfdbg) v2.
		
		Args:
		  input: A `Tensor`. Input tensor, to be summarized by the op.
		  output_dtype: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.
		    Optional. The type of the output. Can be float32 or float64 (default: float32).
		  tensor_debug_mode: An optional `int`. Defaults to `-1`.
		    Tensor debug mode: the mode in which the input tensor is summarized
		      by the op. See the TensorDebugMode enum in
		      tensorflow/core/protobuf/debug_event.proto for details.
		
		    Supported values:
		      2 (CURT_HEALTH): Output a float32/64 tensor of shape [2]. The 1st
		      element is the tensor_id, if provided, and -1 otherwise. The 2nd
		      element is a bit which is set to 1 if the input tensor has an
		      infinity or nan value, or zero otherwise.
		
		      3 (CONCISE_HEALTH): Output a float32/64 tensor of shape [5]. The 1st
		      element is the tensor_id, if provided, and -1 otherwise. The
		      remaining four slots are the total number of elements, -infs,
		      +infs, and nans in the input tensor respectively.
		
		      4 (FULL_HEALTH): Output a float32/64 tensor of shape [11]. The 1st
		      element is the tensor_id, if provided, and -1 otherwise. The 2nd
		      element is the device_id, if provided, and -1 otherwise. The 3rd
		      element holds the datatype value of the input tensor as according
		      to the enumerated type in tensorflow/core/framework/types.proto.
		      The remaining elements hold the total number of elements, -infs,
		      +infs, nans, negative finite numbers, zeros, and positive finite
		      numbers in the input tensor respectively.
		
		      5 (SHAPE): Output a float32/64 tensor of shape [10]. The 1st
		      element is the tensor_id, if provided, and -1 otherwise. The 2nd
		      element holds the datatype value of the input tensor as according
		      to the enumerated type in tensorflow/core/framework/types.proto.
		      The 3rd element holds the rank of the tensor. The 4th element holds
		      the number of elements within the tensor. Finally the remaining 6
		      elements hold the shape of the tensor. If the rank of the tensor
		      is lower than 6, the shape is right padded with zeros. If the rank
		      is greater than 6, the head of the shape is truncated.
		
		      6 (FULL_NUMERICS): Output a float32/64 tensor of shape [22]. The 1st
		      element is the tensor_id, if provided, and -1 otherwise. The 2nd
		      element is the device_id, if provided, and -1 otherwise. The 3rd
		      element holds the datatype value of the input tensor as according
		      to the enumerated type in tensorflow/core/framework/types.proto.
		      The 4th element holds the rank of the tensor. The 5th to 11th
		      elements hold the shape of the tensor. If the rank of the tensor
		      is lower than 6, the shape is right padded with zeros. If the rank
		      is greater than 6, the head of the shape is truncated. The 12th to
		      18th elements hold the number of elements, -infs, +infs, nans,
		      denormal floats, negative finite numbers, zeros, and positive
		      finite numbers in the input tensor respectively. The final four
		      elements hold the min value, max value, mean, and variance of the
		      input tensor.
		
		      8 (REDUCE_INF_NAN_THREE_SLOTS): Output a float32/64 tensor of shape
		      [3]. The 1st element is -inf if any elements of the input tensor
		      is -inf, or zero otherwise. The 2nd element is +inf if any elements
		      of the input tensor is +inf, or zero otherwise.  The 3rd element is
		      nan if any element of the input tensor is nan, or zero otherwise.
		  tensor_id: An optional `int`. Defaults to `-1`.
		    Optional. An integer identifier for the tensor being summarized by this op.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `output_dtype`.
	**/
	static public function DebugNumericSummaryV2(input:Dynamic, ?output_dtype:Dynamic, ?tensor_debug_mode:Dynamic, ?tensor_id:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decode and Crop a JPEG-encoded image to a uint8 tensor.
		
		The attr `channels` indicates the desired number of color channels for the
		decoded image.
		
		Accepted values are:
		
		*   0: Use the number of channels in the JPEG-encoded image.
		*   1: output a grayscale image.
		*   3: output an RGB image.
		
		If needed, the JPEG-encoded image is transformed to match the requested number
		of color channels.
		
		The attr `ratio` allows downscaling the image by an integer factor during
		decoding.  Allowed values are: 1, 2, 4, and 8.  This is much faster than
		downscaling the image later.
		
		
		It is equivalent to a combination of decode and crop, but much faster by only
		decoding partial jpeg image.
		
		Args:
		  contents: A `Tensor` of type `string`. 0-D.  The JPEG-encoded image.
		  crop_window: A `Tensor` of type `int32`.
		    1-D.  The crop window: [crop_y, crop_x, crop_height, crop_width].
		  channels: An optional `int`. Defaults to `0`.
		    Number of color channels for the decoded image.
		  ratio: An optional `int`. Defaults to `1`. Downscaling ratio.
		  fancy_upscaling: An optional `bool`. Defaults to `True`.
		    If true use a slower but nicer upscaling of the
		    chroma planes (yuv420/422 only).
		  try_recover_truncated: An optional `bool`. Defaults to `False`.
		    If true try to recover an image from truncated input.
		  acceptable_fraction: An optional `float`. Defaults to `1`.
		    The minimum required fraction of lines before a truncated
		    input is accepted.
		  dct_method: An optional `string`. Defaults to `""`.
		    string specifying a hint about the algorithm used for
		    decompression.  Defaults to "" which maps to a system-specific
		    default.  Currently valid values are ["INTEGER_FAST",
		    "INTEGER_ACCURATE"].  The hint may be ignored (e.g., the internal
		    jpeg library changes to a version that does not have that specific
		    option.)
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `uint8`.
	**/
	static public function DecodeAndCropJpeg(contents:Dynamic, crop_window:Dynamic, ?channels:Dynamic, ?ratio:Dynamic, ?fancy_upscaling:Dynamic, ?try_recover_truncated:Dynamic, ?acceptable_fraction:Dynamic, ?dct_method:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decode web-safe base64-encoded strings.
		
		Input may or may not have padding at the end. See EncodeBase64 for padding.
		Web-safe means that input must use - and _ instead of + and /.
		
		Args:
		  input: A `Tensor` of type `string`. Base64 strings to decode.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function DecodeBase64(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decode the first frame of a BMP-encoded image to a uint8 tensor.
		
		The attr `channels` indicates the desired number of color channels for the
		decoded image.
		
		Accepted values are:
		
		*   0: Use the number of channels in the BMP-encoded image.
		*   3: output an RGB image.
		*   4: output an RGBA image.
		
		Args:
		  contents: A `Tensor` of type `string`. 0-D.  The BMP-encoded image.
		  channels: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `uint8`.
	**/
	static public function DecodeBmp(contents:Dynamic, ?channels:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Convert CSV records to tensors. Each column maps to one tensor.
		
		RFC 4180 format is expected for the CSV records.
		(https://tools.ietf.org/html/rfc4180)
		Note that we allow leading and trailing spaces with int or float field.
		
		Args:
		  records: A `Tensor` of type `string`.
		    Each string is a record/row in the csv and all records should have
		    the same format.
		  record_defaults: A list of `Tensor` objects with types from: `float32`, `float64`, `int32`, `int64`, `string`.
		    One tensor per column of the input record, with either a
		    scalar default value for that column or an empty vector if the column is
		    required.
		  field_delim: An optional `string`. Defaults to `","`.
		    char delimiter to separate fields in a record.
		  use_quote_delim: An optional `bool`. Defaults to `True`.
		    If false, treats double quotation marks as regular
		    characters inside of the string fields (ignoring RFC 4180, Section 2,
		    Bullet 5).
		  na_value: An optional `string`. Defaults to `""`.
		    Additional string to recognize as NA/NaN.
		  select_cols: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects. Has the same type as `record_defaults`.
	**/
	static public function DecodeCSV(records:Dynamic, record_defaults:Dynamic, ?field_delim:Dynamic, ?use_quote_delim:Dynamic, ?na_value:Dynamic, ?select_cols:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decompress strings.
		
		This op decompresses each element of the `bytes` input `Tensor`, which
		is assumed to be compressed using the given `compression_type`.
		
		The `output` is a string `Tensor` of the same shape as `bytes`,
		each element containing the decompressed data from the corresponding
		element in `bytes`.
		
		Args:
		  bytes: A `Tensor` of type `string`.
		    A Tensor of string which is compressed.
		  compression_type: An optional `string`. Defaults to `""`.
		    A scalar containing either (i) the empty string (no
		    compression), (ii) "ZLIB", or (iii) "GZIP".
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function DecodeCompressed(bytes:Dynamic, ?compression_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decode the frame(s) of a GIF-encoded image to a uint8 tensor.
		
		GIF images with frame or transparency compression are not supported.
		On Linux and MacOS systems, convert animated GIFs from compressed to
		uncompressed by running:
		
		    convert $src.gif -coalesce $dst.gif
		
		This op also supports decoding JPEGs and PNGs, though it is cleaner to use
		`tf.io.decode_image`.
		
		Args:
		  contents: A `Tensor` of type `string`. 0-D.  The GIF-encoded image.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `uint8`.
	**/
	static public function DecodeGif(contents:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Function for decode_bmp, decode_gif, decode_jpeg, and decode_png.
		
		Detects whether an image is a BMP, GIF, JPEG, or PNG, and performs the
		appropriate operation to convert the input bytes string into a Tensor of type
		dtype.
		
		*NOTE*: decode_gif returns a 4-D array [num_frames, height, width, 3], as
		opposed to decode_bmp, decode_jpeg and decode_png, which return 3-D arrays
		[height, width, num_channels]. Make sure to take this into account when
		constructing your graph if you are intermixing GIF files with BMP, JPEG, and/or
		PNG files. Alternately, set the expand_animations argument of this function to
		False, in which case the op will return 3-dimensional tensors and will truncate
		animated GIF files to the first frame.
		
		*NOTE*: If the first frame of an animated GIF does not occupy the entire
		canvas (maximum frame width x maximum frame height), then it fills the
		unoccupied areas (in the first frame) with zeros (black). For frames after the
		first frame that does not occupy the entire canvas, it uses the previous
		frame to fill the unoccupied areas.
		
		Args:
		  contents: A `Tensor` of type `string`. 0-D. The encoded image bytes.
		  channels: An optional `int`. Defaults to `0`.
		    Number of color channels for the decoded image.
		  dtype: An optional `tf.DType` from: `tf.uint8, tf.uint16, tf.float32`. Defaults to `tf.uint8`.
		    The desired DType of the returned Tensor.
		  expand_animations: An optional `bool`. Defaults to `True`.
		    Controls the output shape of the returned op. If True, the returned op will
		    produce a 3-D tensor for PNG, JPEG, and BMP files; and a 4-D tensor for all
		    GIFs, whether animated or not. If, False, the returned op will produce a 3-D
		    tensor for all file types and will truncate animated GIFs to the first frame.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function DecodeImage(contents:Dynamic, ?channels:Dynamic, ?dtype:Dynamic, ?expand_animations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Convert JSON-encoded Example records to binary protocol buffer strings.
		
		
		Note: This is **not** a general purpose JSON parsing op.
		
		This op converts JSON-serialized
		`tf.train.Example` (created with `json_format.MessageToJson`, following the
		[standard JSON mapping](https://developers.google.com/protocol-buffers/docs/proto3#json))
		to a binary-serialized `tf.train.Example` (equivalent to
		`Example.SerializeToString()`) suitable for conversion to tensors with
		`tf.io.parse_example`.
		
		Args:
		  json_examples: A `Tensor` of type `string`.
		    Each string is a JSON object serialized according to the JSON
		    mapping of the Example proto.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function DecodeJSONExample(json_examples:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decode a JPEG-encoded image to a uint8 tensor.
		
		The attr `channels` indicates the desired number of color channels for the
		decoded image.
		
		Accepted values are:
		
		*   0: Use the number of channels in the JPEG-encoded image.
		*   1: output a grayscale image.
		*   3: output an RGB image.
		
		If needed, the JPEG-encoded image is transformed to match the requested number
		of color channels.
		
		The attr `ratio` allows downscaling the image by an integer factor during
		decoding.  Allowed values are: 1, 2, 4, and 8.  This is much faster than
		downscaling the image later.
		
		
		This op also supports decoding PNGs and non-animated GIFs since the interface is
		the same, though it is cleaner to use `tf.io.decode_image`.
		
		Args:
		  contents: A `Tensor` of type `string`. 0-D.  The JPEG-encoded image.
		  channels: An optional `int`. Defaults to `0`.
		    Number of color channels for the decoded image.
		  ratio: An optional `int`. Defaults to `1`. Downscaling ratio.
		  fancy_upscaling: An optional `bool`. Defaults to `True`.
		    If true use a slower but nicer upscaling of the
		    chroma planes (yuv420/422 only).
		  try_recover_truncated: An optional `bool`. Defaults to `False`.
		    If true try to recover an image from truncated input.
		  acceptable_fraction: An optional `float`. Defaults to `1`.
		    The minimum required fraction of lines before a truncated
		    input is accepted.
		  dct_method: An optional `string`. Defaults to `""`.
		    string specifying a hint about the algorithm used for
		    decompression.  Defaults to "" which maps to a system-specific
		    default.  Currently valid values are ["INTEGER_FAST",
		    "INTEGER_ACCURATE"].  The hint may be ignored (e.g., the internal
		    jpeg library changes to a version that does not have that specific
		    option.)
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `uint8`.
	**/
	static public function DecodeJpeg(contents:Dynamic, ?channels:Dynamic, ?ratio:Dynamic, ?fancy_upscaling:Dynamic, ?try_recover_truncated:Dynamic, ?acceptable_fraction:Dynamic, ?dct_method:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reinterpret the bytes of a string as a vector of numbers.
		
		Args:
		  input_bytes: A `Tensor` of type `string`. Tensor of string to be decoded.
		  fixed_length: A `Tensor` of type `int32`.
		    Length in bytes for each element of the decoded output. Must be a multiple
		    of the size of the output type.
		  out_type: A `tf.DType` from: `tf.half, tf.float32, tf.float64, tf.int32, tf.uint16, tf.uint8, tf.int16, tf.int8, tf.int64, tf.bfloat16`.
		  little_endian: An optional `bool`. Defaults to `True`.
		    Whether the input `input_bytes` is in little-endian order. Ignored for
		    `out_type` values that are stored in a single byte, like `uint8`
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `out_type`.
	**/
	static public function DecodePaddedRaw(input_bytes:Dynamic, fixed_length:Dynamic, out_type:Dynamic, ?little_endian:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decode a PNG-encoded image to a uint8 or uint16 tensor.
		
		The attr `channels` indicates the desired number of color channels for the
		decoded image.
		
		Accepted values are:
		
		*   0: Use the number of channels in the PNG-encoded image.
		*   1: output a grayscale image.
		*   3: output an RGB image.
		*   4: output an RGBA image.
		
		If needed, the PNG-encoded image is transformed to match the requested number
		of color channels.
		
		This op also supports decoding JPEGs and non-animated GIFs since the interface
		is the same, though it is cleaner to use `tf.io.decode_image`.
		
		Args:
		  contents: A `Tensor` of type `string`. 0-D.  The PNG-encoded image.
		  channels: An optional `int`. Defaults to `0`.
		    Number of color channels for the decoded image.
		  dtype: An optional `tf.DType` from: `tf.uint8, tf.uint16`. Defaults to `tf.uint8`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function DecodePng(contents:Dynamic, ?channels:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		The op extracts fields from a serialized protocol buffers message into tensors.
		
		The `decode_proto` op extracts fields from a serialized protocol buffers
		message into tensors.  The fields in `field_names` are decoded and converted
		to the corresponding `output_types` if possible.
		
		A `message_type` name must be provided to give context for the field names.
		The actual message descriptor can be looked up either in the linked-in
		descriptor pool or a filename provided by the caller using the
		`descriptor_source` attribute.
		
		Each output tensor is a dense tensor. This means that it is padded to hold
		the largest number of repeated elements seen in the input minibatch. (The
		shape is also padded by one to prevent zero-sized dimensions). The actual
		repeat counts for each example in the minibatch can be found in the `sizes`
		output. In many cases the output of `decode_proto` is fed immediately into
		tf.squeeze if missing values are not a concern. When using tf.squeeze, always
		pass the squeeze dimension explicitly to avoid surprises.
		
		For the most part, the mapping between Proto field types and TensorFlow dtypes
		is straightforward. However, there are a few special cases:
		
		- A proto field that contains a submessage or group can only be converted
		to `DT_STRING` (the serialized submessage). This is to reduce the complexity
		of the API. The resulting string can be used as input to another instance of
		the decode_proto op.
		
		- TensorFlow lacks support for unsigned integers. The ops represent uint64
		types as a `DT_INT64` with the same twos-complement bit pattern (the obvious
		way). Unsigned int32 values can be represented exactly by specifying type
		`DT_INT64`, or using twos-complement if the caller specifies `DT_INT32` in
		the `output_types` attribute.
		
		Both binary and text proto serializations are supported, and can be
		chosen using the `format` attribute.
		
		The `descriptor_source` attribute selects the source of protocol
		descriptors to consult when looking up `message_type`. This may be:
		
		- An empty string  or "local://", in which case protocol descriptors are
		created for C++ (not Python) proto definitions linked to the binary.
		
		- A file, in which case protocol descriptors are created from the file,
		which is expected to contain a `FileDescriptorSet` serialized as a string.
		NOTE: You can build a `descriptor_source` file using the `--descriptor_set_out`
		and `--include_imports` options to the protocol compiler `protoc`.
		
		- A "bytes://<bytes>", in which protocol descriptors are created from `<bytes>`,
		which is expected to be a `FileDescriptorSet` serialized as a string.
		
		Args:
		  bytes: A `Tensor` of type `string`.
		    Tensor of serialized protos with shape `batch_shape`.
		  message_type: A `string`. Name of the proto message type to decode.
		  field_names: A list of `strings`.
		    List of strings containing proto field names. An extension field can be decoded
		    by using its full name, e.g. EXT_PACKAGE.EXT_FIELD_NAME.
		  output_types: A list of `tf.DTypes`.
		    List of TF types to use for the respective field in field_names.
		  descriptor_source: An optional `string`. Defaults to `"local://"`.
		    Either the special value `local://` or a path to a file containing
		    a serialized `FileDescriptorSet`.
		  message_format: An optional `string`. Defaults to `"binary"`.
		    Either `binary` or `text`.
		  sanitize: An optional `bool`. Defaults to `False`.
		    Whether to sanitize the result or not.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sizes, values).
		
		  sizes: A `Tensor` of type `int32`.
		  values: A list of `Tensor` objects of type `output_types`.
	**/
	static public function DecodeProtoV2(bytes:Dynamic, message_type:Dynamic, field_names:Dynamic, output_types:Dynamic, ?descriptor_source:Dynamic, ?message_format:Dynamic, ?sanitize:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reinterpret the bytes of a string as a vector of numbers.
		
		Args:
		  bytes: A `Tensor` of type `string`.
		    All the elements must have the same length.
		  out_type: A `tf.DType` from: `tf.half, tf.float32, tf.float64, tf.int32, tf.uint16, tf.uint8, tf.int16, tf.int8, tf.int64, tf.complex64, tf.complex128, tf.bool, tf.bfloat16`.
		  little_endian: An optional `bool`. Defaults to `True`.
		    Whether the input `bytes` are in little-endian order.
		    Ignored for `out_type` values that are stored in a single byte like
		    `uint8`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `out_type`.
	**/
	static public function DecodeRaw(bytes:Dynamic, out_type:Dynamic, ?little_endian:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decode a 16-bit PCM WAV file to a float tensor.
		
		The -32768 to 32767 signed 16-bit values will be scaled to -1.0 to 1.0 in float.
		
		When desired_channels is set, if the input contains fewer channels than this
		then the last channel will be duplicated to give the requested number, else if
		the input has more channels than requested then the additional channels will be
		ignored.
		
		If desired_samples is set, then the audio will be cropped or padded with zeroes
		to the requested length.
		
		The first output contains a Tensor with the content of the audio samples. The
		lowest dimension will be the number of channels, and the second will be the
		number of samples. For example, a ten-sample-long stereo WAV file should give an
		output shape of [10, 2].
		
		Args:
		  contents: A `Tensor` of type `string`.
		    The WAV-encoded audio, usually from a file.
		  desired_channels: An optional `int`. Defaults to `-1`.
		    Number of sample channels wanted.
		  desired_samples: An optional `int`. Defaults to `-1`.
		    Length of audio requested.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (audio, sample_rate).
		
		  audio: A `Tensor` of type `float32`.
		  sample_rate: A `Tensor` of type `int32`.
	**/
	static public function DecodeWav(contents:Dynamic, ?desired_channels:Dynamic, ?desired_samples:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Makes a copy of `x`.
		
		Args:
		  x: A `Tensor`. The source tensor of type `T`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function DeepCopy(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A container for an iterator resource.
		
		Args:
		  handle: A `Tensor` of type `resource`. A handle to the iterator to delete.
		  deleter: A `Tensor` of type `variant`. A variant deleter.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function DeleteIterator(handle:Dynamic, deleter:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type `resource`.
		  deleter: A `Tensor` of type `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function DeleteMemoryCache(handle:Dynamic, deleter:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A container for an iterator resource.
		
		Args:
		  multi_device_iterator: A `Tensor` of type `resource`.
		    A handle to the multi device iterator to delete.
		  iterators: A list of `Tensor` objects with type `resource`.
		    A list of iterator handles (unused). This is added so that automatic control dependencies get added during function tracing that ensure this op runs after all the dependent iterators are deleted.
		  deleter: A `Tensor` of type `variant`. A variant deleter.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function DeleteMultiDeviceIterator(multi_device_iterator:Dynamic, iterators:Dynamic, deleter:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type `resource`.
		  deleter: A `Tensor` of type `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function DeleteRandomSeedGenerator(handle:Dynamic, deleter:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type `resource`.
		  deleter: A `Tensor` of type `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function DeleteSeedGenerator(handle:Dynamic, deleter:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Delete the tensor specified by its handle in the session.
		
		Args:
		  handle: A `Tensor` of type `string`.
		    The handle for a tensor stored in the session state.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function DeleteSessionTensor(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Counts the number of occurrences of each value in an integer array.
		
		Outputs a vector with length `size` and the same dtype as `weights`. If
		`weights` are empty, then index `i` stores the number of times the value `i` is
		counted in `arr`. If `weights` are non-empty, then index `i` stores the sum of
		the value in `weights` at each index where the corresponding value in `arr` is
		`i`.
		
		Values in `arr` outside of the range [0, size) are ignored.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    1D or 2D int `Tensor`.
		  size: A `Tensor`. Must have the same type as `input`.
		    non-negative int scalar `Tensor`.
		  weights: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.
		    is an int32, int64, float32, or float64 `Tensor` with the same
		    shape as `arr`, or a length-0 `Tensor`, in which case it acts as all weights
		    equal to 1.
		  binary_output: An optional `bool`. Defaults to `False`.
		    bool; Whether the kernel should count the appearance or number of occurrences.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `weights`.
	**/
	static public function DenseBincount(input:Dynamic, size:Dynamic, weights:Dynamic, ?binary_output:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs sparse-output bin counting for a tf.tensor input.
		
		  Counts the number of times each value occurs in the input.
		
		Args:
		  values: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Tensor containing data to count.
		  weights: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.
		    A Tensor of the same shape as indices containing per-index weight values. May
		    also be the empty tensor if no weights are used.
		  binary_output: A `bool`.
		    Whether to output the number of occurrences of each value or 1.
		  minlength: An optional `int` that is `>= -1`. Defaults to `-1`.
		    Minimum value to count. Can be set to -1 for no minimum.
		  maxlength: An optional `int` that is `>= -1`. Defaults to `-1`.
		    Maximum value to count. Can be set to -1 for no maximum.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, output_dense_shape).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor`. Has the same type as `weights`.
		  output_dense_shape: A `Tensor` of type `int64`.
	**/
	static public function DenseCountSparseOutput(values:Dynamic, weights:Dynamic, binary_output:Dynamic, ?minlength:Dynamic, ?maxlength:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts a dense tensor to a (possibly batched) CSRSparseMatrix.
		
		Args:
		  dense_input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `complex64`, `complex128`.
		    A Dense tensor.
		  indices: A `Tensor` of type `int64`. Indices of nonzero elements.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function DenseToCSRSparseMatrix(dense_input:Dynamic, indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies set operation along last dimension of 2 `Tensor` inputs.
		
		See SetOperationOp::SetOperationFromContext for values of `set_operation`.
		
		Output `result` is a `SparseTensor` represented by `result_indices`,
		`result_values`, and `result_shape`. For `set1` and `set2` ranked `n`, this
		has rank `n` and the same 1st `n-1` dimensions as `set1` and `set2`. The `nth`
		dimension contains the result of `set_operation` applied to the corresponding
		`[0...n-1]` dimension of `set`.
		
		Args:
		  set1: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `string`.
		    `Tensor` with rank `n`. 1st `n-1` dimensions must be the same as `set2`.
		    Dimension `n` contains values in a set, duplicates are allowed but ignored.
		  set2: A `Tensor`. Must have the same type as `set1`.
		    `Tensor` with rank `n`. 1st `n-1` dimensions must be the same as `set1`.
		    Dimension `n` contains values in a set, duplicates are allowed but ignored.
		  set_operation: A `string`.
		  validate_indices: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (result_indices, result_values, result_shape).
		
		  result_indices: A `Tensor` of type `int64`.
		  result_values: A `Tensor`. Has the same type as `set1`.
		  result_shape: A `Tensor` of type `int64`.
	**/
	static public function DenseToDenseSetOperation(set1:Dynamic, set2:Dynamic, set_operation:Dynamic, ?validate_indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that batches input elements into a SparseTensor.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A handle to an input dataset. Must have a single component.
		  batch_size: A `Tensor` of type `int64`.
		    A scalar representing the number of elements to accumulate in a
		    batch.
		  row_shape: A `Tensor` of type `int64`.
		    A vector representing the dense shape of each row in the produced
		    SparseTensor. The shape may be partially specified, using `-1` to indicate
		    that a particular dimension should use the maximum size of all batch elements.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function DenseToSparseBatchDataset(input_dataset:Dynamic, batch_size:Dynamic, row_shape:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies set operation along last dimension of `Tensor` and `SparseTensor`.
		
		See SetOperationOp::SetOperationFromContext for values of `set_operation`.
		
		Input `set2` is a `SparseTensor` represented by `set2_indices`, `set2_values`,
		and `set2_shape`. For `set2` ranked `n`, 1st `n-1` dimensions must be the same
		as `set1`. Dimension `n` contains values in a set, duplicates are allowed but
		ignored.
		
		If `validate_indices` is `True`, this op validates the order and range of `set2`
		indices.
		
		Output `result` is a `SparseTensor` represented by `result_indices`,
		`result_values`, and `result_shape`. For `set1` and `set2` ranked `n`, this
		has rank `n` and the same 1st `n-1` dimensions as `set1` and `set2`. The `nth`
		dimension contains the result of `set_operation` applied to the corresponding
		`[0...n-1]` dimension of `set`.
		
		Args:
		  set1: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `string`.
		    `Tensor` with rank `n`. 1st `n-1` dimensions must be the same as `set2`.
		    Dimension `n` contains values in a set, duplicates are allowed but ignored.
		  set2_indices: A `Tensor` of type `int64`.
		    2D `Tensor`, indices of a `SparseTensor`. Must be in row-major
		    order.
		  set2_values: A `Tensor`. Must have the same type as `set1`.
		    1D `Tensor`, values of a `SparseTensor`. Must be in row-major
		    order.
		  set2_shape: A `Tensor` of type `int64`.
		    1D `Tensor`, shape of a `SparseTensor`. `set2_shape[0...n-1]` must
		    be the same as the 1st `n-1` dimensions of `set1`, `result_shape[n]` is the
		    max set size across `n-1` dimensions.
		  set_operation: A `string`.
		  validate_indices: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (result_indices, result_values, result_shape).
		
		  result_indices: A `Tensor` of type `int64`.
		  result_values: A `Tensor`. Has the same type as `set1`.
		  result_shape: A `Tensor` of type `int64`.
	**/
	static public function DenseToSparseSetOperation(set1:Dynamic, set2_indices:Dynamic, set2_values:Dynamic, set2_shape:Dynamic, set_operation:Dynamic, ?validate_indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		DepthToSpace for tensors of type T.
		
		Rearranges data from depth into blocks of spatial data.
		This is the reverse transformation of SpaceToDepth. More specifically,
		this op outputs a copy of the input tensor where values from the `depth`
		dimension are moved in spatial blocks to the `height` and `width` dimensions.
		The attr `block_size` indicates the input block size and how the data is moved.
		
		  * Chunks of data of size `block_size * block_size` from depth are rearranged
		    into non-overlapping blocks of size `block_size x block_size`
		  * The width the output tensor is `input_depth * block_size`, whereas the
		    height is `input_height * block_size`.
		  * The Y, X coordinates within each block of the output image are determined
		    by the high order component of the input channel index.
		  * The depth of the input tensor must be divisible by
		    `block_size * block_size`.
		
		The `data_format` attr specifies the layout of the input and output tensors
		with the following options:
		  "NHWC": `[ batch, height, width, channels ]`
		  "NCHW": `[ batch, channels, height, width ]`
		  "NCHW_VECT_C":
		      `qint8 [ batch, channels / 4, height, width, 4 ]`
		
		It is useful to consider the operation as transforming a 6-D Tensor.
		e.g. for data_format = NHWC,
		     Each element in the input tensor can be specified via 6 coordinates,
		     ordered by decreasing memory layout significance as:
		     n,iY,iX,bY,bX,oC  (where n=batch index, iX, iY means X or Y coordinates
		                        within the input image, bX, bY means coordinates
		                        within the output block, oC means output channels).
		     The output would be the input transposed to the following layout:
		     n,iY,bY,iX,bX,oC
		
		This operation is useful for resizing the activations between convolutions
		(but keeping all data), e.g. instead of pooling. It is also useful for training
		purely convolutional models.
		
		For example, given an input of shape `[1, 1, 1, 4]`, data_format = "NHWC" and
		block_size = 2:
		
		```
		x = [[[[1, 2, 3, 4]]]]
		
		```
		
		This operation will output a tensor of shape `[1, 2, 2, 1]`:
		
		```
		   [[[[1], [2]],
		     [[3], [4]]]]
		```
		
		Here, the input has a batch of 1 and each batch element has shape `[1, 1, 4]`,
		the corresponding output will have 2x2 elements and will have a depth of
		1 channel (1 = `4 / (block_size * block_size)`).
		The output element shape is `[2, 2, 1]`.
		
		For an input tensor with larger depth, here of shape `[1, 1, 1, 12]`, e.g.
		
		```
		x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
		```
		
		This operation, for block size of 2, will return the following tensor of shape
		`[1, 2, 2, 3]`
		
		```
		   [[[[1, 2, 3], [4, 5, 6]],
		     [[7, 8, 9], [10, 11, 12]]]]
		
		```
		
		Similarly, for the following input of shape `[1 2 2 4]`, and a block size of 2:
		
		```
		x =  [[[[1, 2, 3, 4],
		       [5, 6, 7, 8]],
		      [[9, 10, 11, 12],
		       [13, 14, 15, 16]]]]
		```
		
		the operator will return the following tensor of shape `[1 4 4 1]`:
		
		```
		x = [[[ [1],   [2],  [5],  [6]],
		      [ [3],   [4],  [7],  [8]],
		      [ [9],  [10], [13],  [14]],
		      [ [11], [12], [15],  [16]]]]
		
		```
		
		Args:
		  input: A `Tensor`.
		  block_size: An `int` that is `>= 2`.
		    The size of the spatial block, same as in Space2Depth.
		  data_format: An optional `string` from: `"NHWC", "NCHW", "NCHW_VECT_C"`. Defaults to `"NHWC"`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function DepthToSpace(input:Dynamic, block_size:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors.
		
		Given an input tensor of shape `[batch, in_height, in_width, in_channels]`
		and a filter / kernel tensor of shape
		`[filter_height, filter_width, in_channels, channel_multiplier]`, containing
		`in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies
		a different filter to each input channel (expanding from 1 channel to
		`channel_multiplier` channels for each), then concatenates the results
		together. Thus, the output has `in_channels * channel_multiplier` channels.
		
		```
		for k in 0..in_channels-1
		  for q in 0..channel_multiplier-1
		    output[b, i, j, k * channel_multiplier + q] =
		      sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
		                        filter[di, dj, k, q]
		```
		
		Must have `strides[0] = strides[3] = 1`.  For the most common case of the same
		horizontal and vertices strides, `strides = [1, stride, stride, 1]`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		  filter: A `Tensor`. Must have the same type as `input`.
		  strides: A list of `ints`.
		    1-D of length 4.  The stride of the sliding window for each dimension
		    of `input`.
		  padding: A `string` from: `"SAME", "VALID", "EXPLICIT"`.
		    The type of padding algorithm to use.
		  explicit_paddings: An optional list of `ints`. Defaults to `[]`.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, height, width, channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, channels, height, width].
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    1-D tensor of length 4.  The dilation factor for each dimension of
		    `input`. If set to k > 1, there will be k-1 skipped cells between each filter
		    element on that dimension. The dimension order is determined by the value of
		    `data_format`, see above for details. Dilations in the batch and depth
		    dimensions must be 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function DepthwiseConv2dNative(input:Dynamic, filter:Dynamic, strides:Dynamic, padding:Dynamic, ?explicit_paddings:Dynamic, ?data_format:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradients of depthwise convolution with respect to the filter.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    4-D with shape based on `data_format`.  For example, if
		    `data_format` is 'NHWC' then `input` is a 4-D `[batch, in_height,
		    in_width, in_channels]` tensor.
		  filter_sizes: A `Tensor` of type `int32`.
		    An integer vector representing the tensor shape of `filter`,
		    where `filter` is a 4-D
		    `[filter_height, filter_width, in_channels, depthwise_multiplier]` tensor.
		  out_backprop: A `Tensor`. Must have the same type as `input`.
		    4-D with shape  based on `data_format`.
		    For example, if `data_format` is 'NHWC' then
		    out_backprop shape is `[batch, out_height, out_width, out_channels]`.
		    Gradients w.r.t. the output of the convolution.
		  strides: A list of `ints`.
		    The stride of the sliding window for each dimension of the input
		    of the convolution.
		  padding: A `string` from: `"SAME", "VALID", "EXPLICIT"`.
		    The type of padding algorithm to use.
		  explicit_paddings: An optional list of `ints`. Defaults to `[]`.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, height, width, channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, channels, height, width].
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    1-D tensor of length 4.  The dilation factor for each dimension of
		    `input`. If set to k > 1, there will be k-1 skipped cells between each filter
		    element on that dimension. The dimension order is determined by the value of
		    `data_format`, see above for details. Dilations in the batch and depth
		    dimensions must be 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function DepthwiseConv2dNativeBackpropFilter(input:Dynamic, filter_sizes:Dynamic, out_backprop:Dynamic, strides:Dynamic, padding:Dynamic, ?explicit_paddings:Dynamic, ?data_format:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradients of depthwise convolution with respect to the input.
		
		Args:
		  input_sizes: A `Tensor` of type `int32`.
		    An integer vector representing the shape of `input`, based
		    on `data_format`.  For example, if `data_format` is 'NHWC' then
		     `input` is a 4-D `[batch, height, width, channels]` tensor.
		  filter: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    4-D with shape
		    `[filter_height, filter_width, in_channels, depthwise_multiplier]`.
		  out_backprop: A `Tensor`. Must have the same type as `filter`.
		    4-D with shape  based on `data_format`.
		    For example, if `data_format` is 'NHWC' then
		    out_backprop shape is `[batch, out_height, out_width, out_channels]`.
		    Gradients w.r.t. the output of the convolution.
		  strides: A list of `ints`.
		    The stride of the sliding window for each dimension of the input
		    of the convolution.
		  padding: A `string` from: `"SAME", "VALID", "EXPLICIT"`.
		    The type of padding algorithm to use.
		  explicit_paddings: An optional list of `ints`. Defaults to `[]`.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, height, width, channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, channels, height, width].
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    1-D tensor of length 4.  The dilation factor for each dimension of
		    `input`. If set to k > 1, there will be k-1 skipped cells between each filter
		    element on that dimension. The dimension order is determined by the value of
		    `data_format`, see above for details. Dilations in the batch and depth
		    dimensions must be 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `filter`.
	**/
	static public function DepthwiseConv2dNativeBackpropInput(input_sizes:Dynamic, filter:Dynamic, out_backprop:Dynamic, strides:Dynamic, padding:Dynamic, ?explicit_paddings:Dynamic, ?data_format:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Dequantize the 'input' tensor into a float or bfloat16 Tensor.
		
		[min_range, max_range] are scalar floats that specify the range for
		the output. The 'mode' attribute controls exactly which calculations are
		used to convert the float values to their quantized equivalents.
		
		In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:
		
		```
		if T == qint8: in[i] += (range(T) + 1)/ 2.0
		out[i] = min_range + (in[i]* (max_range - min_range) / range(T))
		```
		here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`
		
		*MIN_COMBINED Mode Example*
		
		If the input comes from a QuantizedRelu6, the output type is
		quint8 (range of 0-255) but the possible range of QuantizedRelu6 is
		0-6.  The min_range and max_range values are therefore 0.0 and 6.0.
		Dequantize on quint8 will take each value, cast to float, and multiply
		by 6 / 255.
		Note that if quantizedtype is qint8, the operation will additionally add
		each value by 128 prior to casting.
		
		If the mode is 'MIN_FIRST', then this approach is used:
		
		```c++
		num_discrete_values = 1 << (# of bits in T)
		range_adjust = num_discrete_values / (num_discrete_values - 1)
		range = (range_max - range_min) * range_adjust
		range_scale = range / num_discrete_values
		const double offset_input = static_cast<double>(input) - lowest_quantized;
		result = range_min + ((input - numeric_limits<T>::min()) * range_scale)
		```
		
		If the mode is `SCALED`, dequantization is performed by multiplying each
		input value by a scaling_factor. (Thus an input of 0 always maps to 0.0).
		
		The scaling_factor is determined from `min_range`, `max_range`, and
		`narrow_range` in a way that is compatible with `QuantizeAndDequantize{V2|V3}`
		and `QuantizeV2`, using the following algorithm:
		
		```c++
		
		  const int min_expected_T = std::numeric_limits<T>::min() +
		    (narrow_range ? 1 : 0);
		  const int max_expected_T = std::numeric_limits<T>::max();
		  const float max_expected_T = std::numeric_limits<float>::max();
		
		  const float scale_factor =
		    (std::numeric_limits<T>::min() == 0) ? (max_range / max_expected_T)
		                                         : std::max(min_range / min_expected_T,
		                                                    max_range / max_expected_T);
		```
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  min_range: A `Tensor` of type `float32`.
		    The minimum scalar value possibly produced for the input.
		  max_range: A `Tensor` of type `float32`.
		    The maximum scalar value possibly produced for the input.
		  mode: An optional `string` from: `"MIN_COMBINED", "MIN_FIRST", "SCALED"`. Defaults to `"MIN_COMBINED"`.
		  narrow_range: An optional `bool`. Defaults to `False`.
		  axis: An optional `int`. Defaults to `-1`.
		  dtype: An optional `tf.DType` from: `tf.bfloat16, tf.float32`. Defaults to `tf.float32`.
		    Type of the output tensor. Currently Dequantize supports float and bfloat16.
		    If 'dtype' is 'bfloat16', it only supports 'MIN_COMBINED' mode.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function Dequantize(input:Dynamic, min_range:Dynamic, max_range:Dynamic, ?mode:Dynamic, ?narrow_range:Dynamic, ?axis:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts the given variant tensor to an iterator and stores it in the given resource.
		
		Args:
		  resource_handle: A `Tensor` of type `resource`.
		    A handle to an iterator resource.
		  serialized: A `Tensor` of type `variant`.
		    A variant tensor storing the state of the iterator contained in the
		    resource.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function DeserializeIterator(resource_handle:Dynamic, serialized:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deserialize and concatenate `SparseTensors` from a serialized minibatch.
		
		The input `serialized_sparse` must be a string matrix of shape `[N x 3]` where
		`N` is the minibatch size and the rows correspond to packed outputs of
		`SerializeSparse`.  The ranks of the original `SparseTensor` objects
		must all match.  When the final `SparseTensor` is created, it has rank one
		higher than the ranks of the incoming `SparseTensor` objects
		(they have been concatenated along a new row dimension).
		
		The output `SparseTensor` object's shape values for all dimensions but the
		first are the max across the input `SparseTensor` objects' shape values
		for the corresponding dimensions.  Its first shape value is `N`, the minibatch
		size.
		
		The input `SparseTensor` objects' indices are assumed ordered in
		standard lexicographic order.  If this is not the case, after this
		step run `SparseReorder` to restore index ordering.
		
		For example, if the serialized input is a `[2 x 3]` matrix representing two
		original `SparseTensor` objects:
		
		    index = [ 0]
		            [10]
		            [20]
		    values = [1, 2, 3]
		    shape = [50]
		
		and
		
		    index = [ 2]
		            [10]
		    values = [4, 5]
		    shape = [30]
		
		then the final deserialized `SparseTensor` will be:
		
		    index = [0  0]
		            [0 10]
		            [0 20]
		            [1  2]
		            [1 10]
		    values = [1, 2, 3, 4, 5]
		    shape = [2 50]
		
		Args:
		  serialized_sparse: A `Tensor` of type `string`.
		    2-D, The `N` serialized `SparseTensor` objects.
		    Must have 3 columns.
		  dtype: A `tf.DType`. The `dtype` of the serialized `SparseTensor` objects.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sparse_indices, sparse_values, sparse_shape).
		
		  sparse_indices: A `Tensor` of type `int64`.
		  sparse_values: A `Tensor` of type `dtype`.
		  sparse_shape: A `Tensor` of type `int64`.
	**/
	static public function DeserializeManySparse(serialized_sparse:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deserialize `SparseTensor` objects.
		
		The input `serialized_sparse` must have the shape `[?, ?, ..., ?, 3]` where
		the last dimension stores serialized `SparseTensor` objects and the other N
		dimensions (N >= 0) correspond to a batch. The ranks of the original
		`SparseTensor` objects must all match. When the final `SparseTensor` is
		created, its rank is the rank of the incoming `SparseTensor` objects plus N;
		the sparse tensors have been concatenated along new dimensions, one for each
		batch.
		
		The output `SparseTensor` object's shape values for the original dimensions
		are the max across the input `SparseTensor` objects' shape values for the
		corresponding dimensions. The new dimensions match the size of the batch.
		
		The input `SparseTensor` objects' indices are assumed ordered in
		standard lexicographic order.  If this is not the case, after this
		step run `SparseReorder` to restore index ordering.
		
		For example, if the serialized input is a `[2 x 3]` matrix representing two
		original `SparseTensor` objects:
		
		    index = [ 0]
		            [10]
		            [20]
		    values = [1, 2, 3]
		    shape = [50]
		
		and
		
		    index = [ 2]
		            [10]
		    values = [4, 5]
		    shape = [30]
		
		then the final deserialized `SparseTensor` will be:
		
		    index = [0  0]
		            [0 10]
		            [0 20]
		            [1  2]
		            [1 10]
		    values = [1, 2, 3, 4, 5]
		    shape = [2 50]
		
		Args:
		  serialized_sparse: A `Tensor`. Must be one of the following types: `string`, `variant`.
		    The serialized `SparseTensor` objects. The last dimension
		    must have 3 columns.
		  dtype: A `tf.DType`. The `dtype` of the serialized `SparseTensor` objects.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sparse_indices, sparse_values, sparse_shape).
		
		  sparse_indices: A `Tensor` of type `int64`.
		  sparse_values: A `Tensor` of type `dtype`.
		  sparse_shape: A `Tensor` of type `int64`.
	**/
	static public function DeserializeSparse(serialized_sparse:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deletes the resource specified by the handle.
		
		All subsequent operations using the resource will result in a NotFound
		error status.
		
		Args:
		  resource: A `Tensor` of type `resource`. handle to the resource to delete.
		  ignore_lookup_error: An optional `bool`. Defaults to `True`.
		    whether to ignore the error when the resource
		    doesn't exist.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function DestroyResourceOp(resource:Dynamic, ?ignore_lookup_error:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Destroys the temporary variable and returns its final value.
		
		Sets output to the value of the Tensor pointed to by 'ref', then destroys
		the temporary variable called 'var_name'.
		All other uses of 'ref' *must* have executed before this op.
		This is typically achieved by chaining the ref through each assign op, or by
		using control dependencies.
		
		Outputs the final value of the tensor pointed to by 'ref'.
		
		Args:
		  ref: A mutable `Tensor`. A reference to the temporary variable tensor.
		  var_name: A `string`.
		    Name of the temporary variable, usually the name of the matching
		    'TemporaryVariable' op.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `ref`.
	**/
	static public function DestroyTemporaryVariable(ref:Dynamic, var_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return the index of device the op runs.
		
		Given a list of device names, this operation returns the index of the device
		this op runs. The length of the list is returned in two cases:
		(1) Device does not exist in the given device list.
		(2) It is in XLA compilation.
		
		Args:
		  device_names: A list of `strings`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function DeviceIndex(device_names:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a diagonal tensor with a given diagonal values.
		
		Given a `diagonal`, this operation returns a tensor with the `diagonal` and
		everything else padded with zeros. The diagonal is computed as follows:
		
		Assume `diagonal` has dimensions [D1,..., Dk], then the output is a tensor of
		rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:
		
		`output[i1,..., ik, i1,..., ik] = diagonal[i1, ..., ik]` and 0 everywhere else.
		
		For example:
		
		```
		# 'diagonal' is [1, 2, 3, 4]
		tf.diag(diagonal) ==> [[1, 0, 0, 0]
		                       [0, 2, 0, 0]
		                       [0, 0, 3, 0]
		                       [0, 0, 0, 4]]
		```
		
		Args:
		  diagonal: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.
		    Rank k tensor where k is at most 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `diagonal`.
	**/
	static public function Diag(diagonal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the diagonal part of the tensor.
		
		This operation returns a tensor with the `diagonal` part
		of the `input`. The `diagonal` part is computed as follows:
		
		Assume `input` has dimensions `[D1,..., Dk, D1,..., Dk]`, then the output is a
		tensor of rank `k` with dimensions `[D1,..., Dk]` where:
		
		`diagonal[i1,..., ik] = input[i1, ..., ik, i1,..., ik]`.
		
		For example:
		
		```
		# 'input' is [[1, 0, 0, 0]
		              [0, 2, 0, 0]
		              [0, 0, 3, 0]
		              [0, 0, 0, 4]]
		
		tf.diag_part(input) ==> [1, 2, 3, 4]
		```
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.
		    Rank k tensor where k is even and not zero.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function DiagPart(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes Psi, the derivative of Lgamma (the log of the absolute value of
		
		`Gamma(x)`), element-wise.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Digamma(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the grayscale dilation of 4-D `input` and 3-D `filter` tensors.
		
		The `input` tensor has shape `[batch, in_height, in_width, depth]` and the
		`filter` tensor has shape `[filter_height, filter_width, depth]`, i.e., each
		input channel is processed independently of the others with its own structuring
		function. The `output` tensor has shape
		`[batch, out_height, out_width, depth]`. The spatial dimensions of the output
		tensor depend on the `padding` algorithm. We currently only support the default
		"NHWC" `data_format`.
		
		In detail, the grayscale morphological 2-D dilation is the max-sum correlation
		(for consistency with `conv2d`, we use unmirrored filters):
		
		    output[b, y, x, c] =
		       max_{dy, dx} input[b,
		                          strides[1] * y + rates[1] * dy,
		                          strides[2] * x + rates[2] * dx,
		                          c] +
		                    filter[dy, dx, c]
		
		Max-pooling is a special case when the filter has size equal to the pooling
		kernel size and contains all zeros.
		
		Note on duality: The dilation of `input` by the `filter` is equal to the
		negation of the erosion of `-input` by the reflected `filter`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    4-D with shape `[batch, in_height, in_width, depth]`.
		  filter: A `Tensor`. Must have the same type as `input`.
		    3-D with shape `[filter_height, filter_width, depth]`.
		  strides: A list of `ints` that has length `>= 4`.
		    The stride of the sliding window for each dimension of the input
		    tensor. Must be: `[1, stride_height, stride_width, 1]`.
		  rates: A list of `ints` that has length `>= 4`.
		    The input stride for atrous morphological dilation. Must be:
		    `[1, rate_height, rate_width, 1]`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Dilation2D(input:Dynamic, filter:Dynamic, strides:Dynamic, rates:Dynamic, padding:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient of morphological 2-D dilation with respect to the filter.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    4-D with shape `[batch, in_height, in_width, depth]`.
		  filter: A `Tensor`. Must have the same type as `input`.
		    3-D with shape `[filter_height, filter_width, depth]`.
		  out_backprop: A `Tensor`. Must have the same type as `input`.
		    4-D with shape `[batch, out_height, out_width, depth]`.
		  strides: A list of `ints` that has length `>= 4`.
		    1-D of length 4. The stride of the sliding window for each dimension of
		    the input tensor. Must be: `[1, stride_height, stride_width, 1]`.
		  rates: A list of `ints` that has length `>= 4`.
		    1-D of length 4. The input stride for atrous morphological dilation.
		    Must be: `[1, rate_height, rate_width, 1]`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Dilation2DBackpropFilter(input:Dynamic, filter:Dynamic, out_backprop:Dynamic, strides:Dynamic, rates:Dynamic, padding:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient of morphological 2-D dilation with respect to the input.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    4-D with shape `[batch, in_height, in_width, depth]`.
		  filter: A `Tensor`. Must have the same type as `input`.
		    3-D with shape `[filter_height, filter_width, depth]`.
		  out_backprop: A `Tensor`. Must have the same type as `input`.
		    4-D with shape `[batch, out_height, out_width, depth]`.
		  strides: A list of `ints` that has length `>= 4`.
		    1-D of length 4. The stride of the sliding window for each dimension of
		    the input tensor. Must be: `[1, stride_height, stride_width, 1]`.
		  rates: A list of `ints` that has length `>= 4`.
		    1-D of length 4. The input stride for atrous morphological dilation.
		    Must be: `[1, rate_height, rate_width, 1]`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Dilation2DBackpropInput(input:Dynamic, filter:Dynamic, out_backprop:Dynamic, strides:Dynamic, rates:Dynamic, padding:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A substitute for `InterleaveDataset` on a fixed list of `N` datasets.
		
		Args:
		  selector_input_dataset: A `Tensor` of type `variant`.
		    A dataset of scalar `DT_INT64` elements that determines which of the
		    `N` data inputs should produce the next output element.
		  data_input_datasets: A list of at least 1 `Tensor` objects with type `variant`.
		    `N` datasets with the same type that will be interleaved according to
		    the values of `selector_input_dataset`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  stop_on_empty_dataset: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function DirectedInterleaveDataset(selector_input_dataset:Dynamic, data_input_datasets:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?stop_on_empty_dataset:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x / y element-wise.
		
		*NOTE*: `Div` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Div(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns 0 if the denominator is zero.
		
		
		*NOTE*: `DivNoNan` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `half`, `float32`, `bfloat16`, `float64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function DivNoNan(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Draw bounding boxes on a batch of images.
		
		Outputs a copy of `images` but draws on top of the pixels zero or more bounding
		boxes specified by the locations in `boxes`. The coordinates of the each
		bounding box in `boxes` are encoded as `[y_min, x_min, y_max, x_max]`. The
		bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
		height of the underlying image.
		
		For example, if an image is 100 x 200 pixels (height x width) and the bounding
		box is `[0.1, 0.2, 0.5, 0.9]`, the upper-left and bottom-right coordinates of
		the bounding box will be `(40, 10)` to `(180, 50)` (in (x,y) coordinates).
		
		Parts of the bounding box may fall outside the image.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `float32`, `half`.
		    4-D with shape `[batch, height, width, depth]`. A batch of images.
		  boxes: A `Tensor` of type `float32`.
		    3-D with shape `[batch, num_bounding_boxes, 4]` containing bounding
		    boxes.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `images`.
	**/
	static public function DrawBoundingBoxes(images:Dynamic, boxes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Draw bounding boxes on a batch of images.
		
		Outputs a copy of `images` but draws on top of the pixels zero or more bounding
		boxes specified by the locations in `boxes`. The coordinates of the each
		bounding box in `boxes` are encoded as `[y_min, x_min, y_max, x_max]`. The
		bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
		height of the underlying image.
		
		For example, if an image is 100 x 200 pixels (height x width) and the bounding
		box is `[0.1, 0.2, 0.5, 0.9]`, the upper-left and bottom-right coordinates of
		the bounding box will be `(40, 10)` to `(100, 50)` (in (x,y) coordinates).
		
		Parts of the bounding box may fall outside the image.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `float32`, `half`.
		    4-D with shape `[batch, height, width, depth]`. A batch of images.
		  boxes: A `Tensor` of type `float32`.
		    3-D with shape `[batch, num_bounding_boxes, 4]` containing bounding
		    boxes.
		  colors: A `Tensor` of type `float32`.
		    2-D. A list of RGBA colors to cycle through for the boxes.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `images`.
	**/
	static public function DrawBoundingBoxesV2(images:Dynamic, boxes:Dynamic, colors:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function DummyIterationCounter(?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function DummyMemoryCache(?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function DummySeedGenerator(?name:Dynamic):Dynamic;
	/**
		Partitions `data` into `num_partitions` tensors using indices from `partitions`.
		
		For each index tuple `js` of size `partitions.ndim`, the slice `data[js, ...]`
		becomes part of `outputs[partitions[js]]`.  The slices with `partitions[js] = i`
		are placed in `outputs[i]` in lexicographic order of `js`, and the first
		dimension of `outputs[i]` is the number of entries in `partitions` equal to `i`.
		In detail,
		
		```python
		    outputs[i].shape = [sum(partitions == i)] + data.shape[partitions.ndim:]
		
		    outputs[i] = pack([data[js, ...] for js if partitions[js] == i])
		```
		
		`data.shape` must start with `partitions.shape`.
		
		For example:
		
		```python
		    # Scalar partitions.
		    partitions = 1
		    num_partitions = 2
		    data = [10, 20]
		    outputs[0] = []  # Empty with shape [0, 2]
		    outputs[1] = [[10, 20]]
		
		    # Vector partitions.
		    partitions = [0, 0, 1, 1, 0]
		    num_partitions = 2
		    data = [10, 20, 30, 40, 50]
		    outputs[0] = [10, 20, 50]
		    outputs[1] = [30, 40]
		```
		
		See `dynamic_stitch` for an example on how to merge partitions back.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/DynamicPartition.png" alt>
		</div>
		
		Args:
		  data: A `Tensor`.
		  partitions: A `Tensor` of type `int32`.
		    Any shape.  Indices in the range `[0, num_partitions)`.
		  num_partitions: An `int` that is `>= 1`.
		    The number of partitions to output.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `num_partitions` `Tensor` objects with the same type as `data`.
	**/
	static public function DynamicPartition(data:Dynamic, partitions:Dynamic, num_partitions:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Interleave the values from the `data` tensors into a single tensor.
		
		Builds a merged tensor such that
		
		```python
		    merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
		```
		
		For example, if each `indices[m]` is scalar or vector, we have
		
		```python
		    # Scalar indices:
		    merged[indices[m], ...] = data[m][...]
		
		    # Vector indices:
		    merged[indices[m][i], ...] = data[m][i, ...]
		```
		
		Each `data[i].shape` must start with the corresponding `indices[i].shape`,
		and the rest of `data[i].shape` must be constant w.r.t. `i`.  That is, we
		must have `data[i].shape = indices[i].shape + constant`.  In terms of this
		`constant`, the output shape is
		
		    merged.shape = [max(indices)] + constant
		
		Values are merged in order, so if an index appears in both `indices[m][i]` and
		`indices[n][j]` for `(m,i) < (n,j)` the slice `data[n][j]` will appear in the
		merged result. If you do not need this guarantee, ParallelDynamicStitch might
		perform better on some devices.
		
		For example:
		
		```python
		    indices[0] = 6
		    indices[1] = [4, 1]
		    indices[2] = [[5, 2], [0, 3]]
		    data[0] = [61, 62]
		    data[1] = [[41, 42], [11, 12]]
		    data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
		    merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
		              [51, 52], [61, 62]]
		```
		
		This method can be used to merge partitions created by `dynamic_partition`
		as illustrated on the following example:
		
		```python
		    # Apply function (increments x_i) on elements for which a certain condition
		    # apply (x_i != -1 in this example).
		    x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])
		    condition_mask=tf.not_equal(x,tf.constant(-1.))
		    partitioned_data = tf.dynamic_partition(
		        x, tf.cast(condition_mask, tf.int32) , 2)
		    partitioned_data[1] = partitioned_data[1] + 1.0
		    condition_indices = tf.dynamic_partition(
		        tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)
		    x = tf.dynamic_stitch(condition_indices, partitioned_data)
		    # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain
		    # unchanged.
		```
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/DynamicStitch.png" alt>
		</div>
		
		Args:
		  indices: A list of at least 1 `Tensor` objects with type `int32`.
		  data: A list with the same length as `indices` of `Tensor` objects with the same type.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function DynamicStitch(indices:Dynamic, data:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Eagerly executes a python function to compute func(input)->output. The
		
		semantics of the input, output, and attributes are the same as those for
		PyFunc.
		
		Args:
		  input: A list of `Tensor` objects.
		  token: A `string`.
		  Tout: A list of `tf.DTypes`.
		  is_async: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function EagerPyFunc(input:Dynamic, token:Dynamic, Tout:Dynamic, ?is_async:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the (possibly normalized) Levenshtein Edit Distance.
		
		The inputs are variable-length sequences provided by SparseTensors
		  (hypothesis_indices, hypothesis_values, hypothesis_shape)
		and
		  (truth_indices, truth_values, truth_shape).
		
		The inputs are:
		
		Args:
		  hypothesis_indices: A `Tensor` of type `int64`.
		    The indices of the hypothesis list SparseTensor.
		    This is an N x R int64 matrix.
		  hypothesis_values: A `Tensor`.
		    The values of the hypothesis list SparseTensor.
		    This is an N-length vector.
		  hypothesis_shape: A `Tensor` of type `int64`.
		    The shape of the hypothesis list SparseTensor.
		    This is an R-length vector.
		  truth_indices: A `Tensor` of type `int64`.
		    The indices of the truth list SparseTensor.
		    This is an M x R int64 matrix.
		  truth_values: A `Tensor`. Must have the same type as `hypothesis_values`.
		    The values of the truth list SparseTensor.
		    This is an M-length vector.
		  truth_shape: A `Tensor` of type `int64`. truth indices, vector.
		  normalize: An optional `bool`. Defaults to `True`.
		    boolean (if true, edit distances are normalized by length of truth).
		
		    The output is:
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function EditDistance(hypothesis_indices:Dynamic, hypothesis_values:Dynamic, hypothesis_shape:Dynamic, truth_indices:Dynamic, truth_values:Dynamic, truth_shape:Dynamic, ?normalize:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the eigen decomposition of one or more square matrices.
		
		Computes the eigenvalues and (optionally) right eigenvectors of each inner matrix in
		`input` such that `input[..., :, :] = v[..., :, :] * diag(e[..., :])`. The eigenvalues
		are sorted in non-decreasing order.
		
		```python
		# a is a tensor.
		# e is a tensor of eigenvalues.
		# v is a tensor of eigenvectors.
		e, v = eig(a)
		e = eig(a, compute_v=False)
		```
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `complex64`, `complex128`.
		    `Tensor` input of shape `[N, N]`.
		  Tout: A `tf.DType` from: `tf.complex64, tf.complex128`.
		  compute_v: An optional `bool`. Defaults to `True`.
		    If `True` then eigenvectors will be computed and returned in `v`.
		    Otherwise, only the eigenvalues will be computed.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (e, v).
		
		  e: A `Tensor` of type `Tout`.
		  v: A `Tensor` of type `Tout`.
	**/
	static public function Eig(input:Dynamic, Tout:Dynamic, ?compute_v:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Tensor contraction according to Einstein summation convention.
		
		Implements generalized Tensor contraction and reduction. Each input Tensor must
		have a corresponding input subscript appearing in the comma-separated left-hand
		side of the equation. The right-hand side of the equation consists of the
		output subscript. The input subscripts and the output subscript should consist
		of zero or more named axis labels and at most one ellipsis (`...`).
		
		The named axis labels may be any single character other than those having
		special meaning, namely `,.->`. The behavior of this Op is undefined if it
		receives an ill-formatted equation; since the validation is done at
		graph-building time, we omit format validation checks at runtime.
		
		Note: This Op is *not* intended to be called by the user; instead users should
		call `tf.einsum` directly. It is a hidden Op used by `tf.einsum`.
		
		Operations are applied to the input(s) according to the following rules:
		
		 (a) Generalized Diagonals: For input dimensions corresponding to axis labels
		     appearing more than once in the same input subscript, we take the
		     generalized (`k`-dimensional) diagonal.
		     For example, in the equation `iii->i` with input shape `[3, 3, 3]`, the
		     generalized diagonal would consist of `3` elements at indices `(0, 0, 0)`,
		     `(1, 1, 1)` and `(2, 2, 2)` to create a Tensor of shape `[3]`.
		
		 (b) Reduction: Axes corresponding to labels appearing only in one input
		     subscript but not in the output subscript are summed over prior to Tensor
		     contraction.
		     For example, in the equation `ab,bc->b`, the axis labels `a` and `c` are
		     the reduction axis labels.
		
		 (c) Batch Dimensions: Axes corresponding to labels appearing in each of the
		     input subscripts and also in the output subscript make up the batch
		     dimensions in Tensor contraction. Unnamed axis labels corresponding to
		     ellipsis (`...`) also correspond to batch dimensions.
		     For example, for the equation denoting batch matrix multiplication,
		     `bij,bjk->bik`, the axis label `b` corresponds to a batch dimension.
		
		 (d) Contraction: In case of binary einsum, axes corresponding to labels
		     appearing in two different inputs (and not in the output) are contracted
		     against each other.
		     Considering the batch matrix multiplication equation again
		     (`bij,bjk->bik`), the contracted axis label is `j`.
		
		 (e) Expand Diagonal: If the output subscripts contain repeated (explicit) axis
		     labels, the opposite operation of (a) is applied. For example, in the
		     equation `i->iii`, and input shape `[3]`, the output of shape `[3, 3, 3]`
		     are all zeros, except for the (generalized) diagonal which is populated
		     with values from the input.
		     Note: This operation is not supported by `np.einsum` or `tf.einsum`; it is
		     provided to enable computing the symbolic gradient of `tf.einsum`.
		
		The output subscripts must contain only labels appearing in at least one of the
		input subscripts. Furthermore, all dimensions mapping to the same axis label
		must be equal.
		
		Any of the input and output subscripts may contain at most a single ellipsis
		(`...`). These ellipsis are mapped against dimensions not corresponding to any
		named axis label. If two inputs contain ellipsis, then they are broadcasted
		according to standard NumPy broadcasting
		[rules](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).
		
		The broadcasted dimensions are placed in the corresponding location of the
		ellipsis in the output subscript. If the broadcasted dimensions are non-empty
		and the output subscripts do not contain ellipsis, then an InvalidArgument error
		is raised.
		
		@compatibility(numpy)
		Similar to [`numpy.einsum`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.einsum.html).
		
		Comparison with `numpy.einsum`:
		
		 * This Op only supports unary and binary forms of `numpy.einsum`.
		 * This Op does not support implicit form. (i.e. equations without `->`).
		 * This Op also supports repeated indices in the output subscript, which is not
		   supported by `numpy.einsum`.
		@end_compatibility
		
		Args:
		  inputs: A list of at least 1 `Tensor` objects with the same type.
		    List of 1 or 2 Tensors.
		  equation: A `string`.
		    String describing the Einstein Summation operation; in the format of np.einsum.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `inputs`.
	**/
	static public function Einsum(inputs:Dynamic, equation:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the exponential linear function.
		
		The ELU function is defined as:
		
		 * $ e ^ x - 1 $ if $ x < 0 $
		 * $ x $ if $ x >= 0 $
		
		Examples:
		
		>>> tf.nn.elu(1.0)
		<tf.Tensor: shape=(), dtype=float32, numpy=1.0>
		>>> tf.nn.elu(0.0)
		<tf.Tensor: shape=(), dtype=float32, numpy=0.0>
		>>> tf.nn.elu(-1000.0)
		<tf.Tensor: shape=(), dtype=float32, numpy=-1.0>
		
		See [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
		](http://arxiv.org/abs/1511.07289)
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `features`.
	**/
	static public function Elu(features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradients for the exponential linear (Elu) operation.
		
		Args:
		  gradients: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    The backpropagated gradients to the corresponding Elu operation.
		  outputs: A `Tensor`. Must have the same type as `gradients`.
		    The outputs of the corresponding Elu operation.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `gradients`.
	**/
	static public function EluGrad(gradients:Dynamic, outputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a tensor with the given shape.
		
		This operation creates a tensor of `shape` and `dtype`.
		
		  Args:
		    shape: A `Tensor` of type `int32`.
		      1-D. Represents the shape of the output tensor.
		    dtype: A `tf.DType`.
		    init: An optional `bool`. Defaults to `False`.
		      If True, initialize the returned tensor with the default value of dtype.  Otherwise, the implementation is free not to initializethe tensor's content.
		    name: A name for the operation (optional).
		
		  Returns:
		    A `Tensor` of type `dtype`.
		  
	**/
	static public function Empty(shape:Dynamic, dtype:Dynamic, ?init:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates and returns an empty tensor list.
		
		All list elements must be tensors of dtype element_dtype and shape compatible
		with element_shape.
		
		handle: an empty tensor list.
		element_dtype: the type of elements in the list.
		element_shape: a shape compatible with that of elements in the list.
		
		Args:
		  element_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  max_num_elements: A `Tensor` of type `int32`.
		  element_dtype: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function EmptyTensorList(element_shape:Dynamic, max_num_elements:Dynamic, element_dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Encode strings into web-safe base64 format.
		
		Refer to the following article for more information on base64 format:
		en.wikipedia.org/wiki/Base64. Base64 strings may have padding with '=' at the
		end so that the encoded has length multiple of 4. See Padding section of the
		link above.
		
		Web-safe means that the encoder uses - and _ instead of + and /.
		
		Args:
		  input: A `Tensor` of type `string`. Strings to be encoded.
		  pad: An optional `bool`. Defaults to `False`.
		    Bool whether padding is applied at the ends.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function EncodeBase64(input:Dynamic, ?pad:Dynamic, ?name:Dynamic):Dynamic;
	/**
		JPEG-encode an image.
		
		`image` is a 3-D uint8 Tensor of shape `[height, width, channels]`.
		
		The attr `format` can be used to override the color format of the encoded
		output.  Values can be:
		
		*   `''`: Use a default format based on the number of channels in the image.
		*   `grayscale`: Output a grayscale JPEG image.  The `channels` dimension
		    of `image` must be 1.
		*   `rgb`: Output an RGB JPEG image. The `channels` dimension
		    of `image` must be 3.
		
		If `format` is not specified or is the empty string, a default format is picked
		in function of the number of channels in `image`:
		
		*   1: Output a grayscale image.
		*   3: Output an RGB image.
		
		Args:
		  image: A `Tensor` of type `uint8`.
		    3-D with shape `[height, width, channels]`.
		  format: An optional `string` from: `"", "grayscale", "rgb"`. Defaults to `""`.
		    Per pixel image format.
		  quality: An optional `int`. Defaults to `95`.
		    Quality of the compression from 0 to 100 (higher is better and slower).
		  progressive: An optional `bool`. Defaults to `False`.
		    If True, create a JPEG that loads progressively (coarse to fine).
		  optimize_size: An optional `bool`. Defaults to `False`.
		    If True, spend CPU/RAM to reduce size with no quality change.
		  chroma_downsampling: An optional `bool`. Defaults to `True`.
		    See http://en.wikipedia.org/wiki/Chroma_subsampling.
		  density_unit: An optional `string` from: `"in", "cm"`. Defaults to `"in"`.
		    Unit used to specify `x_density` and `y_density`:
		    pixels per inch (`'in'`) or centimeter (`'cm'`).
		  x_density: An optional `int`. Defaults to `300`.
		    Horizontal pixels per density unit.
		  y_density: An optional `int`. Defaults to `300`.
		    Vertical pixels per density unit.
		  xmp_metadata: An optional `string`. Defaults to `""`.
		    If not empty, embed this XMP metadata in the image header.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function EncodeJpeg(image:Dynamic, ?format:Dynamic, ?quality:Dynamic, ?progressive:Dynamic, ?optimize_size:Dynamic, ?chroma_downsampling:Dynamic, ?density_unit:Dynamic, ?x_density:Dynamic, ?y_density:Dynamic, ?xmp_metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		JPEG encode input image with provided compression quality.
		
		`image` is a 3-D uint8 Tensor of shape `[height, width, channels]`.
		`quality` is an int32 jpeg compression quality value between 0 and 100.
		
		Args:
		  images: A `Tensor` of type `uint8`. Images to adjust.  At least 3-D.
		  quality: A `Tensor` of type `int32`. An int quality to encode to.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function EncodeJpegVariableQuality(images:Dynamic, quality:Dynamic, ?name:Dynamic):Dynamic;
	/**
		PNG-encode an image.
		
		`image` is a 3-D uint8 or uint16 Tensor of shape `[height, width, channels]`
		where `channels` is:
		
		*   1: for grayscale.
		*   2: for grayscale + alpha.
		*   3: for RGB.
		*   4: for RGBA.
		
		The ZLIB compression level, `compression`, can be -1 for the PNG-encoder
		default or a value from 0 to 9.  9 is the highest compression level, generating
		the smallest output, but is slower.
		
		Args:
		  image: A `Tensor`. Must be one of the following types: `uint8`, `uint16`.
		    3-D with shape `[height, width, channels]`.
		  compression: An optional `int`. Defaults to `-1`. Compression level.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function EncodePng(image:Dynamic, ?compression:Dynamic, ?name:Dynamic):Dynamic;
	/**
		The op serializes protobuf messages provided in the input tensors.
		
		The types of the tensors in `values` must match the schema for the fields
		specified in `field_names`. All the tensors in `values` must have a common
		shape prefix, *batch_shape*.
		
		The `sizes` tensor specifies repeat counts for each field.  The repeat count
		(last dimension) of a each tensor in `values` must be greater than or equal
		to corresponding repeat count in `sizes`.
		
		A `message_type` name must be provided to give context for the field names.
		The actual message descriptor can be looked up either in the linked-in
		descriptor pool or a filename provided by the caller using the
		`descriptor_source` attribute.
		
		For the most part, the mapping between Proto field types and TensorFlow dtypes
		is straightforward. However, there are a few special cases:
		
		- A proto field that contains a submessage or group can only be converted
		to `DT_STRING` (the serialized submessage). This is to reduce the complexity
		of the API. The resulting string can be used as input to another instance of
		the decode_proto op.
		
		- TensorFlow lacks support for unsigned integers. The ops represent uint64
		types as a `DT_INT64` with the same twos-complement bit pattern (the obvious
		way). Unsigned int32 values can be represented exactly by specifying type
		`DT_INT64`, or using twos-complement if the caller specifies `DT_INT32` in
		the `output_types` attribute.
		
		The `descriptor_source` attribute selects the source of protocol
		descriptors to consult when looking up `message_type`. This may be:
		
		- An empty string  or "local://", in which case protocol descriptors are
		created for C++ (not Python) proto definitions linked to the binary.
		
		- A file, in which case protocol descriptors are created from the file,
		which is expected to contain a `FileDescriptorSet` serialized as a string.
		NOTE: You can build a `descriptor_source` file using the `--descriptor_set_out`
		and `--include_imports` options to the protocol compiler `protoc`.
		
		- A "bytes://<bytes>", in which protocol descriptors are created from `<bytes>`,
		which is expected to be a `FileDescriptorSet` serialized as a string.
		
		Args:
		  sizes: A `Tensor` of type `int32`.
		    Tensor of int32 with shape `[batch_shape, len(field_names)]`.
		  values: A list of `Tensor` objects.
		    List of tensors containing values for the corresponding field.
		  field_names: A list of `strings`.
		    List of strings containing proto field names.
		  message_type: A `string`. Name of the proto message type to decode.
		  descriptor_source: An optional `string`. Defaults to `"local://"`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function EncodeProto(sizes:Dynamic, values:Dynamic, field_names:Dynamic, message_type:Dynamic, ?descriptor_source:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Encode audio data using the WAV file format.
		
		This operation will generate a string suitable to be saved out to create a .wav
		audio file. It will be encoded in the 16-bit PCM format. It takes in float
		values in the range -1.0f to 1.0f, and any outside that value will be clamped to
		that range.
		
		`audio` is a 2-D float Tensor of shape `[length, channels]`.
		`sample_rate` is a scalar Tensor holding the rate to use (e.g. 44100).
		
		Args:
		  audio: A `Tensor` of type `float32`. 2-D with shape `[length, channels]`.
		  sample_rate: A `Tensor` of type `int32`.
		    Scalar containing the sample frequency.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function EncodeWav(audio:Dynamic, sample_rate:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An op that enqueues a list of input batch tensors to TPUEmbedding.
		
		Args:
		  batch: A list of at least 1 `Tensor` objects with type `int32`.
		    A list of 1D tensors, one for each embedding table, containing the
		    indices into the tables.
		  mode_override: A `Tensor` of type `string`.
		    A string input that overrides the mode specified in the
		    TPUEmbeddingConfiguration. Supported values are {'unspecified', 'inference',
		    'training', 'backward_pass_only'}. When set to 'unspecified', the mode set
		    in TPUEmbeddingConfiguration is used, otherwise mode_override is used.
		  device_ordinal: An optional `int`. Defaults to `-1`.
		    The TPU device to use. Should be >= 0 and less than the number
		    of TPU cores in the task on which the node is placed.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function EnqueueTPUEmbeddingIntegerBatch(batch:Dynamic, mode_override:Dynamic, ?device_ordinal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Eases the porting of code that uses tf.nn.embedding_lookup().
		
		sample_splits[i], embedding_indices[i] and aggregation_weights[i] correspond
		to the ith feature. table_ids[i] indicates which embedding table to look up ith
		feature.
		
		The tensors at corresponding positions in two of the input lists,
		embedding_indices and aggregation_weights, must have the same shape, i.e. rank 1
		with dim_size() equal to the total number of lookups into the table described by
		the corresponding feature.
		
		Args:
		  sample_splits: A list of at least 1 `Tensor` objects with the same type in: `int32`, `int64`.
		    A list of rank 1 Tensors specifying the break points for splitting
		    embedding_indices and aggregation_weights into rows.
		    It corresponds to ids.row_splits in embedding_lookup(), when ids is a
		    RaggedTensor.
		  embedding_indices: A list with the same length as `sample_splits` of `Tensor` objects with the same type in: `int32`, `int64`.
		    A list of rank 1 Tensors, indices into the embedding tables.
		    It corresponds to ids.values in embedding_lookup(), when ids is a RaggedTensor.
		  aggregation_weights: A list with the same length as `sample_splits` of `Tensor` objects with the same type in: `float32`, `float64`.
		    A list of rank 1 Tensors containing per training example
		    aggregation weights. It corresponds to the values field of a RaggedTensor
		    with the same row_splits as ids in embedding_lookup(), when ids is a
		    RaggedTensor.
		  mode_override: A `Tensor` of type `string`.
		    A string input that overrides the mode specified in the
		    TPUEmbeddingConfiguration. Supported values are {'unspecified', 'inference',
		    'training', 'backward_pass_only'}. When set to 'unspecified', the mode set
		    in TPUEmbeddingConfiguration is used, otherwise mode_override is used.
		  table_ids: A list of `ints`.
		    A list of integers specifying the identifier of the embedding table
		    (offset of TableDescriptor in the TPUEmbeddingConfiguration) to lookup the
		    corresponding input. The ith input is looked up using table_ids[i]. The size
		    of the table_ids list must be equal to that of sample_indices,
		    embedding_indices and aggregation_weights.
		  device_ordinal: An optional `int`. Defaults to `-1`.
		    The TPU device to use. Should be >= 0 and less than the number
		    of TPU cores in the task on which the node is placed.
		  combiners: An optional list of `strings`. Defaults to `[]`.
		    A list of string scalars, one for each embedding table that specify
		    how to normalize the embedding activations after weighted summation.
		    Supported combiners are 'mean', 'sum', or 'sqrtn'. It is invalid to have
		    the sum of the weights be 0 for 'mean' or the sum of the squared weights be
		    0 for 'sqrtn'. If combiners isn't passed, the default is to use 'sum' for
		    all tables.
		  max_sequence_lengths: An optional list of `ints`. Defaults to `[]`.
		  num_features: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function EnqueueTPUEmbeddingRaggedTensorBatch(sample_splits:Dynamic, embedding_indices:Dynamic, aggregation_weights:Dynamic, mode_override:Dynamic, table_ids:Dynamic, ?device_ordinal:Dynamic, ?combiners:Dynamic, ?max_sequence_lengths:Dynamic, ?num_features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An op that enqueues TPUEmbedding input indices from a SparseTensor.
		
		This Op eases the porting of code that uses embedding_lookup_sparse(),
		although some Python preprocessing of the SparseTensor arguments to
		embedding_lookup_sparse() is required to produce the arguments to this Op,
		since only a single EnqueueTPUEmbeddingSparseBatch Op is allowed per training
		step.
		
		The tensors at corresponding positions in the three input lists
		must have the same shape, i.e. rank 1 with dim_size() equal to the total
		number of lookups into the table described by the corresponding table_id.
		
		Args:
		  sample_indices: A list of at least 1 `Tensor` objects with the same type in: `int32`, `int64`.
		    A list of rank 1 Tensors specifying the training example and
		    feature to which the corresponding embedding_indices and aggregation_weights
		    values belong. sample_indices[i] must equal b * nf + f, where nf is the
		    number of features from the corresponding table, f is in [0, nf), and
		    b is in [0, batch size).
		  embedding_indices: A list with the same length as `sample_indices` of `Tensor` objects with the same type in: `int32`, `int64`.
		    A list of rank 1 Tensors, indices into the embedding tables.
		  aggregation_weights: A list with the same length as `sample_indices` of `Tensor` objects with the same type in: `float32`, `float64`.
		    A list of rank 1 Tensors containing per sample -- i.e. per
		    (training example, feature) -- aggregation weights.
		  mode_override: A `Tensor` of type `string`.
		    A string input that overrides the mode specified in the
		    TPUEmbeddingConfiguration. Supported values are {'unspecified', 'inference',
		    'training', 'backward_pass_only'}. When set to 'unspecified', the mode set
		    in TPUEmbeddingConfiguration is used, otherwise mode_override is used.
		  device_ordinal: An optional `int`. Defaults to `-1`.
		    The TPU device to use. Should be >= 0 and less than the number
		    of TPU cores in the task on which the node is placed.
		  combiners: An optional list of `strings`. Defaults to `[]`.
		    A list of string scalars, one for each embedding table that specify
		    how to normalize the embedding activations after weighted summation.
		    Supported combiners are 'mean', 'sum', or 'sqrtn'. It is invalid to have
		    the sum of the weights be 0 for 'mean' or the sum of the squared weights be
		    0 for 'sqrtn'. If combiners isn't passed, the default is to use 'sum' for
		    all tables.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function EnqueueTPUEmbeddingSparseBatch(sample_indices:Dynamic, embedding_indices:Dynamic, aggregation_weights:Dynamic, mode_override:Dynamic, ?device_ordinal:Dynamic, ?combiners:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Eases the porting of code that uses tf.nn.embedding_lookup_sparse().
		
		sample_indices[i], embedding_indices[i] and aggregation_weights[i] correspond
		to the ith feature. table_ids[i] indicates which embedding table to look up ith
		feature.
		
		The tensors at corresponding positions in the three input lists (sample_indices,
		embedding_indices and aggregation_weights) must have the same shape, i.e. rank 1
		with dim_size() equal to the total number of lookups into the table described by
		the corresponding feature.
		
		Args:
		  sample_indices: A list of at least 1 `Tensor` objects with the same type in: `int32`, `int64`.
		    A list of rank 1 Tensors specifying the training example to
		    which the corresponding embedding_indices and aggregation_weights values
		    belong. It corresponds to sp_ids.indices[:,0] in  embedding_lookup_sparse().
		  embedding_indices: A list with the same length as `sample_indices` of `Tensor` objects with the same type in: `int32`, `int64`.
		    A list of rank 1 Tensors, indices into the embedding tables.
		    It corresponds to sp_ids.values in embedding_lookup_sparse().
		  aggregation_weights: A list with the same length as `sample_indices` of `Tensor` objects with the same type in: `float32`, `float64`.
		    A list of rank 1 Tensors containing per training example
		    aggregation weights. It corresponds to sp_weights.values in
		    embedding_lookup_sparse().
		  mode_override: A `Tensor` of type `string`.
		    A string input that overrides the mode specified in the
		    TPUEmbeddingConfiguration. Supported values are {'unspecified', 'inference',
		    'training', 'backward_pass_only'}. When set to 'unspecified', the mode set
		    in TPUEmbeddingConfiguration is used, otherwise mode_override is used.
		  table_ids: A list of `ints`.
		    A list of integers specifying the identifier of the embedding table
		    (offset of TableDescriptor in the TPUEmbeddingConfiguration) to lookup the
		    corresponding input. The ith input is looked up using table_ids[i]. The size
		    of the table_ids list must be equal to that of sample_indices,
		    embedding_indices and aggregation_weights.
		  device_ordinal: An optional `int`. Defaults to `-1`.
		    The TPU device to use. Should be >= 0 and less than the number
		    of TPU cores in the task on which the node is placed.
		  combiners: An optional list of `strings`. Defaults to `[]`.
		    A list of string scalars, one for each embedding table that specify
		    how to normalize the embedding activations after weighted summation.
		    Supported combiners are 'mean', 'sum', or 'sqrtn'. It is invalid to have
		    the sum of the weights be 0 for 'mean' or the sum of the squared weights be
		    0 for 'sqrtn'. If combiners isn't passed, the default is to use 'sum' for
		    all tables.
		  max_sequence_lengths: An optional list of `ints`. Defaults to `[]`.
		  num_features: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function EnqueueTPUEmbeddingSparseTensorBatch(sample_indices:Dynamic, embedding_indices:Dynamic, aggregation_weights:Dynamic, mode_override:Dynamic, table_ids:Dynamic, ?device_ordinal:Dynamic, ?combiners:Dynamic, ?max_sequence_lengths:Dynamic, ?num_features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Ensures that the tensor's shape matches the expected shape.
		
		Raises an error if the input tensor's shape does not match the specified shape.
		Returns the input tensor otherwise.
		
		Args:
		  input: A `Tensor`. A tensor, whose shape is to be validated.
		  shape: A `tf.TensorShape` or list of `ints`.
		    The expected (possibly partially specified) shape of the input tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function EnsureShape(input:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates or finds a child frame, and makes `data` available to the child frame.
		
		This op is used together with `Exit` to create loops in the graph.
		The unique `frame_name` is used by the `Executor` to identify frames. If
		`is_constant` is true, `output` is a constant in the child frame; otherwise
		it may be changed in the child frame. At most `parallel_iterations` iterations
		are run in parallel in the child frame.
		
		Args:
		  data: A `Tensor`. The tensor to be made available to the child frame.
		  frame_name: A `string`. The name of the child frame.
		  is_constant: An optional `bool`. Defaults to `False`.
		    If true, the output is constant within the child frame.
		  parallel_iterations: An optional `int`. Defaults to `10`.
		    The number of iterations allowed to run in parallel.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function Enter(data:Dynamic, frame_name:Dynamic, ?is_constant:Dynamic, ?parallel_iterations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of (x == y) element-wise.
		
		*NOTE*: `Equal` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		```python
		x = tf.constant([2, 4])
		y = tf.constant(2)
		tf.math.equal(x, y) ==> array([True, False])
		
		x = tf.constant([2, 4])
		y = tf.constant([2, 4])
		tf.math.equal(x, y) ==> array([True,  True])
		```
		
		Args:
		  x: A `Tensor`.
		  y: A `Tensor`. Must have the same type as `x`.
		  incompatible_shape_error: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function Equal(x:Dynamic, y:Dynamic, ?incompatible_shape_error:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the [Gauss error function](https://en.wikipedia.org/wiki/Error_function) of `x` element-wise. In statistics, for non-negative values of $x$, the error function has the following interpretation: for a random variable $Y$ that is normally distributed with mean 0 and variance $1/\sqrt{2}$, $erf(x)$ is the probability that $Y$ falls in the range $[x, x]$.
		
		For example:
		
		>>> tf.math.erf([[1.0, 2.0, 3.0], [0.0, -1.0, -2.0]])
		<tf.Tensor: shape=(2, 3), dtype=float32, numpy=
		array([[ 0.8427007,  0.9953223,  0.999978 ],
		       [ 0.       , -0.8427007, -0.9953223]], dtype=float32)>
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Erf(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the complementary error function of `x` element-wise.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Erfc(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Erfinv(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the euclidean norm of elements across dimensions of a tensor.
		
		Reduces `input` along the dimensions given in `axis`. Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`axis`. If `keep_dims` is true, the reduced dimensions are
		retained with length 1.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    The tensor to reduce.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The dimensions to reduce. Must be in the range
		    `[-rank(input), rank(input))`.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function EuclideanNorm(input:Dynamic, axis:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Exits the current frame to its parent frame.
		
		Exit makes its input `data` available to the parent frame.
		
		Args:
		  data: A `Tensor`. The tensor to be made available to the parent frame.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function Exit(data:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes exponential of x element-wise.  \\(y = e^x\\).
		
		  This function computes the exponential of every element in the input tensor.
		  i.e. `exp(x)` or `e^(x)`, where `x` is the input tensor.
		  `e` denotes Euler's number and is approximately equal to 2.718281.
		  Output is positive for any real input.
		
		  ```python
		  x = tf.constant(2.0)
		  tf.math.exp(x) ==> 7.389056
		
		  x = tf.constant([2.0, 8.0])
		  tf.math.exp(x) ==> array([7.389056, 2980.958], dtype=float32)
		  ```
		
		  For complex numbers, the exponential value is calculated as follows:
		
		  ```
		  e^(x+iy) = e^x * e^iy = e^x * (cos y + i sin y)
		  ```
		
		  Let's consider complex number 1+1j as an example.
		  e^1 * (cos 1 + i sin 1) = 2.7182818284590 * (0.54030230586+0.8414709848j)
		
		  ```python
		  x = tf.constant(1 + 1j)
		  tf.math.exp(x) ==> 1.4686939399158851+2.2873552871788423j
		  ```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Exp(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Inserts a dimension of 1 into a tensor's shape.
		
		Given a tensor `input`, this operation inserts a dimension of 1 at the
		dimension index `axis` of `input`'s shape. The dimension index `axis` starts at
		zero; if you specify a negative number for `axis` it is counted backward from
		the end.
		
		This operation is useful if you want to add a batch dimension to a single
		element. For example, if you have a single image of shape `[height, width,
		channels]`, you can make it a batch of 1 image with `expand_dims(image, 0)`,
		which will make the shape `[1, height, width, channels]`.
		
		Other examples:
		
		```
		# 't' is a tensor of shape [2]
		shape(expand_dims(t, 0)) ==> [1, 2]
		shape(expand_dims(t, 1)) ==> [2, 1]
		shape(expand_dims(t, -1)) ==> [2, 1]
		
		# 't2' is a tensor of shape [2, 3, 5]
		shape(expand_dims(t2, 0)) ==> [1, 2, 3, 5]
		shape(expand_dims(t2, 2)) ==> [2, 3, 1, 5]
		shape(expand_dims(t2, 3)) ==> [2, 3, 5, 1]
		```
		
		This operation requires that:
		
		`-1-input.dims() <= dim <= input.dims()`
		
		This operation is related to `squeeze()`, which removes dimensions of
		size 1.
		
		Args:
		  input: A `Tensor`.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    0-D (scalar). Specifies the dimension index at which to
		    expand the shape of `input`. Must be in the range
		    `[-rank(input) - 1, rank(input)]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function ExpandDims(input:Dynamic, axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  transformations: A `Tensor` of type `string`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalAssertNextDataset(input_dataset:Dynamic, transformations:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that shards the input dataset.
		
		Creates a dataset that shards the input dataset by num_workers, returning a
		sharded dataset for the index-th worker. This attempts to automatically shard
		a dataset by examining the Dataset graph and inserting a shard op before the
		inputs to a reader Dataset (e.g. CSVDataset, TFRecordDataset).
		
		This dataset will throw a NotFound error if we cannot shard the dataset
		automatically.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  num_workers: A `Tensor` of type `int64`.
		    A scalar representing the number of workers to distribute this dataset across.
		  index: A `Tensor` of type `int64`.
		    A scalar representing the index of the current worker out of num_workers.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  auto_shard_policy: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalAutoShardDataset(input_dataset:Dynamic, num_workers:Dynamic, index:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?auto_shard_policy:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Records the bytes size of each element of `input_dataset` in a StatsAggregator.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  tag: A `Tensor` of type `string`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalBytesProducedStatsDataset(input_dataset:Dynamic, tag:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  filenames: A `Tensor` of type `string`.
		  compression_type: A `Tensor` of type `string`.
		  buffer_size: A `Tensor` of type `int64`.
		  header: A `Tensor` of type `bool`.
		  field_delim: A `Tensor` of type `string`.
		  use_quote_delim: A `Tensor` of type `bool`.
		  na_value: A `Tensor` of type `string`.
		  select_cols: A `Tensor` of type `int64`.
		  record_defaults: A list of `Tensor` objects with types from: `float32`, `float64`, `int32`, `int64`, `string`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalCSVDataset(filenames:Dynamic, compression_type:Dynamic, buffer_size:Dynamic, header:Dynamic, field_delim:Dynamic, use_quote_delim:Dynamic, na_value:Dynamic, select_cols:Dynamic, record_defaults:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_datasets: A list of at least 2 `Tensor` objects with type `variant`.
		  num_experiments: An `int`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalChooseFastestDataset(input_datasets:Dynamic, num_experiments:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the cardinality of `input_dataset`.
		
		Returns the cardinality of `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the dataset to return cardinality for.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function ExperimentalDatasetCardinality(input_dataset:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Writes the given dataset to the given file using the TFRecord format.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the dataset to write.
		  filename: A `Tensor` of type `string`.
		    A scalar string tensor representing the filename to use.
		  compression_type: A `Tensor` of type `string`.
		    A scalar string tensor containing either (i) the empty string (no
		    compression), (ii) "ZLIB", or (iii) "GZIP".
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ExperimentalDatasetToTFRecord(input_dataset:Dynamic, filename:Dynamic, compression_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that batches input elements into a SparseTensor.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A handle to an input dataset. Must have a single component.
		  batch_size: A `Tensor` of type `int64`.
		    A scalar representing the number of elements to accumulate in a
		    batch.
		  row_shape: A `Tensor` of type `int64`.
		    A vector representing the dense shape of each row in the produced
		    SparseTensor. The shape may be partially specified, using `-1` to indicate
		    that a particular dimension should use the maximum size of all batch elements.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalDenseToSparseBatchDataset(input_dataset:Dynamic, batch_size:Dynamic, row_shape:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A substitute for `InterleaveDataset` on a fixed list of `N` datasets.
		
		Args:
		  selector_input_dataset: A `Tensor` of type `variant`.
		    A dataset of scalar `DT_INT64` elements that determines which of the
		    `N` data inputs should produce the next output element.
		  data_input_datasets: A list of at least 1 `Tensor` objects with type `variant`.
		    `N` datasets with the same type that will be interleaved according to
		    the values of `selector_input_dataset`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalDirectedInterleaveDataset(selector_input_dataset:Dynamic, data_input_datasets:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that computes a group-by on `input_dataset`.
		
		Creates a dataset that computes a group-by on `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  key_func_other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when
		    building a closure for `key_func`.
		  init_func_other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when
		    building a closure for `init_func`.
		  reduce_func_other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when
		    building a closure for `reduce_func`.
		  finalize_func_other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when
		    building a closure for `finalize_func`.
		  key_func: A function decorated with @Defun.
		    A function mapping an element of `input_dataset`, concatenated
		    with `key_func_other_arguments` to a scalar value of type DT_INT64.
		  init_func: A function decorated with @Defun.
		    A function mapping a key of type DT_INT64, concatenated with
		    `init_func_other_arguments` to the initial reducer state.
		  reduce_func: A function decorated with @Defun.
		    A function mapping the current reducer state and an element of `input_dataset`,
		    concatenated with `reduce_func_other_arguments` to a new reducer state.
		  finalize_func: A function decorated with @Defun.
		    A function mapping the final reducer state to an output element.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalGroupByReducerDataset(input_dataset:Dynamic, key_func_other_arguments:Dynamic, init_func_other_arguments:Dynamic, reduce_func_other_arguments:Dynamic, finalize_func_other_arguments:Dynamic, key_func:Dynamic, init_func:Dynamic, reduce_func:Dynamic, finalize_func:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that computes a windowed group-by on `input_dataset`.
		
		// TODO(mrry): Support non-int64 keys.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  key_func_other_arguments: A list of `Tensor` objects.
		  reduce_func_other_arguments: A list of `Tensor` objects.
		  window_size_func_other_arguments: A list of `Tensor` objects.
		  key_func: A function decorated with @Defun.
		    A function mapping an element of `input_dataset`, concatenated
		    with `key_func_other_arguments` to a scalar value of type DT_INT64.
		  reduce_func: A function decorated with @Defun.
		  window_size_func: A function decorated with @Defun.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalGroupByWindowDataset(input_dataset:Dynamic, key_func_other_arguments:Dynamic, reduce_func_other_arguments:Dynamic, window_size_func_other_arguments:Dynamic, key_func:Dynamic, reduce_func:Dynamic, window_size_func:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that contains the elements of `input_dataset` ignoring errors.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  log_warning: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalIgnoreErrorsDataset(input_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?log_warning:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the name of the device on which `resource` has been placed.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function ExperimentalIteratorGetDevice(resource:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  filenames: A `Tensor` of type `string`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalLMDBDataset(filenames:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Records the latency of producing `input_dataset` elements in a StatsAggregator.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  tag: A `Tensor` of type `string`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalLatencyStatsDataset(input_dataset:Dynamic, tag:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that fuses mapping with batching.
		
		Creates a dataset that applies `f` to the outputs of `input_dataset` and then
		batches `batch_size` of them.
		
		Unlike a "MapDataset", which applies `f` sequentially, this dataset invokes up
		to `batch_size * num_parallel_batches` copies of `f` in parallel.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when building a closure
		    for `f`.
		  batch_size: A `Tensor` of type `int64`.
		    A scalar representing the number of elements to accumulate in a
		    batch. It determines the number of concurrent invocations of `f` that process
		    elements from `input_dataset` in parallel.
		  num_parallel_calls: A `Tensor` of type `int64`.
		    A scalar representing the maximum number of parallel invocations of the `map_fn`
		    function. Applying the `map_fn` on consecutive input elements in parallel has
		    the potential to improve input pipeline throughput.
		  drop_remainder: A `Tensor` of type `bool`.
		    A scalar representing whether the last batch should be dropped in case its size
		    is smaller than desired.
		  f: A function decorated with @Defun.
		    A function to apply to the outputs of `input_dataset`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  preserve_cardinality: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalMapAndBatchDataset(input_dataset:Dynamic, other_arguments:Dynamic, batch_size:Dynamic, num_parallel_calls:Dynamic, drop_remainder:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?preserve_cardinality:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  other_arguments: A list of `Tensor` objects.
		  f: A function decorated with @Defun.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  use_inter_op_parallelism: An optional `bool`. Defaults to `True`.
		  preserve_cardinality: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalMapDataset(input_dataset:Dynamic, other_arguments:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?use_inter_op_parallelism:Dynamic, ?preserve_cardinality:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  patterns: A `Tensor` of type `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalMatchingFilesDataset(patterns:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that overrides the maximum intra-op parallelism.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  max_intra_op_parallelism: A `Tensor` of type `int64`.
		    Identifies the maximum intra-op parallelism to use.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalMaxIntraOpParallelismDataset(input_dataset:Dynamic, max_intra_op_parallelism:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalNonSerializableDataset(input_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		The resulting dataset is similar to the `InterleaveDataset`, with the exception
		that if retrieving the next value from a dataset would cause the requester to
		block, it will skip that input dataset. This dataset is especially useful
		when loading data from a variable-latency datastores (e.g. HDFS, GCS), as it
		allows the training step to proceed so long as some data is available.
		
		!! WARNING !! This dataset is not deterministic!
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  other_arguments: A list of `Tensor` objects.
		  cycle_length: A `Tensor` of type `int64`.
		  block_length: A `Tensor` of type `int64`.
		  sloppy: A `Tensor` of type `bool`.
		  buffer_output_elements: A `Tensor` of type `int64`.
		  prefetch_input_elements: A `Tensor` of type `int64`.
		  f: A function decorated with @Defun.
		    A function mapping elements of `input_dataset`, concatenated with
		    `other_arguments`, to a Dataset variant that contains elements matching
		    `output_types` and `output_shapes`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalParallelInterleaveDataset(input_dataset:Dynamic, other_arguments:Dynamic, cycle_length:Dynamic, block_length:Dynamic, sloppy:Dynamic, buffer_output_elements:Dynamic, prefetch_input_elements:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms `input_dataset` containing `Example` protos as vectors of DT_STRING into a dataset of `Tensor` or `SparseTensor` objects representing the parsed features.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  num_parallel_calls: A `Tensor` of type `int64`.
		  dense_defaults: A list of `Tensor` objects with types from: `float32`, `int64`, `string`.
		    A dict mapping string keys to `Tensor`s.
		    The keys of the dict must match the dense_keys of the feature.
		  sparse_keys: A list of `strings`.
		    A list of string keys in the examples features.
		    The results for these keys will be returned as `SparseTensor` objects.
		  dense_keys: A list of `strings`.
		    A list of Ndense string Tensors (scalars).
		    The keys expected in the Examples features associated with dense values.
		  sparse_types: A list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`.
		    A list of `DTypes` of the same length as `sparse_keys`.
		    Only `tf.float32` (`FloatList`), `tf.int64` (`Int64List`),
		    and `tf.string` (`BytesList`) are supported.
		  dense_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    List of tuples with the same length as `dense_keys`.
		    The shape of the data for each dense feature referenced by `dense_keys`.
		    Required for any input tensors identified by `dense_keys`.  Must be
		    either fully defined, or may contain an unknown first dimension.
		    An unknown first dimension means the feature is treated as having
		    a variable number of blocks, and the output shape along this dimension
		    is considered unknown at graph build time.  Padding is applied for
		    minibatch elements smaller than the maximum number of blocks for the
		    given feature along this dimension.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type list for the return values.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		    The list of shapes being produced.
		  sloppy: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalParseExampleDataset(input_dataset:Dynamic, num_parallel_calls:Dynamic, dense_defaults:Dynamic, sparse_keys:Dynamic, dense_keys:Dynamic, sparse_types:Dynamic, dense_shapes:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?sloppy:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that uses a custom thread pool to compute `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  num_threads: A `Tensor` of type `int64`.
		    Identifies the number of threads to use for the private threadpool.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalPrivateThreadPoolDataset(input_dataset:Dynamic, num_threads:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a Dataset that returns pseudorandom numbers.
		
		Args:
		  seed: A `Tensor` of type `int64`.
		    A scalar seed for the random number generator. If either seed or
		    seed2 is set to be non-zero, the random number generator is seeded
		    by the given seed.  Otherwise, a random seed is used.
		  seed2: A `Tensor` of type `int64`.
		    A second scalar seed to avoid seed collision.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalRandomDataset(seed:Dynamic, seed2:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that changes the batch size.
		
		Creates a dataset that changes the batch size of the dataset to current batch
		size // num_replicas.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  num_replicas: A `Tensor` of type `int64`.
		    A scalar representing the number of replicas to distribute this batch across. As
		    a result of this transformation the current batch size would end up being
		    divided  by this parameter.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  use_fallback: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalRebatchDataset(input_dataset:Dynamic, num_replicas:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?use_fallback:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset successively reduces `f` over the elements of `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  initial_state: A list of `Tensor` objects.
		  other_arguments: A list of `Tensor` objects.
		  f: A function decorated with @Defun.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  preserve_cardinality: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalScanDataset(input_dataset:Dynamic, initial_state:Dynamic, other_arguments:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?preserve_cardinality:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  stats_aggregator: A `Tensor` of type `resource`.
		  tag: A `Tensor` of type `string`.
		  counter_prefix: A `Tensor` of type `string`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalSetStatsAggregatorDataset(input_dataset:Dynamic, stats_aggregator:Dynamic, tag:Dynamic, counter_prefix:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  sleep_microseconds: A `Tensor` of type `int64`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalSleepDataset(input_dataset:Dynamic, sleep_microseconds:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that passes a sliding window over `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  window_size: A `Tensor` of type `int64`.
		    A scalar representing the number of elements in the
		    sliding window.
		  window_shift: A `Tensor` of type `int64`.
		    A scalar representing the steps moving the sliding window
		    forward in one iteration. It must be positive.
		  window_stride: A `Tensor` of type `int64`.
		    A scalar representing the stride of the input elements of the sliding window.
		    It must be positive.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalSlidingWindowDataset(input_dataset:Dynamic, window_size:Dynamic, window_shift:Dynamic, window_stride:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that executes a SQL query and emits rows of the result set.
		
		Args:
		  driver_name: A `Tensor` of type `string`.
		    The database type. Currently, the only supported type is 'sqlite'.
		  data_source_name: A `Tensor` of type `string`.
		    A connection string to connect to the database.
		  query: A `Tensor` of type `string`. A SQL query to execute.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalSqlDataset(driver_name:Dynamic, data_source_name:Dynamic, query:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a statistics manager resource.
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function ExperimentalStatsAggregatorHandle(?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Produces a summary of any statistics recorded by the given statistics manager.
		
		Args:
		  iterator: A `Tensor` of type `resource`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function ExperimentalStatsAggregatorSummary(iterator:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that stops iteration when predicate` is false.
		
		The `predicate` function must return a scalar boolean and accept the
		following arguments:
		
		* One tensor for each component of an element of `input_dataset`.
		* One tensor for each value in `other_arguments`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when
		    building a closure for `predicate`.
		  predicate: A function decorated with @Defun.
		    A function returning a scalar boolean.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalTakeWhileDataset(input_dataset:Dynamic, other_arguments:Dynamic, predicate:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that uses a custom thread pool to compute `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  thread_pool: A `Tensor` of type `resource`.
		    A resource produced by the ThreadPoolHandle op.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalThreadPoolDataset(input_dataset:Dynamic, thread_pool:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that uses a custom thread pool to compute `input_dataset`.
		
		Args:
		  num_threads: An `int`. The number of threads in the thread pool.
		  display_name: A `string`.
		    A human-readable name for the threads that may be visible in some
		    visualizations.
		    threadpool.
		  max_intra_op_parallelism: An optional `int`. Defaults to `1`.
		    The maximum degree of parallelism to use within operations that execute on this
		    threadpool.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function ExperimentalThreadPoolHandle(num_threads:Dynamic, display_name:Dynamic, ?max_intra_op_parallelism:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A dataset that splits the elements of its input into multiple elements.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalUnbatchDataset(input_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that contains the unique elements of `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ExperimentalUniqueDataset(input_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Expint(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes `exp(x) - 1` element-wise.
		
		  i.e. `exp(x) - 1` or `e^(x) - 1`, where `x` is the input tensor.
		  `e` denotes Euler's number and is approximately equal to 2.718281.
		
		  ```python
		  x = tf.constant(2.0)
		  tf.math.expm1(x) ==> 6.389056
		
		  x = tf.constant([2.0, 8.0])
		  tf.math.expm1(x) ==> array([6.389056, 2979.958], dtype=float32)
		
		  x = tf.constant(1 + 1j)
		  tf.math.expm1(x) ==> (0.46869393991588515+2.2873552871788423j)
		  ```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Expm1(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Extracts a glimpse from the input tensor.
		
		Returns a set of windows called glimpses extracted at location
		`offsets` from the input tensor. If the windows only partially
		overlaps the inputs, the non overlapping areas will be filled with
		random noise.
		
		The result is a 4-D tensor of shape `[batch_size, glimpse_height,
		glimpse_width, channels]`. The channels and batch dimensions are the
		same as that of the input tensor. The height and width of the output
		windows are specified in the `size` parameter.
		
		The argument `normalized` and `centered` controls how the windows are built:
		
		* If the coordinates are normalized but not centered, 0.0 and 1.0
		  correspond to the minimum and maximum of each height and width
		  dimension.
		* If the coordinates are both normalized and centered, they range from
		  -1.0 to 1.0. The coordinates (-1.0, -1.0) correspond to the upper
		  left corner, the lower right corner is located at (1.0, 1.0) and the
		  center is at (0, 0).
		* If the coordinates are not normalized they are interpreted as
		  numbers of pixels.
		
		Args:
		  input: A `Tensor` of type `float32`.
		    A 4-D float tensor of shape `[batch_size, height, width, channels]`.
		  size: A `Tensor` of type `int32`.
		    A 1-D tensor of 2 elements containing the size of the glimpses
		    to extract.  The glimpse height must be specified first, following
		    by the glimpse width.
		  offsets: A `Tensor` of type `float32`.
		    A 2-D integer tensor of shape `[batch_size, 2]` containing
		    the y, x locations of the center of each window.
		  centered: An optional `bool`. Defaults to `True`.
		    indicates if the offset coordinates are centered relative to
		    the image, in which case the (0, 0) offset is relative to the center
		    of the input images. If false, the (0,0) offset corresponds to the
		    upper left corner of the input images.
		  normalized: An optional `bool`. Defaults to `True`.
		    indicates if the offset coordinates are normalized.
		  uniform_noise: An optional `bool`. Defaults to `True`.
		    indicates if the noise should be generated using a
		    uniform distribution or a Gaussian distribution.
		  noise: An optional `string`. Defaults to `"uniform"`.
		    indicates if the noise should `uniform`, `gaussian`, or
		    `zero`. The default is `uniform` which means the noise type
		    will be decided by `uniform_noise`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function ExtractGlimpse(input:Dynamic, size:Dynamic, offsets:Dynamic, ?centered:Dynamic, ?normalized:Dynamic, ?uniform_noise:Dynamic, ?noise:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Extracts a glimpse from the input tensor.
		
		Returns a set of windows called glimpses extracted at location
		`offsets` from the input tensor. If the windows only partially
		overlaps the inputs, the non overlapping areas will be filled with
		random noise.
		
		The result is a 4-D tensor of shape `[batch_size, glimpse_height,
		glimpse_width, channels]`. The channels and batch dimensions are the
		same as that of the input tensor. The height and width of the output
		windows are specified in the `size` parameter.
		
		The argument `normalized` and `centered` controls how the windows are built:
		
		* If the coordinates are normalized but not centered, 0.0 and 1.0
		  correspond to the minimum and maximum of each height and width
		  dimension.
		* If the coordinates are both normalized and centered, they range from
		  -1.0 to 1.0. The coordinates (-1.0, -1.0) correspond to the upper
		  left corner, the lower right corner is located at (1.0, 1.0) and the
		  center is at (0, 0).
		* If the coordinates are not normalized they are interpreted as
		  numbers of pixels.
		
		Args:
		  input: A `Tensor` of type `float32`.
		    A 4-D float tensor of shape `[batch_size, height, width, channels]`.
		  size: A `Tensor` of type `int32`.
		    A 1-D tensor of 2 elements containing the size of the glimpses
		    to extract.  The glimpse height must be specified first, following
		    by the glimpse width.
		  offsets: A `Tensor` of type `float32`.
		    A 2-D integer tensor of shape `[batch_size, 2]` containing
		    the y, x locations of the center of each window.
		  centered: An optional `bool`. Defaults to `True`.
		    indicates if the offset coordinates are centered relative to
		    the image, in which case the (0, 0) offset is relative to the center
		    of the input images. If false, the (0,0) offset corresponds to the
		    upper left corner of the input images.
		  normalized: An optional `bool`. Defaults to `True`.
		    indicates if the offset coordinates are normalized.
		  uniform_noise: An optional `bool`. Defaults to `True`.
		    indicates if the noise should be generated using a
		    uniform distribution or a Gaussian distribution.
		  noise: An optional `string`. Defaults to `"uniform"`.
		    indicates if the noise should `uniform`, `gaussian`, or
		    `zero`. The default is `uniform` which means the noise type
		    will be decided by `uniform_noise`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function ExtractGlimpseV2(input:Dynamic, size:Dynamic, offsets:Dynamic, ?centered:Dynamic, ?normalized:Dynamic, ?uniform_noise:Dynamic, ?noise:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Extract `patches` from `images` and put them in the "depth" output dimension.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `complex64`, `complex128`, `bool`.
		    4-D Tensor with shape `[batch, in_rows, in_cols, depth]`.
		  ksizes: A list of `ints` that has length `>= 4`.
		    The size of the sliding window for each dimension of `images`.
		  strides: A list of `ints` that has length `>= 4`.
		    How far the centers of two consecutive patches are in
		    the images. Must be: `[1, stride_rows, stride_cols, 1]`.
		  rates: A list of `ints` that has length `>= 4`.
		    Must be: `[1, rate_rows, rate_cols, 1]`. This is the
		    input stride, specifying how far two consecutive patch samples are in the
		    input. Equivalent to extracting patches with
		    `patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1)`, followed by
		    subsampling them spatially by a factor of `rates`. This is equivalent to
		    `rate` in dilated (a.k.a. Atrous) convolutions.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `images`.
	**/
	static public function ExtractImagePatches(images:Dynamic, ksizes:Dynamic, strides:Dynamic, rates:Dynamic, padding:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Extract the shape information of a JPEG-encoded image.
		
		This op only parses the image header, so it is much faster than DecodeJpeg.
		
		Args:
		  contents: A `Tensor` of type `string`. 0-D. The JPEG-encoded image.
		  output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		    (Optional) The output type of the operation (int32 or int64).
		    Defaults to int32.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `output_type`.
	**/
	static public function ExtractJpegShape(contents:Dynamic, ?output_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Extract `patches` from `input` and put them in the `"depth"` output dimension. 3D extension of `extract_image_patches`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    5-D Tensor with shape `[batch, in_planes, in_rows, in_cols, depth]`.
		  ksizes: A list of `ints` that has length `>= 5`.
		    The size of the sliding window for each dimension of `input`.
		  strides: A list of `ints` that has length `>= 5`.
		    1-D of length 5. How far the centers of two consecutive patches are in
		    `input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		
		    The size-related attributes are specified as follows:
		
		    ```python
		    ksizes = [1, ksize_planes, ksize_rows, ksize_cols, 1]
		    strides = [1, stride_planes, strides_rows, strides_cols, 1]
		    ```
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function ExtractVolumePatches(input:Dynamic, ksizes:Dynamic, strides:Dynamic, padding:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Fast Fourier transform.
		
		Computes the 1-dimensional discrete Fourier transform over the inner-most
		dimension of `input`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		    A complex tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function FFT(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		2D fast Fourier transform.
		
		Computes the 2-dimensional discrete Fourier transform over the inner-most
		2 dimensions of `input`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		    A complex tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function FFT2D(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		3D fast Fourier transform.
		
		Computes the 3-dimensional discrete Fourier transform over the inner-most 3
		dimensions of `input`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		    A complex tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function FFT3D(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A queue that produces elements in first-in first-out order.
		
		Args:
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a value.
		  shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    The shape of each component in a value. The length of this attr must
		    be either 0 or the same as the length of component_types. If the length of
		    this attr is 0, the shapes of queue elements are not constrained, and
		    only one element may be dequeued at a time.
		  capacity: An optional `int`. Defaults to `-1`.
		    The upper bound on the number of elements in this queue.
		    Negative numbers mean no limit.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this queue is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this queue will be shared under the given name
		    across multiple sessions.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function FIFOQueue(component_types:Dynamic, ?shapes:Dynamic, ?capacity:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A queue that produces elements in first-in first-out order.
		
		Args:
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a value.
		  shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    The shape of each component in a value. The length of this attr must
		    be either 0 or the same as the length of component_types. If the length of
		    this attr is 0, the shapes of queue elements are not constrained, and
		    only one element may be dequeued at a time.
		  capacity: An optional `int`. Defaults to `-1`.
		    The upper bound on the number of elements in this queue.
		    Negative numbers mean no limit.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this queue is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this queue will be shared under the given name
		    across multiple sessions.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function FIFOQueueV2(component_types:Dynamic, ?shapes:Dynamic, ?capacity:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Output a fact about factorials.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function Fact(?name:Dynamic):Dynamic;
	/**
		This op is used as a placeholder in If branch functions. It doesn't provide a
		valid output when run, so must either be removed (e.g. replaced with a
		function input) or guaranteed not to be used (e.g. if mirroring an
		intermediate output needed for the gradient computation of the other branch).
		
		Args:
		  dtype: A `tf.DType`. The type of the output.
		  shape: A `tf.TensorShape` or list of `ints`.
		        The purported shape of the output. This is only used for shape inference;
		        the output will not necessarily have this shape. Can be a partial shape.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function FakeParam(dtype:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.
		
		Attributes
		
		*   `[min; max]` define the clamping range for the `inputs` data.
		*   `inputs` values are quantized into the quantization range (
		`[0; 2^num_bits - 1]` when `narrow_range` is false and `[1; 2^num_bits - 1]`
		when it is true) and then de-quantized and output as floats in `[min; max]`
		interval.
		*   `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.
		
		Before quantization, `min` and `max` values are adjusted with the following
		logic.
		It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,
		the behavior can be unexpected:
		
		*   If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.
		*   If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.
		*   If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,
		`min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.
		
		Quantization is called fake since the output is still in floating point.
		
		Args:
		  inputs: A `Tensor` of type `float32`.
		  min: An optional `float`. Defaults to `-6`.
		  max: An optional `float`. Defaults to `6`.
		  num_bits: An optional `int`. Defaults to `8`.
		  narrow_range: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function FakeQuantWithMinMaxArgs(inputs:Dynamic, ?min:Dynamic, ?max:Dynamic, ?num_bits:Dynamic, ?narrow_range:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute gradients for a FakeQuantWithMinMaxArgs operation.
		
		Args:
		  gradients: A `Tensor` of type `float32`.
		    Backpropagated gradients above the FakeQuantWithMinMaxArgs operation.
		  inputs: A `Tensor` of type `float32`.
		    Values passed as inputs to the FakeQuantWithMinMaxArgs operation.
		  min: An optional `float`. Defaults to `-6`.
		  max: An optional `float`. Defaults to `6`.
		  num_bits: An optional `int`. Defaults to `8`.
		  narrow_range: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function FakeQuantWithMinMaxArgsGradient(gradients:Dynamic, inputs:Dynamic, ?min:Dynamic, ?max:Dynamic, ?num_bits:Dynamic, ?narrow_range:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Fake-quantize the 'inputs' tensor of type float via global float scalars
		
		Fake-quantize the `inputs` tensor of type float via global float scalars
		`min` and `max` to `outputs` tensor of same shape as `inputs`.
		
		Attributes
		
		*   `[min; max]` define the clamping range for the `inputs` data.
		*   `inputs` values are quantized into the quantization range (
		`[0; 2^num_bits - 1]` when `narrow_range` is false and `[1; 2^num_bits - 1]`
		when it is true) and then de-quantized and output as floats in `[min; max]`
		interval.
		*   `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.
		
		Before quantization, `min` and `max` values are adjusted with the following
		logic.
		It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,
		the behavior can be unexpected:
		
		*   If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.
		*   If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.
		*   If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,
		`min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.
		
		This operation has a gradient and thus allows for training `min` and `max`
		values.
		
		Args:
		  inputs: A `Tensor` of type `float32`.
		  min: A `Tensor` of type `float32`.
		  max: A `Tensor` of type `float32`.
		  num_bits: An optional `int`. Defaults to `8`.
		  narrow_range: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function FakeQuantWithMinMaxVars(inputs:Dynamic, min:Dynamic, max:Dynamic, ?num_bits:Dynamic, ?narrow_range:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute gradients for a FakeQuantWithMinMaxVars operation.
		
		Args:
		  gradients: A `Tensor` of type `float32`.
		    Backpropagated gradients above the FakeQuantWithMinMaxVars operation.
		  inputs: A `Tensor` of type `float32`.
		    Values passed as inputs to the FakeQuantWithMinMaxVars operation.
		    min, max: Quantization interval, scalar floats.
		  min: A `Tensor` of type `float32`.
		  max: A `Tensor` of type `float32`.
		  num_bits: An optional `int`. Defaults to `8`.
		    The bitwidth of the quantization; between 2 and 8, inclusive.
		  narrow_range: An optional `bool`. Defaults to `False`.
		    Whether to quantize into 2^num_bits - 1 distinct values.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (backprops_wrt_input, backprop_wrt_min, backprop_wrt_max).
		
		  backprops_wrt_input: A `Tensor` of type `float32`.
		  backprop_wrt_min: A `Tensor` of type `float32`.
		  backprop_wrt_max: A `Tensor` of type `float32`.
	**/
	static public function FakeQuantWithMinMaxVarsGradient(gradients:Dynamic, inputs:Dynamic, min:Dynamic, max:Dynamic, ?num_bits:Dynamic, ?narrow_range:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Fake-quantize the 'inputs' tensor of type float via per-channel floats
		
		Fake-quantize the `inputs` tensor of type float per-channel and one of the
		shapes: `[d]`, `[b, d]` `[b, h, w, d]` via per-channel floats `min` and `max`
		of shape `[d]` to `outputs` tensor of same shape as `inputs`.
		
		Attributes
		
		*   `[min; max]` define the clamping range for the `inputs` data.
		*   `inputs` values are quantized into the quantization range (
		`[0; 2^num_bits - 1]` when `narrow_range` is false and `[1; 2^num_bits - 1]`
		when it is true) and then de-quantized and output as floats in `[min; max]`
		interval.
		*   `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.
		
		Before quantization, `min` and `max` values are adjusted with the following
		logic.
		It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,
		the behavior can be unexpected:
		
		*   If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.
		*   If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.
		*   If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,
		`min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.
		
		This operation has a gradient and thus allows for training `min` and `max`
		values.
		
		Args:
		  inputs: A `Tensor` of type `float32`.
		  min: A `Tensor` of type `float32`.
		  max: A `Tensor` of type `float32`.
		  num_bits: An optional `int`. Defaults to `8`.
		  narrow_range: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function FakeQuantWithMinMaxVarsPerChannel(inputs:Dynamic, min:Dynamic, max:Dynamic, ?num_bits:Dynamic, ?narrow_range:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.
		
		Args:
		  gradients: A `Tensor` of type `float32`.
		    Backpropagated gradients above the FakeQuantWithMinMaxVars operation,
		    shape one of: `[d]`, `[b, d]`,  `[b, h, w, d]`.
		  inputs: A `Tensor` of type `float32`.
		    Values passed as inputs to the FakeQuantWithMinMaxVars operation, shape
		      same as `gradients`.
		    min, max: Quantization interval, floats of shape `[d]`.
		  min: A `Tensor` of type `float32`.
		  max: A `Tensor` of type `float32`.
		  num_bits: An optional `int`. Defaults to `8`.
		    The bitwidth of the quantization; between 2 and 16, inclusive.
		  narrow_range: An optional `bool`. Defaults to `False`.
		    Whether to quantize into 2^num_bits - 1 distinct values.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (backprops_wrt_input, backprop_wrt_min, backprop_wrt_max).
		
		  backprops_wrt_input: A `Tensor` of type `float32`.
		  backprop_wrt_min: A `Tensor` of type `float32`.
		  backprop_wrt_max: A `Tensor` of type `float32`.
	**/
	static public function FakeQuantWithMinMaxVarsPerChannelGradient(gradients:Dynamic, inputs:Dynamic, min:Dynamic, max:Dynamic, ?num_bits:Dynamic, ?narrow_range:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Do not use.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function FakeQueue(resource:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a tensor filled with a scalar value.
		
		This operation creates a tensor of shape `dims` and fills it with `value`.
		
		For example:
		
		```
		# Output tensor has shape [2, 3].
		fill([2, 3], 9) ==> [[9, 9, 9]
		                     [9, 9, 9]]
		```
		
		`tf.fill` differs from `tf.constant` in a few ways:
		
		*   `tf.fill` only supports scalar contents, whereas `tf.constant` supports
		    Tensor values.
		*   `tf.fill` creates an Op in the computation graph that constructs the actual
		    Tensor value at runtime. This is in contrast to `tf.constant` which embeds
		    the entire Tensor into the graph with a `Const` node.
		*   Because `tf.fill` evaluates at graph runtime, it supports dynamic shapes
		    based on other runtime Tensors, unlike `tf.constant`.
		
		Args:
		  dims: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    1-D. Represents the shape of the output tensor.
		  value: A `Tensor`. 0-D (scalar). Value to fill the returned tensor.
		
		    @compatibility(numpy)
		    Equivalent to np.full
		    @end_compatibility
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `value`.
	**/
	static public function Fill(dims:Dynamic, value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset containing elements of first component of `input_dataset` having true in the last component.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function FilterByLastComponentDataset(input_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset containing elements of `input_dataset` matching `predicate`.
		
		The `predicate` function must return a scalar boolean and accept the
		following arguments:
		
		* One tensor for each component of an element of `input_dataset`.
		* One tensor for each value in `other_arguments`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when
		    building a closure for `predicate`.
		  predicate: A function decorated with @Defun.
		    A function returning a scalar boolean.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function FilterDataset(input_dataset:Dynamic, other_arguments:Dynamic, predicate:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset by applying `tf.data.Options` to `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  has_captured_ref: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function FinalizeDataset(input_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?has_captured_ref:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates fingerprint values.
		
		Generates fingerprint values of `data`.
		
		Fingerprint op considers the first dimension of `data` as the batch dimension,
		and `output[i]` contains the fingerprint value generated from contents in
		`data[i, ...]` for all `i`.
		
		Fingerprint op writes fingerprint values as byte arrays. For example, the
		default method `farmhash64` generates a 64-bit fingerprint value at a time.
		This 8-byte value is written out as an `uint8` array of size 8, in little-endian
		order.
		
		For example, suppose that `data` has data type `DT_INT32` and shape (2, 3, 4),
		and that the fingerprint method is `farmhash64`. In this case, the output shape
		is (2, 8), where 2 is the batch dimension size of `data`, and 8 is the size of
		each fingerprint value in bytes. `output[0, :]` is generated from 12 integers in
		`data[0, :, :]` and similarly `output[1, :]` is generated from other 12 integers
		in `data[1, :, :]`.
		
		Note that this op fingerprints the raw underlying buffer, and it does not
		fingerprint Tensor's metadata such as data type and/or shape. For example, the
		fingerprint values are invariant under reshapes and bitcasts as long as the
		batch dimension remain the same:
		
		```
		Fingerprint(data) == Fingerprint(Reshape(data, ...))
		Fingerprint(data) == Fingerprint(Bitcast(data, ...))
		```
		
		For string data, one should expect `Fingerprint(data) !=
		Fingerprint(ReduceJoin(data))` in general.
		
		Args:
		  data: A `Tensor`. Must have rank 1 or higher.
		  method: A `Tensor` of type `string`.
		    Fingerprint method used by this op. Currently available method is
		    `farmhash::fingerprint64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `uint8`.
	**/
	static public function Fingerprint(data:Dynamic, method:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that emits the records from one or more binary files.
		
		Args:
		  filenames: A `Tensor` of type `string`.
		    A scalar or a vector containing the name(s) of the file(s) to be
		    read.
		  header_bytes: A `Tensor` of type `int64`.
		    A scalar representing the number of bytes to skip at the
		    beginning of a file.
		  record_bytes: A `Tensor` of type `int64`.
		    A scalar representing the number of bytes in each record.
		  footer_bytes: A `Tensor` of type `int64`.
		    A scalar representing the number of bytes to skip at the end
		    of a file.
		  buffer_size: A `Tensor` of type `int64`.
		    A scalar representing the number of bytes to buffer. Must be > 0.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function FixedLengthRecordDataset(filenames:Dynamic, header_bytes:Dynamic, record_bytes:Dynamic, footer_bytes:Dynamic, buffer_size:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  filenames: A `Tensor` of type `string`.
		  header_bytes: A `Tensor` of type `int64`.
		  record_bytes: A `Tensor` of type `int64`.
		  footer_bytes: A `Tensor` of type `int64`.
		  buffer_size: A `Tensor` of type `int64`.
		  compression_type: A `Tensor` of type `string`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function FixedLengthRecordDatasetV2(filenames:Dynamic, header_bytes:Dynamic, record_bytes:Dynamic, footer_bytes:Dynamic, buffer_size:Dynamic, compression_type:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A Reader that outputs fixed-length records from a file.
		
		Args:
		  record_bytes: An `int`. Number of bytes in the record.
		  header_bytes: An optional `int`. Defaults to `0`.
		    Number of bytes in the header, defaults to 0.
		  footer_bytes: An optional `int`. Defaults to `0`.
		    Number of bytes in the footer, defaults to 0.
		  hop_bytes: An optional `int`. Defaults to `0`.
		    Number of bytes to hop before each read. Default of 0 means using
		    record_bytes.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function FixedLengthRecordReader(record_bytes:Dynamic, ?header_bytes:Dynamic, ?footer_bytes:Dynamic, ?hop_bytes:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A Reader that outputs fixed-length records from a file.
		
		Args:
		  record_bytes: An `int`. Number of bytes in the record.
		  header_bytes: An optional `int`. Defaults to `0`.
		    Number of bytes in the header, defaults to 0.
		  footer_bytes: An optional `int`. Defaults to `0`.
		    Number of bytes in the footer, defaults to 0.
		  hop_bytes: An optional `int`. Defaults to `0`.
		    Number of bytes to hop before each read. Default of 0 means using
		    record_bytes.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  encoding: An optional `string`. Defaults to `""`.
		    The type of encoding for the file. Currently ZLIB and GZIP
		    are supported. Defaults to none.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function FixedLengthRecordReaderV2(record_bytes:Dynamic, ?header_bytes:Dynamic, ?footer_bytes:Dynamic, ?hop_bytes:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?encoding:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates labels for candidate sampling with a learned unigram distribution.
		
		A unigram sampler could use a fixed unigram distribution read from a
		file or passed in as an in-memory array instead of building up the distribution
		from data on the fly. There is also an option to skew the distribution by
		applying a distortion power to the weights.
		
		The vocabulary file should be in CSV-like format, with the last field
		being the weight associated with the word.
		
		For each batch, this op picks a single set of sampled candidate labels.
		
		The advantages of sampling candidates per-batch are simplicity and the
		possibility of efficient dense matrix multiplication. The disadvantage is that
		the sampled candidates must be chosen independently of the context and of the
		true labels.
		
		Args:
		  true_classes: A `Tensor` of type `int64`.
		    A batch_size * num_true matrix, in which each row contains the
		    IDs of the num_true target_classes in the corresponding original label.
		  num_true: An `int` that is `>= 1`. Number of true labels per context.
		  num_sampled: An `int` that is `>= 1`.
		    Number of candidates to randomly sample.
		  unique: A `bool`.
		    If unique is true, we sample with rejection, so that all sampled
		    candidates in a batch are unique. This requires some approximation to
		    estimate the post-rejection sampling probabilities.
		  range_max: An `int` that is `>= 1`.
		    The sampler will sample integers from the interval [0, range_max).
		  vocab_file: An optional `string`. Defaults to `""`.
		    Each valid line in this file (which should have a CSV-like format)
		    corresponds to a valid word ID. IDs are in sequential order, starting from
		    num_reserved_ids. The last entry in each line is expected to be a value
		    corresponding to the count or relative probability. Exactly one of vocab_file
		    and unigrams needs to be passed to this op.
		  distortion: An optional `float`. Defaults to `1`.
		    The distortion is used to skew the unigram probability distribution.
		    Each weight is first raised to the distortion's power before adding to the
		    internal unigram distribution. As a result, distortion = 1.0 gives regular
		    unigram sampling (as defined by the vocab file), and distortion = 0.0 gives
		    a uniform distribution.
		  num_reserved_ids: An optional `int`. Defaults to `0`.
		    Optionally some reserved IDs can be added in the range [0,
		    ..., num_reserved_ids) by the users. One use case is that a special unknown
		    word token is used as ID 0. These IDs will have a sampling probability of 0.
		  num_shards: An optional `int` that is `>= 1`. Defaults to `1`.
		    A sampler can be used to sample from a subset of the original range
		    in order to speed up the whole computation through parallelism. This parameter
		    (together with 'shard') indicates the number of partitions that are being
		    used in the overall computation.
		  shard: An optional `int` that is `>= 0`. Defaults to `0`.
		    A sampler can be used to sample from a subset of the original range
		    in order to speed up the whole computation through parallelism. This parameter
		    (together with 'num_shards') indicates the particular partition number of a
		    sampler op, when partitioning is being used.
		  unigrams: An optional list of `floats`. Defaults to `[]`.
		    A list of unigram counts or probabilities, one per ID in sequential
		    order. Exactly one of vocab_file and unigrams should be passed to this op.
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    An second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sampled_candidates, true_expected_count, sampled_expected_count).
		
		  sampled_candidates: A `Tensor` of type `int64`.
		  true_expected_count: A `Tensor` of type `float32`.
		  sampled_expected_count: A `Tensor` of type `float32`.
	**/
	static public function FixedUnigramCandidateSampler(true_classes:Dynamic, num_true:Dynamic, num_sampled:Dynamic, unique:Dynamic, range_max:Dynamic, ?vocab_file:Dynamic, ?distortion:Dynamic, ?num_reserved_ids:Dynamic, ?num_shards:Dynamic, ?shard:Dynamic, ?unigrams:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		Unlike MapDataset, the `f` in FlatMapDataset is expected to return a
		Dataset variant, and FlatMapDataset will flatten successive results
		into a single Dataset.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  other_arguments: A list of `Tensor` objects.
		  f: A function decorated with @Defun.
		    A function mapping elements of `input_dataset`, concatenated with
		    `other_arguments`, to a Dataset variant that contains elements matching
		    `output_types` and `output_shapes`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function FlatMapDataset(input_dataset:Dynamic, other_arguments:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns element-wise largest integer not greater than x.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Floor(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x // y element-wise.
		
		*NOTE*: `floor_div` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function FloorDiv(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns element-wise remainder of division. When `x < 0` xor `y < 0` is
		
		true, this follows Python semantics in that the result here is consistent
		with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.
		
		*NOTE*: `math.floormod` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function FloorMod(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function FlushSummaryWriter(writer:Dynamic, ?name:Dynamic):Dynamic;
	/**
		```python
		 output = input;
		 for i in range(start, limit, delta)
		   output = body(i, output);
		```
		
		Args:
		  start: A `Tensor` of type `int32`. The lower bound. An int32
		  limit: A `Tensor` of type `int32`. The upper bound. An int32
		  delta: A `Tensor` of type `int32`. The increment. An int32
		  input: A list of `Tensor` objects.
		    A list of input tensors whose types are T.
		  body: A function decorated with @Defun.
		        A function that takes a list of tensors (int32, T) and returns another
		        list of tensors (T).
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects. Has the same type as `input`.
	**/
	static public function For(start:Dynamic, limit:Dynamic, delta:Dynamic, input:Dynamic, body:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs fractional average pooling on the input.
		
		Fractional average pooling is similar to Fractional max pooling in the pooling
		region generation step. The only difference is that after pooling regions are
		generated, a mean operation is performed instead of a max operation in each
		pooling region.
		
		Args:
		  value: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `int64`.
		    4-D with shape `[batch, height, width, channels]`.
		  pooling_ratio: A list of `floats` that has length `>= 4`.
		    Pooling ratio for each dimension of `value`, currently only
		    supports row and col dimension and should be >= 1.0. For example, a valid
		    pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements
		    must be 1.0 because we don't allow pooling on batch and channels
		    dimensions. 1.44 and 1.73 are pooling ratio on height and width dimensions
		    respectively.
		  pseudo_random: An optional `bool`. Defaults to `False`.
		    When set to True, generates the pooling sequence in a
		    pseudorandom fashion, otherwise, in a random fashion. Check paper [Benjamin
		    Graham, Fractional Max-Pooling](http://arxiv.org/abs/1412.6071) for
		    difference between pseudorandom and random.
		  overlapping: An optional `bool`. Defaults to `False`.
		    When set to True, it means when pooling, the values at the boundary
		    of adjacent pooling cells are used by both cells. For example:
		
		    `index  0  1  2  3  4`
		
		    `value  20 5  16 3  7`
		
		    If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
		    The result would be [41/3, 26/3] for fractional avg pooling.
		  deterministic: An optional `bool`. Defaults to `False`.
		    When set to True, a fixed pooling region will be used when
		    iterating over a FractionalAvgPool node in the computation graph. Mainly used
		    in unit test to make FractionalAvgPool deterministic.
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    An second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, row_pooling_sequence, col_pooling_sequence).
		
		  output: A `Tensor`. Has the same type as `value`.
		  row_pooling_sequence: A `Tensor` of type `int64`.
		  col_pooling_sequence: A `Tensor` of type `int64`.
	**/
	static public function FractionalAvgPool(value:Dynamic, pooling_ratio:Dynamic, ?pseudo_random:Dynamic, ?overlapping:Dynamic, ?deterministic:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradient of the FractionalAvgPool function.
		
		Unlike FractionalMaxPoolGrad, we don't need to find arg_max for
		FractionalAvgPoolGrad, we just need to evenly back-propagate each element of
		out_backprop to those indices that form the same pooling cell. Therefore, we
		just need to know the shape of original input tensor, instead of the whole
		tensor.
		
		Args:
		  orig_input_tensor_shape: A `Tensor` of type `int64`.
		    Original input tensor shape for `fractional_avg_pool`
		  out_backprop: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `int64`.
		    4-D with shape `[batch, height, width, channels]`.  Gradients
		    w.r.t. the output of `fractional_avg_pool`.
		  row_pooling_sequence: A `Tensor` of type `int64`.
		    row pooling sequence, form pooling region with
		    col_pooling_sequence.
		  col_pooling_sequence: A `Tensor` of type `int64`.
		    column pooling sequence, form pooling region with
		    row_pooling sequence.
		  overlapping: An optional `bool`. Defaults to `False`.
		    When set to True, it means when pooling, the values at the boundary
		    of adjacent pooling cells are used by both cells. For example:
		
		    `index  0  1  2  3  4`
		
		    `value  20 5  16 3  7`
		
		    If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
		    The result would be [41/3, 26/3] for fractional avg pooling.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `out_backprop`.
	**/
	static public function FractionalAvgPoolGrad(orig_input_tensor_shape:Dynamic, out_backprop:Dynamic, row_pooling_sequence:Dynamic, col_pooling_sequence:Dynamic, ?overlapping:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs fractional max pooling on the input.
		
		Fractional max pooling is slightly different than regular max pooling.  In
		regular max pooling, you downsize an input set by taking the maximum value of
		smaller N x N subsections of the set (often 2x2), and try to reduce the set by
		a factor of N, where N is an integer.  Fractional max pooling, as you might
		expect from the word "fractional", means that the overall reduction ratio N
		does not have to be an integer.
		
		The sizes of the pooling regions are generated randomly but are fairly uniform.
		For example, let's look at the height dimension, and the constraints on the
		list of rows that will be pool boundaries.
		
		First we define the following:
		
		1.  input_row_length : the number of rows from the input set
		2.  output_row_length : which will be smaller than the input
		3.  alpha = input_row_length / output_row_length : our reduction ratio
		4.  K = floor(alpha)
		5.  row_pooling_sequence : this is the result list of pool boundary rows
		
		Then, row_pooling_sequence should satisfy:
		
		1.  a[0] = 0 : the first value of the sequence is 0
		2.  a[end] = input_row_length : the last value of the sequence is the size
		3.  K <= (a[i+1] - a[i]) <= K+1 : all intervals are K or K+1 size
		4.  length(row_pooling_sequence) = output_row_length+1
		
		For more details on fractional max pooling, see this paper:
		[Benjamin Graham, Fractional Max-Pooling](http://arxiv.org/abs/1412.6071)
		
		Args:
		  value: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `int64`.
		    4-D with shape `[batch, height, width, channels]`.
		  pooling_ratio: A list of `floats` that has length `>= 4`.
		    Pooling ratio for each dimension of `value`, currently only
		    supports row and col dimension and should be >= 1.0. For example, a valid
		    pooling ratio looks like [1.0, 1.44, 1.73, 1.0]. The first and last elements
		    must be 1.0 because we don't allow pooling on batch and channels
		    dimensions. 1.44 and 1.73 are pooling ratio on height and width dimensions
		    respectively.
		  pseudo_random: An optional `bool`. Defaults to `False`.
		    When set to True, generates the pooling sequence in a
		    pseudorandom fashion, otherwise, in a random fashion. Check paper [Benjamin
		    Graham, Fractional Max-Pooling](http://arxiv.org/abs/1412.6071) for
		    difference between pseudorandom and random.
		  overlapping: An optional `bool`. Defaults to `False`.
		    When set to True, it means when pooling, the values at the boundary
		    of adjacent pooling cells are used by both cells. For example:
		
		    `index  0  1  2  3  4`
		
		    `value  20 5  16 3  7`
		
		    If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
		    The result would be [20, 16] for fractional max pooling.
		  deterministic: An optional `bool`. Defaults to `False`.
		    When set to True, a fixed pooling region will be used when
		    iterating over a FractionalMaxPool node in the computation graph. Mainly used
		    in unit test to make FractionalMaxPool deterministic.
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    An second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, row_pooling_sequence, col_pooling_sequence).
		
		  output: A `Tensor`. Has the same type as `value`.
		  row_pooling_sequence: A `Tensor` of type `int64`.
		  col_pooling_sequence: A `Tensor` of type `int64`.
	**/
	static public function FractionalMaxPool(value:Dynamic, pooling_ratio:Dynamic, ?pseudo_random:Dynamic, ?overlapping:Dynamic, ?deterministic:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradient of the FractionalMaxPool function.
		
		Args:
		  orig_input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `int64`.
		    Original input for `fractional_max_pool`
		  orig_output: A `Tensor`. Must have the same type as `orig_input`.
		    Original output for `fractional_max_pool`
		  out_backprop: A `Tensor`. Must have the same type as `orig_input`.
		    4-D with shape `[batch, height, width, channels]`.  Gradients
		    w.r.t. the output of `fractional_max_pool`.
		  row_pooling_sequence: A `Tensor` of type `int64`.
		    row pooling sequence, form pooling region with
		    col_pooling_sequence.
		  col_pooling_sequence: A `Tensor` of type `int64`.
		    column pooling sequence, form pooling region with
		    row_pooling sequence.
		  overlapping: An optional `bool`. Defaults to `False`.
		    When set to True, it means when pooling, the values at the boundary
		    of adjacent pooling cells are used by both cells. For example:
		
		    `index  0  1  2  3  4`
		
		    `value  20 5  16 3  7`
		
		    If the pooling sequence is [0, 2, 4], then 16, at index 2 will be used twice.
		    The result would be [20, 16] for fractional max pooling.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `orig_input`.
	**/
	static public function FractionalMaxPoolGrad(orig_input:Dynamic, orig_output:Dynamic, out_backprop:Dynamic, row_pooling_sequence:Dynamic, col_pooling_sequence:Dynamic, ?overlapping:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function FresnelCos(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function FresnelSin(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Batch normalization.
		
		Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
		The size of 1D Tensors matches the dimension C of the 4D Tensors.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`.
		    A 4D Tensor for input data.
		  scale: A `Tensor`. Must have the same type as `x`.
		    A 1D Tensor for scaling factor, to scale the normalized x.
		  offset: A `Tensor`. Must have the same type as `x`.
		    A 1D Tensor for offset, to shift to the normalized x.
		  mean: A `Tensor`. Must have the same type as `x`.
		    A 1D Tensor for population mean. Used for inference only;
		    must be empty for training.
		  variance: A `Tensor`. Must have the same type as `x`.
		    A 1D Tensor for population variance. Used for inference only;
		    must be empty for training.
		  epsilon: An optional `float`. Defaults to `0.0001`.
		    A small float number added to the variance of x.
		  exponential_avg_factor: An optional `float`. Defaults to `1`.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    The data format for x and y. Either "NHWC" (default) or "NCHW".
		  is_training: An optional `bool`. Defaults to `True`.
		    A bool value to indicate the operation is for training (default)
		    or inference.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (y, batch_mean, batch_variance, reserve_space_1, reserve_space_2).
		
		  y: A `Tensor`. Has the same type as `x`.
		  batch_mean: A `Tensor`. Has the same type as `x`.
		  batch_variance: A `Tensor`. Has the same type as `x`.
		  reserve_space_1: A `Tensor`. Has the same type as `x`.
		  reserve_space_2: A `Tensor`. Has the same type as `x`.
	**/
	static public function FusedBatchNorm(x:Dynamic, scale:Dynamic, offset:Dynamic, mean:Dynamic, variance:Dynamic, ?epsilon:Dynamic, ?exponential_avg_factor:Dynamic, ?data_format:Dynamic, ?is_training:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gradient for batch normalization.
		
		Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
		The size of 1D Tensors matches the dimension C of the 4D Tensors.
		
		Args:
		  y_backprop: A `Tensor`. Must be one of the following types: `float32`.
		    A 4D Tensor for the gradient with respect to y.
		  x: A `Tensor`. Must have the same type as `y_backprop`.
		    A 4D Tensor for input data.
		  scale: A `Tensor`. Must have the same type as `y_backprop`.
		    A 1D Tensor for scaling factor, to scale the normalized x.
		  reserve_space_1: A `Tensor`. Must have the same type as `y_backprop`.
		    When is_training is True, a 1D Tensor for the computed batch
		    mean to be reused in gradient computation. When is_training is
		    False, a 1D Tensor for the population mean to be reused in both
		    1st and 2nd order gradient computation.
		  reserve_space_2: A `Tensor`. Must have the same type as `y_backprop`.
		    When is_training is True, a 1D Tensor for the computed batch
		    variance (inverted variance in the cuDNN case) to be reused in
		    gradient computation. When is_training is False, a 1D Tensor
		    for the population variance to be reused in both 1st and 2nd
		    order gradient computation.
		  epsilon: An optional `float`. Defaults to `0.0001`.
		    A small float number added to the variance of x.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    The data format for y_backprop, x, x_backprop.
		    Either "NHWC" (default) or "NCHW".
		  is_training: An optional `bool`. Defaults to `True`.
		    A bool value to indicate the operation is for training (default)
		    or inference.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (x_backprop, scale_backprop, offset_backprop, reserve_space_3, reserve_space_4).
		
		  x_backprop: A `Tensor`. Has the same type as `y_backprop`.
		  scale_backprop: A `Tensor`. Has the same type as `y_backprop`.
		  offset_backprop: A `Tensor`. Has the same type as `y_backprop`.
		  reserve_space_3: A `Tensor`. Has the same type as `y_backprop`.
		  reserve_space_4: A `Tensor`. Has the same type as `y_backprop`.
	**/
	static public function FusedBatchNormGrad(y_backprop:Dynamic, x:Dynamic, scale:Dynamic, reserve_space_1:Dynamic, reserve_space_2:Dynamic, ?epsilon:Dynamic, ?data_format:Dynamic, ?is_training:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gradient for batch normalization.
		
		Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
		The size of 1D Tensors matches the dimension C of the 4D Tensors.
		
		Args:
		  y_backprop: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
		    A 4D Tensor for the gradient with respect to y.
		  x: A `Tensor`. Must have the same type as `y_backprop`.
		    A 4D Tensor for input data.
		  scale: A `Tensor` of type `float32`.
		    A 1D Tensor for scaling factor, to scale the normalized x.
		  reserve_space_1: A `Tensor`. Must be one of the following types: `float32`.
		    When is_training is True, a 1D Tensor for the computed batch
		    mean to be reused in gradient computation. When is_training is
		    False, a 1D Tensor for the population mean to be reused in both
		    1st and 2nd order gradient computation.
		  reserve_space_2: A `Tensor`. Must have the same type as `reserve_space_1`.
		    When is_training is True, a 1D Tensor for the computed batch
		    variance (inverted variance in the cuDNN case) to be reused in
		    gradient computation. When is_training is False, a 1D Tensor
		    for the population variance to be reused in both 1st and 2nd
		    order gradient computation.
		  epsilon: An optional `float`. Defaults to `0.0001`.
		    A small float number added to the variance of x.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    The data format for y_backprop, x, x_backprop.
		    Either "NHWC" (default) or "NCHW".
		  is_training: An optional `bool`. Defaults to `True`.
		    A bool value to indicate the operation is for training (default)
		    or inference.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (x_backprop, scale_backprop, offset_backprop, reserve_space_3, reserve_space_4).
		
		  x_backprop: A `Tensor`. Has the same type as `y_backprop`.
		  scale_backprop: A `Tensor`. Has the same type as `reserve_space_1`.
		  offset_backprop: A `Tensor`. Has the same type as `reserve_space_1`.
		  reserve_space_3: A `Tensor`. Has the same type as `reserve_space_1`.
		  reserve_space_4: A `Tensor`. Has the same type as `reserve_space_1`.
	**/
	static public function FusedBatchNormGradV2(y_backprop:Dynamic, x:Dynamic, scale:Dynamic, reserve_space_1:Dynamic, reserve_space_2:Dynamic, ?epsilon:Dynamic, ?data_format:Dynamic, ?is_training:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gradient for batch normalization.
		
		Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
		The size of 1D Tensors matches the dimension C of the 4D Tensors.
		
		Args:
		  y_backprop: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
		    A 4D Tensor for the gradient with respect to y.
		  x: A `Tensor`. Must have the same type as `y_backprop`.
		    A 4D Tensor for input data.
		  scale: A `Tensor` of type `float32`.
		    A 1D Tensor for scaling factor, to scale the normalized x.
		  reserve_space_1: A `Tensor`. Must be one of the following types: `float32`.
		    When is_training is True, a 1D Tensor for the computed batch
		    mean to be reused in gradient computation. When is_training is
		    False, a 1D Tensor for the population mean to be reused in both
		    1st and 2nd order gradient computation.
		  reserve_space_2: A `Tensor`. Must have the same type as `reserve_space_1`.
		    When is_training is True, a 1D Tensor for the computed batch
		    variance (inverted variance in the cuDNN case) to be reused in
		    gradient computation. When is_training is False, a 1D Tensor
		    for the population variance to be reused in both 1st and 2nd
		    order gradient computation.
		  reserve_space_3: A `Tensor`. Must have the same type as `reserve_space_1`.
		    When is_training is True, a 1D Tensor for some intermediate results to be reused
		    in gradient computation. When is_training is False, a dummy empty Tensor will be
		    created.
		  epsilon: An optional `float`. Defaults to `0.0001`.
		    A small float number added to the variance of x.
		  data_format: An optional `string` from: `"NHWC", "NCHW", "NDHWC", "NCDHW"`. Defaults to `"NHWC"`.
		    The data format for y_backprop, x, x_backprop.
		    Either "NHWC" (default) or "NCHW".
		  is_training: An optional `bool`. Defaults to `True`.
		    A bool value to indicate the operation is for training (default)
		    or inference.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (x_backprop, scale_backprop, offset_backprop, reserve_space_4, reserve_space_5).
		
		  x_backprop: A `Tensor`. Has the same type as `y_backprop`.
		  scale_backprop: A `Tensor`. Has the same type as `reserve_space_1`.
		  offset_backprop: A `Tensor`. Has the same type as `reserve_space_1`.
		  reserve_space_4: A `Tensor`. Has the same type as `reserve_space_1`.
		  reserve_space_5: A `Tensor`. Has the same type as `reserve_space_1`.
	**/
	static public function FusedBatchNormGradV3(y_backprop:Dynamic, x:Dynamic, scale:Dynamic, reserve_space_1:Dynamic, reserve_space_2:Dynamic, reserve_space_3:Dynamic, ?epsilon:Dynamic, ?data_format:Dynamic, ?is_training:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Batch normalization.
		
		Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
		The size of 1D Tensors matches the dimension C of the 4D Tensors.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
		    A 4D Tensor for input data.
		  scale: A `Tensor`. Must be one of the following types: `float32`.
		    A 1D Tensor for scaling factor, to scale the normalized x.
		  offset: A `Tensor`. Must have the same type as `scale`.
		    A 1D Tensor for offset, to shift to the normalized x.
		  mean: A `Tensor`. Must have the same type as `scale`.
		    A 1D Tensor for population mean. Used for inference only;
		    must be empty for training.
		  variance: A `Tensor`. Must have the same type as `scale`.
		    A 1D Tensor for population variance. Used for inference only;
		    must be empty for training.
		  epsilon: An optional `float`. Defaults to `0.0001`.
		    A small float number added to the variance of x.
		  exponential_avg_factor: An optional `float`. Defaults to `1`.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    The data format for x and y. Either "NHWC" (default) or "NCHW".
		  is_training: An optional `bool`. Defaults to `True`.
		    A bool value to indicate the operation is for training (default)
		    or inference.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (y, batch_mean, batch_variance, reserve_space_1, reserve_space_2).
		
		  y: A `Tensor`. Has the same type as `x`.
		  batch_mean: A `Tensor`. Has the same type as `scale`.
		  batch_variance: A `Tensor`. Has the same type as `scale`.
		  reserve_space_1: A `Tensor`. Has the same type as `scale`.
		  reserve_space_2: A `Tensor`. Has the same type as `scale`.
	**/
	static public function FusedBatchNormV2(x:Dynamic, scale:Dynamic, offset:Dynamic, mean:Dynamic, variance:Dynamic, ?epsilon:Dynamic, ?exponential_avg_factor:Dynamic, ?data_format:Dynamic, ?is_training:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Batch normalization.
		
		Note that the size of 4D Tensors are defined by either "NHWC" or "NCHW".
		The size of 1D Tensors matches the dimension C of the 4D Tensors.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
		    A 4D Tensor for input data.
		  scale: A `Tensor`. Must be one of the following types: `float32`.
		    A 1D Tensor for scaling factor, to scale the normalized x.
		  offset: A `Tensor`. Must have the same type as `scale`.
		    A 1D Tensor for offset, to shift to the normalized x.
		  mean: A `Tensor`. Must have the same type as `scale`.
		    A 1D Tensor for population mean. Used for inference only;
		    must be empty for training.
		  variance: A `Tensor`. Must have the same type as `scale`.
		    A 1D Tensor for population variance. Used for inference only;
		    must be empty for training.
		  epsilon: An optional `float`. Defaults to `0.0001`.
		    A small float number added to the variance of x.
		  exponential_avg_factor: An optional `float`. Defaults to `1`.
		  data_format: An optional `string` from: `"NHWC", "NCHW", "NDHWC", "NCDHW"`. Defaults to `"NHWC"`.
		    The data format for x and y. Either "NHWC" (default) or "NCHW".
		  is_training: An optional `bool`. Defaults to `True`.
		    A bool value to indicate the operation is for training (default)
		    or inference.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (y, batch_mean, batch_variance, reserve_space_1, reserve_space_2, reserve_space_3).
		
		  y: A `Tensor`. Has the same type as `x`.
		  batch_mean: A `Tensor`. Has the same type as `scale`.
		  batch_variance: A `Tensor`. Has the same type as `scale`.
		  reserve_space_1: A `Tensor`. Has the same type as `scale`.
		  reserve_space_2: A `Tensor`. Has the same type as `scale`.
		  reserve_space_3: A `Tensor`. Has the same type as `scale`.
	**/
	static public function FusedBatchNormV3(x:Dynamic, scale:Dynamic, offset:Dynamic, mean:Dynamic, variance:Dynamic, ?epsilon:Dynamic, ?exponential_avg_factor:Dynamic, ?data_format:Dynamic, ?is_training:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs a padding as a preprocess during a convolution.
		
		Similar to FusedResizeAndPadConv2d, this op allows for an optimized
		implementation where the spatial padding transformation stage is fused with the
		im2col lookup, but in this case without the bilinear filtering required for
		resizing. Fusing the padding prevents the need to write out the intermediate
		results as whole tensors, reducing memory pressure, and we can get some latency
		gains by merging the transformation calculations.
		The data_format attribute for Conv2D isn't supported by this op, and 'NHWC'
		order is used instead.
		Internally this op uses a single per-graph scratch buffer, which means that it
		will block if multiple versions are being run in parallel. This is because this
		operator is primarily an optimization to minimize memory usage.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		    4-D with shape `[batch, in_height, in_width, in_channels]`.
		  paddings: A `Tensor` of type `int32`.
		    A two-column matrix specifying the padding sizes. The number of
		    rows must be the same as the rank of `input`.
		  filter: A `Tensor`. Must have the same type as `input`. 4-D with shape
		    `[filter_height, filter_width, in_channels, out_channels]`.
		  mode: A `string` from: `"REFLECT", "SYMMETRIC"`.
		  strides: A list of `ints`.
		    1-D of length 4.  The stride of the sliding window for each dimension
		    of `input`. Must be in the same order as the dimension specified with format.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function FusedPadConv2D(input:Dynamic, paddings:Dynamic, filter:Dynamic, mode:Dynamic, strides:Dynamic, padding:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs a resize and padding as a preprocess during a convolution.
		
		It's often possible to do spatial transformations more efficiently as part of
		the packing stage of a convolution, so this op allows for an optimized
		implementation where these stages are fused together. This prevents the need to
		write out the intermediate results as whole tensors, reducing memory pressure,
		and we can get some latency gains by merging the transformation calculations.
		The data_format attribute for Conv2D isn't supported by this op, and defaults to
		'NHWC' order.
		Internally this op uses a single per-graph scratch buffer, which means that it
		will block if multiple versions are being run in parallel. This is because this
		operator is primarily an optimization to minimize memory usage.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		    4-D with shape `[batch, in_height, in_width, in_channels]`.
		  size: A `Tensor` of type `int32`.
		    A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
		    new size for the images.
		  paddings: A `Tensor` of type `int32`.
		    A two-column matrix specifying the padding sizes. The number of
		    rows must be the same as the rank of `input`.
		  filter: A `Tensor`. Must have the same type as `input`. 4-D with shape
		    `[filter_height, filter_width, in_channels, out_channels]`.
		  mode: A `string` from: `"REFLECT", "SYMMETRIC"`.
		  strides: A list of `ints`.
		    1-D of length 4.  The stride of the sliding window for each dimension
		    of `input`. Must be in the same order as the dimension specified with format.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  resize_align_corners: An optional `bool`. Defaults to `False`.
		    If true, the centers of the 4 corner pixels of the input and output tensors are
		    aligned, preserving the values at the corner pixels. Defaults to false.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function FusedResizeAndPadConv2D(input:Dynamic, size:Dynamic, paddings:Dynamic, filter:Dynamic, mode:Dynamic, strides:Dynamic, padding:Dynamic, ?resize_align_corners:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the GRU cell forward propagation for 1 time step.
		
		Args
		    x: Input to the GRU cell.
		    h_prev: State input from the previous GRU cell.
		    w_ru: Weight matrix for the reset and update gate.
		    w_c: Weight matrix for the cell connection gate.
		    b_ru: Bias vector for the reset and update gate.
		    b_c: Bias vector for the cell connection gate.
		
		Returns
		    r: Output of the reset gate.
		    u: Output of the update gate.
		    c: Output of the cell connection gate.
		    h: Current state of the GRU cell.
		
		Note on notation of the variables:
		
		Concatenation of a and b is represented by a_b
		Element-wise dot product of a and b is represented by ab
		Element-wise dot product is represented by \circ
		Matrix multiplication is represented by *
		
		Biases are initialized with :
		`b_ru` - constant_initializer(1.0)
		`b_c` - constant_initializer(0.0)
		
		This kernel op implements the following mathematical equations:
		
		```
		x_h_prev = [x, h_prev]
		
		[r_bar u_bar] = x_h_prev * w_ru + b_ru
		
		r = sigmoid(r_bar)
		u = sigmoid(u_bar)
		
		h_prevr = h_prev \circ r
		
		x_h_prevr = [x h_prevr]
		
		c_bar = x_h_prevr * w_c + b_c
		c = tanh(c_bar)
		
		h = (1-u) \circ c + u \circ h_prev
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`.
		  h_prev: A `Tensor`. Must have the same type as `x`.
		  w_ru: A `Tensor`. Must have the same type as `x`.
		  w_c: A `Tensor`. Must have the same type as `x`.
		  b_ru: A `Tensor`. Must have the same type as `x`.
		  b_c: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (r, u, c, h).
		
		  r: A `Tensor`. Has the same type as `x`.
		  u: A `Tensor`. Has the same type as `x`.
		  c: A `Tensor`. Has the same type as `x`.
		  h: A `Tensor`. Has the same type as `x`.
	**/
	static public function GRUBlockCell(x:Dynamic, h_prev:Dynamic, w_ru:Dynamic, w_c:Dynamic, b_ru:Dynamic, b_c:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the GRU cell back-propagation for 1 time step.
		
		Args
		    x: Input to the GRU cell.
		    h_prev: State input from the previous GRU cell.
		    w_ru: Weight matrix for the reset and update gate.
		    w_c: Weight matrix for the cell connection gate.
		    b_ru: Bias vector for the reset and update gate.
		    b_c: Bias vector for the cell connection gate.
		    r: Output of the reset gate.
		    u: Output of the update gate.
		    c: Output of the cell connection gate.
		    d_h: Gradients of the h_new wrt to objective function.
		
		Returns
		    d_x: Gradients of the x wrt to objective function.
		    d_h_prev: Gradients of the h wrt to objective function.
		    d_c_bar Gradients of the c_bar wrt to objective function.
		    d_r_bar_u_bar Gradients of the r_bar & u_bar wrt to objective function.
		
		This kernel op implements the following mathematical equations:
		
		Note on notation of the variables:
		
		Concatenation of a and b is represented by a_b
		Element-wise dot product of a and b is represented by ab
		Element-wise dot product is represented by \circ
		Matrix multiplication is represented by *
		
		Additional notes for clarity:
		
		`w_ru` can be segmented into 4 different matrices.
		```
		w_ru = [w_r_x w_u_x
		        w_r_h_prev w_u_h_prev]
		```
		Similarly, `w_c` can be segmented into 2 different matrices.
		```
		w_c = [w_c_x w_c_h_prevr]
		```
		Same goes for biases.
		```
		b_ru = [b_ru_x b_ru_h]
		b_c = [b_c_x b_c_h]
		```
		Another note on notation:
		```
		d_x = d_x_component_1 + d_x_component_2
		
		where d_x_component_1 = d_r_bar * w_r_x^T + d_u_bar * w_r_x^T
		and d_x_component_2 = d_c_bar * w_c_x^T
		
		d_h_prev = d_h_prev_component_1 + d_h_prevr \circ r + d_h \circ u
		where d_h_prev_componenet_1 = d_r_bar * w_r_h_prev^T + d_u_bar * w_r_h_prev^T
		```
		
		Mathematics behind the Gradients below:
		```
		d_c_bar = d_h \circ (1-u) \circ (1-c \circ c)
		d_u_bar = d_h \circ (h-c) \circ u \circ (1-u)
		
		d_r_bar_u_bar = [d_r_bar d_u_bar]
		
		[d_x_component_1 d_h_prev_component_1] = d_r_bar_u_bar * w_ru^T
		
		[d_x_component_2 d_h_prevr] = d_c_bar * w_c^T
		
		d_x = d_x_component_1 + d_x_component_2
		
		d_h_prev = d_h_prev_component_1 + d_h_prevr \circ r + u
		```
		Below calculation is performed in the python wrapper for the Gradients
		(not in the gradient kernel.)
		```
		d_w_ru = x_h_prevr^T * d_c_bar
		
		d_w_c = x_h_prev^T * d_r_bar_u_bar
		
		d_b_ru = sum of d_r_bar_u_bar along axis = 0
		
		d_b_c = sum of d_c_bar along axis = 0
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`.
		  h_prev: A `Tensor`. Must have the same type as `x`.
		  w_ru: A `Tensor`. Must have the same type as `x`.
		  w_c: A `Tensor`. Must have the same type as `x`.
		  b_ru: A `Tensor`. Must have the same type as `x`.
		  b_c: A `Tensor`. Must have the same type as `x`.
		  r: A `Tensor`. Must have the same type as `x`.
		  u: A `Tensor`. Must have the same type as `x`.
		  c: A `Tensor`. Must have the same type as `x`.
		  d_h: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (d_x, d_h_prev, d_c_bar, d_r_bar_u_bar).
		
		  d_x: A `Tensor`. Has the same type as `x`.
		  d_h_prev: A `Tensor`. Has the same type as `x`.
		  d_c_bar: A `Tensor`. Has the same type as `x`.
		  d_r_bar_u_bar: A `Tensor`. Has the same type as `x`.
	**/
	static public function GRUBlockCellGrad(x:Dynamic, h_prev:Dynamic, w_ru:Dynamic, w_c:Dynamic, b_ru:Dynamic, b_c:Dynamic, r:Dynamic, u:Dynamic, c:Dynamic, d_h:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gather slices from `params` according to `indices`.
		
		`indices` must be an integer tensor of any dimension (usually 0-D or 1-D).
		Produces an output tensor with shape `indices.shape + params.shape[1:]` where:
		
		```python
		    # Scalar indices
		    output[:, ..., :] = params[indices, :, ... :]
		
		    # Vector indices
		    output[i, :, ..., :] = params[indices[i], :, ... :]
		
		    # Higher rank indices
		    output[i, ..., j, :, ... :] = params[indices[i, ..., j], :, ..., :]
		```
		
		If `indices` is a permutation and `len(indices) == params.shape[0]` then
		this operation will permute `params` accordingly.
		
		`validate_indices`: DEPRECATED. If this operation is assigned to CPU, values in
		`indices` are always validated to be within range. If assigned to GPU,
		out-of-bound indices result in safe but unspecified behavior, which may include
		raising an error.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/Gather.png" alt>
		</div>
		
		Args:
		  params: A `Tensor`.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  validate_indices: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `params`.
	**/
	static public function Gather(params:Dynamic, indices:Dynamic, ?validate_indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gather slices from `params` into a Tensor with shape specified by `indices`.
		
		`indices` is a K-dimensional integer tensor, best thought of as a
		(K-1)-dimensional tensor of indices into `params`, where each element defines a
		slice of `params`:
		
		    output[\\(i_0, ..., i_{K-2}\\)] = params[indices[\\(i_0, ..., i_{K-2}\\)]]
		
		Whereas in `tf.gather` `indices` defines slices into the `axis`
		dimension of `params`, in `tf.gather_nd`, `indices` defines slices into the
		first `N` dimensions of `params`, where `N = indices.shape[-1]`.
		
		The last dimension of `indices` can be at most the rank of
		`params`:
		
		    indices.shape[-1] <= params.rank
		
		The last dimension of `indices` corresponds to elements
		(if `indices.shape[-1] == params.rank`) or slices
		(if `indices.shape[-1] < params.rank`) along dimension `indices.shape[-1]`
		of `params`.  The output tensor has shape
		
		    indices.shape[:-1] + params.shape[indices.shape[-1]:]
		
		Note that on CPU, if an out of bound index is found, an error is returned.
		On GPU, if an out of bound index is found, a 0 is stored in the
		corresponding output value.
		
		Some examples below.
		
		Simple indexing into a matrix:
		
		```python
		    indices = [[0, 0], [1, 1]]
		    params = [['a', 'b'], ['c', 'd']]
		    output = ['a', 'd']
		```
		
		Slice indexing into a matrix:
		
		```python
		    indices = [[1], [0]]
		    params = [['a', 'b'], ['c', 'd']]
		    output = [['c', 'd'], ['a', 'b']]
		```
		
		Indexing into a 3-tensor:
		
		```python
		    indices = [[1]]
		    params = [[['a0', 'b0'], ['c0', 'd0']],
		              [['a1', 'b1'], ['c1', 'd1']]]
		    output = [[['a1', 'b1'], ['c1', 'd1']]]
		
		
		    indices = [[0, 1], [1, 0]]
		    params = [[['a0', 'b0'], ['c0', 'd0']],
		              [['a1', 'b1'], ['c1', 'd1']]]
		    output = [['c0', 'd0'], ['a1', 'b1']]
		
		
		    indices = [[0, 0, 1], [1, 0, 1]]
		    params = [[['a0', 'b0'], ['c0', 'd0']],
		              [['a1', 'b1'], ['c1', 'd1']]]
		    output = ['b0', 'b1']
		```
		
		Batched indexing into a matrix:
		
		```python
		    indices = [[[0, 0]], [[0, 1]]]
		    params = [['a', 'b'], ['c', 'd']]
		    output = [['a'], ['b']]
		```
		
		Batched slice indexing into a matrix:
		
		```python
		    indices = [[[1]], [[0]]]
		    params = [['a', 'b'], ['c', 'd']]
		    output = [[['c', 'd']], [['a', 'b']]]
		```
		
		Batched indexing into a 3-tensor:
		
		```python
		    indices = [[[1]], [[0]]]
		    params = [[['a0', 'b0'], ['c0', 'd0']],
		              [['a1', 'b1'], ['c1', 'd1']]]
		    output = [[[['a1', 'b1'], ['c1', 'd1']]],
		              [[['a0', 'b0'], ['c0', 'd0']]]]
		
		    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]]
		    params = [[['a0', 'b0'], ['c0', 'd0']],
		              [['a1', 'b1'], ['c1', 'd1']]]
		    output = [[['c0', 'd0'], ['a1', 'b1']],
		              [['a0', 'b0'], ['c1', 'd1']]]
		
		
		    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]]
		    params = [[['a0', 'b0'], ['c0', 'd0']],
		              [['a1', 'b1'], ['c1', 'd1']]]
		    output = [['b0', 'b1'], ['d0', 'c1']]
		```
		
		See also `tf.gather` and `tf.batch_gather`.
		
		Args:
		  params: A `Tensor`. The tensor from which to gather values.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Index tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `params`.
	**/
	static public function GatherNd(params:Dynamic, indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gather slices from `params` axis `axis` according to `indices`.
		
		`indices` must be an integer tensor of any dimension (usually 0-D or 1-D).
		Produces an output tensor with shape `params.shape[:axis] +
		indices.shape[batch_dims:] + params.shape[axis + 1:]` where:
		
		```python
		    # Scalar indices (output is rank(params) - 1).
		    output[a_0, ..., a_n, b_0, ..., b_n] =
		      params[a_0, ..., a_n, indices, b_0, ..., b_n]
		
		    # Vector indices (output is rank(params)).
		    output[a_0, ..., a_n, i, b_0, ..., b_n] =
		      params[a_0, ..., a_n, indices[i], b_0, ..., b_n]
		
		    # Higher rank indices (output is rank(params) + rank(indices) - 1).
		    output[a_0, ..., a_n, i, ..., j, b_0, ... b_n] =
		      params[a_0, ..., a_n, indices[i, ..., j], b_0, ..., b_n]
		```
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/Gather.png" alt>
		</div>
		
		Note that on CPU, if an out of bound index is found, an error is returned.
		On GPU, if an out of bound index is found, a 0 is stored in the
		corresponding output value.
		
		See also `tf.batch_gather` and `tf.gather_nd`.
		
		Args:
		  params: A `Tensor`.
		    The tensor from which to gather values. Must be at least rank
		    `axis + 1`.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Index tensor. Must be in range `[0, params.shape[axis])`.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The axis in `params` to gather `indices` from. Defaults to the first
		    dimension. Supports negative indexes.
		  batch_dims: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `params`.
	**/
	static public function GatherV2(params:Dynamic, indices:Dynamic, axis:Dynamic, ?batch_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		This op produces Region of Interests from given bounding boxes(bbox_deltas) encoded wrt anchors according to eq.2 in arXiv:1506.01497
		
		      The op selects top `pre_nms_topn` scoring boxes, decodes them with respect to anchors,
		      applies non-maximal suppression on overlapping boxes with higher than
		      `nms_threshold` intersection-over-union (iou) value, discarding boxes where shorter
		      side is less than `min_size`.
		      Inputs:
		      `scores`: A 4D tensor of shape [Batch, Height, Width, Num Anchors] containing the scores per anchor at given position
		      `bbox_deltas`: is a tensor of shape [Batch, Height, Width, 4 x Num Anchors] boxes encoded to each anchor
		      `anchors`: A 1D tensor of shape [4 x Num Anchors], representing the anchors.
		      Outputs:
		      `rois`: output RoIs, a 3D tensor of shape [Batch, post_nms_topn, 4], padded by 0 if less than post_nms_topn candidates found.
		      `roi_probabilities`: probability scores of each roi in 'rois', a 2D tensor of shape [Batch,post_nms_topn], padded with 0 if needed, sorted by scores.
		
		Args:
		  scores: A `Tensor` of type `float32`.
		    A 4-D float tensor of shape `[num_images, height, width, num_achors]` containing scores of the boxes for given anchors, can be unsorted.
		  bbox_deltas: A `Tensor` of type `float32`.
		    A 4-D float tensor of shape `[num_images, height, width, 4 x num_anchors]`. encoding boxes with respec to each anchor.
		    Coordinates are given in the form [dy, dx, dh, dw].
		  image_info: A `Tensor` of type `float32`.
		    A 2-D float tensor of shape `[num_images, 5]` containing image information Height, Width, Scale.
		  anchors: A `Tensor` of type `float32`.
		    A 2-D float tensor of shape `[num_anchors, 4]` describing the anchor boxes. Boxes are formatted in the form [y1, x1, y2, x2].
		  nms_threshold: A `Tensor` of type `float32`.
		    A scalar float tensor for non-maximal-suppression threshold.
		  pre_nms_topn: A `Tensor` of type `int32`.
		    A scalar int tensor for the number of top scoring boxes to be used as input.
		  min_size: A `Tensor` of type `float32`.
		    A scalar float tensor. Any box that has a smaller size than min_size will be discarded.
		  post_nms_topn: An optional `int`. Defaults to `300`.
		    An integer. Maximum number of rois in the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (rois, roi_probabilities).
		
		  rois: A `Tensor` of type `float32`.
		  roi_probabilities: A `Tensor` of type `float32`.
	**/
	static public function GenerateBoundingBoxProposals(scores:Dynamic, bbox_deltas:Dynamic, image_info:Dynamic, anchors:Dynamic, nms_threshold:Dynamic, pre_nms_topn:Dynamic, min_size:Dynamic, ?post_nms_topn:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Given a path to new and old vocabulary files, returns a remapping Tensor of
		
		length `num_new_vocab`, where `remapping[i]` contains the row number in the old
		vocabulary that corresponds to row `i` in the new vocabulary (starting at line
		`new_vocab_offset` and up to `num_new_vocab` entities), or `-1` if entry `i`
		in the new vocabulary is not in the old vocabulary.  The old vocabulary is
		constrained to the first `old_vocab_size` entries if `old_vocab_size` is not the
		default value of -1.
		
		`num_vocab_offset` enables
		use in the partitioned variable case, and should generally be set through
		examining partitioning info.  The format of the files should be a text file,
		with each line containing a single entity within the vocabulary.
		
		For example, with `new_vocab_file` a text file containing each of the following
		elements on a single line: `[f0, f1, f2, f3]`, old_vocab_file = [f1, f0, f3],
		`num_new_vocab = 3, new_vocab_offset = 1`, the returned remapping would be
		`[0, -1, 2]`.
		
		The op also returns a count of how many entries in the new vocabulary
		were present in the old vocabulary, which is used to calculate the number of
		values to initialize in a weight matrix remapping
		
		This functionality can be used to remap both row vocabularies (typically,
		features) and column vocabularies (typically, classes) from TensorFlow
		checkpoints.  Note that the partitioning logic relies on contiguous vocabularies
		corresponding to div-partitioned variables.  Moreover, the underlying remapping
		uses an IndexTable (as opposed to an inexact CuckooTable), so client code should
		use the corresponding index_table_from_file() as the FeatureColumn framework
		does (as opposed to tf.feature_to_id(), which uses a CuckooTable).
		
		Args:
		  new_vocab_file: A `Tensor` of type `string`. Path to the new vocab file.
		  old_vocab_file: A `Tensor` of type `string`. Path to the old vocab file.
		  new_vocab_offset: An `int` that is `>= 0`.
		    How many entries into the new vocab file to start reading.
		  num_new_vocab: An `int` that is `>= 0`.
		    Number of entries in the new vocab file to remap.
		  old_vocab_size: An optional `int` that is `>= -1`. Defaults to `-1`.
		    Number of entries in the old vocab file to consider.  If -1,
		    use the entire old vocabulary.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (remapping, num_present).
		
		  remapping: A `Tensor` of type `int64`.
		  num_present: A `Tensor` of type `int32`.
	**/
	static public function GenerateVocabRemapping(new_vocab_file:Dynamic, old_vocab_file:Dynamic, new_vocab_offset:Dynamic, num_new_vocab:Dynamic, ?old_vocab_size:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that invokes a function to generate elements.
		
		Args:
		  init_func_other_args: A list of `Tensor` objects.
		  next_func_other_args: A list of `Tensor` objects.
		  finalize_func_other_args: A list of `Tensor` objects.
		  init_func: A function decorated with @Defun.
		  next_func: A function decorated with @Defun.
		  finalize_func: A function decorated with @Defun.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function GeneratorDataset(init_func_other_args:Dynamic, next_func_other_args:Dynamic, finalize_func_other_args:Dynamic, init_func:Dynamic, next_func:Dynamic, finalize_func:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gets the element at the specified index in a dataset.
		
		Args:
		  dataset: A `Tensor` of type `variant`.
		  index: A `Tensor` of type `int64`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `output_types`.
	**/
	static public function GetElementAtIndex(dataset:Dynamic, index:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the `tf.data.Options` attached to `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function GetOptions(input_dataset:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Store the input tensor in the state of the current session.
		
		Args:
		  value: A `Tensor`. The tensor to be stored.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function GetSessionHandle(value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Store the input tensor in the state of the current session.
		
		Args:
		  value: A `Tensor`. The tensor to be stored.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function GetSessionHandleV2(value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Get the value of the tensor specified by its handle.
		
		Args:
		  handle: A `Tensor` of type `string`.
		    The handle for a tensor stored in the session state.
		  dtype: A `tf.DType`. The type of the output value.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function GetSessionTensor(handle:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of (x > y) element-wise.
		
		*NOTE*: `math.greater` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Example:
		
		```python
		x = tf.constant([5, 4, 6])
		y = tf.constant([5, 2, 5])
		tf.math.greater(x, y) ==> [False, True, True]
		
		x = tf.constant([5, 4, 6])
		y = tf.constant([5])
		tf.math.greater(x, y) ==> [False, False, True]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function Greater(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of (x >= y) element-wise.
		
		*NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Example:
		
		```python
		x = tf.constant([5, 4, 6, 7])
		y = tf.constant([5, 2, 5, 10])
		tf.math.greater_equal(x, y) ==> [True, True, True, False]
		
		x = tf.constant([5, 4, 6, 7])
		y = tf.constant([5])
		tf.math.greater_equal(x, y) ==> [True, False, True, True]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function GreaterEqual(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that computes a group-by on `input_dataset`.
		
		Creates a dataset that computes a group-by on `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  key_func_other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when
		    building a closure for `key_func`.
		  init_func_other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when
		    building a closure for `init_func`.
		  reduce_func_other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when
		    building a closure for `reduce_func`.
		  finalize_func_other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when
		    building a closure for `finalize_func`.
		  key_func: A function decorated with @Defun.
		    A function mapping an element of `input_dataset`, concatenated
		    with `key_func_other_arguments` to a scalar value of type DT_INT64.
		  init_func: A function decorated with @Defun.
		    A function mapping a key of type DT_INT64, concatenated with
		    `init_func_other_arguments` to the initial reducer state.
		  reduce_func: A function decorated with @Defun.
		    A function mapping the current reducer state and an element of `input_dataset`,
		    concatenated with `reduce_func_other_arguments` to a new reducer state.
		  finalize_func: A function decorated with @Defun.
		    A function mapping the final reducer state to an output element.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function GroupByReducerDataset(input_dataset:Dynamic, key_func_other_arguments:Dynamic, init_func_other_arguments:Dynamic, reduce_func_other_arguments:Dynamic, finalize_func_other_arguments:Dynamic, key_func:Dynamic, init_func:Dynamic, reduce_func:Dynamic, finalize_func:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that computes a windowed group-by on `input_dataset`.
		
		// TODO(mrry): Support non-int64 keys.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  key_func_other_arguments: A list of `Tensor` objects.
		  reduce_func_other_arguments: A list of `Tensor` objects.
		  window_size_func_other_arguments: A list of `Tensor` objects.
		  key_func: A function decorated with @Defun.
		    A function mapping an element of `input_dataset`, concatenated
		    with `key_func_other_arguments` to a scalar value of type DT_INT64.
		  reduce_func: A function decorated with @Defun.
		  window_size_func: A function decorated with @Defun.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function GroupByWindowDataset(input_dataset:Dynamic, key_func_other_arguments:Dynamic, reduce_func_other_arguments:Dynamic, window_size_func_other_arguments:Dynamic, key_func:Dynamic, reduce_func:Dynamic, window_size_func:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gives a guarantee to the TF runtime that the input tensor is a constant.
		
		The runtime is then free to make optimizations based on this.
		
		Only accepts value typed tensors as inputs and rejects resource variable handles
		as input.
		
		Returns the input tensor without modification.
		
		Args:
		  input: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function GuaranteeConst(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Convert one or more images from HSV to RGB.
		
		Outputs a tensor of the same shape as the `images` tensor, containing the RGB
		value of the pixels. The output is only well defined if the value in `images`
		are in `[0,1]`.
		
		See `rgb_to_hsv` for a description of the HSV encoding.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    1-D or higher rank. HSV data to convert. Last dimension must be size 3.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `images`.
	**/
	static public function HSVToRGB(images:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a non-initialized hash table.
		
		This op creates a hash table, specifying the type of its keys and values.
		Before using the table you will have to initialize it.  After initialization the
		table will be immutable.
		
		Args:
		  key_dtype: A `tf.DType`. Type of the table keys.
		  value_dtype: A `tf.DType`. Type of the table values.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this table is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this table is shared under the given name across
		    multiple sessions.
		  use_node_name_sharing: An optional `bool`. Defaults to `False`.
		    If true and shared_name is empty, the table is shared
		    using the node name.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function HashTable(key_dtype:Dynamic, value_dtype:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?use_node_name_sharing:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a non-initialized hash table.
		
		This op creates a hash table, specifying the type of its keys and values.
		Before using the table you will have to initialize it.  After initialization the
		table will be immutable.
		
		Args:
		  key_dtype: A `tf.DType`. Type of the table keys.
		  value_dtype: A `tf.DType`. Type of the table values.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this table is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this table is shared under the given name across
		    multiple sessions.
		  use_node_name_sharing: An optional `bool`. Defaults to `False`.
		    If true and shared_name is empty, the table is shared
		    using the node name.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function HashTableV2(key_dtype:Dynamic, value_dtype:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?use_node_name_sharing:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return histogram of values.
		
		Given the tensor `values`, this operation returns a rank 1 histogram counting
		the number of entries in `values` that fall into every bin.  The bins are
		equal width and determined by the arguments `value_range` and `nbins`.
		
		```python
		# Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)
		nbins = 5
		value_range = [0.0, 5.0]
		new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]
		
		with tf.get_default_session() as sess:
		  hist = tf.histogram_fixed_width(new_values, value_range, nbins=5)
		  variables.global_variables_initializer().run()
		  sess.run(hist) => [2, 1, 1, 0, 2]
		```
		
		Args:
		  values: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.
		    Numeric `Tensor`.
		  value_range: A `Tensor`. Must have the same type as `values`.
		    Shape [2] `Tensor` of same `dtype` as `values`.
		    values <= value_range[0] will be mapped to hist[0],
		    values >= value_range[1] will be mapped to hist[-1].
		  nbins: A `Tensor` of type `int32`.
		    Scalar `int32 Tensor`.  Number of histogram bins.
		  dtype: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function HistogramFixedWidth(values:Dynamic, value_range:Dynamic, nbins:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs a `Summary` protocol buffer with a histogram.
		
		The generated
		[`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)
		has one summary value containing a histogram for `values`.
		
		This op reports an `InvalidArgument` error if any value is not finite.
		
		Args:
		  tag: A `Tensor` of type `string`.
		    Scalar.  Tag to use for the `Summary.Value`.
		  values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    Any shape. Values to use to build the histogram.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function HistogramSummary(tag:Dynamic, values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Inverse fast Fourier transform.
		
		Computes the inverse 1-dimensional discrete Fourier transform over the
		inner-most dimension of `input`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		    A complex tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function IFFT(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Inverse 2D fast Fourier transform.
		
		Computes the inverse 2-dimensional discrete Fourier transform over the
		inner-most 2 dimensions of `input`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		    A complex tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function IFFT2D(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Inverse 3D fast Fourier transform.
		
		Computes the inverse 3-dimensional discrete Fourier transform over the
		inner-most 3 dimensions of `input`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		    A complex tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function IFFT3D(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Inverse real-valued fast Fourier transform.
		
		Computes the inverse 1-dimensional discrete Fourier transform of a real-valued
		signal over the inner-most dimension of `input`.
		
		The inner-most dimension of `input` is assumed to be the result of `RFFT`: the
		`fft_length / 2 + 1` unique components of the DFT of a real-valued signal. If
		`fft_length` is not provided, it is computed from the size of the inner-most
		dimension of `input` (`fft_length = 2 * (inner - 1)`). If the FFT length used to
		compute `input` is odd, it should be provided since it cannot be inferred
		properly.
		
		Along the axis `IRFFT` is computed on, if `fft_length / 2 + 1` is smaller
		than the corresponding dimension of `input`, the dimension is cropped. If it is
		larger, the dimension is padded with zeros.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		    A complex tensor.
		  fft_length: A `Tensor` of type `int32`.
		    An int32 tensor of shape [1]. The FFT length.
		  Treal: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Treal`.
	**/
	static public function IRFFT(input:Dynamic, fft_length:Dynamic, ?Treal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Inverse 2D real-valued fast Fourier transform.
		
		Computes the inverse 2-dimensional discrete Fourier transform of a real-valued
		signal over the inner-most 2 dimensions of `input`.
		
		The inner-most 2 dimensions of `input` are assumed to be the result of `RFFT2D`:
		The inner-most dimension contains the `fft_length / 2 + 1` unique components of
		the DFT of a real-valued signal. If `fft_length` is not provided, it is computed
		from the size of the inner-most 2 dimensions of `input`. If the FFT length used
		to compute `input` is odd, it should be provided since it cannot be inferred
		properly.
		
		Along each axis `IRFFT2D` is computed on, if `fft_length` (or
		`fft_length / 2 + 1` for the inner-most dimension) is smaller than the
		corresponding dimension of `input`, the dimension is cropped. If it is larger,
		the dimension is padded with zeros.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		    A complex tensor.
		  fft_length: A `Tensor` of type `int32`.
		    An int32 tensor of shape [2]. The FFT length for each dimension.
		  Treal: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Treal`.
	**/
	static public function IRFFT2D(input:Dynamic, fft_length:Dynamic, ?Treal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Inverse 3D real-valued fast Fourier transform.
		
		Computes the inverse 3-dimensional discrete Fourier transform of a real-valued
		signal over the inner-most 3 dimensions of `input`.
		
		The inner-most 3 dimensions of `input` are assumed to be the result of `RFFT3D`:
		The inner-most dimension contains the `fft_length / 2 + 1` unique components of
		the DFT of a real-valued signal. If `fft_length` is not provided, it is computed
		from the size of the inner-most 3 dimensions of `input`. If the FFT length used
		to compute `input` is odd, it should be provided since it cannot be inferred
		properly.
		
		Along each axis `IRFFT3D` is computed on, if `fft_length` (or
		`fft_length / 2 + 1` for the inner-most dimension) is smaller than the
		corresponding dimension of `input`, the dimension is cropped. If it is larger,
		the dimension is padded with zeros.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		    A complex tensor.
		  fft_length: A `Tensor` of type `int32`.
		    An int32 tensor of shape [3]. The FFT length for each dimension.
		  Treal: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Treal`.
	**/
	static public function IRFFT3D(input:Dynamic, fft_length:Dynamic, ?Treal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return a tensor with the same shape and contents as the input tensor or value.
		
		Args:
		  input: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Identity(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a list of tensors with the same shapes and contents as the input
		
		tensors.
		
		This op can be used to override the gradient for complicated functions. For
		example, suppose y = f(x) and we wish to apply a custom function g for backprop
		such that dx = g(dy). In Python,
		
		```python
		with tf.get_default_graph().gradient_override_map(
		    {'IdentityN': 'OverrideGradientWithG'}):
		  y, _ = identity_n([f(x), x])
		
		@tf.RegisterGradient('OverrideGradientWithG')
		def ApplyG(op, dy, _):
		  return [None, g(dy)]  # Do not backprop to f(x).
		```
		
		Args:
		  input: A list of `Tensor` objects.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects. Has the same type as `input`.
	**/
	static public function IdentityN(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A Reader that outputs the queued work as both the key and value.
		
		To use, enqueue strings in a Queue.  ReaderRead will take the front
		work string and output (work, work).
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function IdentityReader(?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A Reader that outputs the queued work as both the key and value.
		
		To use, enqueue strings in a Queue.  ReaderRead will take the front
		work string and output (work, work).
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function IdentityReaderV2(?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		output = cond ? then_branch(input) : else_branch(input)
		
		Args:
		  cond: A `Tensor`.
		          A Tensor. If the tensor is a scalar of non-boolean type, the
		          scalar is converted to a boolean according to the
		          following rule: if the scalar is a numerical value, non-zero means
		          `True` and zero means False; if the scalar is a string, non-empty
		          means `True` and empty means `False`. If the tensor is not a scalar,
		          being empty means False and being non-empty means True.
		  input: A list of `Tensor` objects. A list of input tensors.
		  Tout: A list of `tf.DTypes`. A list of output types.
		  then_branch: A function decorated with @Defun.
		          A function that takes 'inputs' and returns a list of tensors, whose
		          types are the same as what else_branch returns.
		  else_branch: A function decorated with @Defun.
		        A function that takes 'inputs' and returns a list of tensors, whose
		        types are the same as what then_branch returns.
		  output_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function If(cond:Dynamic, input:Dynamic, Tout:Dynamic, then_branch:Dynamic, else_branch:Dynamic, ?output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute the lower regularized incomplete Gamma function `P(a, x)`.
		
		The lower regularized incomplete Gamma function is defined as:
		
		
		\\(P(a, x) = gamma(a, x) / Gamma(a) = 1 - Q(a, x)\\)
		
		where
		
		\\(gamma(a, x) = \\int_{0}^{x} t^{a-1} exp(-t) dt\\)
		
		is the lower incomplete Gamma function.
		
		Note, above `Q(a, x)` (`Igammac`) is the upper regularized complete
		Gamma function.
		
		Args:
		  a: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  x: A `Tensor`. Must have the same type as `a`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `a`.
	**/
	static public function Igamma(a:Dynamic, x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient of `igamma(a, x)` wrt `a`.
		
		Args:
		  a: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		  x: A `Tensor`. Must have the same type as `a`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `a`.
	**/
	static public function IgammaGradA(a:Dynamic, x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute the upper regularized incomplete Gamma function `Q(a, x)`.
		
		The upper regularized incomplete Gamma function is defined as:
		
		\\(Q(a, x) = Gamma(a, x) / Gamma(a) = 1 - P(a, x)\\)
		
		where
		
		\\(Gamma(a, x) = \int_{x}^{\infty} t^{a-1} exp(-t) dt\\)
		
		is the upper incomplete Gamma function.
		
		Note, above `P(a, x)` (`Igamma`) is the lower regularized complete
		Gamma function.
		
		Args:
		  a: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  x: A `Tensor`. Must have the same type as `a`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `a`.
	**/
	static public function Igammac(a:Dynamic, x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that contains the elements of `input_dataset` ignoring errors.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  log_warning: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function IgnoreErrorsDataset(input_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?log_warning:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the imaginary part of a complex number.
		
		Given a tensor `input` of complex numbers, this operation returns a tensor of
		type `float` that is the imaginary part of each element in `input`. All
		elements in `input` must be complex numbers of the form \\(a + bj\\), where *a*
		is the real part and *b* is the imaginary part returned by this operation.
		
		For example:
		
		```
		# tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
		tf.imag(input) ==> [4.75, 5.75]
		```
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		  Tout: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Tout`.
	**/
	static public function Imag(input:Dynamic, ?Tout:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies the given transform to each of the images.
		
		If one row of `transforms` is `[a0, a1, a2, b0, b1, b2, c0, c1]`, then it maps
		the *output* point `(x, y)` to a transformed *input* point
		`(x', y') = ((a0 x + a1 y + a2) / k, (b0 x + b1 y + b2) / k)`, where
		`k = c0 x + c1 y + 1`. If the transformed point lays outside of the input
		image, the output pixel is set to 0.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `uint8`, `int32`, `int64`, `half`, `float32`, `float64`.
		    4-D with shape `[batch, height, width, channels]`.
		  transforms: A `Tensor` of type `float32`.
		    2-D Tensor, `[batch, 8]` or `[1, 8]` matrix, where each row corresponds to a 3 x 3
		    projective transformation matrix, with the last entry assumed to be 1. If there
		    is one row, the same transformation will be applied to all images.
		  output_shape: A `Tensor` of type `int32`.
		    1-D Tensor [new_height, new_width].
		  interpolation: A `string`. Interpolation method, "NEAREST" or "BILINEAR".
		  fill_mode: An optional `string`. Defaults to `"CONSTANT"`.
		    Fill mode, "REFLECT", "WRAP", or "CONSTANT".
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `images`.
	**/
	static public function ImageProjectiveTransformV2(images:Dynamic, transforms:Dynamic, output_shape:Dynamic, interpolation:Dynamic, ?fill_mode:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies the given transform to each of the images.
		
		If one row of `transforms` is `[a0, a1, a2, b0, b1, b2, c0, c1]`, then it maps
		the *output* point `(x, y)` to a transformed *input* point
		`(x', y') = ((a0 x + a1 y + a2) / k, (b0 x + b1 y + b2) / k)`, where
		`k = c0 x + c1 y + 1`. If the transformed point lays outside of the input
		image, the output pixel is set to fill_value.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `uint8`, `int32`, `int64`, `half`, `float32`, `float64`.
		    4-D with shape `[batch, height, width, channels]`.
		  transforms: A `Tensor` of type `float32`.
		    2-D Tensor, `[batch, 8]` or `[1, 8]` matrix, where each row corresponds to a 3 x 3
		    projective transformation matrix, with the last entry assumed to be 1. If there
		    is one row, the same transformation will be applied to all images.
		  output_shape: A `Tensor` of type `int32`.
		    1-D Tensor [new_height, new_width].
		  fill_value: A `Tensor` of type `float32`.
		    float, the value to be filled when fill_mode is constant".
		  interpolation: A `string`. Interpolation method, "NEAREST" or "BILINEAR".
		  fill_mode: An optional `string`. Defaults to `"CONSTANT"`.
		    Fill mode, "REFLECT", "WRAP", "CONSTANT", or "NEAREST".
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `images`.
	**/
	static public function ImageProjectiveTransformV3(images:Dynamic, transforms:Dynamic, output_shape:Dynamic, fill_value:Dynamic, interpolation:Dynamic, ?fill_mode:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs a `Summary` protocol buffer with images.
		
		The summary has up to `max_images` summary values containing images. The
		images are built from `tensor` which must be 4-D with shape `[batch_size,
		height, width, channels]` and where `channels` can be:
		
		*  1: `tensor` is interpreted as Grayscale.
		*  3: `tensor` is interpreted as RGB.
		*  4: `tensor` is interpreted as RGBA.
		
		The images have the same number of channels as the input tensor. For float
		input, the values are normalized one image at a time to fit in the range
		`[0, 255]`.  `uint8` values are unchanged.  The op uses two different
		normalization algorithms:
		
		*  If the input values are all positive, they are rescaled so the largest one
		   is 255.
		
		*  If any input value is negative, the values are shifted so input value 0.0
		   is at 127.  They are then rescaled so that either the smallest value is 0,
		   or the largest one is 255.
		
		The `tag` argument is a scalar `Tensor` of type `string`.  It is used to
		build the `tag` of the summary values:
		
		*  If `max_images` is 1, the summary value tag is '*tag* /image'.
		*  If `max_images` is greater than 1, the summary value tags are
		   generated sequentially as '*tag* /image/0', '*tag* /image/1', etc.
		
		The `bad_color` argument is the color to use in the generated images for
		non-finite input values.  It is a `uint8` 1-D tensor of length `channels`.
		Each element must be in the range `[0, 255]` (It represents the value of a
		pixel in the output image).  Non-finite values in the input tensor are
		replaced by this tensor in the output image.  The default value is the color
		red.
		
		Args:
		  tag: A `Tensor` of type `string`.
		    Scalar. Used to build the `tag` attribute of the summary values.
		  tensor: A `Tensor`. Must be one of the following types: `uint8`, `float32`, `half`, `float64`.
		    4-D of shape `[batch_size, height, width, channels]` where
		    `channels` is 1, 3, or 4.
		  max_images: An optional `int` that is `>= 1`. Defaults to `3`.
		    Max number of batch elements to generate images for.
		  bad_color: An optional `tf.TensorProto`. Defaults to `dtype: DT_UINT8 tensor_shape { dim { size: 4 } } int_val: 255 int_val: 0 int_val: 0 int_val: 255`.
		    Color to use for pixels with non-finite values.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function ImageSummary(tag:Dynamic, tensor:Dynamic, ?max_images:Dynamic, ?bad_color:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns immutable tensor from memory region.
		
		The current implementation memmaps the tensor from a file.
		
		Args:
		  dtype: A `tf.DType`. Type of the returned tensor.
		  shape: A `tf.TensorShape` or list of `ints`. Shape of the returned tensor.
		  memory_region_name: A `string`.
		    Name of readonly memory region used by the tensor, see
		    NewReadOnlyMemoryRegionFromFile in tensorflow::Env.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function ImmutableConst(dtype:Dynamic, shape:Dynamic, memory_region_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  event: A `Tensor` of type `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ImportEvent(writer:Dynamic, event:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Says whether the targets are in the top `K` predictions.
		
		This outputs a `batch_size` bool array, an entry `out[i]` is `true` if the
		prediction for the target class is among the top `k` predictions among
		all predictions for example `i`. Note that the behavior of `InTopK` differs
		from the `TopK` op in its handling of ties; if multiple classes have the
		same prediction value and straddle the top-`k` boundary, all of those
		classes are considered to be in the top `k`.
		
		More formally, let
		
		  \\(predictions_i\\) be the predictions for all classes for example `i`,
		  \\(targets_i\\) be the target class for example `i`,
		  \\(out_i\\) be the output for example `i`,
		
		$$out_i = predictions_{i, targets_i} \in TopKIncludingTies(predictions_i)$$
		
		Args:
		  predictions: A `Tensor` of type `float32`.
		    A `batch_size` x `classes` tensor.
		  targets: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A `batch_size` vector of class ids.
		  k: An `int`. Number of top elements to look at for computing precision.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function InTopK(predictions:Dynamic, targets:Dynamic, k:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Says whether the targets are in the top `K` predictions.
		
		This outputs a `batch_size` bool array, an entry `out[i]` is `true` if the
		prediction for the target class is among the top `k` predictions among
		all predictions for example `i`. Note that the behavior of `InTopK` differs
		from the `TopK` op in its handling of ties; if multiple classes have the
		same prediction value and straddle the top-`k` boundary, all of those
		classes are considered to be in the top `k`.
		
		More formally, let
		
		  \\(predictions_i\\) be the predictions for all classes for example `i`,
		  \\(targets_i\\) be the target class for example `i`,
		  \\(out_i\\) be the output for example `i`,
		
		$$out_i = predictions_{i, targets_i} \in TopKIncludingTies(predictions_i)$$
		
		Args:
		  predictions: A `Tensor` of type `float32`.
		    A `batch_size` x `classes` tensor.
		  targets: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A `batch_size` vector of class ids.
		  k: A `Tensor`. Must have the same type as `targets`.
		    Number of top elements to look at for computing precision.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function InTopKV2(predictions:Dynamic, targets:Dynamic, k:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A placeholder op for a value that will be fed into the computation.
		
		Args:
		  dtype: A `tf.DType`. The type of elements in the tensor.
		  shape: A `tf.TensorShape` or list of `ints`. The shape of the tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function InfeedDequeue(dtype:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Fetches multiple values from infeed as an XLA tuple.
		
		Args:
		  dtypes: A list of `tf.DTypes` that has length `>= 1`.
		    The element types of each element in `outputs`.
		  shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    The shapes of each tensor in `outputs`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `dtypes`.
	**/
	static public function InfeedDequeueTuple(dtypes:Dynamic, shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An op which feeds a single Tensor value into the computation.
		
		Args:
		  input: A `Tensor`.
		    A tensor that will be provided using the infeed mechanism.
		  shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `[]`.
		    The shape of the tensor.
		  layout: An optional list of `ints`. Defaults to `[]`.
		    A vector holding the requested layout in minor-to-major sequence.
		    If a layout attribute is passed, but its values are all -1, the layout will
		    be computed by the infeed operation.
		  device_ordinal: An optional `int`. Defaults to `-1`.
		    The TPU device to use. This should be -1 when the Op
		    is running on a TPU device, and >= 0 when the Op is running on the CPU
		    device.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function InfeedEnqueue(input:Dynamic, ?shape:Dynamic, ?layout:Dynamic, ?device_ordinal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An op which enqueues prelinearized buffer into TPU infeed.
		
		Args:
		  input: A `Tensor` of type `variant`.
		    A variant tensor representing linearized output.
		  device_ordinal: An optional `int`. Defaults to `-1`.
		    The TPU device to use. This should be -1 when the Op is running on a TPU device
		    and = 0 when the Op is running on the CPU device.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function InfeedEnqueuePrelinearizedBuffer(input:Dynamic, ?device_ordinal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Feeds multiple Tensor values into the computation as an XLA tuple.
		
		Args:
		  inputs: A list of `Tensor` objects.
		    A list of tensors that will be provided using the infeed mechanism.
		  shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    The shapes of each tensor in `inputs`.
		  layouts: An optional list of `ints`. Defaults to `[]`.
		    A vector holding the requested layout in minor-to-major sequence for
		    all the tuple shapes, in the order the shapes appear in the "shapes" input.
		    The layout elements for a sub-shape can be set to -1, in which case the
		    corresponding layout will be computed by the infeed operation.
		  device_ordinal: An optional `int`. Defaults to `-1`.
		    The TPU device to use. This should be -1 when the Op
		    is running on a TPU device, and >= 0 when the Op is running on the CPU
		    device.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function InfeedEnqueueTuple(inputs:Dynamic, shapes:Dynamic, ?layouts:Dynamic, ?device_ordinal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Table initializer that takes two tensors for keys and values respectively.
		
		Args:
		  table_handle: A `Tensor` of type mutable `string`.
		    Handle to a table which will be initialized.
		  keys: A `Tensor`. Keys of type Tkey.
		  values: A `Tensor`. Values of type Tval.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function InitializeTable(table_handle:Dynamic, keys:Dynamic, values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  table_handle: A `Tensor` of type `resource`.
		  dataset: A `Tensor` of type `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function InitializeTableFromDataset(table_handle:Dynamic, dataset:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Initializes a table from a text file.
		
		It inserts one key-value pair into the table for each line of the file.
		The key and value is extracted from the whole line content, elements from the
		split line based on `delimiter` or the line number (starting from zero).
		Where to extract the key and value from a line is specified by `key_index` and
		`value_index`.
		
		- A value of -1 means use the line number(starting from zero), expects `int64`.
		- A value of -2 means use the whole line content, expects `string`.
		- A value >= 0 means use the index (starting at zero) of the split line based
		  on `delimiter`.
		
		Args:
		  table_handle: A `Tensor` of type mutable `string`.
		    Handle to a table which will be initialized.
		  filename: A `Tensor` of type `string`. Filename of a vocabulary text file.
		  key_index: An `int` that is `>= -2`.
		    Column index in a line to get the table `key` values from.
		  value_index: An `int` that is `>= -2`.
		    Column index that represents information of a line to get the table
		    `value` values from.
		  vocab_size: An optional `int` that is `>= -1`. Defaults to `-1`.
		    Number of elements of the file, use -1 if unknown.
		  delimiter: An optional `string`. Defaults to `"\t"`.
		    Delimiter to separate fields in a line.
		  offset: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function InitializeTableFromTextFile(table_handle:Dynamic, filename:Dynamic, key_index:Dynamic, value_index:Dynamic, ?vocab_size:Dynamic, ?delimiter:Dynamic, ?offset:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Initializes a table from a text file.
		
		It inserts one key-value pair into the table for each line of the file.
		The key and value is extracted from the whole line content, elements from the
		split line based on `delimiter` or the line number (starting from zero).
		Where to extract the key and value from a line is specified by `key_index` and
		`value_index`.
		
		- A value of -1 means use the line number(starting from zero), expects `int64`.
		- A value of -2 means use the whole line content, expects `string`.
		- A value >= 0 means use the index (starting at zero) of the split line based
		  on `delimiter`.
		
		Args:
		  table_handle: A `Tensor` of type `resource`.
		    Handle to a table which will be initialized.
		  filename: A `Tensor` of type `string`. Filename of a vocabulary text file.
		  key_index: An `int` that is `>= -2`.
		    Column index in a line to get the table `key` values from.
		  value_index: An `int` that is `>= -2`.
		    Column index that represents information of a line to get the table
		    `value` values from.
		  vocab_size: An optional `int` that is `>= -1`. Defaults to `-1`.
		    Number of elements of the file, use -1 if unknown.
		  delimiter: An optional `string`. Defaults to `"\t"`.
		    Delimiter to separate fields in a line.
		  offset: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function InitializeTableFromTextFileV2(table_handle:Dynamic, filename:Dynamic, key_index:Dynamic, value_index:Dynamic, ?vocab_size:Dynamic, ?delimiter:Dynamic, ?offset:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Table initializer that takes two tensors for keys and values respectively.
		
		Args:
		  table_handle: A `Tensor` of type `resource`.
		    Handle to a table which will be initialized.
		  keys: A `Tensor`. Keys of type Tkey.
		  values: A `Tensor`. Values of type Tval.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function InitializeTableV2(table_handle:Dynamic, keys:Dynamic, values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adds v into specified rows of x.
		
		    Computes y = x; y[i, :] += v; return y.
		
		Args:
		  x: A `Tensor`. A `Tensor` of type T.
		  i: A `Tensor` of type `int32`.
		    A vector. Indices into the left-most dimension of `x`.
		  v: A `Tensor`. Must have the same type as `x`.
		    A `Tensor` of type T. Same dimension sizes as x except the first dimension, which must be the same as i's size.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function InplaceAdd(x:Dynamic, i:Dynamic, v:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Subtracts `v` into specified rows of `x`.
		
		  Computes y = x; y[i, :] -= v; return y.
		
		Args:
		  x: A `Tensor`. A `Tensor` of type T.
		  i: A `Tensor` of type `int32`.
		    A vector. Indices into the left-most dimension of `x`.
		  v: A `Tensor`. Must have the same type as `x`.
		    A `Tensor` of type T. Same dimension sizes as x except the first dimension, which must be the same as i's size.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function InplaceSub(x:Dynamic, i:Dynamic, v:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Updates specified rows 'i' with values 'v'.
		
		Computes `x[i, :] = v; return x`.
		
		Originally this function is mutative however for compilation we make this
		operation create / operate on a copy of `x`.
		
		Args:
		  x: A `Tensor`. A tensor of type `T`.
		  i: A `Tensor` of type `int32`.
		    A vector. Indices into the left-most dimension of `x`.
		  v: A `Tensor`. Must have the same type as `x`.
		    A `Tensor` of type T. Same dimension sizes as x except the first dimension, which must be the same as i's size.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function InplaceUpdate(x:Dynamic, i:Dynamic, v:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		Unlike MapDataset, the `f` in InterleaveDataset is expected to return
		a Dataset variant, and InterleaveDataset will flatten successive
		results into a single Dataset. Unlike FlatMapDataset,
		InterleaveDataset will interleave sequences of up to `block_length`
		consecutive elements from `cycle_length` input elements.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  other_arguments: A list of `Tensor` objects.
		  cycle_length: A `Tensor` of type `int64`.
		  block_length: A `Tensor` of type `int64`.
		  f: A function decorated with @Defun.
		    A function mapping elements of `input_dataset`, concatenated with
		    `other_arguments`, to a Dataset variant that contains elements matching
		    `output_types` and `output_shapes`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function InterleaveDataset(input_dataset:Dynamic, other_arguments:Dynamic, cycle_length:Dynamic, block_length:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the reciprocal of x element-wise.
		
		I.e., \\(y = 1 / x\\).
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Inv(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient for the inverse of `x` wrt its input.
		
		Specifically, `grad = -dy * y*y`, where `y = 1/x`, and `dy`
		is the corresponding input gradient.
		
		Args:
		  y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  dy: A `Tensor`. Must have the same type as `y`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `y`.
	**/
	static public function InvGrad(y:Dynamic, dy:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Invert (flip) each bit of supported types; for example, type `uint8` value 01010101 becomes 10101010.
		
		Flip each bit of supported types.  For example, type `int8` (decimal 2) binary 00000010 becomes (decimal -3) binary 11111101.
		This operation is performed on each element of the tensor argument `x`.
		
		Example:
		```python
		import tensorflow as tf
		from tensorflow.python.ops import bitwise_ops
		
		# flip 2 (00000010) to -3 (11111101)
		tf.assert_equal(-3, bitwise_ops.invert(2))
		
		dtype_list = [dtypes.int8, dtypes.int16, dtypes.int32, dtypes.int64,
		              dtypes.uint8, dtypes.uint16, dtypes.uint32, dtypes.uint64]
		
		inputs = [0, 5, 3, 14]
		for dtype in dtype_list:
		  # Because of issues with negative numbers, let's test this indirectly.
		  # 1. invert(a) and a = 0
		  # 2. invert(a) or a = invert(0)
		  input_tensor = tf.constant([0, 5, 3, 14], dtype=dtype)
		  not_a_and_a, not_a_or_a, not_0 = [bitwise_ops.bitwise_and(
		                                      input_tensor, bitwise_ops.invert(input_tensor)),
		                                    bitwise_ops.bitwise_or(
		                                      input_tensor, bitwise_ops.invert(input_tensor)),
		                                    bitwise_ops.invert(
		                                      tf.constant(0, dtype=dtype))]
		
		  expected = tf.constant([0, 0, 0, 0], dtype=tf.float32)
		  tf.assert_equal(tf.cast(not_a_and_a, tf.float32), expected)
		
		  expected = tf.cast([not_0] * 4, tf.float32)
		  tf.assert_equal(tf.cast(not_a_or_a, tf.float32), expected)
		
		  # For unsigned dtypes let's also check the result directly.
		  if dtype.is_unsigned:
		    inverted = bitwise_ops.invert(input_tensor)
		    expected = tf.constant([dtype.max - x for x in inputs], dtype=tf.float32)
		    tf.assert_equal(tf.cast(inverted, tf.float32), tf.cast(expected, tf.float32))
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Invert(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the inverse permutation of a tensor.
		
		This operation computes the inverse of an index permutation. It takes a 1-D
		integer tensor `x`, which represents the indices of a zero-based array, and
		swaps each value with its index position. In other words, for an output tensor
		`y` and an input tensor `x`, this operation computes the following:
		
		`y[x[i]] = i for i in [0, 1, ..., len(x) - 1]`
		
		The values must include 0. There can be no duplicate values or negative values.
		
		For example:
		
		```
		# tensor `x` is [3, 4, 0, 2, 1]
		invert_permutation(x) ==> [2, 4, 3, 0, 1]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int32`, `int64`. 1-D.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function InvertPermutation(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Checks whether a tree ensemble has been initialized.
		
		Args:
		  tree_ensemble_handle: A `Tensor` of type `resource`.
		    Handle to the tree ensemble resource.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function IsBoostedTreesEnsembleInitialized(tree_ensemble_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Checks whether a quantile stream has been initialized.
		
		An Op that checks if quantile stream resource is initialized.
		
		Args:
		  quantile_stream_resource_handle: A `Tensor` of type `resource`.
		    resource; The reference to quantile stream resource handle.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function IsBoostedTreesQuantileStreamResourceInitialized(quantile_stream_resource_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns which elements of x are finite.
		
		@compatibility(numpy)
		Equivalent to np.isfinite
		@end_compatibility
		
		Example:
		
		```python
		x = tf.constant([5.0, 4.8, 6.8, np.inf, np.nan])
		tf.math.is_finite(x) ==> [True, True, True, False, False]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function IsFinite(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns which elements of x are Inf.
		
		@compatibility(numpy)
		Equivalent to np.isinf
		@end_compatibility
		
		Example:
		
		```python
		x = tf.constant([5.0, np.inf, 6.8, np.inf])
		tf.math.is_inf(x) ==> [False, True, False, True]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function IsInf(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns which elements of x are NaN.
		
		@compatibility(numpy)
		Equivalent to np.isnan
		@end_compatibility
		
		Example:
		
		```python
		x = tf.constant([5.0, np.nan, 6.8, np.nan, np.inf])
		tf.math.is_nan(x) ==> [False, True, False, True, False]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function IsNan(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Whether TPU Embedding is initialized in a distributed TPU system.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function IsTPUEmbeddingInitialized(?name:Dynamic):Dynamic;
	/**
		Checks whether a tensor has been initialized.
		
		Outputs boolean scalar indicating whether the tensor has been initialized.
		
		Args:
		  ref: A mutable `Tensor`.
		    Should be from a `Variable` node. May be uninitialized.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function IsVariableInitialized(ref:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Solves a batch of isotonic regression problems.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    A (batch_size, dim)-tensor holding a batch of inputs.
		  output_dtype: An optional `tf.DType` from: `tf.half, tf.bfloat16, tf.float32, tf.float64`. Defaults to `tf.float32`.
		    Dtype of output.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, segments).
		
		  output: A `Tensor` of type `output_dtype`.
		  segments: A `Tensor` of type `int32`.
	**/
	static public function IsotonicRegression(input:Dynamic, ?output_dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A container for an iterator resource.
		
		Args:
		  shared_name: A `string`.
		  container: A `string`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function Iterator(shared_name:Dynamic, container:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts the given string representing a handle to an iterator to a resource.
		
		Args:
		  string_handle: A `Tensor` of type `string`.
		    A string representation of the given handle.
		  output_types: An optional list of `tf.DTypes`. Defaults to `[]`.
		    If specified, defines the type of each tuple component in an
		    element produced by the resulting iterator.
		  output_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    If specified, defines the shape of each tuple component in an
		    element produced by the resulting iterator.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function IteratorFromStringHandle(string_handle:Dynamic, ?output_types:Dynamic, ?output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  string_handle: A `Tensor` of type `string`.
		  output_types: An optional list of `tf.DTypes`. Defaults to `[]`.
		  output_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function IteratorFromStringHandleV2(string_handle:Dynamic, ?output_types:Dynamic, ?output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the name of the device on which `resource` has been placed.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function IteratorGetDevice(resource:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gets the next output from the given iterator .
		
		Args:
		  iterator: A `Tensor` of type `resource`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `output_types`.
	**/
	static public function IteratorGetNext(iterator:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gets the next output from the given iterator as an Optional variant.
		
		Args:
		  iterator: A `Tensor` of type `resource`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function IteratorGetNextAsOptional(iterator:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gets the next output from the given iterator.
		
		This operation is a synchronous version IteratorGetNext. It should only be used
		in situations where the iterator does not block the calling thread, or where
		the calling thread is not a member of the thread pool used to execute parallel
		operations (e.g. in eager mode).
		
		Args:
		  iterator: A `Tensor` of type `resource`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `output_types`.
	**/
	static public function IteratorGetNextSync(iterator:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts the given `resource_handle` representing an iterator to a string.
		
		Args:
		  resource_handle: A `Tensor` of type `resource`.
		    A handle to an iterator resource.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function IteratorToStringHandle(resource_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  shared_name: A `string`.
		  container: A `string`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function IteratorV2(shared_name:Dynamic, container:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		L2 Loss.
		
		Computes half the L2 norm of a tensor without the `sqrt`:
		
		    output = sum(t ** 2) / 2
		
		Args:
		  t: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    Typically 2-D, but may have any dimensions.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `t`.
	**/
	static public function L2Loss(t:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that emits the key-value pairs in one or more LMDB files.
		
		The Lightning Memory-Mapped Database Manager, or LMDB, is an embedded binary
		key-value database. This dataset can read the contents of LMDB database files,
		the names of which generally have the `.mdb` suffix.
		
		Each output element consists of a key-value pair represented as a pair of
		scalar string `Tensor`s, where the first `Tensor` contains the key and the
		second `Tensor` contains the value.
		
		LMDB uses different file formats on big- and little-endian machines.
		`LMDBDataset` can only read files in the format of the host machine.
		
		Args:
		  filenames: A `Tensor` of type `string`.
		    A scalar or a vector containing the name(s) of the binary file(s) to be
		    read.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function LMDBDataset(filenames:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A Reader that outputs the records from a LMDB file.
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function LMDBReader(?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Local Response Normalization.
		
		The 4-D `input` tensor is treated as a 3-D array of 1-D vectors (along the last
		dimension), and each vector is normalized independently.  Within a given vector,
		each component is divided by the weighted, squared sum of inputs within
		`depth_radius`.  In detail,
		
		    sqr_sum[a, b, c, d] =
		        sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
		    output = input / (bias + alpha * sqr_sum) ** beta
		
		For details, see [Krizhevsky et al., ImageNet classification with deep
		convolutional neural networks (NIPS 2012)](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks).
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
		    4-D.
		  depth_radius: An optional `int`. Defaults to `5`.
		    0-D.  Half-width of the 1-D normalization window.
		  bias: An optional `float`. Defaults to `1`.
		    An offset (usually positive to avoid dividing by 0).
		  alpha: An optional `float`. Defaults to `1`.
		    A scale factor, usually positive.
		  beta: An optional `float`. Defaults to `0.5`. An exponent.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function LRN(input:Dynamic, ?depth_radius:Dynamic, ?bias:Dynamic, ?alpha:Dynamic, ?beta:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gradients for Local Response Normalization.
		
		Args:
		  input_grads: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
		    4-D with shape `[batch, height, width, channels]`.
		  input_image: A `Tensor`. Must have the same type as `input_grads`.
		    4-D with shape `[batch, height, width, channels]`.
		  output_image: A `Tensor`. Must have the same type as `input_grads`.
		    4-D with shape `[batch, height, width, channels]`.
		  depth_radius: An optional `int`. Defaults to `5`. A depth radius.
		  bias: An optional `float`. Defaults to `1`.
		    An offset (usually > 0 to avoid dividing by 0).
		  alpha: An optional `float`. Defaults to `1`.
		    A scale factor, usually positive.
		  beta: An optional `float`. Defaults to `0.5`. An exponent.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input_grads`.
	**/
	static public function LRNGrad(input_grads:Dynamic, input_image:Dynamic, output_image:Dynamic, ?depth_radius:Dynamic, ?bias:Dynamic, ?alpha:Dynamic, ?beta:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the LSTM cell forward propagation for 1 time step.
		
		This implementation uses 1 weight matrix and 1 bias vector, and there's an
		optional peephole connection.
		
		This kernel op implements the following mathematical equations:
		
		```python
		xh = [x, h_prev]
		[i, f, ci, o] = xh * w + b
		f = f + forget_bias
		
		if not use_peephole:
		  wci = wcf = wco = 0
		
		i = sigmoid(cs_prev * wci + i)
		f = sigmoid(cs_prev * wcf + f)
		ci = tanh(ci)
		
		cs = ci .* i + cs_prev .* f
		cs = clip(cs, cell_clip)
		
		o = sigmoid(cs * wco + o)
		co = tanh(cs)
		h = co .* o
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    The input to the LSTM cell, shape (batch_size, num_inputs).
		  cs_prev: A `Tensor`. Must have the same type as `x`.
		    Value of the cell state at previous time step.
		  h_prev: A `Tensor`. Must have the same type as `x`.
		    Output of the previous cell at previous time step.
		  w: A `Tensor`. Must have the same type as `x`. The weight matrix.
		  wci: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for input gate peephole connection.
		  wcf: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for forget gate peephole connection.
		  wco: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for output gate peephole connection.
		  b: A `Tensor`. Must have the same type as `x`. The bias vector.
		  forget_bias: An optional `float`. Defaults to `1`. The forget gate bias.
		  cell_clip: An optional `float`. Defaults to `3`.
		    Value to clip the 'cs' value to.
		  use_peephole: An optional `bool`. Defaults to `False`.
		    Whether to use peephole weights.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (i, cs, f, o, ci, co, h).
		
		  i: A `Tensor`. Has the same type as `x`.
		  cs: A `Tensor`. Has the same type as `x`.
		  f: A `Tensor`. Has the same type as `x`.
		  o: A `Tensor`. Has the same type as `x`.
		  ci: A `Tensor`. Has the same type as `x`.
		  co: A `Tensor`. Has the same type as `x`.
		  h: A `Tensor`. Has the same type as `x`.
	**/
	static public function LSTMBlockCell(x:Dynamic, cs_prev:Dynamic, h_prev:Dynamic, w:Dynamic, wci:Dynamic, wcf:Dynamic, wco:Dynamic, b:Dynamic, ?forget_bias:Dynamic, ?cell_clip:Dynamic, ?use_peephole:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the LSTM cell backward propagation for 1 timestep.
		
		This implementation is to be used in conjunction of LSTMBlockCell.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    The input to the LSTM cell, shape (batch_size, num_inputs).
		  cs_prev: A `Tensor`. Must have the same type as `x`.
		    The previous cell state.
		  h_prev: A `Tensor`. Must have the same type as `x`. The previous h state.
		  w: A `Tensor`. Must have the same type as `x`. The weight matrix.
		  wci: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for input gate peephole connection.
		  wcf: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for forget gate peephole connection.
		  wco: A `Tensor`. Must have the same type as `x`.
		    The weight matrix for output gate peephole connection.
		  b: A `Tensor`. Must have the same type as `x`. The bias vector.
		  i: A `Tensor`. Must have the same type as `x`. The input gate.
		  cs: A `Tensor`. Must have the same type as `x`.
		    The cell state before the tanh.
		  f: A `Tensor`. Must have the same type as `x`. The forget gate.
		  o: A `Tensor`. Must have the same type as `x`. The output gate.
		  ci: A `Tensor`. Must have the same type as `x`. The cell input.
		  co: A `Tensor`. Must have the same type as `x`. The cell after the tanh.
		  cs_grad: A `Tensor`. Must have the same type as `x`.
		    The current gradient of cs.
		  h_grad: A `Tensor`. Must have the same type as `x`.
		    The gradient of h vector.
		  use_peephole: A `bool`. Whether the cell uses peephole connections.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (cs_prev_grad, dicfo, wci_grad, wcf_grad, wco_grad).
		
		  cs_prev_grad: A `Tensor`. Has the same type as `x`.
		  dicfo: A `Tensor`. Has the same type as `x`.
		  wci_grad: A `Tensor`. Has the same type as `x`.
		  wcf_grad: A `Tensor`. Has the same type as `x`.
		  wco_grad: A `Tensor`. Has the same type as `x`.
	**/
	static public function LSTMBlockCellGrad(x:Dynamic, cs_prev:Dynamic, h_prev:Dynamic, w:Dynamic, wci:Dynamic, wcf:Dynamic, wco:Dynamic, b:Dynamic, i:Dynamic, cs:Dynamic, f:Dynamic, o:Dynamic, ci:Dynamic, co:Dynamic, cs_grad:Dynamic, h_grad:Dynamic, use_peephole:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Records the latency of producing `input_dataset` elements in a StatsAggregator.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  tag: A `Tensor` of type `string`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function LatencyStatsDataset(input_dataset:Dynamic, tag:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes rectified linear: `max(features, features * alpha)`.
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		  alpha: An optional `float`. Defaults to `0.2`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `features`.
	**/
	static public function LeakyRelu(features:Dynamic, ?alpha:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes rectified linear gradients for a LeakyRelu operation.
		
		Args:
		  gradients: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    The backpropagated gradients to the corresponding LeakyRelu operation.
		  features: A `Tensor`. Must have the same type as `gradients`.
		    The features passed as input to the corresponding LeakyRelu operation,
		    OR the outputs of that operation (both work equivalently).
		  alpha: An optional `float`. Defaults to `0.2`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `gradients`.
	**/
	static public function LeakyReluGrad(gradients:Dynamic, features:Dynamic, ?alpha:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates labels for candidate sampling with a learned unigram distribution.
		
		See explanations of candidate sampling and the data formats at
		go/candidate-sampling.
		
		For each batch, this op picks a single set of sampled candidate labels.
		
		The advantages of sampling candidates per-batch are simplicity and the
		possibility of efficient dense matrix multiplication. The disadvantage is that
		the sampled candidates must be chosen independently of the context and of the
		true labels.
		
		Args:
		  true_classes: A `Tensor` of type `int64`.
		    A batch_size * num_true matrix, in which each row contains the
		    IDs of the num_true target_classes in the corresponding original label.
		  num_true: An `int` that is `>= 1`. Number of true labels per context.
		  num_sampled: An `int` that is `>= 1`.
		    Number of candidates to randomly sample.
		  unique: A `bool`.
		    If unique is true, we sample with rejection, so that all sampled
		    candidates in a batch are unique. This requires some approximation to
		    estimate the post-rejection sampling probabilities.
		  range_max: An `int` that is `>= 1`.
		    The sampler will sample integers from the interval [0, range_max).
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    An second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sampled_candidates, true_expected_count, sampled_expected_count).
		
		  sampled_candidates: A `Tensor` of type `int64`.
		  true_expected_count: A `Tensor` of type `float32`.
		  sampled_expected_count: A `Tensor` of type `float32`.
	**/
	static public function LearnedUnigramCandidateSampler(true_classes:Dynamic, num_true:Dynamic, num_sampled:Dynamic, unique:Dynamic, range_max:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Elementwise computes the bitwise left-shift of `x` and `y`.
		
		If `y` is negative, or greater than or equal to the width of `x` in bits the
		result is implementation defined.
		
		Example:
		
		```python
		import tensorflow as tf
		from tensorflow.python.ops import bitwise_ops
		import numpy as np
		dtype_list = [tf.int8, tf.int16, tf.int32, tf.int64]
		
		for dtype in dtype_list:
		  lhs = tf.constant([-1, -5, -3, -14], dtype=dtype)
		  rhs = tf.constant([5, 0, 7, 11], dtype=dtype)
		
		  left_shift_result = bitwise_ops.left_shift(lhs, rhs)
		
		  print(left_shift_result)
		
		# This will print:
		# tf.Tensor([ -32   -5 -128    0], shape=(4,), dtype=int8)
		# tf.Tensor([   -32     -5   -384 -28672], shape=(4,), dtype=int16)
		# tf.Tensor([   -32     -5   -384 -28672], shape=(4,), dtype=int32)
		# tf.Tensor([   -32     -5   -384 -28672], shape=(4,), dtype=int64)
		
		lhs = np.array([-2, 64, 101, 32], dtype=np.int8)
		rhs = np.array([-1, -5, -3, -14], dtype=np.int8)
		bitwise_ops.left_shift(lhs, rhs)
		# <tf.Tensor: shape=(4,), dtype=int8, numpy=array([ -2,  64, 101,  32], dtype=int8)>
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function LeftShift(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		The resulting dataset is similar to the `InterleaveDataset`, with the exception
		that if retrieving the next value from a dataset would cause the requester to
		block, it will skip that input dataset. This dataset is especially useful
		when loading data from a variable-latency datastores (e.g. HDFS, GCS), as it
		allows the training step to proceed so long as some data is available.
		
		!! WARNING !! This dataset is not deterministic!
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  other_arguments: A list of `Tensor` objects.
		  cycle_length: A `Tensor` of type `int64`.
		  block_length: A `Tensor` of type `int64`.
		  buffer_output_elements: A `Tensor` of type `int64`.
		  prefetch_input_elements: A `Tensor` of type `int64`.
		  f: A function decorated with @Defun.
		    A function mapping elements of `input_dataset`, concatenated with
		    `other_arguments`, to a Dataset variant that contains elements matching
		    `output_types` and `output_shapes`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  deterministic: An optional `string`. Defaults to `"default"`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function LegacyParallelInterleaveDatasetV2(input_dataset:Dynamic, other_arguments:Dynamic, cycle_length:Dynamic, block_length:Dynamic, buffer_output_elements:Dynamic, prefetch_input_elements:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?deterministic:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of (x < y) element-wise.
		
		*NOTE*: `math.less` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Example:
		
		```python
		x = tf.constant([5, 4, 6])
		y = tf.constant([5])
		tf.math.less(x, y) ==> [False, True, False]
		
		x = tf.constant([5, 4, 6])
		y = tf.constant([5, 6, 7])
		tf.math.less(x, y) ==> [False, True, True]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function Less(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of (x <= y) element-wise.
		
		*NOTE*: `math.less_equal` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Example:
		
		```python
		x = tf.constant([5, 4, 6])
		y = tf.constant([5])
		tf.math.less_equal(x, y) ==> [True, True, False]
		
		x = tf.constant([5, 4, 6])
		y = tf.constant([5, 6, 6])
		tf.math.less_equal(x, y) ==> [True, True, True]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function LessEqual(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the log of the absolute value of `Gamma(x)` element-wise.
		
		  For positive numbers, this function computes log((input - 1)!) for every element in the tensor.
		  `lgamma(5) = log((5-1)!) = log(4!) = log(24) = 3.1780539`
		
		Example:
		
		```python
		x = tf.constant([0, 0.5, 1, 4.5, -4, -5.6])
		tf.math.lgamma(x) ==> [inf, 0.5723649, 0., 2.4537368, inf, -4.6477685]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Lgamma(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates values in an interval.
		
		A sequence of `num` evenly-spaced values are generated beginning at `start`.
		If `num > 1`, the values in the sequence increase by `stop - start / num - 1`,
		so that the last one is exactly `stop`.
		
		For example:
		
		```
		tf.linspace(10.0, 12.0, 3, name="linspace") => [ 10.0  11.0  12.0]
		```
		
		Args:
		  start: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		    0-D tensor. First entry in the range.
		  stop: A `Tensor`. Must have the same type as `start`.
		    0-D tensor. Last entry in the range.
		  num: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    0-D tensor. Number of values to generate.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `start`.
	**/
	static public function LinSpace(start:Dynamic, stop:Dynamic, num:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the difference between two lists of numbers or strings.
		
		Given a list `x` and a list `y`, this operation returns a list `out` that
		represents all values that are in `x` but not in `y`. The returned list `out`
		is sorted in the same order that the numbers appear in `x` (duplicates are
		preserved). This operation also returns a list `idx` that represents the
		position of each `out` element in `x`. In other words:
		
		`out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]`
		
		For example, given this input:
		
		```
		x = [1, 2, 3, 4, 5, 6]
		y = [1, 3, 5]
		```
		
		This operation would return:
		
		```
		out ==> [2, 4, 6]
		idx ==> [1, 3, 5]
		```
		
		Args:
		  x: A `Tensor`. 1-D. Values to keep.
		  y: A `Tensor`. Must have the same type as `x`. 1-D. Values to remove.
		  out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (out, idx).
		
		  out: A `Tensor`. Has the same type as `x`.
		  idx: A `Tensor` of type `out_idx`.
	**/
	static public function ListDiff(x:Dynamic, y:Dynamic, ?out_idx:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Loads a 2-D (matrix) `Tensor` with name `old_tensor_name` from the checkpoint
		
		at `ckpt_path` and potentially reorders its rows and columns using the
		specified remappings.
		
		Most users should use one of the wrapper initializers (such as
		`tf.contrib.framework.load_and_remap_matrix_initializer`) instead of this
		function directly.
		
		The remappings are 1-D tensors with the following properties:
		
		* `row_remapping` must have exactly `num_rows` entries. Row `i` of the output
		  matrix will be initialized from the row corresponding to index
		  `row_remapping[i]` in the old `Tensor` from the checkpoint.
		* `col_remapping` must have either 0 entries (indicating that no column
		  reordering is needed) or `num_cols` entries. If specified, column `j` of the
		  output matrix will be initialized from the column corresponding to index
		  `col_remapping[j]` in the old `Tensor` from the checkpoint.
		* A value of -1 in either of the remappings signifies a "missing" entry. In that
		  case, values from the `initializing_values` tensor will be used to fill that
		  missing row or column. If `row_remapping` has `r` missing entries and
		  `col_remapping` has `c` missing entries, then the following condition must be
		  true:
		
		`(r * num_cols) + (c * num_rows) - (r * c) == len(initializing_values)`
		
		The remapping tensors can be generated using the GenerateVocabRemapping op.
		
		As an example, with row_remapping = [1, 0, -1], col_remapping = [0, 2, -1],
		initializing_values = [0.5, -0.5, 0.25, -0.25, 42], and w(i, j) representing
		the value from row i, column j of the old tensor in the checkpoint, the output
		matrix will look like the following:
		
		[[w(1, 0),  w(1, 2),  0.5],
		 [w(0, 0),  w(0, 2), -0.5],
		 [0.25,    -0.25,      42]]
		
		Args:
		  ckpt_path: A `Tensor` of type `string`.
		    Path to the TensorFlow checkpoint (version 2, `TensorBundle`) from
		    which the old matrix `Tensor` will be loaded.
		  old_tensor_name: A `Tensor` of type `string`.
		    Name of the 2-D `Tensor` to load from checkpoint.
		  row_remapping: A `Tensor` of type `int64`.
		    An int `Tensor` of row remappings (generally created by
		    `generate_vocab_remapping`).  Even if no row remapping is needed, this must
		    still be an index-valued Tensor (e.g. [0, 1, 2, ...]), or a shifted
		    index-valued `Tensor` (e.g. [8, 9, 10, ...], for partitioned `Variables`).
		  col_remapping: A `Tensor` of type `int64`.
		    An int `Tensor` of column remappings (generally created by
		    `generate_vocab_remapping`).  May be a size-0 `Tensor` if only row remapping
		    is to be done (e.g. column ordering is the same).
		  initializing_values: A `Tensor` of type `float32`.
		    A float `Tensor` containing  values to fill in for cells
		    in the output matrix that are not loaded from the checkpoint. Length must be
		    exactly the same as the number of missing / new cells.
		  num_rows: An `int` that is `>= 0`.
		    Number of rows (length of the 1st dimension) in the output matrix.
		  num_cols: An `int` that is `>= 1`.
		    Number of columns (length of the 2nd dimension) in the output matrix.
		  max_rows_in_memory: An optional `int`. Defaults to `-1`.
		    The maximum number of rows to load from the checkpoint at
		    once. If less than or equal to 0, the entire matrix will be loaded into
		    memory. Setting this arg trades increased disk reads for lower memory usage.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function LoadAndRemapMatrix(ckpt_path:Dynamic, old_tensor_name:Dynamic, row_remapping:Dynamic, col_remapping:Dynamic, initializing_values:Dynamic, num_rows:Dynamic, num_cols:Dynamic, ?max_rows_in_memory:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  path: A `Tensor` of type `string`.
		  reader_func_other_args: A list of `Tensor` objects.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  reader_func: A function decorated with @Defun.
		  compression: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function LoadDataset(path:Dynamic, reader_func_other_args:Dynamic, output_types:Dynamic, output_shapes:Dynamic, reader_func:Dynamic, ?compression:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load ADAM embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the ADAM optimization algorithm.
		  momenta: A `Tensor` of type `float32`.
		    Value of momenta used in the ADAM optimization algorithm.
		  velocities: A `Tensor` of type `float32`.
		    Value of velocities used in the ADAM optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingADAMParameters(parameters:Dynamic, momenta:Dynamic, velocities:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load Adadelta embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the Adadelta optimization algorithm.
		  accumulators: A `Tensor` of type `float32`.
		    Value of accumulators used in the Adadelta optimization algorithm.
		  updates: A `Tensor` of type `float32`.
		    Value of updates used in the Adadelta optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingAdadeltaParameters(parameters:Dynamic, accumulators:Dynamic, updates:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load Adagrad Momentum embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the Adagrad Momentum optimization algorithm.
		  accumulators: A `Tensor` of type `float32`.
		    Value of accumulators used in the Adagrad Momentum optimization algorithm.
		  momenta: A `Tensor` of type `float32`.
		    Value of momenta used in the Adagrad Momentum optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingAdagradMomentumParameters(parameters:Dynamic, accumulators:Dynamic, momenta:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load Adagrad embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the Adagrad optimization algorithm.
		  accumulators: A `Tensor` of type `float32`.
		    Value of accumulators used in the Adagrad optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingAdagradParameters(parameters:Dynamic, accumulators:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load centered RMSProp embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the centered RMSProp optimization algorithm.
		  ms: A `Tensor` of type `float32`.
		    Value of ms used in the centered RMSProp optimization algorithm.
		  mom: A `Tensor` of type `float32`.
		    Value of mom used in the centered RMSProp optimization algorithm.
		  mg: A `Tensor` of type `float32`.
		    Value of mg used in the centered RMSProp optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingCenteredRMSPropParameters(parameters:Dynamic, ms:Dynamic, mom:Dynamic, mg:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load FTRL embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the FTRL optimization algorithm.
		  accumulators: A `Tensor` of type `float32`.
		    Value of accumulators used in the FTRL optimization algorithm.
		  linears: A `Tensor` of type `float32`.
		    Value of linears used in the FTRL optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingFTRLParameters(parameters:Dynamic, accumulators:Dynamic, linears:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load frequency estimator embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the frequency estimator optimization algorithm.
		  last_hit_step: A `Tensor` of type `float32`.
		    Value of last_hit_step used in the frequency estimator optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingFrequencyEstimatorParameters(parameters:Dynamic, last_hit_step:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load MDL Adagrad Light embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the MDL Adagrad Light optimization algorithm.
		  accumulators: A `Tensor` of type `float32`.
		    Value of accumulators used in the MDL Adagrad Light optimization algorithm.
		  weights: A `Tensor` of type `float32`.
		    Value of weights used in the MDL Adagrad Light optimization algorithm.
		  benefits: A `Tensor` of type `float32`.
		    Value of benefits used in the MDL Adagrad Light optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingMDLAdagradLightParameters(parameters:Dynamic, accumulators:Dynamic, weights:Dynamic, benefits:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load Momentum embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the Momentum optimization algorithm.
		  momenta: A `Tensor` of type `float32`.
		    Value of momenta used in the Momentum optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingMomentumParameters(parameters:Dynamic, momenta:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load proximal Adagrad embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the proximal Adagrad optimization algorithm.
		  accumulators: A `Tensor` of type `float32`.
		    Value of accumulators used in the proximal Adagrad optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingProximalAdagradParameters(parameters:Dynamic, accumulators:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		  v: A `Tensor` of type `float32`.
		  m: A `Tensor` of type `float32`.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingProximalYogiParameters(parameters:Dynamic, v:Dynamic, m:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load RMSProp embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the RMSProp optimization algorithm.
		  ms: A `Tensor` of type `float32`.
		    Value of ms used in the RMSProp optimization algorithm.
		  mom: A `Tensor` of type `float32`.
		    Value of mom used in the RMSProp optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingRMSPropParameters(parameters:Dynamic, ms:Dynamic, mom:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Load SGD embedding parameters.
		
		An op that loads optimization parameters into HBM for embedding. Must be
		preceded by a ConfigureTPUEmbeddingHost op that sets up the correct
		embedding table configuration. For example, this op is used to install
		parameters that are loaded from a checkpoint before a training loop is
		executed.
		
		Args:
		  parameters: A `Tensor` of type `float32`.
		    Value of parameters used in the stochastic gradient descent optimization algorithm.
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LoadTPUEmbeddingStochasticGradientDescentParameters(parameters:Dynamic, num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes natural logarithm of x element-wise.
		
		I.e., \\(y = \log_e x\\).
		
		Example:
		>>> x = tf.constant([0, 0.5, 1, 5])
		>>> tf.math.log(x)
		<tf.Tensor: shape=(4,), dtype=float32, numpy=array([      -inf, -0.6931472,  0.       ,  1.609438 ], dtype=float32)>
		
		See: https://en.wikipedia.org/wiki/Logarithm
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Log(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes natural logarithm of (1 + x) element-wise.
		
		I.e., \\(y = \log_e (1 + x)\\).
		
		Example:
		>>> x = tf.constant([0, 0.5, 1, 5])
		>>> tf.math.log1p(x)
		<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.       , 0.4054651, 0.6931472, 1.7917595], dtype=float32)>
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Log1p(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the sign and the log of the absolute value of the determinant of
		
		one or more square matrices.
		
		The input is a tensor of shape `[N, M, M]` whose inner-most 2 dimensions
		form square matrices. The outputs are two tensors containing the signs and
		absolute values of the log determinants for all N input submatrices
		`[..., :, :]` such that `determinant = sign*exp(log_abs_determinant)`.
		The `log_abs_determinant` is computed as `det(P)*sum(log(diag(LU)))` where `LU`
		is the `LU` decomposition of the input and `P` is the corresponding
		permutation matrix.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.
		    Shape is `[N, M, M]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sign, log_abs_determinant).
		
		  sign: A `Tensor`. Has the same type as `input`.
		  log_abs_determinant: A `Tensor`. Has the same type as `input`.
	**/
	static public function LogMatrixDeterminant(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes log softmax activations.
		
		For each batch `i` and class `j` we have
		
		    logsoftmax[i, j] = logits[i, j] - log(sum(exp(logits[i])))
		
		Args:
		  logits: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    2-D with shape `[batch_size, num_classes]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `logits`.
	**/
	static public function LogSoftmax(logits:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates labels for candidate sampling with a log-uniform distribution.
		
		See explanations of candidate sampling and the data formats at
		go/candidate-sampling.
		
		For each batch, this op picks a single set of sampled candidate labels.
		
		The advantages of sampling candidates per-batch are simplicity and the
		possibility of efficient dense matrix multiplication. The disadvantage is that
		the sampled candidates must be chosen independently of the context and of the
		true labels.
		
		Args:
		  true_classes: A `Tensor` of type `int64`.
		    A batch_size * num_true matrix, in which each row contains the
		    IDs of the num_true target_classes in the corresponding original label.
		  num_true: An `int` that is `>= 1`. Number of true labels per context.
		  num_sampled: An `int` that is `>= 1`.
		    Number of candidates to randomly sample.
		  unique: A `bool`.
		    If unique is true, we sample with rejection, so that all sampled
		    candidates in a batch are unique. This requires some approximation to
		    estimate the post-rejection sampling probabilities.
		  range_max: An `int` that is `>= 1`.
		    The sampler will sample integers from the interval [0, range_max).
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    An second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sampled_candidates, true_expected_count, sampled_expected_count).
		
		  sampled_candidates: A `Tensor` of type `int64`.
		  true_expected_count: A `Tensor` of type `float32`.
		  sampled_expected_count: A `Tensor` of type `float32`.
	**/
	static public function LogUniformCandidateSampler(true_classes:Dynamic, num_true:Dynamic, num_sampled:Dynamic, unique:Dynamic, range_max:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of x AND y element-wise.
		
		Logical AND function.
		
		Requires that `x` and `y` have the same shape or have
		[broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		shapes. For example, `x` and `y` can be:
		
		  - Two single elements of type `bool`.
		  - One `tf.Tensor` of type `bool` and one single `bool`, where the result will
		    be calculated by applying logical AND with the single element to each
		    element in the larger Tensor.
		  - Two `tf.Tensor` objects of type `bool` of the same shape. In this case,
		    the result will be the element-wise logical AND of the two input tensors.
		
		You can also use the `&` operator instead.
		
		Usage:
		
		  >>> a = tf.constant([True])
		  >>> b = tf.constant([False])
		  >>> tf.math.logical_and(a, b)
		  <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>
		  >>> a & b
		  <tf.Tensor: shape=(1,), dtype=bool, numpy=array([False])>
		
		  >>> c = tf.constant([True])
		  >>> x = tf.constant([False, True, True, False])
		  >>> tf.math.logical_and(c, x)
		  <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>
		  >>> c & x
		  <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False,  True,  True, False])>
		
		  >>> y = tf.constant([False, False, True, True])
		  >>> z = tf.constant([False, True, False, True])
		  >>> tf.math.logical_and(y, z)
		  <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])>
		  >>> y & z
		  <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, False, False, True])>
		
		  This op also supports broadcasting
		
		  >>> tf.logical_and([[True, False]], [[True], [False]])
		  <tf.Tensor: shape=(2, 2), dtype=bool, numpy=
		    array([[ True, False],
		           [False, False]])>
		
		The reduction version of this elementwise operation is `tf.math.reduce_all`.
		
		Args:
		    x: A `tf.Tensor` of type bool.
		    y: A `tf.Tensor` of type bool.
		    name: A name for the operation (optional).
		
		Returns:
		  A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.
		
		Args:
		  x: A `Tensor` of type `bool`.
		  y: A `Tensor` of type `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function LogicalAnd(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of `NOT x` element-wise.
		
		Example:
		
		>>> tf.math.logical_not(tf.constant([True, False]))
		<tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>
		
		Args:
		  x: A `Tensor` of type `bool`. A `Tensor` of type `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function LogicalNot(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of x OR y element-wise.
		
		Logical OR function.
		
		Requires that `x` and `y` have the same shape or have
		[broadcast-compatible](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		shapes. For example, `x` and `y` can be:
		
		- Two single elements of type `bool`.
		- One `tf.Tensor` of type `bool` and one single `bool`, where the result will
		  be calculated by applying logical OR with the single element to each
		  element in the larger Tensor.
		- Two `tf.Tensor` objects of type `bool` of the same shape. In this case,
		  the result will be the element-wise logical OR of the two input tensors.
		
		You can also use the `|` operator instead.
		
		Usage:
		
		  >>> a = tf.constant([True])
		  >>> b = tf.constant([False])
		  >>> tf.math.logical_or(a, b)
		  <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>
		  >>> a | b
		  <tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>
		
		  >>> c = tf.constant([False])
		  >>> x = tf.constant([False, True, True, False])
		  >>> tf.math.logical_or(c, x)
		  <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>
		  >>> c | x
		  <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True,  True, False])>
		
		  >>> y = tf.constant([False, False, True, True])
		  >>> z = tf.constant([False, True, False, True])
		  >>> tf.math.logical_or(y, z)
		  <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>
		  >>> y | z
		  <tf.Tensor: shape=(4,), dtype=bool, numpy=array([False, True, True, True])>
		
		  This op also supports broadcasting
		
		  >>> tf.logical_or([[True, False]], [[True], [False]])
		  <tf.Tensor: shape=(2, 2), dtype=bool, numpy=
		  array([[ True,  True],
		       [ True, False]])>
		
		The reduction version of this elementwise operation is `tf.math.reduce_any`.
		
		Args:
		    x: A `tf.Tensor` of type bool.
		    y: A `tf.Tensor` of type bool.
		    name: A name for the operation (optional).
		
		Returns:
		  A `tf.Tensor` of type bool with the shape that `x` and `y` broadcast to.
		
		Args:
		  x: A `Tensor` of type `bool`.
		  y: A `Tensor` of type `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function LogicalOr(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs all keys and values in the table.
		
		Args:
		  table_handle: A `Tensor` of type mutable `string`. Handle to the table.
		  Tkeys: A `tf.DType`.
		  Tvalues: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (keys, values).
		
		  keys: A `Tensor` of type `Tkeys`.
		  values: A `Tensor` of type `Tvalues`.
	**/
	static public function LookupTableExport(table_handle:Dynamic, Tkeys:Dynamic, Tvalues:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs all keys and values in the table.
		
		Args:
		  table_handle: A `Tensor` of type `resource`. Handle to the table.
		  Tkeys: A `tf.DType`.
		  Tvalues: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (keys, values).
		
		  keys: A `Tensor` of type `Tkeys`.
		  values: A `Tensor` of type `Tvalues`.
	**/
	static public function LookupTableExportV2(table_handle:Dynamic, Tkeys:Dynamic, Tvalues:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Looks up keys in a table, outputs the corresponding values.
		
		The tensor `keys` must of the same type as the keys of the table.
		The output `values` is of the type of the table values.
		
		The scalar `default_value` is the value output for keys not present in the
		table. It must also be of the same type as the table values.
		
		Args:
		  table_handle: A `Tensor` of type mutable `string`. Handle to the table.
		  keys: A `Tensor`. Any shape.  Keys to look up.
		  default_value: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `default_value`.
	**/
	static public function LookupTableFind(table_handle:Dynamic, keys:Dynamic, default_value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Looks up keys in a table, outputs the corresponding values.
		
		The tensor `keys` must of the same type as the keys of the table.
		The output `values` is of the type of the table values.
		
		The scalar `default_value` is the value output for keys not present in the
		table. It must also be of the same type as the table values.
		
		Args:
		  table_handle: A `Tensor` of type `resource`. Handle to the table.
		  keys: A `Tensor`. Any shape.  Keys to look up.
		  default_value: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `default_value`.
	**/
	static public function LookupTableFindV2(table_handle:Dynamic, keys:Dynamic, default_value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Replaces the contents of the table with the specified keys and values.
		
		The tensor `keys` must be of the same type as the keys of the table.
		The tensor `values` must be of the type of the table values.
		
		Args:
		  table_handle: A `Tensor` of type mutable `string`. Handle to the table.
		  keys: A `Tensor`. Any shape.  Keys to look up.
		  values: A `Tensor`. Values to associate with keys.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LookupTableImport(table_handle:Dynamic, keys:Dynamic, values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Replaces the contents of the table with the specified keys and values.
		
		The tensor `keys` must be of the same type as the keys of the table.
		The tensor `values` must be of the type of the table values.
		
		Args:
		  table_handle: A `Tensor` of type `resource`. Handle to the table.
		  keys: A `Tensor`. Any shape.  Keys to look up.
		  values: A `Tensor`. Values to associate with keys.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LookupTableImportV2(table_handle:Dynamic, keys:Dynamic, values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Updates the table to associates keys with values.
		
		The tensor `keys` must be of the same type as the keys of the table.
		The tensor `values` must be of the type of the table values.
		
		Args:
		  table_handle: A `Tensor` of type mutable `string`. Handle to the table.
		  keys: A `Tensor`. Any shape.  Keys to look up.
		  values: A `Tensor`. Values to associate with keys.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LookupTableInsert(table_handle:Dynamic, keys:Dynamic, values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Updates the table to associates keys with values.
		
		The tensor `keys` must be of the same type as the keys of the table.
		The tensor `values` must be of the type of the table values.
		
		Args:
		  table_handle: A `Tensor` of type `resource`. Handle to the table.
		  keys: A `Tensor`. Any shape.  Keys to look up.
		  values: A `Tensor`. Values to associate with keys.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LookupTableInsertV2(table_handle:Dynamic, keys:Dynamic, values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Removes keys and its associated values from a table.
		
		The tensor `keys` must of the same type as the keys of the table. Keys not
		already in the table are silently ignored.
		
		Args:
		  table_handle: A `Tensor` of type `resource`. Handle to the table.
		  keys: A `Tensor`. Any shape.  Keys of the elements to remove.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function LookupTableRemoveV2(table_handle:Dynamic, keys:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the number of elements in the given table.
		
		Args:
		  table_handle: A `Tensor` of type mutable `string`. Handle to the table.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function LookupTableSize(table_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the number of elements in the given table.
		
		Args:
		  table_handle: A `Tensor` of type `resource`. Handle to the table.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function LookupTableSizeV2(table_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Forwards the input to the output.
		
		This operator represents the loop termination condition used by the
		"pivot" switches of a loop.
		
		Args:
		  input: A `Tensor` of type `bool`.
		    A boolean scalar, representing the branch predicate of the Switch op.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function LoopCond(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies lower_bound(sorted_search_values, values) along each row.
		
		Each set of rows with the same index in (sorted_inputs, values) is treated
		independently.  The resulting row is the equivalent of calling
		`np.searchsorted(sorted_inputs, values, side='left')`.
		
		The result is not a global index to the entire
		`Tensor`, but rather just the index in the last dimension.
		
		A 2-D example:
		  sorted_sequence = [[0, 3, 9, 9, 10],
		                     [1, 2, 3, 4, 5]]
		  values = [[2, 4, 9],
		            [0, 2, 6]]
		
		  result = LowerBound(sorted_sequence, values)
		
		  result == [[1, 2, 2],
		             [0, 1, 5]]
		
		Args:
		  sorted_inputs: A `Tensor`. 2-D Tensor where each row is ordered.
		  values: A `Tensor`. Must have the same type as `sorted_inputs`.
		    2-D Tensor with the same numbers of rows as `sorted_search_values`. Contains
		    the values that will be searched for in `sorted_search_values`.
		  out_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `out_type`.
	**/
	static public function LowerBound(sorted_inputs:Dynamic, values:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the LU decomposition of one or more square matrices.
		
		The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
		form square matrices.
		
		The input has to be invertible.
		
		The output consists of two tensors LU and P containing the LU decomposition
		of all input submatrices `[..., :, :]`. LU encodes the lower triangular and
		upper triangular factors.
		
		For each input submatrix of shape `[M, M]`, L is a lower triangular matrix of
		shape `[M, M]` with unit diagonal whose entries correspond to the strictly lower
		triangular part of LU. U is a upper triangular matrix of shape `[M, M]` whose
		entries correspond to the upper triangular part, including the diagonal, of LU.
		
		P represents a permutation matrix encoded as a list of indices each between `0`
		and `M-1`, inclusive. If P_mat denotes the permutation matrix corresponding to
		P, then the L, U and P satisfies P_mat * input = L * U.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		    A tensor of shape `[..., M, M]` whose inner-most 2 dimensions form matrices of
		    size `[M, M]`.
		  output_idx_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (lu, p).
		
		  lu: A `Tensor`. Has the same type as `input`.
		  p: A `Tensor` of type `output_idx_type`.
	**/
	static public function Lu(input:Dynamic, ?output_idx_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Makes a new iterator from the given `dataset` and stores it in `iterator`.
		
		This operation may be executed multiple times. Each execution will reset the
		iterator in `iterator` to the first element of `dataset`.
		
		Args:
		  dataset: A `Tensor` of type `variant`.
		  iterator: A `Tensor` of type `resource`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function MakeIterator(dataset:Dynamic, iterator:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that fuses mapping with batching.
		
		Creates a dataset that applies `f` to the outputs of `input_dataset` and then
		batches `batch_size` of them.
		
		Unlike a "MapDataset", which applies `f` sequentially, this dataset invokes up
		to `batch_size * num_parallel_batches` copies of `f` in parallel.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when building a closure
		    for `f`.
		  batch_size: A `Tensor` of type `int64`.
		    A scalar representing the number of elements to accumulate in a
		    batch. It determines the number of concurrent invocations of `f` that process
		    elements from `input_dataset` in parallel.
		  num_parallel_calls: A `Tensor` of type `int64`.
		    A scalar representing the maximum number of parallel invocations of the `map_fn`
		    function. Applying the `map_fn` on consecutive input elements in parallel has
		    the potential to improve input pipeline throughput.
		  drop_remainder: A `Tensor` of type `bool`.
		    A scalar representing whether the last batch should be dropped in case its size
		    is smaller than desired.
		  f: A function decorated with @Defun.
		    A function to apply to the outputs of `input_dataset`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  preserve_cardinality: An optional `bool`. Defaults to `False`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function MapAndBatchDataset(input_dataset:Dynamic, other_arguments:Dynamic, batch_size:Dynamic, num_parallel_calls:Dynamic, drop_remainder:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?preserve_cardinality:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op removes all elements in the underlying container.
		
		Args:
		  dtypes: A list of `tf.DTypes`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function MapClear(dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  other_arguments: A list of `Tensor` objects.
		  f: A function decorated with @Defun.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  use_inter_op_parallelism: An optional `bool`. Defaults to `True`.
		  preserve_cardinality: An optional `bool`. Defaults to `False`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function MapDataset(input_dataset:Dynamic, other_arguments:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?use_inter_op_parallelism:Dynamic, ?preserve_cardinality:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Maps a function on the list of tensors unpacked from arguments on dimension 0.
		The function given by `f` is assumed to be stateless, and is executed
		concurrently on all the slices; up to batch_size (i.e. the size of the 0th
		dimension of each argument) functions will be scheduled at once.
		
		The `max_intra_op_parallelism` attr, which defaults to 1, can be used to
		limit the intra op parallelism. To limit inter-op parallelism, a user can
		set a private threadpool on the dataset using `tf.data.Options`'s
		`ThreadingOptions`.
		
		Note that this op is not exposed to users directly, but is invoked in tf.data
		rewrites.
		
		Args:
		  arguments: A list of `Tensor` objects.
		        A list of tensors whose types are `Targuments`, corresponding to the inputs
		        the function should be mapped over.
		  captured_inputs: A list of `Tensor` objects.
		        A list of tensors whose types are `Tcaptured`, corresponding to the captured
		        inputs of the defun.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		    A list of types.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		    A list of shapes.
		  f: A function decorated with @Defun.
		  max_intra_op_parallelism: An optional `int`. Defaults to `1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `output_types`.
	**/
	static public function MapDefun(arguments:Dynamic, captured_inputs:Dynamic, output_types:Dynamic, output_shapes:Dynamic, f:Dynamic, ?max_intra_op_parallelism:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op returns the number of incomplete elements in the underlying container.
		
		Args:
		  dtypes: A list of `tf.DTypes`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function MapIncompleteSize(dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op peeks at the values at the specified key.  If the
		
		underlying container does not contain this key
		this op will block until it does.
		
		Args:
		  key: A `Tensor` of type `int64`.
		  indices: A `Tensor` of type `int32`.
		  dtypes: A list of `tf.DTypes` that has length `>= 1`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `dtypes`.
	**/
	static public function MapPeek(key:Dynamic, indices:Dynamic, dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op returns the number of elements in the underlying container.
		
		Args:
		  dtypes: A list of `tf.DTypes`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function MapSize(dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Stage (key, values) in the underlying container which behaves like a hashtable.
		
		Args:
		  key: A `Tensor` of type `int64`. int64
		  indices: A `Tensor` of type `int32`.
		  values: A list of `Tensor` objects. a list of tensors
		    dtypes A list of data types that inserted values should adhere to.
		  dtypes: A list of `tf.DTypes`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		    Maximum number of elements in the Staging Area. If > 0, inserts
		    on the container will block when the capacity is reached.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this queue is placed in the given container. Otherwise,
		    a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    It is necessary to match this name to the matching Unstage Op.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function MapStage(key:Dynamic, indices:Dynamic, values:Dynamic, dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op removes and returns the values associated with the key
		
		from the underlying container.   If the underlying container
		does not contain this key, the op will block until it does.
		
		Args:
		  key: A `Tensor` of type `int64`.
		  indices: A `Tensor` of type `int32`.
		  dtypes: A list of `tf.DTypes` that has length `>= 1`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `dtypes`.
	**/
	static public function MapUnstage(key:Dynamic, indices:Dynamic, dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op removes and returns a random (key, value)
		
		from the underlying container.   If the underlying container
		does not contain elements, the op will block until it does.
		
		Args:
		  indices: A `Tensor` of type `int32`.
		  dtypes: A list of `tf.DTypes` that has length `>= 1`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (key, values).
		
		  key: A `Tensor` of type `int64`.
		  values: A list of `Tensor` objects of type `dtypes`.
	**/
	static public function MapUnstageNoKey(indices:Dynamic, dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Multiply the matrix "a" by the matrix "b".
		
		The inputs must be two-dimensional matrices and the inner dimension of
		"a" (after being transposed if transpose_a is true) must match the
		outer dimension of "b" (after being transposed if transposed_b is
		true).
		
		*Note*: The default kernel implementation for MatMul on GPUs uses
		cublas.
		
		Args:
		  a: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.
		  b: A `Tensor`. Must have the same type as `a`.
		  transpose_a: An optional `bool`. Defaults to `False`.
		    If true, "a" is transposed before multiplication.
		  transpose_b: An optional `bool`. Defaults to `False`.
		    If true, "b" is transposed before multiplication.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `a`.
	**/
	static public function MatMul(a:Dynamic, b:Dynamic, ?transpose_a:Dynamic, ?transpose_b:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the set of files matching one or more glob patterns.
		
		Note that this routine only supports wildcard characters in the
		basename portion of the pattern, not in the directory portion.
		Note also that the order of filenames returned is deterministic.
		
		Args:
		  pattern: A `Tensor` of type `string`.
		    Shell wildcard pattern(s). Scalar or vector of type string.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function MatchingFiles(pattern:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  patterns: A `Tensor` of type `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function MatchingFilesDataset(patterns:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Copy a tensor setting everything outside a central band in each innermost matrix to zero.
		
		The `band` part is computed as follows:
		Assume `input` has `k` dimensions `[I, J, K, ..., M, N]`, then the output is a
		tensor with the same shape where
		
		`band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.
		
		The indicator function
		
		`in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower)) &&
		                 (num_upper < 0 || (n-m) <= num_upper)`.
		
		For example:
		
		```
		# if 'input' is [[ 0,  1,  2, 3]
		#                [-1,  0,  1, 2]
		#                [-2, -1,  0, 1]
		#                [-3, -2, -1, 0]],
		
		tf.linalg.band_part(input, 1, -1) ==> [[ 0,  1,  2, 3]
		                                       [-1,  0,  1, 2]
		                                       [ 0, -1,  0, 1]
		                                       [ 0,  0, -1, 0]],
		
		tf.linalg.band_part(input, 2, 1) ==> [[ 0,  1,  0, 0]
		                                      [-1,  0,  1, 0]
		                                      [-2, -1,  0, 1]
		                                      [ 0, -2, -1, 0]]
		```
		
		Useful special cases:
		
		```
		 tf.linalg.band_part(input, 0, -1) ==> Upper triangular part.
		 tf.linalg.band_part(input, -1, 0) ==> Lower triangular part.
		 tf.linalg.band_part(input, 0, 0) ==> Diagonal.
		```
		
		Args:
		  input: A `Tensor`. Rank `k` tensor.
		  num_lower: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    0-D tensor. Number of subdiagonals to keep. If negative, keep entire
		    lower triangle.
		  num_upper: A `Tensor`. Must have the same type as `num_lower`.
		    0-D tensor. Number of superdiagonals to keep. If negative, keep
		    entire upper triangle.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixBandPart(input:Dynamic, num_lower:Dynamic, num_upper:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the determinant of one or more square matrices.
		
		The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
		form square matrices. The output is a tensor containing the determinants
		for all input submatrices `[..., :, :]`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.
		    Shape is `[..., M, M]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixDeterminant(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a batched diagonal tensor with a given batched diagonal values.
		
		Given a `diagonal`, this operation returns a tensor with the `diagonal` and
		everything else padded with zeros. The diagonal is computed as follows:
		
		Assume `diagonal` has `k` dimensions `[I, J, K, ..., N]`, then the output is a
		tensor of rank `k+1` with dimensions [I, J, K, ..., N, N]` where:
		
		`output[i, j, k, ..., m, n] = 1{m=n} * diagonal[i, j, k, ..., n]`.
		
		For example:
		
		```
		# 'diagonal' is [[1, 2, 3, 4], [5, 6, 7, 8]]
		
		and diagonal.shape = (2, 4)
		
		tf.matrix_diag(diagonal) ==> [[[1, 0, 0, 0]
		                                     [0, 2, 0, 0]
		                                     [0, 0, 3, 0]
		                                     [0, 0, 0, 4]],
		                                    [[5, 0, 0, 0]
		                                     [0, 6, 0, 0]
		                                     [0, 0, 7, 0]
		                                     [0, 0, 0, 8]]]
		
		which has shape (2, 4, 4)
		```
		
		Args:
		  diagonal: A `Tensor`. Rank `k`, where `k >= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `diagonal`.
	**/
	static public function MatrixDiag(diagonal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the batched diagonal part of a batched tensor.
		
		This operation returns a tensor with the `diagonal` part
		of the batched `input`. The `diagonal` part is computed as follows:
		
		Assume `input` has `k` dimensions `[I, J, K, ..., M, N]`, then the output is a
		tensor of rank `k - 1` with dimensions `[I, J, K, ..., min(M, N)]` where:
		
		`diagonal[i, j, k, ..., n] = input[i, j, k, ..., n, n]`.
		
		The input must be at least a matrix.
		
		For example:
		
		```
		# 'input' is [[[1, 0, 0, 0]
		               [0, 2, 0, 0]
		               [0, 0, 3, 0]
		               [0, 0, 0, 4]],
		              [[5, 0, 0, 0]
		               [0, 6, 0, 0]
		               [0, 0, 7, 0]
		               [0, 0, 0, 8]]]
		
		and input.shape = (2, 4, 4)
		
		tf.matrix_diag_part(input) ==> [[1, 2, 3, 4], [5, 6, 7, 8]]
		
		which has shape (2, 4)
		```
		
		Args:
		  input: A `Tensor`. Rank `k` tensor where `k >= 2`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixDiagPart(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the batched diagonal part of a batched tensor.
		
		Returns a tensor with the `k[0]`-th to `k[1]`-th diagonals of the batched
		`input`.
		
		Assume `input` has `r` dimensions `[I, J, ..., L, M, N]`.
		Let `max_diag_len` be the maximum length among all diagonals to be extracted,
		`max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`
		Let `num_diags` be the number of diagonals to extract,
		`num_diags = k[1] - k[0] + 1`.
		
		If `num_diags == 1`, the output tensor is of rank `r - 1` with shape
		`[I, J, ..., L, max_diag_len]` and values:
		
		```
		diagonal[i, j, ..., l, n]
		  = input[i, j, ..., l, n+y, n+x] ; if 0 <= n+y < M and 0 <= n+x < N,
		    padding_value                 ; otherwise.
		```
		where `y = max(-k[1], 0)`, `x = max(k[1], 0)`.
		
		Otherwise, the output tensor has rank `r` with dimensions
		`[I, J, ..., L, num_diags, max_diag_len]` with values:
		
		```
		diagonal[i, j, ..., l, m, n]
		  = input[i, j, ..., l, n+y, n+x] ; if 0 <= n+y < M and 0 <= n+x < N,
		    padding_value                 ; otherwise.
		```
		where `d = k[1] - m`, `y = max(-d, 0)`, and `x = max(d, 0)`.
		
		The input must be at least a matrix.
		
		For example:
		
		```
		input = np.array([[[1, 2, 3, 4],  # Input shape: (2, 3, 4)
		                   [5, 6, 7, 8],
		                   [9, 8, 7, 6]],
		                  [[5, 4, 3, 2],
		                   [1, 2, 3, 4],
		                   [5, 6, 7, 8]]])
		
		# A main diagonal from each batch.
		tf.matrix_diag_part(input) ==> [[1, 6, 7],  # Output shape: (2, 3)
		                                [5, 2, 7]]
		
		# A superdiagonal from each batch.
		tf.matrix_diag_part(input, k = 1)
		  ==> [[2, 7, 6],  # Output shape: (2, 3)
		       [4, 3, 8]]
		
		# A tridiagonal band from each batch.
		tf.matrix_diag_part(input, k = (-1, 1))
		  ==> [[[2, 7, 6],  # Output shape: (2, 3, 3)
		        [1, 6, 7],
		        [5, 8, 0]],
		       [[4, 3, 8],
		        [5, 2, 7],
		        [1, 6, 0]]]
		
		# Padding value = 9
		tf.matrix_diag_part(input, k = (1, 3), padding_value = 9)
		  ==> [[[4, 9, 9],  # Output shape: (2, 3, 3)
		        [3, 8, 9],
		        [2, 7, 6]],
		       [[2, 9, 9],
		        [3, 4, 9],
		        [4, 3, 8]]]
		```
		
		Args:
		  input: A `Tensor`. Rank `r` tensor where `r >= 2`.
		  k: A `Tensor` of type `int32`.
		    Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main
		    diagonal, and negative value means subdiagonals. `k` can be a single integer
		    (for a single diagonal) or a pair of integers specifying the low and high ends
		    of a matrix band. `k[0]` must not be larger than `k[1]`.
		  padding_value: A `Tensor`. Must have the same type as `input`.
		    The value to fill the area outside the specified diagonal band with.
		    Default is 0.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixDiagPartV2(input:Dynamic, k:Dynamic, padding_value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the batched diagonal part of a batched tensor.
		
		Returns a tensor with the `k[0]`-th to `k[1]`-th diagonals of the batched
		`input`.
		
		Assume `input` has `r` dimensions `[I, J, ..., L, M, N]`.
		Let `max_diag_len` be the maximum length among all diagonals to be extracted,
		`max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`
		Let `num_diags` be the number of diagonals to extract,
		`num_diags = k[1] - k[0] + 1`.
		
		If `num_diags == 1`, the output tensor is of rank `r - 1` with shape
		`[I, J, ..., L, max_diag_len]` and values:
		
		```
		diagonal[i, j, ..., l, n]
		  = input[i, j, ..., l, n+y, n+x] ; if 0 <= n+y < M and 0 <= n+x < N,
		    padding_value                 ; otherwise.
		```
		where `y = max(-k[1], 0)`, `x = max(k[1], 0)`.
		
		Otherwise, the output tensor has rank `r` with dimensions
		`[I, J, ..., L, num_diags, max_diag_len]` with values:
		
		```
		diagonal[i, j, ..., l, m, n]
		  = input[i, j, ..., l, n+y, n+x] ; if 0 <= n+y < M and 0 <= n+x < N,
		    padding_value                 ; otherwise.
		```
		where `d = k[1] - m`, `y = max(-d, 0) - offset`, and `x = max(d, 0) - offset`.
		
		`offset` is zero except when the alignment of the diagonal is to the right.
		```
		offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}
		                                           and `d >= 0`) or
		                                         (`align` in {LEFT_RIGHT, RIGHT_RIGHT}
		                                           and `d <= 0`)
		         0                          ; otherwise
		```
		where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.
		
		The input must be at least a matrix.
		
		For example:
		
		```
		input = np.array([[[1, 2, 3, 4],  # Input shape: (2, 3, 4)
		                   [5, 6, 7, 8],
		                   [9, 8, 7, 6]],
		                  [[5, 4, 3, 2],
		                   [1, 2, 3, 4],
		                   [5, 6, 7, 8]]])
		
		# A main diagonal from each batch.
		tf.matrix_diag_part(input) ==> [[1, 6, 7],  # Output shape: (2, 3)
		                                [5, 2, 7]]
		
		# A superdiagonal from each batch.
		tf.matrix_diag_part(input, k = 1)
		  ==> [[2, 7, 6],  # Output shape: (2, 3)
		       [4, 3, 8]]
		
		# A band from each batch.
		tf.matrix_diag_part(input, k = (-1, 2))
		  ==> [[[0, 3, 8],  # Output shape: (2, 4, 3)
		        [2, 7, 6],
		        [1, 6, 7],
		        [5, 8, 0]],
		       [[0, 3, 4],
		        [4, 3, 8],
		        [5, 2, 7],
		        [1, 6, 0]]]
		
		# LEFT_RIGHT alignment.
		tf.matrix_diag_part(input, k = (-1, 2), align="LEFT_RIGHT")
		  ==> [[[3, 8, 0],  # Output shape: (2, 4, 3)
		        [2, 7, 6],
		        [1, 6, 7],
		        [0, 5, 8]],
		       [[3, 4, 0],
		        [4, 3, 8],
		        [5, 2, 7],
		        [0, 1, 6]]]
		
		# max_diag_len can be shorter than the main diagonal.
		tf.matrix_diag_part(input, k = (-2, -1))
		  ==> [[[5, 8],
		        [9, 0]],
		       [[1, 6],
		        [5, 0]]]
		
		# padding_value = 9
		tf.matrix_diag_part(input, k = (1, 3), padding_value = 9)
		  ==> [[[9, 9, 4],  # Output shape: (2, 3, 3)
		        [9, 3, 8],
		        [2, 7, 6]],
		       [[9, 9, 2],
		        [9, 3, 4],
		        [4, 3, 8]]]
		
		```
		
		Args:
		  input: A `Tensor`. Rank `r` tensor where `r >= 2`.
		  k: A `Tensor` of type `int32`.
		    Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main
		    diagonal, and negative value means subdiagonals. `k` can be a single integer
		    (for a single diagonal) or a pair of integers specifying the low and high ends
		    of a matrix band. `k[0]` must not be larger than `k[1]`.
		  padding_value: A `Tensor`. Must have the same type as `input`.
		    The value to fill the area outside the specified diagonal band with.
		    Default is 0.
		  align: An optional `string` from: `"LEFT_RIGHT", "RIGHT_LEFT", "LEFT_LEFT", "RIGHT_RIGHT"`. Defaults to `"RIGHT_LEFT"`.
		    Some diagonals are shorter than `max_diag_len` and need to be padded. `align` is
		    a string specifying how superdiagonals and subdiagonals should be aligned,
		    respectively. There are four possible alignments: "RIGHT_LEFT" (default),
		    "LEFT_RIGHT", "LEFT_LEFT", and "RIGHT_RIGHT". "RIGHT_LEFT" aligns superdiagonals
		    to the right (left-pads the row) and subdiagonals to the left (right-pads the
		    row). It is the packing format LAPACK uses. cuSPARSE uses "LEFT_RIGHT", which is
		    the opposite alignment.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixDiagPartV3(input:Dynamic, k:Dynamic, padding_value:Dynamic, ?align:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a batched diagonal tensor with given batched diagonal values.
		
		Returns a tensor with the contents in `diagonal` as `k[0]`-th to `k[1]`-th
		diagonals of a matrix, with everything else padded with `padding`. `num_rows`
		and `num_cols` specify the dimension of the innermost matrix of the output. If
		both are not specified, the op assumes the innermost matrix is square and infers
		its size from `k` and the innermost dimension of `diagonal`. If only one of them
		is specified, the op assumes the unspecified value is the smallest possible
		based on other criteria.
		
		Let `diagonal` have `r` dimensions `[I, J, ..., L, M, N]`. The output tensor has
		rank `r+1` with shape `[I, J, ..., L, M, num_rows, num_cols]` when only one
		diagonal is given (`k` is an integer or `k[0] == k[1]`). Otherwise, it has rank
		`r` with shape `[I, J, ..., L, num_rows, num_cols]`.
		
		The second innermost dimension of `diagonal` has double meaning.
		When `k` is scalar or `k[0] == k[1]`, `M` is part of the batch size
		[I, J, ..., M], and the output tensor is:
		
		```
		output[i, j, ..., l, m, n]
		  = diagonal[i, j, ..., l, n-max(d_upper, 0)] ; if n - m == d_upper
		    padding_value                             ; otherwise
		```
		
		Otherwise, `M` is treated as the number of diagonals for the matrix in the
		same batch (`M = k[1]-k[0]+1`), and the output tensor is:
		
		```
		output[i, j, ..., l, m, n]
		  = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] <= d <= k[1]
		    padding_value                                     ; otherwise
		```
		where `d = n - m`, `diag_index = k[1] - d`, and `index_in_diag = n - max(d, 0)`.
		
		For example:
		
		```
		# The main diagonal.
		diagonal = np.array([[1, 2, 3, 4],            # Input shape: (2, 4)
		                     [5, 6, 7, 8]])
		tf.matrix_diag(diagonal) ==> [[[1, 0, 0, 0],  # Output shape: (2, 4, 4)
		                               [0, 2, 0, 0],
		                               [0, 0, 3, 0],
		                               [0, 0, 0, 4]],
		                              [[5, 0, 0, 0],
		                               [0, 6, 0, 0],
		                               [0, 0, 7, 0],
		                               [0, 0, 0, 8]]]
		
		# A superdiagonal (per batch).
		diagonal = np.array([[1, 2, 3],  # Input shape: (2, 3)
		                     [4, 5, 6]])
		tf.matrix_diag(diagonal, k = 1)
		  ==> [[[0, 1, 0, 0],  # Output shape: (2, 4, 4)
		        [0, 0, 2, 0],
		        [0, 0, 0, 3],
		        [0, 0, 0, 0]],
		       [[0, 4, 0, 0],
		        [0, 0, 5, 0],
		        [0, 0, 0, 6],
		        [0, 0, 0, 0]]]
		
		# A band of diagonals.
		diagonals = np.array([[[1, 2, 3],  # Input shape: (2, 2, 3)
		                       [4, 5, 0]],
		                      [[6, 7, 9],
		                       [9, 1, 0]]])
		tf.matrix_diag(diagonals, k = (-1, 0))
		  ==> [[[1, 0, 0],  # Output shape: (2, 3, 3)
		        [4, 2, 0],
		        [0, 5, 3]],
		       [[6, 0, 0],
		        [9, 7, 0],
		        [0, 1, 9]]]
		
		# Rectangular matrix.
		diagonal = np.array([1, 2])  # Input shape: (2)
		tf.matrix_diag(diagonal, k = -1, num_rows = 3, num_cols = 4)
		  ==> [[0, 0, 0, 0],  # Output shape: (3, 4)
		       [1, 0, 0, 0],
		       [0, 2, 0, 0]]
		
		# Rectangular matrix with inferred num_cols and padding_value = 9.
		tf.matrix_diag(diagonal, k = -1, num_rows = 3, padding_value = 9)
		  ==> [[9, 9],  # Output shape: (3, 2)
		       [1, 9],
		       [9, 2]]
		```
		
		Args:
		  diagonal: A `Tensor`. Rank `r`, where `r >= 1`
		  k: A `Tensor` of type `int32`.
		    Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main
		    diagonal, and negative value means subdiagonals. `k` can be a single integer
		    (for a single diagonal) or a pair of integers specifying the low and high ends
		    of a matrix band. `k[0]` must not be larger than `k[1]`.
		  num_rows: A `Tensor` of type `int32`.
		    The number of rows of the output matrix. If it is not provided, the op assumes
		    the output matrix is a square matrix and infers the matrix size from k and the
		    innermost dimension of `diagonal`.
		  num_cols: A `Tensor` of type `int32`.
		    The number of columns of the output matrix. If it is not provided, the op
		    assumes the output matrix is a square matrix and infers the matrix size from
		    k and the innermost dimension of `diagonal`.
		  padding_value: A `Tensor`. Must have the same type as `diagonal`.
		    The number to fill the area outside the specified diagonal band with.
		    Default is 0.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `diagonal`.
	**/
	static public function MatrixDiagV2(diagonal:Dynamic, k:Dynamic, num_rows:Dynamic, num_cols:Dynamic, padding_value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a batched diagonal tensor with given batched diagonal values.
		
		Returns a tensor with the contents in `diagonal` as `k[0]`-th to `k[1]`-th
		diagonals of a matrix, with everything else padded with `padding`. `num_rows`
		and `num_cols` specify the dimension of the innermost matrix of the output. If
		both are not specified, the op assumes the innermost matrix is square and infers
		its size from `k` and the innermost dimension of `diagonal`. If only one of them
		is specified, the op assumes the unspecified value is the smallest possible
		based on other criteria.
		
		Let `diagonal` have `r` dimensions `[I, J, ..., L, M, N]`. The output tensor has
		rank `r+1` with shape `[I, J, ..., L, M, num_rows, num_cols]` when only one
		diagonal is given (`k` is an integer or `k[0] == k[1]`). Otherwise, it has rank
		`r` with shape `[I, J, ..., L, num_rows, num_cols]`.
		
		The second innermost dimension of `diagonal` has double meaning.
		When `k` is scalar or `k[0] == k[1]`, `M` is part of the batch size
		[I, J, ..., M], and the output tensor is:
		
		```
		output[i, j, ..., l, m, n]
		  = diagonal[i, j, ..., l, n-max(d_upper, 0)] ; if n - m == d_upper
		    padding_value                             ; otherwise
		```
		
		Otherwise, `M` is treated as the number of diagonals for the matrix in the
		same batch (`M = k[1]-k[0]+1`), and the output tensor is:
		
		```
		output[i, j, ..., l, m, n]
		  = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] <= d <= k[1]
		    padding_value                                     ; otherwise
		```
		where `d = n - m`, `diag_index = [k] - d`, and
		`index_in_diag = n - max(d, 0) + offset`.
		
		`offset` is zero except when the alignment of the diagonal is to the right.
		```
		offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}
		                                           and `d >= 0`) or
		                                         (`align` in {LEFT_RIGHT, RIGHT_RIGHT}
		                                           and `d <= 0`)
		         0                          ; otherwise
		```
		where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.
		
		For example:
		
		```
		# The main diagonal.
		diagonal = np.array([[1, 2, 3, 4],            # Input shape: (2, 4)
		                     [5, 6, 7, 8]])
		tf.matrix_diag(diagonal) ==> [[[1, 0, 0, 0],  # Output shape: (2, 4, 4)
		                               [0, 2, 0, 0],
		                               [0, 0, 3, 0],
		                               [0, 0, 0, 4]],
		                              [[5, 0, 0, 0],
		                               [0, 6, 0, 0],
		                               [0, 0, 7, 0],
		                               [0, 0, 0, 8]]]
		
		# A superdiagonal (per batch).
		diagonal = np.array([[1, 2, 3],  # Input shape: (2, 3)
		                     [4, 5, 6]])
		tf.matrix_diag(diagonal, k = 1)
		  ==> [[[0, 1, 0, 0],  # Output shape: (2, 4, 4)
		        [0, 0, 2, 0],
		        [0, 0, 0, 3],
		        [0, 0, 0, 0]],
		       [[0, 4, 0, 0],
		        [0, 0, 5, 0],
		        [0, 0, 0, 6],
		        [0, 0, 0, 0]]]
		
		# A tridiagonal band (per batch).
		diagonals = np.array([[[0, 8, 9],  # Input shape: (2, 2, 3)
		                       [1, 2, 3],
		                       [4, 5, 0]],
		                      [[0, 2, 3],
		                       [6, 7, 9],
		                       [9, 1, 0]]])
		tf.matrix_diag(diagonals, k = (-1, 1))
		  ==> [[[1, 8, 0],  # Output shape: (2, 3, 3)
		        [4, 2, 9],
		        [0, 5, 3]],
		       [[6, 2, 0],
		        [9, 7, 3],
		        [0, 1, 9]]]
		
		# LEFT_RIGHT alignment.
		diagonals = np.array([[[8, 9, 0],  # Input shape: (2, 2, 3)
		                       [1, 2, 3],
		                       [0, 4, 5]],
		                      [[2, 3, 0],
		                       [6, 7, 9],
		                       [0, 9, 1]]])
		tf.matrix_diag(diagonals, k = (-1, 1), align="LEFT_RIGHT")
		  ==> [[[1, 8, 0],  # Output shape: (2, 3, 3)
		        [4, 2, 9],
		        [0, 5, 3]],
		       [[6, 2, 0],
		        [9, 7, 3],
		        [0, 1, 9]]]
		
		# Rectangular matrix.
		diagonal = np.array([1, 2])  # Input shape: (2)
		tf.matrix_diag(diagonal, k = -1, num_rows = 3, num_cols = 4)
		  ==> [[0, 0, 0, 0],  # Output shape: (3, 4)
		       [1, 0, 0, 0],
		       [0, 2, 0, 0]]
		
		# Rectangular matrix with inferred num_cols and padding_value = 9.
		tf.matrix_diag(diagonal, k = -1, num_rows = 3, padding_value = 9)
		  ==> [[9, 9],  # Output shape: (3, 2)
		       [1, 9],
		       [9, 2]]
		
		```
		
		Args:
		  diagonal: A `Tensor`. Rank `r`, where `r >= 1`
		  k: A `Tensor` of type `int32`.
		    Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main
		    diagonal, and negative value means subdiagonals. `k` can be a single integer
		    (for a single diagonal) or a pair of integers specifying the low and high ends
		    of a matrix band. `k[0]` must not be larger than `k[1]`.
		  num_rows: A `Tensor` of type `int32`.
		    The number of rows of the output matrix. If it is not provided, the op assumes
		    the output matrix is a square matrix and infers the matrix size from k and the
		    innermost dimension of `diagonal`.
		  num_cols: A `Tensor` of type `int32`.
		    The number of columns of the output matrix. If it is not provided, the op
		    assumes the output matrix is a square matrix and infers the matrix size from
		    k and the innermost dimension of `diagonal`.
		  padding_value: A `Tensor`. Must have the same type as `diagonal`.
		    The number to fill the area outside the specified diagonal band with.
		    Default is 0.
		  align: An optional `string` from: `"LEFT_RIGHT", "RIGHT_LEFT", "LEFT_LEFT", "RIGHT_RIGHT"`. Defaults to `"RIGHT_LEFT"`.
		    Some diagonals are shorter than `max_diag_len` and need to be padded. `align` is
		    a string specifying how superdiagonals and subdiagonals should be aligned,
		    respectively. There are four possible alignments: "RIGHT_LEFT" (default),
		    "LEFT_RIGHT", "LEFT_LEFT", and "RIGHT_RIGHT". "RIGHT_LEFT" aligns superdiagonals
		    to the right (left-pads the row) and subdiagonals to the left (right-pads the
		    row). It is the packing format LAPACK uses. cuSPARSE uses "LEFT_RIGHT", which is
		    the opposite alignment.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `diagonal`.
	**/
	static public function MatrixDiagV3(diagonal:Dynamic, k:Dynamic, num_rows:Dynamic, num_cols:Dynamic, padding_value:Dynamic, ?align:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated, use python implementation tf.linalg.matrix_exponential.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixExponential(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).
		
		
		The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
		form square matrices. The output is a tensor of the same shape as the input
		containing the inverse for all input submatrices `[..., :, :]`.
		
		The op uses LU decomposition with partial pivoting to compute the inverses.
		
		If a matrix is not invertible there is no guarantee what the op does. It
		may detect the condition and raise an exception or it may simply return a
		garbage result.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		    Shape is `[..., M, M]`.
		  adjoint: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixInverse(input:Dynamic, ?adjoint:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the matrix logarithm of one or more square matrices:
		
		
		\\(log(exp(A)) = A\\)
		
		This op is only defined for complex matrices. If A is positive-definite and
		real, then casting to a complex matrix, taking the logarithm and casting back
		to a real matrix will give the correct result.
		
		This function computes the matrix logarithm using the Schur-Parlett algorithm.
		Details of the algorithm can be found in Section 11.6.2 of:
		Nicholas J. Higham, Functions of Matrices: Theory and Computation, SIAM 2008.
		ISBN 978-0-898716-46-7.
		
		The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
		form square matrices. The output is a tensor of the same shape as the input
		containing the exponential for all input submatrices `[..., :, :]`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		    Shape is `[..., M, M]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixLogarithm(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a batched matrix tensor with new batched diagonal values.
		
		Given `input` and `diagonal`, this operation returns a tensor with the
		same shape and values as `input`, except for the main diagonal of the
		innermost matrices.  These will be overwritten by the values in `diagonal`.
		
		The output is computed as follows:
		
		Assume `input` has `k+1` dimensions `[I, J, K, ..., M, N]` and `diagonal` has
		`k` dimensions `[I, J, K, ..., min(M, N)]`.  Then the output is a
		tensor of rank `k+1` with dimensions `[I, J, K, ..., M, N]` where:
		
		  * `output[i, j, k, ..., m, n] = diagonal[i, j, k, ..., n]` for `m == n`.
		  * `output[i, j, k, ..., m, n] = input[i, j, k, ..., m, n]` for `m != n`.
		
		Args:
		  input: A `Tensor`. Rank `k+1`, where `k >= 1`.
		  diagonal: A `Tensor`. Must have the same type as `input`.
		    Rank `k`, where `k >= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixSetDiag(input:Dynamic, diagonal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a batched matrix tensor with new batched diagonal values.
		
		Given `input` and `diagonal`, this operation returns a tensor with the
		same shape and values as `input`, except for the specified diagonals of the
		innermost matrices. These will be overwritten by the values in `diagonal`.
		
		`input` has `r+1` dimensions `[I, J, ..., L, M, N]`. When `k` is scalar or
		`k[0] == k[1]`, `diagonal` has `r` dimensions `[I, J, ..., L, max_diag_len]`.
		Otherwise, it has `r+1` dimensions `[I, J, ..., L, num_diags, max_diag_len]`.
		`num_diags` is the number of diagonals, `num_diags = k[1] - k[0] + 1`.
		`max_diag_len` is the longest diagonal in the range `[k[0], k[1]]`,
		`max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`
		
		The output is a tensor of rank `k+1` with dimensions `[I, J, ..., L, M, N]`.
		If `k` is scalar or `k[0] == k[1]`:
		
		```
		output[i, j, ..., l, m, n]
		  = diagonal[i, j, ..., l, n-max(k[1], 0)] ; if n - m == k[1]
		    input[i, j, ..., l, m, n]              ; otherwise
		```
		
		Otherwise,
		
		```
		output[i, j, ..., l, m, n]
		  = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] <= d <= k[1]
		    input[i, j, ..., l, m, n]                         ; otherwise
		```
		where `d = n - m`, `diag_index = k[1] - d`, and `index_in_diag = n - max(d, 0)`.
		
		For example:
		
		```
		# The main diagonal.
		input = np.array([[[7, 7, 7, 7],              # Input shape: (2, 3, 4)
		                   [7, 7, 7, 7],
		                   [7, 7, 7, 7]],
		                  [[7, 7, 7, 7],
		                   [7, 7, 7, 7],
		                   [7, 7, 7, 7]]])
		diagonal = np.array([[1, 2, 3],               # Diagonal shape: (2, 3)
		                     [4, 5, 6]])
		tf.matrix_set_diag(diagonal) ==> [[[1, 7, 7, 7],  # Output shape: (2, 3, 4)
		                                   [7, 2, 7, 7],
		                                   [7, 7, 3, 7]],
		                                  [[4, 7, 7, 7],
		                                   [7, 5, 7, 7],
		                                   [7, 7, 6, 7]]]
		
		# A superdiagonal (per batch).
		tf.matrix_set_diag(diagonal, k = 1)
		  ==> [[[7, 1, 7, 7],  # Output shape: (2, 3, 4)
		        [7, 7, 2, 7],
		        [7, 7, 7, 3]],
		       [[7, 4, 7, 7],
		        [7, 7, 5, 7],
		        [7, 7, 7, 6]]]
		
		# A band of diagonals.
		diagonals = np.array([[[1, 2, 3],  # Diagonal shape: (2, 2, 3)
		                       [4, 5, 0]],
		                      [[6, 1, 2],
		                       [3, 4, 0]]])
		tf.matrix_set_diag(diagonals, k = (-1, 0))
		  ==> [[[1, 7, 7, 7],  # Output shape: (2, 3, 4)
		        [4, 2, 7, 7],
		        [0, 5, 3, 7]],
		       [[6, 7, 7, 7],
		        [3, 1, 7, 7],
		        [7, 4, 2, 7]]]
		
		```
		
		Args:
		  input: A `Tensor`. Rank `r+1`, where `r >= 1`.
		  diagonal: A `Tensor`. Must have the same type as `input`.
		    Rank `r` when `k` is an integer or `k[0] == k[1]`. Otherwise, it has rank `r+1`.
		    `k >= 1`.
		  k: A `Tensor` of type `int32`.
		    Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main
		    diagonal, and negative value means subdiagonals. `k` can be a single integer
		    (for a single diagonal) or a pair of integers specifying the low and high ends
		    of a matrix band. `k[0]` must not be larger than `k[1]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixSetDiagV2(input:Dynamic, diagonal:Dynamic, k:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a batched matrix tensor with new batched diagonal values.
		
		Given `input` and `diagonal`, this operation returns a tensor with the
		same shape and values as `input`, except for the specified diagonals of the
		innermost matrices. These will be overwritten by the values in `diagonal`.
		
		`input` has `r+1` dimensions `[I, J, ..., L, M, N]`. When `k` is scalar or
		`k[0] == k[1]`, `diagonal` has `r` dimensions `[I, J, ..., L, max_diag_len]`.
		Otherwise, it has `r+1` dimensions `[I, J, ..., L, num_diags, max_diag_len]`.
		`num_diags` is the number of diagonals, `num_diags = k[1] - k[0] + 1`.
		`max_diag_len` is the longest diagonal in the range `[k[0], k[1]]`,
		`max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`
		
		The output is a tensor of rank `k+1` with dimensions `[I, J, ..., L, M, N]`.
		If `k` is scalar or `k[0] == k[1]`:
		
		```
		output[i, j, ..., l, m, n]
		  = diagonal[i, j, ..., l, n-max(k[1], 0)] ; if n - m == k[1]
		    input[i, j, ..., l, m, n]              ; otherwise
		```
		
		Otherwise,
		
		```
		output[i, j, ..., l, m, n]
		  = diagonal[i, j, ..., l, diag_index, index_in_diag] ; if k[0] <= d <= k[1]
		    input[i, j, ..., l, m, n]                         ; otherwise
		```
		where `d = n - m`, `diag_index = k[1] - d`, and
		`index_in_diag = n - max(d, 0) + offset`.
		
		`offset` is zero except when the alignment of the diagonal is to the right.
		```
		offset = max_diag_len - diag_len(d) ; if (`align` in {RIGHT_LEFT, RIGHT_RIGHT}
		                                           and `d >= 0`) or
		                                         (`align` in {LEFT_RIGHT, RIGHT_RIGHT}
		                                           and `d <= 0`)
		         0                          ; otherwise
		```
		where `diag_len(d) = min(cols - max(d, 0), rows + min(d, 0))`.
		
		For example:
		
		```
		# The main diagonal.
		input = np.array([[[7, 7, 7, 7],              # Input shape: (2, 3, 4)
		                   [7, 7, 7, 7],
		                   [7, 7, 7, 7]],
		                  [[7, 7, 7, 7],
		                   [7, 7, 7, 7],
		                   [7, 7, 7, 7]]])
		diagonal = np.array([[1, 2, 3],               # Diagonal shape: (2, 3)
		                     [4, 5, 6]])
		tf.matrix_set_diag(input, diagonal)
		  ==> [[[1, 7, 7, 7],  # Output shape: (2, 3, 4)
		        [7, 2, 7, 7],
		        [7, 7, 3, 7]],
		       [[4, 7, 7, 7],
		        [7, 5, 7, 7],
		        [7, 7, 6, 7]]]
		
		# A superdiagonal (per batch).
		tf.matrix_set_diag(input, diagonal, k = 1)
		  ==> [[[7, 1, 7, 7],  # Output shape: (2, 3, 4)
		        [7, 7, 2, 7],
		        [7, 7, 7, 3]],
		       [[7, 4, 7, 7],
		        [7, 7, 5, 7],
		        [7, 7, 7, 6]]]
		
		# A band of diagonals.
		diagonals = np.array([[[0, 9, 1],  # Diagonal shape: (2, 4, 3)
		                       [6, 5, 8],
		                       [1, 2, 3],
		                       [4, 5, 0]],
		                      [[0, 1, 2],
		                       [5, 6, 4],
		                       [6, 1, 2],
		                       [3, 4, 0]]])
		tf.matrix_set_diag(input, diagonals, k = (-1, 2))
		  ==> [[[1, 6, 9, 7],  # Output shape: (2, 3, 4)
		        [4, 2, 5, 1],
		        [7, 5, 3, 8]],
		       [[6, 5, 1, 7],
		        [3, 1, 6, 2],
		        [7, 4, 2, 4]]]
		
		# LEFT_RIGHT alignment.
		diagonals = np.array([[[9, 1, 0],  # Diagonal shape: (2, 4, 3)
		                       [6, 5, 8],
		                       [1, 2, 3],
		                       [0, 4, 5]],
		                      [[1, 2, 0],
		                       [5, 6, 4],
		                       [6, 1, 2],
		                       [0, 3, 4]]])
		tf.matrix_set_diag(input, diagonals, k = (-1, 2), align="LEFT_RIGHT")
		  ==> [[[1, 6, 9, 7],  # Output shape: (2, 3, 4)
		        [4, 2, 5, 1],
		        [7, 5, 3, 8]],
		       [[6, 5, 1, 7],
		        [3, 1, 6, 2],
		        [7, 4, 2, 4]]]
		
		```
		
		Args:
		  input: A `Tensor`. Rank `r+1`, where `r >= 1`.
		  diagonal: A `Tensor`. Must have the same type as `input`.
		    Rank `r` when `k` is an integer or `k[0] == k[1]`. Otherwise, it has rank `r+1`.
		    `k >= 1`.
		  k: A `Tensor` of type `int32`.
		    Diagonal offset(s). Positive value means superdiagonal, 0 refers to the main
		    diagonal, and negative value means subdiagonals. `k` can be a single integer
		    (for a single diagonal) or a pair of integers specifying the low and high ends
		    of a matrix band. `k[0]` must not be larger than `k[1]`.
		  align: An optional `string` from: `"LEFT_RIGHT", "RIGHT_LEFT", "LEFT_LEFT", "RIGHT_RIGHT"`. Defaults to `"RIGHT_LEFT"`.
		    Some diagonals are shorter than `max_diag_len` and need to be padded. `align` is
		    a string specifying how superdiagonals and subdiagonals should be aligned,
		    respectively. There are four possible alignments: "RIGHT_LEFT" (default),
		    "LEFT_RIGHT", "LEFT_LEFT", and "RIGHT_RIGHT". "RIGHT_LEFT" aligns superdiagonals
		    to the right (left-pads the row) and subdiagonals to the left (right-pads the
		    row). It is the packing format LAPACK uses. cuSPARSE uses "LEFT_RIGHT", which is
		    the opposite alignment.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixSetDiagV3(input:Dynamic, diagonal:Dynamic, k:Dynamic, ?align:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Solves systems of linear equations.
		
		`Matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
		form square matrices. `Rhs` is a tensor of shape `[..., M, K]`. The `output` is
		a tensor shape `[..., M, K]`.  If `adjoint` is `False` then each output matrix
		satisfies `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]`.
		If `adjoint` is `True` then each output matrix satisfies
		`adjoint(matrix[..., :, :]) * output[..., :, :] = rhs[..., :, :]`.
		
		Args:
		  matrix: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		    Shape is `[..., M, M]`.
		  rhs: A `Tensor`. Must have the same type as `matrix`.
		    Shape is `[..., M, K]`.
		  adjoint: An optional `bool`. Defaults to `False`.
		    Boolean indicating whether to solve with `matrix` or its (block-wise)
		    adjoint.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `matrix`.
	**/
	static public function MatrixSolve(matrix:Dynamic, rhs:Dynamic, ?adjoint:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Solves one or more linear least-squares problems.
		
		`matrix` is a tensor of shape `[..., M, N]` whose inner-most 2 dimensions
		form real or complex matrices of size `[M, N]`. `Rhs` is a tensor of the same
		type as `matrix` and shape `[..., M, K]`.
		The output is a tensor shape `[..., N, K]` where each output matrix solves
		each of the equations
		`matrix[..., :, :]` * `output[..., :, :]` = `rhs[..., :, :]`
		in the least squares sense.
		
		We use the following notation for (complex) matrix and right-hand sides
		in the batch:
		
		`matrix`=\\(A \in \mathbb{C}^{m \times n}\\),
		`rhs`=\\(B  \in \mathbb{C}^{m \times k}\\),
		`output`=\\(X  \in \mathbb{C}^{n \times k}\\),
		`l2_regularizer`=\\(\lambda \in \mathbb{R}\\).
		
		If `fast` is `True`, then the solution is computed by solving the normal
		equations using Cholesky decomposition. Specifically, if \\(m \ge n\\) then
		\\(X = (A^H A + \lambda I)^{-1} A^H B\\), which solves the least-squares
		problem \\(X = \mathrm{argmin}_{Z \in \Re^{n \times k} } ||A Z - B||_F^2 + \lambda ||Z||_F^2\\).
		If \\(m \lt n\\) then `output` is computed as
		\\(X = A^H (A A^H + \lambda I)^{-1} B\\), which (for \\(\lambda = 0\\)) is the
		minimum-norm solution to the under-determined linear system, i.e.
		\\(X = \mathrm{argmin}_{Z \in \mathbb{C}^{n \times k} } ||Z||_F^2 \\),
		subject to \\(A Z = B\\). Notice that the fast path is only numerically stable
		when \\(A\\) is numerically full rank and has a condition number
		\\(\mathrm{cond}(A) \lt \frac{1}{\sqrt{\epsilon_{mach} } }\\) or \\(\lambda\\) is
		sufficiently large.
		
		If `fast` is `False` an algorithm based on the numerically robust complete
		orthogonal decomposition is used. This computes the minimum-norm
		least-squares solution, even when \\(A\\) is rank deficient. This path is
		typically 6-7 times slower than the fast path. If `fast` is `False` then
		`l2_regularizer` is ignored.
		
		Args:
		  matrix: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		    Shape is `[..., M, N]`.
		  rhs: A `Tensor`. Must have the same type as `matrix`.
		    Shape is `[..., M, K]`.
		  l2_regularizer: A `Tensor` of type `float64`. Scalar tensor.
		
		    @compatibility(numpy)
		    Equivalent to np.linalg.lstsq
		    @end_compatibility
		  fast: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `matrix`.
	**/
	static public function MatrixSolveLs(matrix:Dynamic, rhs:Dynamic, l2_regularizer:Dynamic, ?fast:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the matrix square root of one or more square matrices:
		
		matmul(sqrtm(A), sqrtm(A)) = A
		
		The input matrix should be invertible. If the input matrix is real, it should
		have no eigenvalues which are real and negative (pairs of complex conjugate
		eigenvalues are allowed).
		
		The matrix square root is computed by first reducing the matrix to
		quasi-triangular form with the real Schur decomposition. The square root
		of the quasi-triangular matrix is then computed directly. Details of
		the algorithm can be found in: Nicholas J. Higham, "Computing real
		square roots of a real matrix", Linear Algebra Appl., 1987.
		
		The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
		form square matrices. The output is a tensor of the same shape as the input
		containing the matrix square root for all input submatrices `[..., :, :]`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		    Shape is `[..., M, M]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MatrixSquareRoot(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Solves systems of linear equations with upper or lower triangular matrices by backsubstitution.
		
		
		`matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions form
		square matrices. If `lower` is `True` then the strictly upper triangular part
		of each inner-most matrix is assumed to be zero and not accessed.
		If `lower` is False then the strictly lower triangular part of each inner-most
		matrix is assumed to be zero and not accessed.
		`rhs` is a tensor of shape `[..., M, N]`.
		
		The output is a tensor of shape `[..., M, N]`. If `adjoint` is
		`True` then the innermost matrices in `output` satisfy matrix equations
		`matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]`.
		If `adjoint` is `False` then the strictly then the  innermost matrices in
		`output` satisfy matrix equations
		`adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]`.
		
		Note, the batch shapes for the inputs only need to broadcast.
		
		Example:
		```python
		
		a = tf.constant([[3,  0,  0,  0],
		                 [2,  1,  0,  0],
		                 [1,  0,  1,  0],
		                 [1,  1,  1,  1]], dtype=tf.float32)
		
		b = tf.constant([[4],
		                 [2],
		                 [4],
		                 [2]], dtype=tf.float32)
		
		x = tf.linalg.triangular_solve(a, b, lower=True)
		x
		# <tf.Tensor: shape=(4, 1), dtype=float32, numpy=
		# array([[ 1.3333334 ],
		#        [-0.66666675],
		#        [ 2.6666665 ],
		#        [-1.3333331 ]], dtype=float32)>
		
		# in python3 one can use `a@x`
		tf.matmul(a, x)
		# <tf.Tensor: shape=(4, 1), dtype=float32, numpy=
		# array([[4.       ],
		#        [2.       ],
		#        [4.       ],
		#        [1.9999999]], dtype=float32)>
		```
		
		Args:
		  matrix: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		    Shape is `[..., M, M]`.
		  rhs: A `Tensor`. Must have the same type as `matrix`.
		    Shape is `[..., M, K]`.
		  lower: An optional `bool`. Defaults to `True`.
		    Boolean indicating whether the innermost matrices in `matrix` are
		    lower or upper triangular.
		  adjoint: An optional `bool`. Defaults to `False`.
		    Boolean indicating whether to solve with `matrix` or its (block-wise)
		             adjoint.
		
		    @compatibility(numpy)
		    Equivalent to scipy.linalg.solve_triangular
		    @end_compatibility
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `matrix`.
	**/
	static public function MatrixTriangularSolve(matrix:Dynamic, rhs:Dynamic, ?lower:Dynamic, ?adjoint:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the maximum of elements across dimensions of a tensor.
		
		Reduces `input` along the dimensions given in `axis`. Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`axis`. If `keep_dims` is true, the reduced dimensions are
		retained with length 1.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The tensor to reduce.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The dimensions to reduce. Must be in the range
		    `[-rank(input), rank(input))`.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Max(input:Dynamic, axis:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that overrides the maximum intra-op parallelism.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  max_intra_op_parallelism: A `Tensor` of type `int64`.
		    Identifies the maximum intra-op parallelism to use.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function MaxIntraOpParallelismDataset(input_dataset:Dynamic, max_intra_op_parallelism:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs max pooling on the input.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`, `int64`, `uint8`, `int16`, `int8`, `uint16`, `qint8`.
		    4-D input to pool over.
		  ksize: A list of `ints` that has length `>= 4`.
		    The size of the window for each dimension of the input tensor.
		  strides: A list of `ints` that has length `>= 4`.
		    The stride of the sliding window for each dimension of the
		    input tensor.
		  padding: A `string` from: `"SAME", "VALID", "EXPLICIT"`.
		    The type of padding algorithm to use.
		  explicit_paddings: An optional list of `ints`. Defaults to `[]`.
		  data_format: An optional `string` from: `"NHWC", "NCHW", "NCHW_VECT_C"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MaxPool(input:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?explicit_paddings:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs 3D max pooling on the input.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
		    Shape `[batch, depth, rows, cols, channels]` tensor to pool over.
		  ksize: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The size of the window for each dimension of
		    the input tensor. Must have `ksize[0] = ksize[4] = 1`.
		  strides: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The stride of the sliding window for each
		    dimension of `input`. Must have `strides[0] = strides[4] = 1`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
		    The data format of the input and output data. With the
		    default format "NDHWC", the data is stored in the order of:
		        [batch, in_depth, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCDHW", the data storage order is:
		        [batch, in_channels, in_depth, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MaxPool3D(input:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradients of 3D max pooling function.
		
		Args:
		  orig_input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
		    The original input tensor.
		  orig_output: A `Tensor`. Must have the same type as `orig_input`.
		    The original output tensor.
		  grad: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`.
		    Output backprop of shape `[batch, depth, rows, cols, channels]`.
		  ksize: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The size of the window for each dimension of
		    the input tensor. Must have `ksize[0] = ksize[4] = 1`.
		  strides: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The stride of the sliding window for each
		    dimension of `input`. Must have `strides[0] = strides[4] = 1`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
		    The data format of the input and output data. With the
		    default format "NDHWC", the data is stored in the order of:
		        [batch, in_depth, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCDHW", the data storage order is:
		        [batch, in_channels, in_depth, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `grad`.
	**/
	static public function MaxPool3DGrad(orig_input:Dynamic, orig_output:Dynamic, grad:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes second-order gradients of the maxpooling function.
		
		Args:
		  orig_input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    The original input tensor.
		  orig_output: A `Tensor`. Must have the same type as `orig_input`.
		    The original output tensor.
		  grad: A `Tensor`. Must have the same type as `orig_input`.
		    Output backprop of shape `[batch, depth, rows, cols, channels]`.
		  ksize: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The size of the window for each dimension of
		    the input tensor. Must have `ksize[0] = ksize[4] = 1`.
		  strides: A list of `ints` that has length `>= 5`.
		    1-D tensor of length 5. The stride of the sliding window for each
		    dimension of `input`. Must have `strides[0] = strides[4] = 1`.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NDHWC", "NCDHW"`. Defaults to `"NDHWC"`.
		    The data format of the input and output data. With the
		    default format "NDHWC", the data is stored in the order of:
		        [batch, in_depth, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCDHW", the data storage order is:
		        [batch, in_channels, in_depth, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `orig_input`.
	**/
	static public function MaxPool3DGradGrad(orig_input:Dynamic, orig_output:Dynamic, grad:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradients of the maxpooling function.
		
		Args:
		  orig_input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    The original input tensor.
		  orig_output: A `Tensor`. Must have the same type as `orig_input`.
		    The original output tensor.
		  grad: A `Tensor`. Must have the same type as `orig_input`.
		    4-D.  Gradients w.r.t. the output of `max_pool`.
		  ksize: A list of `ints` that has length `>= 4`.
		    The size of the window for each dimension of the input tensor.
		  strides: A list of `ints` that has length `>= 4`.
		    The stride of the sliding window for each dimension of the
		    input tensor.
		  padding: A `string` from: `"SAME", "VALID", "EXPLICIT"`.
		    The type of padding algorithm to use.
		  explicit_paddings: An optional list of `ints`. Defaults to `[]`.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `orig_input`.
	**/
	static public function MaxPoolGrad(orig_input:Dynamic, orig_output:Dynamic, grad:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?explicit_paddings:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes second-order gradients of the maxpooling function.
		
		Args:
		  orig_input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    The original input tensor.
		  orig_output: A `Tensor`. Must have the same type as `orig_input`.
		    The original output tensor.
		  grad: A `Tensor`. Must have the same type as `orig_input`.
		    4-D.  Gradients of gradients w.r.t. the input of `max_pool`.
		  ksize: A list of `ints` that has length `>= 4`.
		    The size of the window for each dimension of the input tensor.
		  strides: A list of `ints` that has length `>= 4`.
		    The stride of the sliding window for each dimension of the
		    input tensor.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `orig_input`.
	**/
	static public function MaxPoolGradGrad(orig_input:Dynamic, orig_output:Dynamic, grad:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes second-order gradients of the maxpooling function.
		
		Args:
		  orig_input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    The original input tensor.
		  orig_output: A `Tensor`. Must have the same type as `orig_input`.
		    The original output tensor.
		  grad: A `Tensor`. Must have the same type as `orig_input`.
		    4-D.  Gradients of gradients w.r.t. the input of `max_pool`.
		  ksize: A `Tensor` of type `int32`.
		    The size of the window for each dimension of the input tensor.
		  strides: A `Tensor` of type `int32`.
		    The stride of the sliding window for each dimension of the
		    input tensor.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `orig_input`.
	**/
	static public function MaxPoolGradGradV2(orig_input:Dynamic, orig_output:Dynamic, grad:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes second-order gradients of the maxpooling function.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    The original input.
		  grad: A `Tensor`. Must have the same type as `input`.
		    4-D with shape `[batch, height, width, channels]`.  Gradients w.r.t. the
		    input of `max_pool`.
		  argmax: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The indices of the maximum values chosen for each output of `max_pool`.
		  ksize: A list of `ints` that has length `>= 4`.
		    The size of the window for each dimension of the input tensor.
		  strides: A list of `ints` that has length `>= 4`.
		    The stride of the sliding window for each dimension of the
		    input tensor.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  include_batch_in_index: An optional `bool`. Defaults to `False`.
		    Whether to include batch dimension in flattened index of `argmax`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MaxPoolGradGradWithArgmax(input:Dynamic, grad:Dynamic, argmax:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?include_batch_in_index:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradients of the maxpooling function.
		
		Args:
		  orig_input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    The original input tensor.
		  orig_output: A `Tensor`. Must have the same type as `orig_input`.
		    The original output tensor.
		  grad: A `Tensor`. Must have the same type as `orig_input`.
		    4-D.  Gradients w.r.t. the output of `max_pool`.
		  ksize: A `Tensor` of type `int32`.
		    The size of the window for each dimension of the input tensor.
		  strides: A `Tensor` of type `int32`.
		    The stride of the sliding window for each dimension of the
		    input tensor.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NHWC", "NCHW"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `orig_input`.
	**/
	static public function MaxPoolGradV2(orig_input:Dynamic, orig_output:Dynamic, grad:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradients of the maxpooling function.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    The original input.
		  grad: A `Tensor`. Must have the same type as `input`.
		    4-D with shape `[batch, height, width, channels]`.  Gradients w.r.t. the
		    output of `max_pool`.
		  argmax: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The indices of the maximum values chosen for each output of `max_pool`.
		  ksize: A list of `ints` that has length `>= 4`.
		    The size of the window for each dimension of the input tensor.
		  strides: A list of `ints` that has length `>= 4`.
		    The stride of the sliding window for each dimension of the
		    input tensor.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  include_batch_in_index: An optional `bool`. Defaults to `False`.
		    Whether to include batch dimension in flattened index of `argmax`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MaxPoolGradWithArgmax(input:Dynamic, grad:Dynamic, argmax:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?include_batch_in_index:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs max pooling on the input.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`, `int64`, `uint8`, `int16`, `int8`, `uint16`, `qint8`.
		    4-D input to pool over.
		  ksize: A `Tensor` of type `int32`.
		    The size of the window for each dimension of the input tensor.
		  strides: A `Tensor` of type `int32`.
		    The stride of the sliding window for each dimension of the
		    input tensor.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  data_format: An optional `string` from: `"NHWC", "NCHW", "NCHW_VECT_C"`. Defaults to `"NHWC"`.
		    Specify the data format of the input and output data. With the
		    default format "NHWC", the data is stored in the order of:
		        [batch, in_height, in_width, in_channels].
		    Alternatively, the format could be "NCHW", the data storage order of:
		        [batch, in_channels, in_height, in_width].
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MaxPoolV2(input:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs max pooling on the input and outputs both max values and indices.
		
		The indices in `argmax` are flattened, so that a maximum value at position
		`[b, y, x, c]` becomes flattened index:
		`(y * width + x) * channels + c` if `include_batch_in_index` is False;
		`((b * height + y) * width + x) * channels + c` if `include_batch_in_index` is True.
		
		The indices returned are always in `[0, height) x [0, width)` before flattening,
		even if padding is involved and the mathematically correct answer is outside
		(either negative or too large).  This is a bug, but fixing it is difficult to do
		in a safe backwards compatible way, especially due to flattening.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    4-D with shape `[batch, height, width, channels]`.  Input to pool over.
		  ksize: A list of `ints` that has length `>= 4`.
		    The size of the window for each dimension of the input tensor.
		  strides: A list of `ints` that has length `>= 4`.
		    The stride of the sliding window for each dimension of the
		    input tensor.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  Targmax: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.
		  include_batch_in_index: An optional `bool`. Defaults to `False`.
		    Whether to include batch dimension in flattened index of `argmax`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, argmax).
		
		  output: A `Tensor`. Has the same type as `input`.
		  argmax: A `Tensor` of type `Targmax`.
	**/
	static public function MaxPoolWithArgmax(input:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?Targmax:Dynamic, ?include_batch_in_index:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the max of x and y (i.e. x > y ? x : y) element-wise.
		
		Example:
		
		>>> x = tf.constant([0., 0., 0., 0.])
		>>> y = tf.constant([-2., 0., 2., 5.])
		>>> tf.math.maximum(x, y)
		<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 2., 5.], dtype=float32)>
		
		Note that `maximum` supports [broadcast semantics](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) for `x` and `y`.
		
		>>> x = tf.constant([-5., 0., 0., 0.])
		>>> y = tf.constant([-3.])
		>>> tf.math.maximum(x, y)
		<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-3., 0., 0., 0.], dtype=float32)>
		
		The reduction version of this elementwise operation is `tf.math.reduce_max`
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `uint32`, `int64`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Maximum(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the mean of elements across dimensions of a tensor.
		
		Reduces `input` along the dimensions given in `axis`. Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`axis`. If `keep_dims` is true, the reduced dimensions are
		retained with length 1.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    The tensor to reduce.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The dimensions to reduce. Must be in the range
		    `[-rank(input), rank(input))`.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Mean(input:Dynamic, axis:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Forwards the value of an available tensor from `inputs` to `output`.
		
		`Merge` waits for at least one of the tensors in `inputs` to become available.
		It is usually combined with `Switch` to implement branching.
		
		`Merge` forwards the first tensor to become available to `output`, and sets
		`value_index` to its index in `inputs`.
		
		Args:
		  inputs: A list of at least 1 `Tensor` objects with the same type.
		    The input tensors, exactly one of which will become available.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, value_index).
		
		  output: A `Tensor`. Has the same type as `inputs`.
		  value_index: A `Tensor` of type `int32`.
	**/
	static public function Merge(inputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Merges summaries.
		
		This op creates a
		[`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)
		protocol buffer that contains the union of all the values in the input
		summaries.
		
		When the Op is run, it reports an `InvalidArgument` error if multiple values
		in the summaries to merge use the same tag.
		
		Args:
		  inputs: A list of at least 1 `Tensor` objects with type `string`.
		    Can be of any shape.  Each must contain serialized `Summary` protocol
		    buffers.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function MergeSummary(inputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		V2 format specific: merges the metadata files of sharded checkpoints.  The
		
		result is one logical checkpoint, with one physical metadata file and renamed
		data files.
		
		Intended for "grouping" multiple checkpoints in a sharded checkpoint setup.
		
		If delete_old_dirs is true, attempts to delete recursively the dirname of each
		path in the input checkpoint_prefixes.  This is useful when those paths are non
		user-facing temporary locations.
		
		Args:
		  checkpoint_prefixes: A `Tensor` of type `string`.
		    prefixes of V2 checkpoints to merge.
		  destination_prefix: A `Tensor` of type `string`.
		    scalar.  The desired final prefix.  Allowed to be the same
		    as one of the checkpoint_prefixes.
		  delete_old_dirs: An optional `bool`. Defaults to `True`. see above.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function MergeV2Checkpoints(checkpoint_prefixes:Dynamic, destination_prefix:Dynamic, ?delete_old_dirs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms a spectrogram into a form that's useful for speech recognition.
		
		Mel Frequency Cepstral Coefficients are a way of representing audio data that's
		been effective as an input feature for machine learning. They are created by
		taking the spectrum of a spectrogram (a 'cepstrum'), and discarding some of the
		higher frequencies that are less significant to the human ear. They have a long
		history in the speech recognition world, and https://en.wikipedia.org/wiki/Mel-frequency_cepstrum
		is a good resource to learn more.
		
		Args:
		  spectrogram: A `Tensor` of type `float32`.
		    Typically produced by the Spectrogram op, with magnitude_squared
		    set to true.
		  sample_rate: A `Tensor` of type `int32`.
		    How many samples per second the source audio used.
		  upper_frequency_limit: An optional `float`. Defaults to `4000`.
		    The highest frequency to use when calculating the
		    ceptstrum.
		  lower_frequency_limit: An optional `float`. Defaults to `20`.
		    The lowest frequency to use when calculating the
		    ceptstrum.
		  filterbank_channel_count: An optional `int`. Defaults to `40`.
		    Resolution of the Mel bank used internally.
		  dct_coefficient_count: An optional `int`. Defaults to `13`.
		    How many output channels to produce per time slice.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function Mfcc(spectrogram:Dynamic, sample_rate:Dynamic, ?upper_frequency_limit:Dynamic, ?lower_frequency_limit:Dynamic, ?filterbank_channel_count:Dynamic, ?dct_coefficient_count:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the minimum of elements across dimensions of a tensor.
		
		Reduces `input` along the dimensions given in `axis`. Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`axis`. If `keep_dims` is true, the reduced dimensions are
		retained with length 1.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The tensor to reduce.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The dimensions to reduce. Must be in the range
		    `[-rank(input), rank(input))`.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Min(input:Dynamic, axis:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the min of x and y (i.e. x < y ? x : y) element-wise.
		
		Both inputs are number-type tensors (except complex).  `minimum` expects that
		both tensors have the same `dtype`.
		
		Examples:
		
		>>> x = tf.constant([0., 0., 0., 0.])
		>>> y = tf.constant([-5., -2., 0., 3.])
		>>> tf.math.minimum(x, y)
		<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-5., -2., 0., 0.], dtype=float32)>
		
		Note that `minimum` supports [broadcast semantics](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) for `x` and `y`.
		
		>>> x = tf.constant([-5., 0., 0., 0.])
		>>> y = tf.constant([-3.])
		>>> tf.math.minimum(x, y)
		<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-5., -3., -3., -3.], dtype=float32)>
		
		The reduction version of this elementwise operation is `tf.math.reduce_min`
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `uint32`, `int64`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Minimum(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Pads a tensor with mirrored values.
		
		This operation pads a `input` with mirrored values according to the `paddings`
		you specify. `paddings` is an integer tensor with shape `[n, 2]`, where n is
		the rank of `input`. For each dimension D of `input`, `paddings[D, 0]` indicates
		how many values to add before the contents of `input` in that dimension, and
		`paddings[D, 1]` indicates how many values to add after the contents of `input`
		in that dimension. Both `paddings[D, 0]` and `paddings[D, 1]` must be no greater
		than `input.dim_size(D)` (or `input.dim_size(D) - 1`) if `copy_border` is true
		(if false, respectively).
		
		The padded size of each dimension D of the output is:
		
		`paddings(D, 0) + input.dim_size(D) + paddings(D, 1)`
		
		For example:
		
		```
		# 't' is [[1, 2, 3], [4, 5, 6]].
		# 'paddings' is [[1, 1]], [2, 2]].
		# 'mode' is SYMMETRIC.
		# rank of 't' is 2.
		pad(t, paddings) ==> [[2, 1, 1, 2, 3, 3, 2]
		                      [2, 1, 1, 2, 3, 3, 2]
		                      [5, 4, 4, 5, 6, 6, 5]
		                      [5, 4, 4, 5, 6, 6, 5]]
		```
		
		Args:
		  input: A `Tensor`. The input tensor to be padded.
		  paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A two-column matrix specifying the padding sizes. The number of
		    rows must be the same as the rank of `input`.
		  mode: A `string` from: `"REFLECT", "SYMMETRIC"`.
		    Either `REFLECT` or `SYMMETRIC`. In reflect mode the padded regions
		    do not include the borders, while in symmetric mode the padded regions
		    do include the borders. For example, if `input` is `[1, 2, 3]` and `paddings`
		    is `[0, 2]`, then the output is `[1, 2, 3, 2, 1]` in reflect mode, and
		    it is `[1, 2, 3, 3, 2]` in symmetric mode.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MirrorPad(input:Dynamic, paddings:Dynamic, mode:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gradient op for `MirrorPad` op. This op folds a mirror-padded tensor.
		
		This operation folds the padded areas of `input` by `MirrorPad` according to the
		`paddings` you specify. `paddings` must be the same as `paddings` argument
		given to the corresponding `MirrorPad` op.
		
		The folded size of each dimension D of the output is:
		
		`input.dim_size(D) - paddings(D, 0) - paddings(D, 1)`
		
		For example:
		
		```
		# 't' is [[1, 2, 3], [4, 5, 6], [7, 8, 9]].
		# 'paddings' is [[0, 1]], [0, 1]].
		# 'mode' is SYMMETRIC.
		# rank of 't' is 2.
		pad(t, paddings) ==> [[ 1,  5]
		                      [11, 28]]
		```
		
		Args:
		  input: A `Tensor`. The input tensor to be folded.
		  paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A two-column matrix specifying the padding sizes. The number of
		    rows must be the same as the rank of `input`.
		  mode: A `string` from: `"REFLECT", "SYMMETRIC"`.
		    The mode used in the `MirrorPad` op.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function MirrorPadGrad(input:Dynamic, paddings:Dynamic, mode:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns element-wise remainder of division. This emulates C semantics in that
		
		the result here is consistent with a truncating divide. E.g.
		`tf.truncatediv(x, y) * y + truncate_mod(x, y) = x`.
		
		*NOTE*: `Mod` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `half`, `half`, `bfloat16`, `float32`, `float64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Mod(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Identity transformation that models performance.
		
		Identity transformation that models performance.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  algorithm: An optional `int`. Defaults to `0`.
		  cpu_budget: An optional `int`. Defaults to `0`.
		  ram_budget: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ModelDataset(input_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?algorithm:Dynamic, ?cpu_budget:Dynamic, ?ram_budget:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x * y element-wise.
		
		*NOTE*: `Multiply` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Mul(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x * y element-wise. Returns zero if y is zero, even if x if infinite or NaN.
		
		*NOTE*: `MulNoNan` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function MulNoNan(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a MultiDeviceIterator resource.
		
		Args:
		  devices: A list of `strings` that has length `>= 1`.
		    A list of devices the iterator works across.
		  shared_name: A `string`.
		    If non-empty, this resource will be shared under the given name
		    across multiple sessions.
		  container: A `string`.
		    If non-empty, this resource is placed in the given container.
		    Otherwise, a default container is used.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type list for the return values.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		    The list of shapes being produced.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function MultiDeviceIterator(devices:Dynamic, shared_name:Dynamic, container:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates a MultiDeviceIterator resource from its provided string handle.
		
		Args:
		  string_handle: A `Tensor` of type `string`.
		    String representing the resource.
		  output_types: An optional list of `tf.DTypes`. Defaults to `[]`.
		    The type list for the return values.
		  output_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    The list of shapes being produced.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function MultiDeviceIteratorFromStringHandle(string_handle:Dynamic, ?output_types:Dynamic, ?output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gets next element for the provided shard number.
		
		Args:
		  multi_device_iterator: A `Tensor` of type `resource`.
		    A MultiDeviceIterator resource.
		  shard_num: A `Tensor` of type `int32`.
		    Integer representing which shard to fetch data for.
		  incarnation_id: A `Tensor` of type `int64`.
		    Which incarnation of the MultiDeviceIterator is running.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type list for the return values.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		    The list of shapes being produced.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `output_types`.
	**/
	static public function MultiDeviceIteratorGetNextFromShard(multi_device_iterator:Dynamic, shard_num:Dynamic, incarnation_id:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Initializes the multi device iterator with the given dataset.
		
		Args:
		  dataset: A `Tensor` of type `variant`. Dataset to be iterated upon.
		  multi_device_iterator: A `Tensor` of type `resource`.
		    A MultiDeviceIteratorResource.
		  max_buffer_size: A `Tensor` of type `int64`.
		    The maximum size of the host side per device buffer to keep.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function MultiDeviceIteratorInit(dataset:Dynamic, multi_device_iterator:Dynamic, max_buffer_size:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Produces a string handle for the given MultiDeviceIterator.
		
		Args:
		  multi_device_iterator: A `Tensor` of type `resource`.
		    A MultiDeviceIterator resource.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function MultiDeviceIteratorToStringHandle(multi_device_iterator:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Draws samples from a multinomial distribution.
		
		Args:
		  logits: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    2-D Tensor with shape `[batch_size, num_classes]`.  Each slice `[i, :]`
		    represents the unnormalized log probabilities for all classes.
		  num_samples: A `Tensor` of type `int32`.
		    0-D.  Number of independent samples to draw for each row slice.
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 is set to be non-zero, the internal random number
		    generator is seeded by the given seed.  Otherwise, a random seed is used.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  output_dtype: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `output_dtype`.
	**/
	static public function Multinomial(logits:Dynamic, num_samples:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?output_dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates an empty hash table that uses tensors as the backing store.
		
		It uses "open addressing" with quadratic reprobing to resolve
		collisions.
		
		This op creates a mutable hash table, specifying the type of its keys and
		values. Each value must be a scalar. Data can be inserted into the table using
		the insert operations. It does not support the initialization operation.
		
		Args:
		  empty_key: A `Tensor`.
		    The key used to represent empty key buckets internally. Must not
		    be used in insert or lookup operations.
		  value_dtype: A `tf.DType`. Type of the table values.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this table is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this table is shared under the given name across
		    multiple sessions.
		  use_node_name_sharing: An optional `bool`. Defaults to `False`.
		  value_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `[]`.
		    The shape of each value.
		  initial_num_buckets: An optional `int`. Defaults to `131072`.
		    The initial number of hash table buckets. Must be a power
		    to 2.
		  max_load_factor: An optional `float`. Defaults to `0.8`.
		    The maximum ratio between number of entries and number of
		    buckets before growing the table. Must be between 0 and 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function MutableDenseHashTable(empty_key:Dynamic, value_dtype:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?use_node_name_sharing:Dynamic, ?value_shape:Dynamic, ?initial_num_buckets:Dynamic, ?max_load_factor:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates an empty hash table that uses tensors as the backing store.
		
		It uses "open addressing" with quadratic reprobing to resolve
		collisions.
		
		This op creates a mutable hash table, specifying the type of its keys and
		values. Each value must be a scalar. Data can be inserted into the table using
		the insert operations. It does not support the initialization operation.
		
		Args:
		  empty_key: A `Tensor`.
		    The key used to represent empty key buckets internally. Must not
		    be used in insert or lookup operations.
		  deleted_key: A `Tensor`. Must have the same type as `empty_key`.
		  value_dtype: A `tf.DType`. Type of the table values.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this table is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this table is shared under the given name across
		    multiple sessions.
		  use_node_name_sharing: An optional `bool`. Defaults to `False`.
		  value_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `[]`.
		    The shape of each value.
		  initial_num_buckets: An optional `int`. Defaults to `131072`.
		    The initial number of hash table buckets. Must be a power
		    to 2.
		  max_load_factor: An optional `float`. Defaults to `0.8`.
		    The maximum ratio between number of entries and number of
		    buckets before growing the table. Must be between 0 and 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function MutableDenseHashTableV2(empty_key:Dynamic, deleted_key:Dynamic, value_dtype:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?use_node_name_sharing:Dynamic, ?value_shape:Dynamic, ?initial_num_buckets:Dynamic, ?max_load_factor:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates an empty hash table.
		
		This op creates a mutable hash table, specifying the type of its keys and
		values. Each value must be a scalar. Data can be inserted into the table using
		the insert operations. It does not support the initialization operation.
		
		Args:
		  key_dtype: A `tf.DType`. Type of the table keys.
		  value_dtype: A `tf.DType`. Type of the table values.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this table is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this table is shared under the given name across
		    multiple sessions.
		  use_node_name_sharing: An optional `bool`. Defaults to `False`.
		    If true and shared_name is empty, the table is shared
		    using the node name.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function MutableHashTable(key_dtype:Dynamic, value_dtype:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?use_node_name_sharing:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates an empty hash table.
		
		This op creates a mutable hash table, specifying the type of its keys and
		values. Each value must be a vector. Data can be inserted into the table using
		the insert operations. It does not support the initialization operation.
		
		Args:
		  key_dtype: A `tf.DType`. Type of the table keys.
		  value_dtype: A `tf.DType`. Type of the table values.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this table is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this table is shared under the given name across
		    multiple sessions.
		  use_node_name_sharing: An optional `bool`. Defaults to `False`.
		  value_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function MutableHashTableOfTensors(key_dtype:Dynamic, value_dtype:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?use_node_name_sharing:Dynamic, ?value_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates an empty hash table.
		
		This op creates a mutable hash table, specifying the type of its keys and
		values. Each value must be a vector. Data can be inserted into the table using
		the insert operations. It does not support the initialization operation.
		
		Args:
		  key_dtype: A `tf.DType`. Type of the table keys.
		  value_dtype: A `tf.DType`. Type of the table values.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this table is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this table is shared under the given name across
		    multiple sessions.
		  use_node_name_sharing: An optional `bool`. Defaults to `False`.
		  value_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function MutableHashTableOfTensorsV2(key_dtype:Dynamic, value_dtype:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?use_node_name_sharing:Dynamic, ?value_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates an empty hash table.
		
		This op creates a mutable hash table, specifying the type of its keys and
		values. Each value must be a scalar. Data can be inserted into the table using
		the insert operations. It does not support the initialization operation.
		
		Args:
		  key_dtype: A `tf.DType`. Type of the table keys.
		  value_dtype: A `tf.DType`. Type of the table values.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this table is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this table is shared under the given name across
		    multiple sessions.
		  use_node_name_sharing: An optional `bool`. Defaults to `False`.
		    If true and shared_name is empty, the table is shared
		    using the node name.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function MutableHashTableV2(key_dtype:Dynamic, value_dtype:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?use_node_name_sharing:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Locks a mutex resource.  The output is the lock.  So long as the lock tensor
		
		is alive, any other request to use `MutexLock` with this mutex will wait.
		
		This is particularly useful for creating a critical section when used in
		conjunction with `MutexLockIdentity`:
		
		```python
		
		mutex = mutex_v2(
		  shared_name=handle_name, container=container, name=name)
		
		def execute_in_critical_section(fn, *args, **kwargs):
		  lock = gen_resource_variable_ops.mutex_lock(mutex)
		
		  with ops.control_dependencies([lock]):
		    r = fn(*args, **kwargs)
		
		  with ops.control_dependencies(nest.flatten(r)):
		    with ops.colocate_with(mutex):
		      ensure_lock_exists = mutex_lock_identity(lock)
		
		    # Make sure that if any element of r is accessed, all of
		    # them are executed together.
		    r = nest.map_structure(tf.identity, r)
		
		  with ops.control_dependencies([ensure_lock_exists]):
		    return nest.map_structure(tf.identity, r)
		```
		
		While `fn` is running in the critical section, no other functions which wish to
		use this critical section may run.
		
		Often the use case is that two executions of the same graph, in parallel,
		wish to run `fn`; and we wish to ensure that only one of them executes
		at a time.  This is especially important if `fn` modifies one or more
		variables at a time.
		
		It is also useful if two separate functions must share a resource, but we
		wish to ensure the usage is exclusive.
		
		Args:
		  mutex: A `Tensor` of type `resource`. The mutex resource to lock.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function MutexLock(mutex:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a Mutex resource that can be locked by `MutexLock`.
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this variable is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this variable is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function MutexV2(?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs a tensor containing the reduction across all input tensors.
		
		Outputs a tensor containing the reduction across all input tensors passed to ops
		within the same `shared_name.
		
		The graph should be constructed so if one op runs with shared_name value `c`,
		then `num_devices` ops will run with shared_name value `c`.  Failure to do so
		will cause the graph execution to fail to complete.
		
		input: the input to the reduction
		data: the value of the reduction across all `num_devices` devices.
		reduction: the reduction operation to perform.
		num_devices: The number of devices participating in this reduction.
		shared_name: Identifier that shared between ops of the same reduction.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `int32`, `int64`.
		  reduction: A `string` from: `"min", "max", "prod", "sum"`.
		  num_devices: An `int`.
		  shared_name: A `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function NcclAllReduce(input:Dynamic, reduction:Dynamic, num_devices:Dynamic, shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Sends `input` to all devices that are connected to the output.
		
		Sends `input` to all devices that are connected to the output.
		
		The graph should be constructed so that all ops connected to the output have a
		valid device assignment, and the op itself is assigned one of these devices.
		
		input: The input to the broadcast.
		output: The same as input.
		shape: The shape of the input tensor.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `int32`, `int64`.
		  shape: A `tf.TensorShape` or list of `ints`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function NcclBroadcast(input:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reduces `input` from `num_devices` using `reduction` to a single device.
		
		Reduces `input` from `num_devices` using `reduction` to a single device.
		
		The graph should be constructed so that all inputs have a valid device
		assignment, and the op itself is assigned one of these devices.
		
		input: The input to the reduction.
		data: the value of the reduction across all `num_devices` devices.
		reduction: the reduction operation to perform.
		
		Args:
		  input: A list of at least 1 `Tensor` objects with the same type in: `half`, `float32`, `float64`, `int32`, `int64`.
		  reduction: A `string` from: `"min", "max", "prod", "sum"`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function NcclReduce(input:Dynamic, reduction:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Ndtri(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes numerical negative value element-wise.
		
		I.e., \\(y = -x\\).
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Neg(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the next representable value of `x1` in the direction of `x2`, element-wise.
		
		This operation returns the same result as the C++ std::nextafter function.
		
		It can also return a subnormal number.
		
		@compatibility(cpp)
		Equivalent to C++ std::nextafter function.
		@end_compatibility
		
		Args:
		  x1: A `Tensor`. Must be one of the following types: `float64`, `float32`.
		  x2: A `Tensor`. Must have the same type as `x1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x1`.
	**/
	static public function NextAfter(x1:Dynamic, x2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Makes its input available to the next iteration.
		
		Args:
		  data: A `Tensor`. The tensor to be made available to the next iteration.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function NextIteration(data:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Does nothing. Only useful as a placeholder for control edges.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function NoOp(?name:Dynamic):Dynamic;
	/**
		Non-deterministically generates some integers.
		
		This op may use some OS-provided source of non-determinism (e.g. an RNG), so each execution will give different results.
		
		Args:
		  shape: A `Tensor`. The shape of the output tensor.
		  dtype: An optional `tf.DType`. Defaults to `tf.int64`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function NonDeterministicInts(shape:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Greedily selects a subset of bounding boxes in descending order of score,
		
		pruning away boxes that have high intersection-over-union (IOU) overlap
		with previously selected boxes.  Bounding boxes are supplied as
		[y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
		diagonal pair of box corners and the coordinates can be provided as normalized
		(i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
		is agnostic to where the origin is in the coordinate system.  Note that this
		algorithm is invariant to orthogonal transformations and translations
		of the coordinate system; thus translating or reflections of the coordinate
		system result in the same boxes being selected by the algorithm.
		The output of this operation is a set of integers indexing into the input
		collection of bounding boxes representing the selected boxes.  The bounding
		box coordinates corresponding to the selected indices can then be obtained
		using the `tf.gather operation`.  For example:
		  selected_indices = tf.image.non_max_suppression(
		      boxes, scores, max_output_size, iou_threshold)
		  selected_boxes = tf.gather(boxes, selected_indices)
		
		Args:
		  boxes: A `Tensor` of type `float32`.
		    A 2-D float tensor of shape `[num_boxes, 4]`.
		  scores: A `Tensor` of type `float32`.
		    A 1-D float tensor of shape `[num_boxes]` representing a single
		    score corresponding to each box (each row of boxes).
		  max_output_size: A `Tensor` of type `int32`.
		    A scalar integer tensor representing the maximum number of
		    boxes to be selected by non max suppression.
		  iou_threshold: An optional `float`. Defaults to `0.5`.
		    A float representing the threshold for deciding whether boxes
		    overlap too much with respect to IOU.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function NonMaxSuppression(boxes:Dynamic, scores:Dynamic, max_output_size:Dynamic, ?iou_threshold:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Greedily selects a subset of bounding boxes in descending order of score,
		
		pruning away boxes that have high intersection-over-union (IOU) overlap
		with previously selected boxes.  Bounding boxes are supplied as
		[y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
		diagonal pair of box corners and the coordinates can be provided as normalized
		(i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
		is agnostic to where the origin is in the coordinate system.  Note that this
		algorithm is invariant to orthogonal transformations and translations
		of the coordinate system; thus translating or reflections of the coordinate
		system result in the same boxes being selected by the algorithm.
		
		The output of this operation is a set of integers indexing into the input
		collection of bounding boxes representing the selected boxes.  The bounding
		box coordinates corresponding to the selected indices can then be obtained
		using the `tf.gather operation`.  For example:
		
		  selected_indices = tf.image.non_max_suppression_v2(
		      boxes, scores, max_output_size, iou_threshold)
		  selected_boxes = tf.gather(boxes, selected_indices)
		
		Args:
		  boxes: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    A 2-D float tensor of shape `[num_boxes, 4]`.
		  scores: A `Tensor`. Must have the same type as `boxes`.
		    A 1-D float tensor of shape `[num_boxes]` representing a single
		    score corresponding to each box (each row of boxes).
		  max_output_size: A `Tensor` of type `int32`.
		    A scalar integer tensor representing the maximum number of
		    boxes to be selected by non max suppression.
		  iou_threshold: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    A 0-D float tensor representing the threshold for deciding whether
		    boxes overlap too much with respect to IOU.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function NonMaxSuppressionV2(boxes:Dynamic, scores:Dynamic, max_output_size:Dynamic, iou_threshold:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Greedily selects a subset of bounding boxes in descending order of score,
		
		pruning away boxes that have high intersection-over-union (IOU) overlap
		with previously selected boxes.  Bounding boxes with score less than
		`score_threshold` are removed.  Bounding boxes are supplied as
		[y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
		diagonal pair of box corners and the coordinates can be provided as normalized
		(i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
		is agnostic to where the origin is in the coordinate system and more
		generally is invariant to orthogonal transformations and translations
		of the coordinate system; thus translating or reflections of the coordinate
		system result in the same boxes being selected by the algorithm.
		The output of this operation is a set of integers indexing into the input
		collection of bounding boxes representing the selected boxes.  The bounding
		box coordinates corresponding to the selected indices can then be obtained
		using the `tf.gather operation`.  For example:
		  selected_indices = tf.image.non_max_suppression_v2(
		      boxes, scores, max_output_size, iou_threshold, score_threshold)
		  selected_boxes = tf.gather(boxes, selected_indices)
		
		Args:
		  boxes: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    A 2-D float tensor of shape `[num_boxes, 4]`.
		  scores: A `Tensor`. Must have the same type as `boxes`.
		    A 1-D float tensor of shape `[num_boxes]` representing a single
		    score corresponding to each box (each row of boxes).
		  max_output_size: A `Tensor` of type `int32`.
		    A scalar integer tensor representing the maximum number of
		    boxes to be selected by non max suppression.
		  iou_threshold: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    A 0-D float tensor representing the threshold for deciding whether
		    boxes overlap too much with respect to IOU.
		  score_threshold: A `Tensor`. Must have the same type as `iou_threshold`.
		    A 0-D float tensor representing the threshold for deciding when to remove
		    boxes based on score.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function NonMaxSuppressionV3(boxes:Dynamic, scores:Dynamic, max_output_size:Dynamic, iou_threshold:Dynamic, score_threshold:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Greedily selects a subset of bounding boxes in descending order of score,
		
		pruning away boxes that have high intersection-over-union (IOU) overlap
		with previously selected boxes.  Bounding boxes with score less than
		`score_threshold` are removed.  Bounding boxes are supplied as
		[y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
		diagonal pair of box corners and the coordinates can be provided as normalized
		(i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
		is agnostic to where the origin is in the coordinate system and more
		generally is invariant to orthogonal transformations and translations
		of the coordinate system; thus translating or reflections of the coordinate
		system result in the same boxes being selected by the algorithm.
		The output of this operation is a set of integers indexing into the input
		collection of bounding boxes representing the selected boxes.  The bounding
		box coordinates corresponding to the selected indices can then be obtained
		using the `tf.gather operation`.  For example:
		  selected_indices = tf.image.non_max_suppression_v2(
		      boxes, scores, max_output_size, iou_threshold, score_threshold)
		  selected_boxes = tf.gather(boxes, selected_indices)
		
		Args:
		  boxes: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    A 2-D float tensor of shape `[num_boxes, 4]`.
		  scores: A `Tensor`. Must have the same type as `boxes`.
		    A 1-D float tensor of shape `[num_boxes]` representing a single
		    score corresponding to each box (each row of boxes).
		  max_output_size: A `Tensor` of type `int32`.
		    A scalar integer tensor representing the maximum number of
		    boxes to be selected by non max suppression.
		  iou_threshold: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    A 0-D float tensor representing the threshold for deciding whether
		    boxes overlap too much with respect to IOU.
		  score_threshold: A `Tensor`. Must have the same type as `iou_threshold`.
		    A 0-D float tensor representing the threshold for deciding when to remove
		    boxes based on score.
		  pad_to_max_output_size: An optional `bool`. Defaults to `False`.
		    If true, the output `selected_indices` is padded to be of length
		    `max_output_size`. Defaults to false.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (selected_indices, valid_outputs).
		
		  selected_indices: A `Tensor` of type `int32`.
		  valid_outputs: A `Tensor` of type `int32`.
	**/
	static public function NonMaxSuppressionV4(boxes:Dynamic, scores:Dynamic, max_output_size:Dynamic, iou_threshold:Dynamic, score_threshold:Dynamic, ?pad_to_max_output_size:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Greedily selects a subset of bounding boxes in descending order of score,
		
		pruning away boxes that have high intersection-over-union (IOU) overlap
		with previously selected boxes.  Bounding boxes with score less than
		`score_threshold` are removed.  Bounding boxes are supplied as
		[y1, x1, y2, x2], where (y1, x1) and (y2, x2) are the coordinates of any
		diagonal pair of box corners and the coordinates can be provided as normalized
		(i.e., lying in the interval [0, 1]) or absolute.  Note that this algorithm
		is agnostic to where the origin is in the coordinate system and more
		generally is invariant to orthogonal transformations and translations
		of the coordinate system; thus translating or reflections of the coordinate
		system result in the same boxes being selected by the algorithm.
		The output of this operation is a set of integers indexing into the input
		collection of bounding boxes representing the selected boxes.  The bounding
		box coordinates corresponding to the selected indices can then be obtained
		using the `tf.gather operation`.  For example:
		  selected_indices = tf.image.non_max_suppression_v2(
		      boxes, scores, max_output_size, iou_threshold, score_threshold)
		  selected_boxes = tf.gather(boxes, selected_indices)
		This op also supports a Soft-NMS (with Gaussian weighting) mode (c.f.
		Bodla et al, https://arxiv.org/abs/1704.04503) where boxes reduce the score
		of other overlapping boxes instead of directly causing them to be pruned.
		To enable this Soft-NMS mode, set the `soft_nms_sigma` parameter to be
		larger than 0.
		
		Args:
		  boxes: A `Tensor`. Must be one of the following types: `half`, `float32`.
		    A 2-D float tensor of shape `[num_boxes, 4]`.
		  scores: A `Tensor`. Must have the same type as `boxes`.
		    A 1-D float tensor of shape `[num_boxes]` representing a single
		    score corresponding to each box (each row of boxes).
		  max_output_size: A `Tensor` of type `int32`.
		    A scalar integer tensor representing the maximum number of
		    boxes to be selected by non max suppression.
		  iou_threshold: A `Tensor`. Must have the same type as `boxes`.
		    A 0-D float tensor representing the threshold for deciding whether
		    boxes overlap too much with respect to IOU.
		  score_threshold: A `Tensor`. Must have the same type as `boxes`.
		    A 0-D float tensor representing the threshold for deciding when to remove
		    boxes based on score.
		  soft_nms_sigma: A `Tensor`. Must have the same type as `boxes`.
		    A 0-D float tensor representing the sigma parameter for Soft NMS; see Bodla et
		    al (c.f. https://arxiv.org/abs/1704.04503).  When `soft_nms_sigma=0.0` (which
		    is default), we fall back to standard (hard) NMS.
		  pad_to_max_output_size: An optional `bool`. Defaults to `False`.
		    If true, the output `selected_indices` is padded to be of length
		    `max_output_size`. Defaults to false.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (selected_indices, selected_scores, valid_outputs).
		
		  selected_indices: A `Tensor` of type `int32`.
		  selected_scores: A `Tensor`. Has the same type as `boxes`.
		  valid_outputs: A `Tensor` of type `int32`.
	**/
	static public function NonMaxSuppressionV5(boxes:Dynamic, scores:Dynamic, max_output_size:Dynamic, iou_threshold:Dynamic, score_threshold:Dynamic, soft_nms_sigma:Dynamic, ?pad_to_max_output_size:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Greedily selects a subset of bounding boxes in descending order of score,
		
		pruning away boxes that have high overlaps
		with previously selected boxes.  Bounding boxes with score less than
		`score_threshold` are removed. N-by-n overlap values are supplied as square matrix,
		which allows for defining a custom overlap criterium (eg. intersection over union,
		intersection over area, etc.).
		
		The output of this operation is a set of integers indexing into the input
		collection of bounding boxes representing the selected boxes.  The bounding
		box coordinates corresponding to the selected indices can then be obtained
		using the `tf.gather operation`.  For example:
		
		  selected_indices = tf.image.non_max_suppression_with_overlaps(
		      overlaps, scores, max_output_size, overlap_threshold, score_threshold)
		  selected_boxes = tf.gather(boxes, selected_indices)
		
		Args:
		  overlaps: A `Tensor` of type `float32`.
		    A 2-D float tensor of shape `[num_boxes, num_boxes]` representing
		    the n-by-n box overlap values.
		  scores: A `Tensor` of type `float32`.
		    A 1-D float tensor of shape `[num_boxes]` representing a single
		    score corresponding to each box (each row of boxes).
		  max_output_size: A `Tensor` of type `int32`.
		    A scalar integer tensor representing the maximum number of
		    boxes to be selected by non max suppression.
		  overlap_threshold: A `Tensor` of type `float32`.
		    A 0-D float tensor representing the threshold for deciding whether
		    boxes overlap too.
		  score_threshold: A `Tensor` of type `float32`.
		    A 0-D float tensor representing the threshold for deciding when to remove
		    boxes based on score.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function NonMaxSuppressionWithOverlaps(overlaps:Dynamic, scores:Dynamic, max_output_size:Dynamic, overlap_threshold:Dynamic, score_threshold:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function NonSerializableDataset(input_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the truth value of (x != y) element-wise.
		
		*NOTE*: `NotEqual` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`.
		  y: A `Tensor`. Must have the same type as `x`.
		  incompatible_shape_error: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function NotEqual(x:Dynamic, y:Dynamic, ?incompatible_shape_error:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Finds values of the `n`-th order statistic for the last dimension.
		
		If the input is a vector (rank-1), finds the entries which is the nth-smallest
		value in the vector and outputs their values as scalar tensor.
		
		For matrices (resp. higher rank input), computes the entries which is the
		nth-smallest value in each row (resp. vector along the last dimension). Thus,
		
		    values.shape = input.shape[:-1]
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    1-D or higher with last dimension at least `n+1`.
		  n: A `Tensor` of type `int32`.
		    0-D. Position of sorted vector to select along the last dimension (along
		    each row for matrices). Valid range of n is `[0, input.shape[:-1])`
		  reverse: An optional `bool`. Defaults to `False`.
		    When set to True, find the nth-largest value in the vector and vice
		    versa.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function NthElement(input:Dynamic, n:Dynamic, ?reverse:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a one-hot tensor.
		
		The locations represented by indices in `indices` take value `on_value`,
		while all other locations take value `off_value`.
		
		If the input `indices` is rank `N`, the output will have rank `N+1`,
		The new axis is created at dimension `axis` (default: the new axis is
		appended at the end).
		
		If `indices` is a scalar the output shape will be a vector of length `depth`.
		
		If `indices` is a vector of length `features`, the output shape will be:
		```
		  features x depth if axis == -1
		  depth x features if axis == 0
		```
		
		If `indices` is a matrix (batch) with shape `[batch, features]`,
		the output shape will be:
		```
		  batch x features x depth if axis == -1
		  batch x depth x features if axis == 1
		  depth x batch x features if axis == 0
		```
		
		
		Examples
		=========
		
		Suppose that
		```
		  indices = [0, 2, -1, 1]
		  depth = 3
		  on_value = 5.0
		  off_value = 0.0
		  axis = -1
		```
		
		Then output is `[4 x 3]`:
		```
		output =
		  [5.0 0.0 0.0]  // one_hot(0)
		  [0.0 0.0 5.0]  // one_hot(2)
		  [0.0 0.0 0.0]  // one_hot(-1)
		  [0.0 5.0 0.0]  // one_hot(1)
		```
		
		Suppose that
		```
		  indices = [0, 2, -1, 1]
		  depth = 3
		  on_value = 0.0
		  off_value = 3.0
		  axis = 0
		```
		
		Then output is `[3 x 4]`:
		```
		output =
		  [0.0 3.0 3.0 3.0]
		  [3.0 3.0 3.0 0.0]
		  [3.0 3.0 3.0 3.0]
		  [3.0 0.0 3.0 3.0]
		//  ^                one_hot(0)
		//      ^            one_hot(2)
		//          ^        one_hot(-1)
		//              ^    one_hot(1)
		```
		
		Suppose that
		```
		  indices = [[0, 2], [1, -1]]
		  depth = 3
		  on_value = 1.0
		  off_value = 0.0
		  axis = -1
		```
		
		Then output is `[2 x 2 x 3]`:
		```
		output =
		  [
		    [1.0, 0.0, 0.0]  // one_hot(0)
		    [0.0, 0.0, 1.0]  // one_hot(2)
		  ][
		    [0.0, 1.0, 0.0]  // one_hot(1)
		    [0.0, 0.0, 0.0]  // one_hot(-1)
		  ]
		```
		
		Args:
		  indices: A `Tensor`. Must be one of the following types: `uint8`, `int32`, `int64`.
		    A tensor of indices.
		  depth: A `Tensor` of type `int32`.
		    A scalar defining the depth of the one hot dimension.
		  on_value: A `Tensor`.
		    A scalar defining the value to fill in output when `indices[j] = i`.
		  off_value: A `Tensor`. Must have the same type as `on_value`.
		    A scalar defining the value to fill in output when `indices[j] != i`.
		  axis: An optional `int`. Defaults to `-1`.
		    The axis to fill (default: -1, a new inner-most axis).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `on_value`.
	**/
	static public function OneHot(indices:Dynamic, depth:Dynamic, on_value:Dynamic, off_value:Dynamic, ?axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Makes a "one-shot" iterator that can be iterated only once.
		
		A one-shot iterator bundles the logic for defining the dataset and
		the state of the iterator in a single op, which allows simple input
		pipelines to be defined without an additional initialization
		("MakeIterator") step.
		
		One-shot iterators have the following limitations:
		
		* They do not support parameterization: all logic for creating the underlying
		  dataset must be bundled in the `dataset_factory` function.
		* They are not resettable. Once a one-shot iterator reaches the end of its
		  underlying dataset, subsequent "IteratorGetNext" operations on that
		  iterator will always produce an `OutOfRange` error.
		
		For greater flexibility, use "Iterator" and "MakeIterator" to define
		an iterator using an arbitrary subgraph, which may capture tensors
		(including fed values) as parameters, and which may be reset multiple
		times by rerunning "MakeIterator".
		
		Args:
		  dataset_factory: A function decorated with @Defun.
		    A function of type `() -> DT_VARIANT`, where the returned
		    DT_VARIANT is a dataset.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function OneShotIterator(dataset_factory:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a tensor of ones with the same shape and type as x.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`, `complex64`, `complex128`, `bool`.
		    a tensor of type T.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function OnesLike(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset by applying optimizations to `input_dataset`.
		
		Creates a dataset by applying optimizations to `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  optimizations: A `Tensor` of type `string`.
		    A `tf.string` vector `tf.Tensor` identifying optimizations to use.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  optimization_configs: An optional list of `strings`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function OptimizeDataset(input_dataset:Dynamic, optimizations:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?optimization_configs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset by applying related optimizations to `input_dataset`.
		
		Creates a dataset by applying related optimizations to `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  optimizations_enabled: A `Tensor` of type `string`.
		    A `tf.string` vector `tf.Tensor` identifying user enabled optimizations.
		  optimizations_disabled: A `Tensor` of type `string`.
		    A `tf.string` vector `tf.Tensor` identifying user disabled optimizations.
		  optimizations_default: A `Tensor` of type `string`.
		    A `tf.string` vector `tf.Tensor` identifying optimizations by default.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  optimization_configs: An optional list of `strings`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function OptimizeDatasetV2(input_dataset:Dynamic, optimizations_enabled:Dynamic, optimizations_disabled:Dynamic, optimizations_default:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?optimization_configs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Constructs an Optional variant from a tuple of tensors.
		
		Args:
		  components: A list of `Tensor` objects.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function OptionalFromValue(components:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the value stored in an Optional variant or raises an error if none exists.
		
		Args:
		  optional: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `output_types`.
	**/
	static public function OptionalGetValue(optional:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns true if and only if the given Optional variant has a value.
		
		Args:
		  optional: A `Tensor` of type `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function OptionalHasValue(optional:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates an Optional variant with no value.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function OptionalNone(?name:Dynamic):Dynamic;
	/**
		Creates a dataset by attaching tf.data.Options to `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  serialized_options: A `string`.
		    A `tf.string` scalar `tf.Tensor` of serialized `tf.data.Options` protocol buffer.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function OptionsDataset(input_dataset:Dynamic, serialized_options:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op removes all elements in the underlying container.
		
		Args:
		  dtypes: A list of `tf.DTypes`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function OrderedMapClear(dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op returns the number of incomplete elements in the underlying container.
		
		Args:
		  dtypes: A list of `tf.DTypes`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function OrderedMapIncompleteSize(dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op peeks at the values at the specified key.  If the
		
		underlying container does not contain this key
		this op will block until it does.   This Op is optimized for
		performance.
		
		Args:
		  key: A `Tensor` of type `int64`.
		  indices: A `Tensor` of type `int32`.
		  dtypes: A list of `tf.DTypes` that has length `>= 1`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `dtypes`.
	**/
	static public function OrderedMapPeek(key:Dynamic, indices:Dynamic, dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op returns the number of elements in the underlying container.
		
		Args:
		  dtypes: A list of `tf.DTypes`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function OrderedMapSize(dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Stage (key, values) in the underlying container which behaves like a ordered
		
		associative container.   Elements are ordered by key.
		
		Args:
		  key: A `Tensor` of type `int64`. int64
		  indices: A `Tensor` of type `int32`.
		  values: A list of `Tensor` objects. a list of tensors
		    dtypes A list of data types that inserted values should adhere to.
		  dtypes: A list of `tf.DTypes`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		    Maximum number of elements in the Staging Area. If > 0, inserts
		    on the container will block when the capacity is reached.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this queue is placed in the given container. Otherwise,
		    a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    It is necessary to match this name to the matching Unstage Op.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function OrderedMapStage(key:Dynamic, indices:Dynamic, values:Dynamic, dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op removes and returns the values associated with the key
		
		from the underlying container.   If the underlying container
		does not contain this key, the op will block until it does.
		
		Args:
		  key: A `Tensor` of type `int64`.
		  indices: A `Tensor` of type `int32`.
		  dtypes: A list of `tf.DTypes` that has length `>= 1`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `dtypes`.
	**/
	static public function OrderedMapUnstage(key:Dynamic, indices:Dynamic, dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op removes and returns the (key, value) element with the smallest
		
		key from the underlying container.   If the underlying container
		does not contain elements, the op will block until it does.
		
		Args:
		  indices: A `Tensor` of type `int32`.
		  dtypes: A list of `tf.DTypes` that has length `>= 1`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (key, values).
		
		  key: A `Tensor` of type `int64`.
		  values: A list of `Tensor` objects of type `dtypes`.
	**/
	static public function OrderedMapUnstageNoKey(indices:Dynamic, dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieves a single tensor from the computation outfeed.
		
		This operation will block indefinitely until data is available.
		
		Args:
		  dtype: A `tf.DType`. The type of elements in the tensor.
		  shape: A `tf.TensorShape` or list of `ints`. The shape of the tensor.
		  device_ordinal: An optional `int`. Defaults to `-1`.
		    The TPU device to use. This should be -1 when the Op
		    is running on a TPU device, and >= 0 when the Op is running on the CPU
		    device.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function OutfeedDequeue(dtype:Dynamic, shape:Dynamic, ?device_ordinal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve multiple values from the computation outfeed.
		
		This operation will block indefinitely until data is available. Output `i`
		corresponds to XLA tuple element `i`.
		
		Args:
		  dtypes: A list of `tf.DTypes` that has length `>= 1`.
		    The element types of each element in `outputs`.
		  shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    The shapes of each tensor in `outputs`.
		  device_ordinal: An optional `int`. Defaults to `-1`.
		    The TPU device to use. This should be -1 when the Op
		    is running on a TPU device, and >= 0 when the Op is running on the CPU
		    device.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `dtypes`.
	**/
	static public function OutfeedDequeueTuple(dtypes:Dynamic, shapes:Dynamic, ?device_ordinal:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve multiple values from the computation outfeed. Device ordinal is a
		tensor allowing dynamic outfeed.
		
		  This operation will block indefinitely until data is available. Output `i`
		  corresponds to XLA tuple element `i`.
		
		  Args:
		    device_ordinal: A `Tensor` of type `int32`.
		      An int scalar tensor, representing the TPU device to use. This should be -1 when
		      the Op is running on a TPU device, and >= 0 when the Op is running on the CPU
		      device.
		    dtypes: A list of `tf.DTypes` that has length `>= 1`.
		      The element types of each element in `outputs`.
		    shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		      The shapes of each tensor in `outputs`.
		    name: A name for the operation (optional).
		
		  Returns:
		    A list of `Tensor` objects of type `dtypes`.
		  
	**/
	static public function OutfeedDequeueTupleV2(device_ordinal:Dynamic, dtypes:Dynamic, shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieves a single tensor from the computation outfeed. Device ordinal is a
		tensor allowing dynamic outfeed.
		
		  This operation will block indefinitely until data is available.
		
		  Args:
		    device_ordinal: A `Tensor` of type `int32`.
		      An int scalar tensor, representing the TPU device to use. This should be -1 when
		      the Op is running on a TPU device, and >= 0 when the Op is running on the CPU
		      device.
		    dtype: A `tf.DType`. The type of elements in the tensor.
		    shape: A `tf.TensorShape` or list of `ints`. The shape of the tensor.
		    name: A name for the operation (optional).
		
		  Returns:
		    A `Tensor` of type `dtype`.
		  
	**/
	static public function OutfeedDequeueV2(device_ordinal:Dynamic, dtype:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Enqueue a Tensor on the computation outfeed.
		
		Args:
		  input: A `Tensor`. A tensor that will be inserted into the outfeed queue.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function OutfeedEnqueue(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Enqueue multiple Tensor values on the computation outfeed.
		
		Args:
		  inputs: A list of `Tensor` objects.
		    A list of tensors that will be inserted into the outfeed queue as an
		    XLA tuple.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function OutfeedEnqueueTuple(inputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Packs a list of `N` rank-`R` tensors into one rank-`(R+1)` tensor.
		
		Packs the `N` tensors in `values` into a tensor with rank one higher than each
		tensor in `values`, by packing them along the `axis` dimension.
		Given a list of tensors of shape `(A, B, C)`;
		
		if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.
		if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.
		Etc.
		
		For example:
		
		```
		# 'x' is [1, 4]
		# 'y' is [2, 5]
		# 'z' is [3, 6]
		pack([x, y, z]) => [[1, 4], [2, 5], [3, 6]]  # Pack along first dim.
		pack([x, y, z], axis=1) => [[1, 2, 3], [4, 5, 6]]
		```
		
		This is the opposite of `unpack`.
		
		Args:
		  values: A list of at least 1 `Tensor` objects with the same type.
		    Must be of same shape and type.
		  axis: An optional `int`. Defaults to `0`.
		    Dimension along which to pack.  Negative values wrap around, so the
		    valid range is `[-(R+1), R+1)`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `values`.
	**/
	static public function Pack(values:Dynamic, ?axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Pads a tensor with zeros.
		
		This operation pads a `input` with zeros according to the `paddings` you
		specify. `paddings` is an integer tensor with shape `[Dn, 2]`, where n is the
		rank of `input`. For each dimension D of `input`, `paddings[D, 0]` indicates
		how many zeros to add before the contents of `input` in that dimension, and
		`paddings[D, 1]` indicates how many zeros to add after the contents of `input`
		in that dimension.
		
		The padded size of each dimension D of the output is:
		
		`paddings(D, 0) + input.dim_size(D) + paddings(D, 1)`
		
		For example:
		
		```
		# 't' is [[1, 1], [2, 2]]
		# 'paddings' is [[1, 1], [2, 2]]
		# rank of 't' is 2
		pad(t, paddings) ==> [[0, 0, 0, 0, 0, 0]
		                      [0, 0, 1, 1, 0, 0]
		                      [0, 0, 2, 2, 0, 0]
		                      [0, 0, 0, 0, 0, 0]]
		```
		
		Args:
		  input: A `Tensor`.
		  paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Pad(input:Dynamic, paddings:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Pads a tensor.
		
		This operation pads `input` according to the `paddings` and `constant_values`
		you specify. `paddings` is an integer tensor with shape `[Dn, 2]`, where n is
		the rank of `input`. For each dimension D of `input`, `paddings[D, 0]` indicates
		how many padding values to add before the contents of `input` in that dimension,
		and `paddings[D, 1]` indicates how many padding values to add after the contents
		of `input` in that dimension. `constant_values` is a scalar tensor of the same
		type as `input` that indicates the value to use for padding `input`.
		
		The padded size of each dimension D of the output is:
		
		`paddings(D, 0) + input.dim_size(D) + paddings(D, 1)`
		
		For example:
		
		```
		# 't' is [[1, 1], [2, 2]]
		# 'paddings' is [[1, 1], [2, 2]]
		# 'constant_values' is 0
		# rank of 't' is 2
		pad(t, paddings) ==> [[0, 0, 0, 0, 0, 0]
		                      [0, 0, 1, 1, 0, 0]
		                      [0, 0, 2, 2, 0, 0]
		                      [0, 0, 0, 0, 0, 0]]
		```
		
		Args:
		  input: A `Tensor`.
		  paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  constant_values: A `Tensor`. Must have the same type as `input`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function PadV2(input:Dynamic, paddings:Dynamic, constant_values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that batches and pads `batch_size` elements from the input.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  batch_size: A `Tensor` of type `int64`.
		    A scalar representing the number of elements to accumulate in a
		    batch.
		  padded_shapes: A list of at least 1 `Tensor` objects with type `int64`.
		    A list of int64 tensors representing the desired padded shapes
		    of the corresponding output components. These shapes may be partially
		    specified, using `-1` to indicate that a particular dimension should be
		    padded to the maximum size of all batch elements.
		  padding_values: A list of `Tensor` objects.
		    A list of scalars containing the padding value to use for
		    each of the outputs.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function PaddedBatchDataset(input_dataset:Dynamic, batch_size:Dynamic, padded_shapes:Dynamic, padding_values:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that batches and pads `batch_size` elements from the input.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  batch_size: A `Tensor` of type `int64`.
		    A scalar representing the number of elements to accumulate in a
		    batch.
		  padded_shapes: A list of at least 1 `Tensor` objects with type `int64`.
		    A list of int64 tensors representing the desired padded shapes
		    of the corresponding output components. These shapes may be partially
		    specified, using `-1` to indicate that a particular dimension should be
		    padded to the maximum size of all batch elements.
		  padding_values: A list of `Tensor` objects.
		    A list of scalars containing the padding value to use for
		    each of the outputs.
		  drop_remainder: A `Tensor` of type `bool`.
		    A scalar representing whether the last batch should be dropped in case its size
		    is smaller than desired.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  parallel_copy: An optional `bool`. Defaults to `False`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function PaddedBatchDatasetV2(input_dataset:Dynamic, batch_size:Dynamic, padded_shapes:Dynamic, padding_values:Dynamic, drop_remainder:Dynamic, output_shapes:Dynamic, ?parallel_copy:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A queue that produces elements in first-in first-out order.
		
		Variable-size shapes are allowed by setting the corresponding shape dimensions
		to 0 in the shape attr.  In this case DequeueMany will pad up to the maximum
		size of any given element in the minibatch.  See below for details.
		
		Args:
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a value.
		  shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    The shape of each component in a value. The length of this attr must
		    be either 0 or the same as the length of component_types.
		    Shapes of fixed rank but variable size are allowed by setting
		    any shape dimension to -1.  In this case, the inputs' shape may vary along
		    the given dimension, and DequeueMany will pad the given dimension with
		    zeros up to the maximum shape of all elements in the given batch.
		    If the length of this attr is 0, different queue elements may have
		    different ranks and shapes, but only one element may be dequeued at a time.
		  capacity: An optional `int`. Defaults to `-1`.
		    The upper bound on the number of elements in this queue.
		    Negative numbers mean no limit.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this queue is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this queue will be shared under the given name
		    across multiple sessions.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function PaddingFIFOQueue(component_types:Dynamic, ?shapes:Dynamic, ?capacity:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A queue that produces elements in first-in first-out order.
		
		Variable-size shapes are allowed by setting the corresponding shape dimensions
		to 0 in the shape attr.  In this case DequeueMany will pad up to the maximum
		size of any given element in the minibatch.  See below for details.
		
		Args:
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a value.
		  shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    The shape of each component in a value. The length of this attr must
		    be either 0 or the same as the length of component_types.
		    Shapes of fixed rank but variable size are allowed by setting
		    any shape dimension to -1.  In this case, the inputs' shape may vary along
		    the given dimension, and DequeueMany will pad the given dimension with
		    zeros up to the maximum shape of all elements in the given batch.
		    If the length of this attr is 0, different queue elements may have
		    different ranks and shapes, but only one element may be dequeued at a time.
		  capacity: An optional `int`. Defaults to `-1`.
		    The upper bound on the number of elements in this queue.
		    Negative numbers mean no limit.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this queue is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this queue will be shared under the given name
		    across multiple sessions.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function PaddingFIFOQueueV2(component_types:Dynamic, ?shapes:Dynamic, ?capacity:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  batch_size: A `Tensor` of type `int64`.
		  num_parallel_calls: A `Tensor` of type `int64`.
		  drop_remainder: A `Tensor` of type `bool`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  parallel_copy: An optional `bool`. Defaults to `False`.
		  deterministic: An optional `string`. Defaults to `"default"`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ParallelBatchDataset(input_dataset:Dynamic, batch_size:Dynamic, num_parallel_calls:Dynamic, drop_remainder:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?parallel_copy:Dynamic, ?deterministic:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Concatenates a list of `N` tensors along the first dimension.
		
		The input tensors are all required to have size 1 in the first dimension.
		
		For example:
		
		```
		# 'x' is [[1, 4]]
		# 'y' is [[2, 5]]
		# 'z' is [[3, 6]]
		parallel_concat([x, y, z]) => [[1, 4], [2, 5], [3, 6]]  # Pack along first dim.
		```
		
		The difference between concat and parallel_concat is that concat requires all
		of the inputs be computed before the operation will begin but doesn't require
		that the input shapes be known during graph construction.  Parallel concat
		will copy pieces of the input into the output as they become available, in
		some situations this can provide a performance benefit.
		
		Args:
		  values: A list of at least 1 `Tensor` objects with the same type.
		    Tensors to be concatenated. All must have size 1 in the first dimension
		    and same shape.
		  shape: A `tf.TensorShape` or list of `ints`.
		    the final shape of the result; should be equal to the shapes of any input
		    but with the number of input values in the first dimension.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `values`.
	**/
	static public function ParallelConcat(values:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Interleave the values from the `data` tensors into a single tensor.
		
		Builds a merged tensor such that
		
		```python
		    merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
		```
		
		For example, if each `indices[m]` is scalar or vector, we have
		
		```python
		    # Scalar indices:
		    merged[indices[m], ...] = data[m][...]
		
		    # Vector indices:
		    merged[indices[m][i], ...] = data[m][i, ...]
		```
		
		Each `data[i].shape` must start with the corresponding `indices[i].shape`,
		and the rest of `data[i].shape` must be constant w.r.t. `i`.  That is, we
		must have `data[i].shape = indices[i].shape + constant`.  In terms of this
		`constant`, the output shape is
		
		    merged.shape = [max(indices)] + constant
		
		Values may be merged in parallel, so if an index appears in both `indices[m][i]`
		and `indices[n][j]`, the result may be invalid. This differs from the normal
		DynamicStitch operator that defines the behavior in that case.
		
		For example:
		
		```python
		    indices[0] = 6
		    indices[1] = [4, 1]
		    indices[2] = [[5, 2], [0, 3]]
		    data[0] = [61, 62]
		    data[1] = [[41, 42], [11, 12]]
		    data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
		    merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
		              [51, 52], [61, 62]]
		```
		
		This method can be used to merge partitions created by `dynamic_partition`
		as illustrated on the following example:
		
		```python
		    # Apply function (increments x_i) on elements for which a certain condition
		    # apply (x_i != -1 in this example).
		    x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])
		    condition_mask=tf.not_equal(x,tf.constant(-1.))
		    partitioned_data = tf.dynamic_partition(
		        x, tf.cast(condition_mask, tf.int32) , 2)
		    partitioned_data[1] = partitioned_data[1] + 1.0
		    condition_indices = tf.dynamic_partition(
		        tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)
		    x = tf.dynamic_stitch(condition_indices, partitioned_data)
		    # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain
		    # unchanged.
		```
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/DynamicStitch.png" alt>
		</div>
		
		Args:
		  indices: A list of at least 1 `Tensor` objects with type `int32`.
		  data: A list with the same length as `indices` of `Tensor` objects with the same type.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function ParallelDynamicStitch(indices:Dynamic, data:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		The resulting dataset is similar to the `InterleaveDataset`, with the exception
		that if retrieving the next value from a dataset would cause the requester to
		block, it will skip that input dataset. This dataset is especially useful
		when loading data from a variable-latency datastores (e.g. HDFS, GCS), as it
		allows the training step to proceed so long as some data is available.
		
		!! WARNING !! If the `sloppy` parameter is set to `True`, the operation of this
		dataset will not be deterministic!
		
		This dataset has been superseded by `ParallelInterleaveDatasetV2`.  New code
		should use `ParallelInterleaveDatasetV2`.
		
		The Python API `tf.data.experimental.parallel_interleave` creates instances of
		this op. `tf.data.experimental.parallel_interleave` is a deprecated API.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    Dataset that produces a stream of arguments for the function `f`.
		  other_arguments: A list of `Tensor` objects.
		    Additional arguments to pass to `f` beyond those produced by `input_dataset`.
		    Evaluated once when the dataset is instantiated.
		  cycle_length: A `Tensor` of type `int64`.
		    Number of datasets (each created by applying `f` to the elements of
		    `input_dataset`) among which the `ParallelInterleaveDataset` will cycle in a
		    round-robin fashion.
		  block_length: A `Tensor` of type `int64`.
		    Number of elements at a time to produce from each interleaved invocation of a
		    dataset returned by `f`.
		  sloppy: A `Tensor` of type `bool`.
		    If `True`, return elements as they become available, even if that means returning
		    these elements in a non-deterministic order. Sloppy operation may result in better
		    performance in the presence of stragglers, but the dataset will still block if
		    all of its open streams are blocked.
		    If `False`, always return elements in a deterministic order.
		  buffer_output_elements: A `Tensor` of type `int64`.
		    The number of elements each iterator being interleaved should buffer (similar
		    to the `.prefetch()` transformation for each interleaved iterator).
		  prefetch_input_elements: A `Tensor` of type `int64`.
		    Determines the number of iterators to prefetch, allowing buffers to warm up and
		    data to be pre-fetched without blocking the main thread.
		  f: A function decorated with @Defun.
		    A function mapping elements of `input_dataset`, concatenated with
		    `other_arguments`, to a Dataset variant that contains elements matching
		    `output_types` and `output_shapes`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ParallelInterleaveDataset(input_dataset:Dynamic, other_arguments:Dynamic, cycle_length:Dynamic, block_length:Dynamic, sloppy:Dynamic, buffer_output_elements:Dynamic, prefetch_input_elements:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		The resulting dataset is similar to the `InterleaveDataset`, except that the
		dataset will fetch records from the interleaved datasets in parallel.
		
		The `tf.data` Python API creates instances of this op from
		`Dataset.interleave()` when the `num_parallel_calls` parameter of that method
		is set to any value other than `None`.
		
		By default, the output of this dataset will be deterministic, which may result
		in the dataset blocking if the next data item to be returned isn't available.
		In order to avoid head-of-line blocking, one can set the
		`experimental_deterministic` parameter of `tf.data.Options` to `False`,
		which can improve performance at the expense of non-determinism.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    Dataset that produces a stream of arguments for the function `f`.
		  other_arguments: A list of `Tensor` objects.
		    Additional arguments to pass to `f` beyond those produced by `input_dataset`.
		    Evaluated once when the dataset is instantiated.
		  cycle_length: A `Tensor` of type `int64`.
		    Number of datasets (each created by applying `f` to the elements of
		    `input_dataset`) among which the `ParallelInterleaveDatasetV2` will cycle in a
		    round-robin fashion.
		  block_length: A `Tensor` of type `int64`.
		    Number of elements at a time to produce from each interleaved invocation of a
		    dataset returned by `f`.
		  num_parallel_calls: A `Tensor` of type `int64`.
		    Determines the number of threads that should be used for fetching data from
		    input datasets in parallel. The Python API `tf.data.experimental.AUTOTUNE`
		    constant can be used to indicate that the level of parallelism should be autotuned.
		  f: A function decorated with @Defun.
		    A function mapping elements of `input_dataset`, concatenated with
		    `other_arguments`, to a Dataset variant that contains elements matching
		    `output_types` and `output_shapes`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  sloppy: An optional `bool`. Defaults to `False`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ParallelInterleaveDatasetV2(input_dataset:Dynamic, other_arguments:Dynamic, cycle_length:Dynamic, block_length:Dynamic, num_parallel_calls:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?sloppy:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		The resulting dataset is similar to the `InterleaveDataset`, except that the
		dataset will fetch records from the interleaved datasets in parallel.
		
		The `tf.data` Python API creates instances of this op from
		`Dataset.interleave()` when the `num_parallel_calls` parameter of that method
		is set to any value other than `None`.
		
		By default, the output of this dataset will be deterministic, which may result
		in the dataset blocking if the next data item to be returned isn't available.
		In order to avoid head-of-line blocking, one can either set the `deterministic`
		attribute to "false", or leave it as "default" and set the
		`experimental_deterministic` parameter of `tf.data.Options` to `False`.
		This can improve performance at the expense of non-determinism.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    Dataset that produces a stream of arguments for the function `f`.
		  other_arguments: A list of `Tensor` objects.
		    Additional arguments to pass to `f` beyond those produced by `input_dataset`.
		    Evaluated once when the dataset is instantiated.
		  cycle_length: A `Tensor` of type `int64`.
		    Number of datasets (each created by applying `f` to the elements of
		    `input_dataset`) among which the `ParallelInterleaveDatasetV2` will cycle in a
		    round-robin fashion.
		  block_length: A `Tensor` of type `int64`.
		    Number of elements at a time to produce from each interleaved invocation of a
		    dataset returned by `f`.
		  num_parallel_calls: A `Tensor` of type `int64`.
		    Determines the number of threads that should be used for fetching data from
		    input datasets in parallel. The Python API `tf.data.experimental.AUTOTUNE`
		    constant can be used to indicate that the level of parallelism should be autotuned.
		  f: A function decorated with @Defun.
		    A function mapping elements of `input_dataset`, concatenated with
		    `other_arguments`, to a Dataset variant that contains elements matching
		    `output_types` and `output_shapes`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  deterministic: An optional `string`. Defaults to `"default"`.
		    A string indicating the op-level determinism to use. Deterministic controls
		    whether the interleave is allowed to return elements out of order if the next
		    element to be returned isn't available, but a later element is. Options are
		    "true", "false", and "default". "default" indicates that determinism should be
		    decided by the `experimental_deterministic` parameter of `tf.data.Options`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ParallelInterleaveDatasetV3(input_dataset:Dynamic, other_arguments:Dynamic, cycle_length:Dynamic, block_length:Dynamic, num_parallel_calls:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?deterministic:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		The resulting dataset is similar to the `InterleaveDataset`, except that the
		dataset will fetch records from the interleaved datasets in parallel.
		
		The `tf.data` Python API creates instances of this op from
		`Dataset.interleave()` when the `num_parallel_calls` parameter of that method
		is set to any value other than `None`.
		
		By default, the output of this dataset will be deterministic, which may result
		in the dataset blocking if the next data item to be returned isn't available.
		In order to avoid head-of-line blocking, one can either set the `deterministic`
		attribute to "false", or leave it as "default" and set the
		`experimental_deterministic` parameter of `tf.data.Options` to `False`.
		This can improve performance at the expense of non-determinism.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    Dataset that produces a stream of arguments for the function `f`.
		  other_arguments: A list of `Tensor` objects.
		    Additional arguments to pass to `f` beyond those produced by `input_dataset`.
		    Evaluated once when the dataset is instantiated.
		  cycle_length: A `Tensor` of type `int64`.
		    Number of datasets (each created by applying `f` to the elements of
		    `input_dataset`) among which the `ParallelInterleaveDatasetV2` will cycle in a
		    round-robin fashion.
		  block_length: A `Tensor` of type `int64`.
		    Number of elements at a time to produce from each interleaved invocation of a
		    dataset returned by `f`.
		  buffer_output_elements: A `Tensor` of type `int64`.
		    The number of elements each iterator being interleaved should buffer (similar
		    to the `.prefetch()` transformation for each interleaved iterator).
		  prefetch_input_elements: A `Tensor` of type `int64`.
		    Determines the number of iterators to prefetch, allowing buffers to warm up and
		    data to be pre-fetched without blocking the main thread.
		  num_parallel_calls: A `Tensor` of type `int64`.
		    Determines the number of threads that should be used for fetching data from
		    input datasets in parallel. The Python API `tf.data.experimental.AUTOTUNE`
		    constant can be used to indicate that the level of parallelism should be autotuned.
		  f: A function decorated with @Defun.
		    A function mapping elements of `input_dataset`, concatenated with
		    `other_arguments`, to a Dataset variant that contains elements matching
		    `output_types` and `output_shapes`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  deterministic: An optional `string`. Defaults to `"default"`.
		    A string indicating the op-level determinism to use. Deterministic controls
		    whether the interleave is allowed to return elements out of order if the next
		    element to be returned isn't available, but a later element is. Options are
		    "true", "false", and "default". "default" indicates that determinism should be
		    decided by the `experimental_deterministic` parameter of `tf.data.Options`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ParallelInterleaveDatasetV4(input_dataset:Dynamic, other_arguments:Dynamic, cycle_length:Dynamic, block_length:Dynamic, buffer_output_elements:Dynamic, prefetch_input_elements:Dynamic, num_parallel_calls:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?deterministic:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		Unlike a "MapDataset", which applies `f` sequentially, this dataset invokes up
		to `num_parallel_calls` copies of `f` in parallel.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  other_arguments: A list of `Tensor` objects.
		  num_parallel_calls: A `Tensor` of type `int32`.
		    The number of concurrent invocations of `f` that process
		    elements from `input_dataset` in parallel.
		  f: A function decorated with @Defun.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  use_inter_op_parallelism: An optional `bool`. Defaults to `True`.
		  sloppy: An optional `bool`. Defaults to `False`.
		  preserve_cardinality: An optional `bool`. Defaults to `False`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ParallelMapDataset(input_dataset:Dynamic, other_arguments:Dynamic, num_parallel_calls:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?use_inter_op_parallelism:Dynamic, ?sloppy:Dynamic, ?preserve_cardinality:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that applies `f` to the outputs of `input_dataset`.
		
		Unlike a "MapDataset", which applies `f` sequentially, this dataset invokes up
		to `num_parallel_calls` copies of `f` in parallel.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  other_arguments: A list of `Tensor` objects.
		  num_parallel_calls: A `Tensor` of type `int64`.
		    The number of concurrent invocations of `f` that process
		    elements from `input_dataset` in parallel.
		  f: A function decorated with @Defun.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  use_inter_op_parallelism: An optional `bool`. Defaults to `True`.
		  deterministic: An optional `string`. Defaults to `"default"`.
		  preserve_cardinality: An optional `bool`. Defaults to `False`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ParallelMapDatasetV2(input_dataset:Dynamic, other_arguments:Dynamic, num_parallel_calls:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?use_inter_op_parallelism:Dynamic, ?deterministic:Dynamic, ?preserve_cardinality:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random values from a normal distribution. The parameters may each be a
		
		scalar which applies to the entire output, or a vector of length shape[0] which
		stores the parameters for each batch.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor. Batches are indexed by the 0th dimension.
		  means: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    The mean parameter of each batch.
		  stdevs: A `Tensor`. Must have the same type as `means`.
		    The standard deviation parameter of each batch. Must be greater than 0.
		  minvals: A `Tensor`. Must have the same type as `means`.
		    The minimum cutoff. May be -infinity.
		  maxvals: A `Tensor`. Must have the same type as `means`.
		    The maximum cutoff. May be +infinity, and must be more than the minval
		    for each batch.
		  seed: An optional `int`. Defaults to `0`.
		    If either `seed` or `seed2` are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `means`.
	**/
	static public function ParameterizedTruncatedNormal(shape:Dynamic, means:Dynamic, stdevs:Dynamic, minvals:Dynamic, maxvals:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms a vector of brain.Example protos (as strings) into typed tensors.
		
		Args:
		  serialized: A `Tensor` of type `string`.
		    A vector containing a batch of binary serialized Example protos.
		  names: A `Tensor` of type `string`.
		    A vector containing the names of the serialized protos.
		    May contain, for example, table key (descriptive) names for the
		    corresponding serialized protos.  These are purely useful for debugging
		    purposes, and the presence of values here has no effect on the output.
		    May also be an empty vector if no names are available.
		    If non-empty, this vector must be the same length as "serialized".
		  sparse_keys: A list of `Tensor` objects with type `string`.
		    A list of Nsparse string Tensors (scalars).
		    The keys expected in the Examples' features associated with sparse values.
		  dense_keys: A list of `Tensor` objects with type `string`.
		    A list of Ndense string Tensors (scalars).
		    The keys expected in the Examples' features associated with dense values.
		  dense_defaults: A list of `Tensor` objects with types from: `float32`, `int64`, `string`.
		    A list of Ndense Tensors (some may be empty).
		    dense_defaults[j] provides default values
		    when the example's feature_map lacks dense_key[j].  If an empty Tensor is
		    provided for dense_defaults[j], then the Feature dense_keys[j] is required.
		    The input type is inferred from dense_defaults[j], even when it's empty.
		    If dense_defaults[j] is not empty, and dense_shapes[j] is fully defined,
		    then the shape of dense_defaults[j] must match that of dense_shapes[j].
		    If dense_shapes[j] has an undefined major dimension (variable strides dense
		    feature), dense_defaults[j] must contain a single element:
		    the padding element.
		  sparse_types: A list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`.
		    A list of Nsparse types; the data types of data in each Feature
		    given in sparse_keys.
		    Currently the ParseExample supports DT_FLOAT (FloatList),
		    DT_INT64 (Int64List), and DT_STRING (BytesList).
		  dense_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    A list of Ndense shapes; the shapes of data in each Feature
		    given in dense_keys.
		    The number of elements in the Feature corresponding to dense_key[j]
		    must always equal dense_shapes[j].NumEntries().
		    If dense_shapes[j] == (D0, D1, ..., DN) then the shape of output
		    Tensor dense_values[j] will be (|serialized|, D0, D1, ..., DN):
		    The dense outputs are just the inputs row-stacked by batch.
		    This works for dense_shapes[j] = (-1, D1, ..., DN).  In this case
		    the shape of the output Tensor dense_values[j] will be
		    (|serialized|, M, D1, .., DN), where M is the maximum number of blocks
		    of elements of length D1 * .... * DN, across all minibatch entries
		    in the input.  Any minibatch entry with less than M blocks of elements of
		    length D1 * ... * DN will be padded with the corresponding default_value
		    scalar element along the second dimension.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sparse_indices, sparse_values, sparse_shapes, dense_values).
		
		  sparse_indices: A list with the same length as `sparse_keys` of `Tensor` objects with type `int64`.
		  sparse_values: A list of `Tensor` objects of type `sparse_types`.
		  sparse_shapes: A list with the same length as `sparse_keys` of `Tensor` objects with type `int64`.
		  dense_values: A list of `Tensor` objects. Has the same type as `dense_defaults`.
	**/
	static public function ParseExample(serialized:Dynamic, names:Dynamic, sparse_keys:Dynamic, dense_keys:Dynamic, dense_defaults:Dynamic, sparse_types:Dynamic, dense_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms `input_dataset` containing `Example` protos as vectors of DT_STRING into a dataset of `Tensor` or `SparseTensor` objects representing the parsed features.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  num_parallel_calls: A `Tensor` of type `int64`.
		  dense_defaults: A list of `Tensor` objects with types from: `float32`, `int64`, `string`.
		    A dict mapping string keys to `Tensor`s.
		    The keys of the dict must match the dense_keys of the feature.
		  sparse_keys: A list of `strings`.
		    A list of string keys in the examples features.
		    The results for these keys will be returned as `SparseTensor` objects.
		  dense_keys: A list of `strings`.
		    A list of Ndense string Tensors (scalars).
		    The keys expected in the Examples features associated with dense values.
		  sparse_types: A list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`.
		    A list of `DTypes` of the same length as `sparse_keys`.
		    Only `tf.float32` (`FloatList`), `tf.int64` (`Int64List`),
		    and `tf.string` (`BytesList`) are supported.
		  dense_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    List of tuples with the same length as `dense_keys`.
		    The shape of the data for each dense feature referenced by `dense_keys`.
		    Required for any input tensors identified by `dense_keys`.  Must be
		    either fully defined, or may contain an unknown first dimension.
		    An unknown first dimension means the feature is treated as having
		    a variable number of blocks, and the output shape along this dimension
		    is considered unknown at graph build time.  Padding is applied for
		    minibatch elements smaller than the maximum number of blocks for the
		    given feature along this dimension.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type list for the return values.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		    The list of shapes being produced.
		  sloppy: An optional `bool`. Defaults to `False`.
		  ragged_keys: An optional list of `strings`. Defaults to `[]`.
		  ragged_value_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		  ragged_split_types: An optional list of `tf.DTypes` from: `tf.int32, tf.int64`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ParseExampleDataset(input_dataset:Dynamic, num_parallel_calls:Dynamic, dense_defaults:Dynamic, sparse_keys:Dynamic, dense_keys:Dynamic, sparse_types:Dynamic, dense_shapes:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?sloppy:Dynamic, ?ragged_keys:Dynamic, ?ragged_value_types:Dynamic, ?ragged_split_types:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms `input_dataset` containing `Example` protos as vectors of DT_STRING into a dataset of `Tensor` or `SparseTensor` objects representing the parsed features.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  num_parallel_calls: A `Tensor` of type `int64`.
		  dense_defaults: A list of `Tensor` objects with types from: `float32`, `int64`, `string`.
		    A dict mapping string keys to `Tensor`s.
		    The keys of the dict must match the dense_keys of the feature.
		  sparse_keys: A list of `strings`.
		    A list of string keys in the examples features.
		    The results for these keys will be returned as `SparseTensor` objects.
		  dense_keys: A list of `strings`.
		    A list of Ndense string Tensors (scalars).
		    The keys expected in the Examples features associated with dense values.
		  sparse_types: A list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`.
		    A list of `DTypes` of the same length as `sparse_keys`.
		    Only `tf.float32` (`FloatList`), `tf.int64` (`Int64List`),
		    and `tf.string` (`BytesList`) are supported.
		  dense_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    List of tuples with the same length as `dense_keys`.
		    The shape of the data for each dense feature referenced by `dense_keys`.
		    Required for any input tensors identified by `dense_keys`.  Must be
		    either fully defined, or may contain an unknown first dimension.
		    An unknown first dimension means the feature is treated as having
		    a variable number of blocks, and the output shape along this dimension
		    is considered unknown at graph build time.  Padding is applied for
		    minibatch elements smaller than the maximum number of blocks for the
		    given feature along this dimension.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type list for the return values.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		    The list of shapes being produced.
		  deterministic: An optional `string`. Defaults to `"default"`.
		    A string indicating the op-level determinism to use. Deterministic controls
		    whether the dataset is allowed to return elements out of order if the next
		    element to be returned isn't available, but a later element is. Options are
		    "true", "false", and "default". "default" indicates that determinism should be
		    decided by the `experimental_deterministic` parameter of `tf.data.Options`.
		  ragged_keys: An optional list of `strings`. Defaults to `[]`.
		  ragged_value_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		  ragged_split_types: An optional list of `tf.DTypes` from: `tf.int32, tf.int64`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ParseExampleDatasetV2(input_dataset:Dynamic, num_parallel_calls:Dynamic, dense_defaults:Dynamic, sparse_keys:Dynamic, dense_keys:Dynamic, sparse_types:Dynamic, dense_shapes:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?deterministic:Dynamic, ?ragged_keys:Dynamic, ?ragged_value_types:Dynamic, ?ragged_split_types:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms a vector of tf.Example protos (as strings) into typed tensors.
		
		Args:
		  serialized: A `Tensor` of type `string`.
		    A scalar or vector containing binary serialized Example protos.
		  names: A `Tensor` of type `string`.
		    A tensor containing the names of the serialized protos.
		    Corresponds 1:1 with the `serialized` tensor.
		    May contain, for example, table key (descriptive) names for the
		    corresponding serialized protos.  These are purely useful for debugging
		    purposes, and the presence of values here has no effect on the output.
		    May also be an empty vector if no names are available.
		    If non-empty, this tensor must have the same shape as "serialized".
		  sparse_keys: A `Tensor` of type `string`. Vector of strings.
		    The keys expected in the Examples' features associated with sparse values.
		  dense_keys: A `Tensor` of type `string`. Vector of strings.
		    The keys expected in the Examples' features associated with dense values.
		  ragged_keys: A `Tensor` of type `string`. Vector of strings.
		    The keys expected in the Examples' features associated with ragged values.
		  dense_defaults: A list of `Tensor` objects with types from: `float32`, `int64`, `string`.
		    A list of Tensors (some may be empty).  Corresponds 1:1 with `dense_keys`.
		    dense_defaults[j] provides default values
		    when the example's feature_map lacks dense_key[j].  If an empty Tensor is
		    provided for dense_defaults[j], then the Feature dense_keys[j] is required.
		    The input type is inferred from dense_defaults[j], even when it's empty.
		    If dense_defaults[j] is not empty, and dense_shapes[j] is fully defined,
		    then the shape of dense_defaults[j] must match that of dense_shapes[j].
		    If dense_shapes[j] has an undefined major dimension (variable strides dense
		    feature), dense_defaults[j] must contain a single element:
		    the padding element.
		  num_sparse: An `int` that is `>= 0`. The number of sparse keys.
		  sparse_types: A list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`.
		    A list of `num_sparse` types; the data types of data in each Feature
		    given in sparse_keys.
		    Currently the ParseExample supports DT_FLOAT (FloatList),
		    DT_INT64 (Int64List), and DT_STRING (BytesList).
		  ragged_value_types: A list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`.
		    A list of `num_ragged` types; the data types of data in each Feature
		    given in ragged_keys (where `num_ragged = sparse_keys.size()`).
		    Currently the ParseExample supports DT_FLOAT (FloatList),
		    DT_INT64 (Int64List), and DT_STRING (BytesList).
		  ragged_split_types: A list of `tf.DTypes` from: `tf.int32, tf.int64`.
		    A list of `num_ragged` types; the data types of row_splits in each Feature
		    given in ragged_keys (where `num_ragged = sparse_keys.size()`).
		    May be DT_INT32 or DT_INT64.
		  dense_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    A list of `num_dense` shapes; the shapes of data in each Feature
		    given in dense_keys (where `num_dense = dense_keys.size()`).
		    The number of elements in the Feature corresponding to dense_key[j]
		    must always equal dense_shapes[j].NumEntries().
		    If dense_shapes[j] == (D0, D1, ..., DN) then the shape of output
		    Tensor dense_values[j] will be (|serialized|, D0, D1, ..., DN):
		    The dense outputs are just the inputs row-stacked by batch.
		    This works for dense_shapes[j] = (-1, D1, ..., DN).  In this case
		    the shape of the output Tensor dense_values[j] will be
		    (|serialized|, M, D1, .., DN), where M is the maximum number of blocks
		    of elements of length D1 * .... * DN, across all minibatch entries
		    in the input.  Any minibatch entry with less than M blocks of elements of
		    length D1 * ... * DN will be padded with the corresponding default_value
		    scalar element along the second dimension.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sparse_indices, sparse_values, sparse_shapes, dense_values, ragged_values, ragged_row_splits).
		
		  sparse_indices: A list of `num_sparse` `Tensor` objects with type `int64`.
		  sparse_values: A list of `Tensor` objects of type `sparse_types`.
		  sparse_shapes: A list of `num_sparse` `Tensor` objects with type `int64`.
		  dense_values: A list of `Tensor` objects. Has the same type as `dense_defaults`.
		  ragged_values: A list of `Tensor` objects of type `ragged_value_types`.
		  ragged_row_splits: A list of `Tensor` objects of type `ragged_split_types`.
	**/
	static public function ParseExampleV2(serialized:Dynamic, names:Dynamic, sparse_keys:Dynamic, dense_keys:Dynamic, ragged_keys:Dynamic, dense_defaults:Dynamic, num_sparse:Dynamic, sparse_types:Dynamic, ragged_value_types:Dynamic, ragged_split_types:Dynamic, dense_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms a vector of brain.SequenceExample protos (as strings) into typed tensors.
		
		Args:
		  serialized: A `Tensor` of type `string`.
		    A vector containing binary serialized SequenceExample protos.
		  debug_name: A `Tensor` of type `string`.
		    A vector containing the names of the serialized protos.
		    May contain, for example, table key (descriptive) name for the
		    corresponding serialized proto.  This is purely useful for debugging
		    purposes, and the presence of values here has no effect on the output.
		    May also be an empty vector if no name is available.
		  context_dense_defaults: A list of `Tensor` objects with types from: `float32`, `int64`, `string`.
		    A list of Ncontext_dense Tensors (some may be empty).
		    context_dense_defaults[j] provides default values
		    when the SequenceExample's context map lacks context_dense_key[j].
		    If an empty Tensor is provided for context_dense_defaults[j],
		    then the Feature context_dense_keys[j] is required.
		    The input type is inferred from context_dense_defaults[j], even when it's
		    empty.  If context_dense_defaults[j] is not empty, its shape must match
		    context_dense_shapes[j].
		  feature_list_dense_missing_assumed_empty: A list of `strings`.
		    A vector listing the
		    FeatureList keys which may be missing from the SequenceExamples.  If the
		    associated FeatureList is missing, it is treated as empty.  By default,
		    any FeatureList not listed in this vector must exist in the SequenceExamples.
		  context_sparse_keys: A list of `strings`.
		    A list of Ncontext_sparse string Tensors (scalars).
		    The keys expected in the Examples' features associated with context_sparse
		    values.
		  context_dense_keys: A list of `strings`.
		    A list of Ncontext_dense string Tensors (scalars).
		    The keys expected in the SequenceExamples' context features associated with
		    dense values.
		  feature_list_sparse_keys: A list of `strings`.
		    A list of Nfeature_list_sparse string Tensors
		    (scalars).  The keys expected in the FeatureLists associated with sparse
		    values.
		  feature_list_dense_keys: A list of `strings`.
		    A list of Nfeature_list_dense string Tensors (scalars).
		    The keys expected in the SequenceExamples' feature_lists associated
		    with lists of dense values.
		  Ncontext_sparse: An optional `int` that is `>= 0`. Defaults to `0`.
		  Ncontext_dense: An optional `int` that is `>= 0`. Defaults to `0`.
		  Nfeature_list_sparse: An optional `int` that is `>= 0`. Defaults to `0`.
		  Nfeature_list_dense: An optional `int` that is `>= 0`. Defaults to `0`.
		  context_sparse_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		    A list of Ncontext_sparse types; the data types of data in
		    each context Feature given in context_sparse_keys.
		    Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
		    DT_INT64 (Int64List), and DT_STRING (BytesList).
		  feature_list_dense_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		  context_dense_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    A list of Ncontext_dense shapes; the shapes of data in
		    each context Feature given in context_dense_keys.
		    The number of elements in the Feature corresponding to context_dense_key[j]
		    must always equal context_dense_shapes[j].NumEntries().
		    The shape of context_dense_values[j] will match context_dense_shapes[j].
		  feature_list_sparse_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		    A list of Nfeature_list_sparse types; the data types
		    of data in each FeatureList given in feature_list_sparse_keys.
		    Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
		    DT_INT64 (Int64List), and DT_STRING (BytesList).
		  feature_list_dense_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    A list of Nfeature_list_dense shapes; the shapes of
		    data in each FeatureList given in feature_list_dense_keys.
		    The shape of each Feature in the FeatureList corresponding to
		    feature_list_dense_key[j] must always equal
		    feature_list_dense_shapes[j].NumEntries().
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (context_sparse_indices, context_sparse_values, context_sparse_shapes, context_dense_values, feature_list_sparse_indices, feature_list_sparse_values, feature_list_sparse_shapes, feature_list_dense_values, feature_list_dense_lengths).
		
		  context_sparse_indices: A list of `Ncontext_sparse` `Tensor` objects with type `int64`.
		  context_sparse_values: A list of `Tensor` objects of type `context_sparse_types`.
		  context_sparse_shapes: A list of `Ncontext_sparse` `Tensor` objects with type `int64`.
		  context_dense_values: A list of `Tensor` objects. Has the same type as `context_dense_defaults`.
		  feature_list_sparse_indices: A list of `Nfeature_list_sparse` `Tensor` objects with type `int64`.
		  feature_list_sparse_values: A list of `Tensor` objects of type `feature_list_sparse_types`.
		  feature_list_sparse_shapes: A list of `Nfeature_list_sparse` `Tensor` objects with type `int64`.
		  feature_list_dense_values: A list of `Tensor` objects of type `feature_list_dense_types`.
		  feature_list_dense_lengths: A list of `Nfeature_list_dense` `Tensor` objects with type `int64`.
	**/
	static public function ParseSequenceExample(serialized:Dynamic, debug_name:Dynamic, context_dense_defaults:Dynamic, feature_list_dense_missing_assumed_empty:Dynamic, context_sparse_keys:Dynamic, context_dense_keys:Dynamic, feature_list_sparse_keys:Dynamic, feature_list_dense_keys:Dynamic, ?Ncontext_sparse:Dynamic, ?Ncontext_dense:Dynamic, ?Nfeature_list_sparse:Dynamic, ?Nfeature_list_dense:Dynamic, ?context_sparse_types:Dynamic, ?feature_list_dense_types:Dynamic, ?context_dense_shapes:Dynamic, ?feature_list_sparse_types:Dynamic, ?feature_list_dense_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms a vector of tf.io.SequenceExample protos (as strings) into
		typed tensors.
		
		  Args:
		    serialized: A `Tensor` of type `string`.
		      A scalar or vector containing binary serialized SequenceExample protos.
		    debug_name: A `Tensor` of type `string`.
		      A scalar or vector containing the names of the serialized protos.
		      May contain, for example, table key (descriptive) name for the
		      corresponding serialized proto.  This is purely useful for debugging
		      purposes, and the presence of values here has no effect on the output.
		      May also be an empty vector if no name is available.
		    context_sparse_keys: A `Tensor` of type `string`.
		      The keys expected in the Examples' features associated with context_sparse
		      values.
		    context_dense_keys: A `Tensor` of type `string`.
		      The keys expected in the SequenceExamples' context features associated with
		      dense values.
		    context_ragged_keys: A `Tensor` of type `string`.
		      The keys expected in the Examples' features associated with context_ragged
		      values.
		    feature_list_sparse_keys: A `Tensor` of type `string`.
		      The keys expected in the FeatureLists associated with sparse values.
		    feature_list_dense_keys: A `Tensor` of type `string`.
		      The keys expected in the SequenceExamples' feature_lists associated
		      with lists of dense values.
		    feature_list_ragged_keys: A `Tensor` of type `string`.
		      The keys expected in the FeatureLists associated with ragged values.
		    feature_list_dense_missing_assumed_empty: A `Tensor` of type `bool`.
		      A vector corresponding 1:1 with feature_list_dense_keys, indicating which
		      features may be missing from the SequenceExamples.  If the associated
		      FeatureList is missing, it is treated as empty.
		    context_dense_defaults: A list of `Tensor` objects with types from: `float32`, `int64`, `string`.
		      A list of Ncontext_dense Tensors (some may be empty).
		      context_dense_defaults[j] provides default values
		      when the SequenceExample's context map lacks context_dense_key[j].
		      If an empty Tensor is provided for context_dense_defaults[j],
		      then the Feature context_dense_keys[j] is required.
		      The input type is inferred from context_dense_defaults[j], even when it's
		      empty.  If context_dense_defaults[j] is not empty, its shape must match
		      context_dense_shapes[j].
		    Ncontext_sparse: An optional `int` that is `>= 0`. Defaults to `0`.
		    context_sparse_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		      A list of Ncontext_sparse types; the data types of data in
		      each context Feature given in context_sparse_keys.
		      Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
		      DT_INT64 (Int64List), and DT_STRING (BytesList).
		    context_ragged_value_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		      RaggedTensor.value dtypes for the ragged context features.
		    context_ragged_split_types: An optional list of `tf.DTypes` from: `tf.int32, tf.int64`. Defaults to `[]`.
		      RaggedTensor.row_split dtypes for the ragged context features.
		    context_dense_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		      A list of Ncontext_dense shapes; the shapes of data in
		      each context Feature given in context_dense_keys.
		      The number of elements in the Feature corresponding to context_dense_key[j]
		      must always equal context_dense_shapes[j].NumEntries().
		      The shape of context_dense_values[j] will match context_dense_shapes[j].
		    Nfeature_list_sparse: An optional `int` that is `>= 0`. Defaults to `0`.
		    Nfeature_list_dense: An optional `int` that is `>= 0`. Defaults to `0`.
		    feature_list_dense_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		    feature_list_sparse_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		      A list of Nfeature_list_sparse types; the data types
		      of data in each FeatureList given in feature_list_sparse_keys.
		      Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
		      DT_INT64 (Int64List), and DT_STRING (BytesList).
		    feature_list_ragged_value_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		      RaggedTensor.value dtypes for the ragged FeatureList features.
		    feature_list_ragged_split_types: An optional list of `tf.DTypes` from: `tf.int32, tf.int64`. Defaults to `[]`.
		      RaggedTensor.row_split dtypes for the ragged FeatureList features.
		    feature_list_dense_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		      A list of Nfeature_list_dense shapes; the shapes of
		      data in each FeatureList given in feature_list_dense_keys.
		      The shape of each Feature in the FeatureList corresponding to
		      feature_list_dense_key[j] must always equal
		      feature_list_dense_shapes[j].NumEntries().
		    name: A name for the operation (optional).
		
		  Returns:
		    A tuple of `Tensor` objects (context_sparse_indices, context_sparse_values, context_sparse_shapes, context_dense_values, context_ragged_values, context_ragged_row_splits, feature_list_sparse_indices, feature_list_sparse_values, feature_list_sparse_shapes, feature_list_dense_values, feature_list_dense_lengths, feature_list_ragged_values, feature_list_ragged_outer_splits, feature_list_ragged_inner_splits).
		
		    context_sparse_indices: A list of `Ncontext_sparse` `Tensor` objects with type `int64`.
		    context_sparse_values: A list of `Tensor` objects of type `context_sparse_types`.
		    context_sparse_shapes: A list of `Ncontext_sparse` `Tensor` objects with type `int64`.
		    context_dense_values: A list of `Tensor` objects. Has the same type as `context_dense_defaults`.
		    context_ragged_values: A list of `Tensor` objects of type `context_ragged_value_types`.
		    context_ragged_row_splits: A list of `Tensor` objects of type `context_ragged_split_types`.
		    feature_list_sparse_indices: A list of `Nfeature_list_sparse` `Tensor` objects with type `int64`.
		    feature_list_sparse_values: A list of `Tensor` objects of type `feature_list_sparse_types`.
		    feature_list_sparse_shapes: A list of `Nfeature_list_sparse` `Tensor` objects with type `int64`.
		    feature_list_dense_values: A list of `Tensor` objects of type `feature_list_dense_types`.
		    feature_list_dense_lengths: A list of `Nfeature_list_dense` `Tensor` objects with type `int64`.
		    feature_list_ragged_values: A list of `Tensor` objects of type `feature_list_ragged_value_types`.
		    feature_list_ragged_outer_splits: A list of `Tensor` objects of type `feature_list_ragged_split_types`.
		    feature_list_ragged_inner_splits: A list of `Tensor` objects of type `feature_list_ragged_split_types`.
		  
	**/
	static public function ParseSequenceExampleV2(serialized:Dynamic, debug_name:Dynamic, context_sparse_keys:Dynamic, context_dense_keys:Dynamic, context_ragged_keys:Dynamic, feature_list_sparse_keys:Dynamic, feature_list_dense_keys:Dynamic, feature_list_ragged_keys:Dynamic, feature_list_dense_missing_assumed_empty:Dynamic, context_dense_defaults:Dynamic, ?Ncontext_sparse:Dynamic, ?context_sparse_types:Dynamic, ?context_ragged_value_types:Dynamic, ?context_ragged_split_types:Dynamic, ?context_dense_shapes:Dynamic, ?Nfeature_list_sparse:Dynamic, ?Nfeature_list_dense:Dynamic, ?feature_list_dense_types:Dynamic, ?feature_list_sparse_types:Dynamic, ?feature_list_ragged_value_types:Dynamic, ?feature_list_ragged_split_types:Dynamic, ?feature_list_dense_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms a tf.Example proto (as a string) into typed tensors.
		
		Args:
		  serialized: A `Tensor` of type `string`.
		    A vector containing a batch of binary serialized Example protos.
		  dense_defaults: A list of `Tensor` objects with types from: `float32`, `int64`, `string`.
		    A list of Tensors (some may be empty), whose length matches
		    the length of `dense_keys`. dense_defaults[j] provides default values
		    when the example's feature_map lacks dense_key[j].  If an empty Tensor is
		    provided for dense_defaults[j], then the Feature dense_keys[j] is required.
		    The input type is inferred from dense_defaults[j], even when it's empty.
		    If dense_defaults[j] is not empty, and dense_shapes[j] is fully defined,
		    then the shape of dense_defaults[j] must match that of dense_shapes[j].
		    If dense_shapes[j] has an undefined major dimension (variable strides dense
		    feature), dense_defaults[j] must contain a single element:
		    the padding element.
		  num_sparse: An `int` that is `>= 0`.
		    The number of sparse features to be parsed from the example. This
		    must match the lengths of `sparse_keys` and `sparse_types`.
		  sparse_keys: A list of `strings`. A list of `num_sparse` strings.
		    The keys expected in the Examples' features associated with sparse values.
		  dense_keys: A list of `strings`.
		    The keys expected in the Examples' features associated with dense
		    values.
		  sparse_types: A list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`.
		    A list of `num_sparse` types; the data types of data in each
		    Feature given in sparse_keys.
		    Currently the ParseSingleExample op supports DT_FLOAT (FloatList),
		    DT_INT64 (Int64List), and DT_STRING (BytesList).
		  dense_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    The shapes of data in each Feature given in dense_keys.
		    The length of this list must match the length of `dense_keys`.  The
		    number of elements in the Feature corresponding to dense_key[j] must
		    always equal dense_shapes[j].NumEntries().  If dense_shapes[j] ==
		    (D0, D1, ..., DN) then the shape of output Tensor dense_values[j]
		    will be (D0, D1, ..., DN): In the case dense_shapes[j] = (-1, D1,
		    ..., DN), the shape of the output Tensor dense_values[j] will be (M,
		    D1, .., DN), where M is the number of blocks of elements of length
		    D1 * .... * DN, in the input.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sparse_indices, sparse_values, sparse_shapes, dense_values).
		
		  sparse_indices: A list of `num_sparse` `Tensor` objects with type `int64`.
		  sparse_values: A list of `Tensor` objects of type `sparse_types`.
		  sparse_shapes: A list of `num_sparse` `Tensor` objects with type `int64`.
		  dense_values: A list of `Tensor` objects. Has the same type as `dense_defaults`.
	**/
	static public function ParseSingleExample(serialized:Dynamic, dense_defaults:Dynamic, num_sparse:Dynamic, sparse_keys:Dynamic, dense_keys:Dynamic, sparse_types:Dynamic, dense_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms a scalar brain.SequenceExample proto (as strings) into typed tensors.
		
		Args:
		  serialized: A `Tensor` of type `string`.
		    A scalar containing a binary serialized SequenceExample proto.
		  feature_list_dense_missing_assumed_empty: A `Tensor` of type `string`.
		    A vector listing the
		    FeatureList keys which may be missing from the SequenceExample.  If the
		    associated FeatureList is missing, it is treated as empty.  By default,
		    any FeatureList not listed in this vector must exist in the SequenceExample.
		  context_sparse_keys: A list of `Tensor` objects with type `string`.
		    A list of Ncontext_sparse string Tensors (scalars).
		    The keys expected in the Examples' features associated with context_sparse
		    values.
		  context_dense_keys: A list of `Tensor` objects with type `string`.
		    A list of Ncontext_dense string Tensors (scalars).
		    The keys expected in the SequenceExamples' context features associated with
		    dense values.
		  feature_list_sparse_keys: A list of `Tensor` objects with type `string`.
		    A list of Nfeature_list_sparse string Tensors
		    (scalars).  The keys expected in the FeatureLists associated with sparse
		    values.
		  feature_list_dense_keys: A list of `Tensor` objects with type `string`.
		    A list of Nfeature_list_dense string Tensors (scalars).
		    The keys expected in the SequenceExamples' feature_lists associated
		    with lists of dense values.
		  context_dense_defaults: A list of `Tensor` objects with types from: `float32`, `int64`, `string`.
		    A list of Ncontext_dense Tensors (some may be empty).
		    context_dense_defaults[j] provides default values
		    when the SequenceExample's context map lacks context_dense_key[j].
		    If an empty Tensor is provided for context_dense_defaults[j],
		    then the Feature context_dense_keys[j] is required.
		    The input type is inferred from context_dense_defaults[j], even when it's
		    empty.  If context_dense_defaults[j] is not empty, its shape must match
		    context_dense_shapes[j].
		  debug_name: A `Tensor` of type `string`.
		    A scalar containing the name of the serialized proto.
		    May contain, for example, table key (descriptive) name for the
		    corresponding serialized proto.  This is purely useful for debugging
		    purposes, and the presence of values here has no effect on the output.
		    May also be an empty scalar if no name is available.
		  context_sparse_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		    A list of Ncontext_sparse types; the data types of data in
		    each context Feature given in context_sparse_keys.
		    Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
		    DT_INT64 (Int64List), and DT_STRING (BytesList).
		  feature_list_dense_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		  context_dense_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    A list of Ncontext_dense shapes; the shapes of data in
		    each context Feature given in context_dense_keys.
		    The number of elements in the Feature corresponding to context_dense_key[j]
		    must always equal context_dense_shapes[j].NumEntries().
		    The shape of context_dense_values[j] will match context_dense_shapes[j].
		  feature_list_sparse_types: An optional list of `tf.DTypes` from: `tf.float32, tf.int64, tf.string`. Defaults to `[]`.
		    A list of Nfeature_list_sparse types; the data types
		    of data in each FeatureList given in feature_list_sparse_keys.
		    Currently the ParseSingleSequenceExample supports DT_FLOAT (FloatList),
		    DT_INT64 (Int64List), and DT_STRING (BytesList).
		  feature_list_dense_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    A list of Nfeature_list_dense shapes; the shapes of
		    data in each FeatureList given in feature_list_dense_keys.
		    The shape of each Feature in the FeatureList corresponding to
		    feature_list_dense_key[j] must always equal
		    feature_list_dense_shapes[j].NumEntries().
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (context_sparse_indices, context_sparse_values, context_sparse_shapes, context_dense_values, feature_list_sparse_indices, feature_list_sparse_values, feature_list_sparse_shapes, feature_list_dense_values).
		
		  context_sparse_indices: A list with the same length as `context_sparse_keys` of `Tensor` objects with type `int64`.
		  context_sparse_values: A list of `Tensor` objects of type `context_sparse_types`.
		  context_sparse_shapes: A list with the same length as `context_sparse_keys` of `Tensor` objects with type `int64`.
		  context_dense_values: A list of `Tensor` objects. Has the same type as `context_dense_defaults`.
		  feature_list_sparse_indices: A list with the same length as `feature_list_sparse_keys` of `Tensor` objects with type `int64`.
		  feature_list_sparse_values: A list of `Tensor` objects of type `feature_list_sparse_types`.
		  feature_list_sparse_shapes: A list with the same length as `feature_list_sparse_keys` of `Tensor` objects with type `int64`.
		  feature_list_dense_values: A list of `Tensor` objects of type `feature_list_dense_types`.
	**/
	static public function ParseSingleSequenceExample(serialized:Dynamic, feature_list_dense_missing_assumed_empty:Dynamic, context_sparse_keys:Dynamic, context_dense_keys:Dynamic, feature_list_sparse_keys:Dynamic, feature_list_dense_keys:Dynamic, context_dense_defaults:Dynamic, debug_name:Dynamic, ?context_sparse_types:Dynamic, ?feature_list_dense_types:Dynamic, ?context_dense_shapes:Dynamic, ?feature_list_sparse_types:Dynamic, ?feature_list_dense_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms a serialized tensorflow.TensorProto proto into a Tensor.
		
		Args:
		  serialized: A `Tensor` of type `string`.
		    A scalar string containing a serialized TensorProto proto.
		  out_type: A `tf.DType`.
		    The type of the serialized tensor.  The provided type must match the
		    type of the serialized tensor and no implicit conversion will take place.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `out_type`.
	**/
	static public function ParseTensor(serialized:Dynamic, out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		returns `f(inputs)`, where `f`'s body is placed and partitioned.
		
		Asynchronously executes a function, potentially across multiple devices but
		within a single process. The kernel places and partitions a given function's
		underlying graph, and executes each of the partitioned subgraphs as a function.
		
		Args:
		  args: A list of `Tensor` objects. A list of input tensors.
		  Tout: A list of `tf.DTypes`. A list of output types.
		  f: A function decorated with @Defun.
		          A function that takes 'args', a list of tensors, and returns 'output',
		          another list of tensors. Input and output types are specified by 'Tin'
		          and 'Tout'. The function body of f will be placed and partitioned across
		          devices, setting this op apart from the regular Call op.
		  config: An optional `string`. Defaults to `""`.
		  config_proto: An optional `string`. Defaults to `""`.
		  executor_type: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function PartitionedCall(args:Dynamic, Tout:Dynamic, f:Dynamic, ?config:Dynamic, ?config_proto:Dynamic, ?executor_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A placeholder op for a value that will be fed into the computation.
		
		N.B. This operation will fail with an error if it is executed. It is
		intended as a way to represent a value that will always be fed, and to
		provide attrs that enable the fed value to be checked at runtime.
		
		Args:
		  dtype: A `tf.DType`. The type of elements in the tensor.
		  shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		    (Optional) The shape of the tensor. If the shape has 0 dimensions, the
		    shape is unconstrained.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function Placeholder(dtype:Dynamic, ?shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A placeholder op for a value that will be fed into the computation.
		
		N.B. This operation will fail with an error if it is executed. It is
		intended as a way to represent a value that will always be fed, and to
		provide attrs that enable the fed value to be checked at runtime.
		
		Args:
		  dtype: A `tf.DType`. The type of elements in the tensor.
		  shape: A `tf.TensorShape` or list of `ints`.
		    The shape of the tensor. The shape can be any partially-specified
		    shape.  To be unconstrained, pass in a shape with unknown rank.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function PlaceholderV2(dtype:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A placeholder op that passes through `input` when its output is not fed.
		
		Args:
		  input: A `Tensor`. The default value to produce when `output` is not fed.
		  shape: A `tf.TensorShape` or list of `ints`.
		    The (possibly partial) shape of the tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function PlaceholderWithDefault(input:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute the polygamma function \\(\psi^{(n)}(x)\\).
		
		The polygamma function is defined as:
		
		
		\\(\psi^{(a)}(x) = \frac{d^a}{dx^a} \psi(x)\\)
		
		where \\(\psi(x)\\) is the digamma function.
		The polygamma function is defined only for non-negative integer orders \\a\\.
		
		Args:
		  a: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		  x: A `Tensor`. Must have the same type as `a`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `a`.
	**/
	static public function Polygamma(a:Dynamic, x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes element-wise population count (a.k.a. popcount, bitsum, bitcount).
		
		For each entry in `x`, calculates the number of `1` (on) bits in the binary
		representation of that entry.
		
		**NOTE**: It is more efficient to first `tf.bitcast` your tensors into
		`int32` or `int64` and perform the bitcount on the result, than to feed in
		8- or 16-bit inputs and then aggregate the resulting counts.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `uint8`.
	**/
	static public function PopulationCount(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the power of one value to another.
		
		Given a tensor `x` and a tensor `y`, this operation computes \\(x^y\\) for
		corresponding elements in `x` and `y`. For example:
		
		```
		# tensor 'x' is [[2, 2]], [3, 3]]
		# tensor 'y' is [[8, 16], [2, 3]]
		tf.pow(x, y) ==> [[256, 65536], [9, 27]]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `float32`, `half`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Pow(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that asynchronously prefetches elements from `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  buffer_size: A `Tensor` of type `int64`.
		    The maximum number of elements to buffer in an iterator over
		    this dataset.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  slack_period: An optional `int`. Defaults to `0`.
		  legacy_autotune: An optional `bool`. Defaults to `True`.
		  buffer_size_min: An optional `int`. Defaults to `0`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function PrefetchDataset(input_dataset:Dynamic, buffer_size:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?slack_period:Dynamic, ?legacy_autotune:Dynamic, ?buffer_size_min:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An op which linearizes one Tensor value to an opaque variant tensor.
		
		Args:
		  input: A `Tensor`. A tensor that will be linearized.
		  shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `[]`.
		    The shape of the tensor.
		  layout: An optional list of `ints`. Defaults to `[]`.
		    A vector holding the requested layout in minor-to-major sequence. If a layout
		    attribute is passed but its values are all -1 the layout will be computed by
		    the infeed operation.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function Prelinearize(input:Dynamic, ?shape:Dynamic, ?layout:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An op which linearizes multiple Tensor values to an opaque variant tensor.
		
		Args:
		  inputs: A list of `Tensor` objects.
		    A list of tensors that will be provided using the infeed mechanism.
		  shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    The shapes of each tensor in `inputs`.
		  layouts: An optional list of `ints`. Defaults to `[]`.
		    A vector holding the requested layout in minor-to-major sequence for all the
		    tuple shapes in the order the shapes appear in the "shapes" input. The layout
		    elements for a sub-shape can be set to -1 in which case the corresponding layout
		    will be computed by the infeed operation.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function PrelinearizeTuple(inputs:Dynamic, shapes:Dynamic, ?layouts:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An identity op that triggers an error if a gradient is requested.
		
		When executed in a graph, this op outputs its input tensor as-is.
		
		When building ops to compute gradients, the TensorFlow gradient system
		will return an error when trying to lookup the gradient of this op,
		because no gradient must ever be registered for this function.  This
		op exists to prevent subtle bugs from silently returning unimplemented
		gradients in some corner cases.
		
		Args:
		  input: A `Tensor`. any tensor.
		  message: An optional `string`. Defaults to `""`.
		    Will be printed in the error when anyone tries to differentiate
		    this operation.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function PreventGradient(input:Dynamic, ?message:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Prints a list of tensors.
		
		Passes `input` through to `output` and prints `data` when evaluating.
		
		Args:
		  input: A `Tensor`. The tensor passed to `output`
		  data: A list of `Tensor` objects.
		    A list of tensors to print out when op is evaluated.
		  message: An optional `string`. Defaults to `""`.
		    A string, prefix of the error message.
		  first_n: An optional `int`. Defaults to `-1`.
		    Only log `first_n` number of times. -1 disables logging.
		  summarize: An optional `int`. Defaults to `3`.
		    Only print this many entries of each tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Print(input:Dynamic, data:Dynamic, ?message:Dynamic, ?first_n:Dynamic, ?summarize:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Prints a string scalar.
		
		Prints a string scalar to the desired output_stream.
		
		Args:
		  input: A `Tensor` of type `string`. The string scalar to print.
		  output_stream: An optional `string`. Defaults to `"stderr"`.
		    A string specifying the output stream or logging level to print to.
		  end: An optional `string`. Defaults to `"\n"`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function PrintV2(input:Dynamic, ?output_stream:Dynamic, ?end:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A queue that produces elements sorted by the first component value.
		
		Note that the PriorityQueue requires the first component of any element
		to be a scalar int64, in addition to the other elements declared by
		component_types.  Therefore calls to Enqueue and EnqueueMany (resp. Dequeue
		and DequeueMany) on a PriorityQueue will all require (resp. output) one extra
		entry in their input (resp. output) lists.
		
		Args:
		  shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    The shape of each component in a value. The length of this attr must
		    be either 0 or the same as the length of component_types. If the length of
		    this attr is 0, the shapes of queue elements are not constrained, and
		    only one element may be dequeued at a time.
		  component_types: An optional list of `tf.DTypes`. Defaults to `[]`.
		    The type of each component in a value.
		  capacity: An optional `int`. Defaults to `-1`.
		    The upper bound on the number of elements in this queue.
		    Negative numbers mean no limit.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this queue is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this queue will be shared under the given name
		    across multiple sessions.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function PriorityQueue(shapes:Dynamic, ?component_types:Dynamic, ?capacity:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A queue that produces elements sorted by the first component value.
		
		Note that the PriorityQueue requires the first component of any element
		to be a scalar int64, in addition to the other elements declared by
		component_types.  Therefore calls to Enqueue and EnqueueMany (resp. Dequeue
		and DequeueMany) on a PriorityQueue will all require (resp. output) one extra
		entry in their input (resp. output) lists.
		
		Args:
		  shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`).
		    The shape of each component in a value. The length of this attr must
		    be either 0 or the same as the length of component_types. If the length of
		    this attr is 0, the shapes of queue elements are not constrained, and
		    only one element may be dequeued at a time.
		  component_types: An optional list of `tf.DTypes`. Defaults to `[]`.
		    The type of each component in a value.
		  capacity: An optional `int`. Defaults to `-1`.
		    The upper bound on the number of elements in this queue.
		    Negative numbers mean no limit.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this queue is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this queue will be shared under the given name
		    across multiple sessions.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function PriorityQueueV2(shapes:Dynamic, ?component_types:Dynamic, ?capacity:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that uses a custom thread pool to compute `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  num_threads: A `Tensor` of type `int64`.
		    Identifies the number of threads to use for the private threadpool.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function PrivateThreadPoolDataset(input_dataset:Dynamic, num_threads:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the product of elements across dimensions of a tensor.
		
		Reduces `input` along the dimensions given in `axis`. Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`axis`. If `keep_dims` is true, the reduced dimensions are
		retained with length 1.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    The tensor to reduce.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The dimensions to reduce. Must be in the range
		    `[-rank(input), rank(input))`.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Prod(input:Dynamic, axis:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Invokes a python function to compute func(input)->output.
		
		This operation is considered stateful. For a stateless version, see
		PyFuncStateless.
		
		Args:
		  input: A list of `Tensor` objects.
		    List of Tensors that will provide input to the Op.
		  token: A `string`.
		    A token representing a registered python function in this address space.
		  Tout: A list of `tf.DTypes`. Data types of the outputs from the op.
		    The length of the list specifies the number of outputs.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function PyFunc(input:Dynamic, token:Dynamic, Tout:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A stateless version of PyFunc.
		
		Args:
		  input: A list of `Tensor` objects.
		  token: A `string`.
		  Tout: A list of `tf.DTypes`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function PyFuncStateless(input:Dynamic, token:Dynamic, Tout:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the QR decompositions of one or more matrices.
		
		Computes the QR decomposition of each inner matrix in `tensor` such that
		`tensor[..., :, :] = q[..., :, :] * r[..., :,:])`
		
		Currently, the gradient for the QR decomposition is well-defined only when
		the first `P` columns of the inner matrix are linearly independent, where
		`P` is the minimum of `M` and `N`, the 2 inner-most dimmensions of `tensor`.
		
		```python
		# a is a tensor.
		# q is a tensor of orthonormal matrices.
		# r is a tensor of upper triangular matrices.
		q, r = qr(a)
		q_full, r_full = qr(a, full_matrices=True)
		```
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		    A tensor of shape `[..., M, N]` whose inner-most 2 dimensions
		    form matrices of size `[M, N]`. Let `P` be the minimum of `M` and `N`.
		  full_matrices: An optional `bool`. Defaults to `False`.
		    If true, compute full-sized `q` and `r`. If false
		    (the default), compute only the leading `P` columns of `q`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (q, r).
		
		  q: A `Tensor`. Has the same type as `input`.
		  r: A `Tensor`. Has the same type as `input`.
	**/
	static public function Qr(input:Dynamic, ?full_matrices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Use QuantizeAndDequantizeV2 instead.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  signed_input: An optional `bool`. Defaults to `True`.
		  num_bits: An optional `int`. Defaults to `8`.
		  range_given: An optional `bool`. Defaults to `False`.
		  input_min: An optional `float`. Defaults to `0`.
		  input_max: An optional `float`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function QuantizeAndDequantize(input:Dynamic, ?signed_input:Dynamic, ?num_bits:Dynamic, ?range_given:Dynamic, ?input_min:Dynamic, ?input_max:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Quantizes then dequantizes a tensor.
		
		This op simulates the precision loss from the quantized forward pass by:
		
		1. Quantizing the tensor to fixed point numbers, which should match the target
		   quantization method when it is used in inference.
		2. Dequantizing it back to floating point numbers for the following ops, most
		   likely matmul.
		
		There are different ways to quantize. This version uses only scaling, so 0.0
		maps to 0.
		
		From the specified 'num_bits' in the quantized output type, it determines
		minimum and maximum representable quantized values.
		
		e.g.
		
		*   [-128, 127] for signed, num_bits = 8, or
		*   [0, 255] for unsigned, num_bits = 8.
		
		If range_given == False, the initial input_min, input_max will be determined
		automatically as the minimum and maximum values in the input tensor, otherwise
		the specified values of input_min, input_max are used.
		
		Note: If the input_min, input_max are specified, they do not need to equal the
		actual minimum and maximum values in the tensor. e.g. in some cases it may be
		beneficial to specify these values such that the low probability extremes of the
		input distribution are clipped.
		
		This op determines the maximum scale_factor that would map the initial
		[input_min, input_max] range to a range that lies within the representable
		quantized range.
		
		It determines the scale from one of input_min and input_max, then updates the
		other one to maximize the representable range.
		
		e.g.
		
		*   if the output is signed, num_bits = 8, [input_min, input_max] = [-10.0,
		    5.0]: it would use a scale_factor of -128 / -10.0 = 12.8 In this case, it
		    would update input_max to be 127 / 12.8 = 9.921875
		*   if the output is signed, num_bits = 8, [input_min, input_max] = [-10.0,
		    10.0]: it would use a scale_factor of 127 / 10.0 = 12.7 In this case, it
		    would update input_min to be 128.0 / 12.7 = -10.07874
		*   if the output is unsigned, input_min is forced to be 0, and only the
		    specified input_max is used.
		
		After determining the scale_factor and updating the input range, it applies the
		following to each value in the 'input' tensor.
		
		output = round(clamp(value, input_min, input_max) * scale_factor) / scale_factor.
		
		The above round function rounds the value based on the given round_mode.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		    Tensor to quantize and then dequantize.
		  input_min: A `Tensor`. Must have the same type as `input`.
		    If `range_given == True`, this specifies the minimum input value that needs to
		    be represented, otherwise it is determined from the min value of the `input`
		    tensor.
		  input_max: A `Tensor`. Must have the same type as `input`.
		    If `range_given == True`, this specifies the maximum input value that needs to
		    be represented, otherwise it is determined from the max value of the `input`
		    tensor.
		  signed_input: An optional `bool`. Defaults to `True`.
		    Whether the quantization is signed or unsigned. (actually this parameter should
		    have been called <b>`signed_output`</b>)
		  num_bits: An optional `int`. Defaults to `8`.
		    The bitwidth of the quantization.
		  range_given: An optional `bool`. Defaults to `False`.
		    Whether the range is given or should be determined from the `input` tensor.
		  round_mode: An optional `string` from: `"HALF_TO_EVEN", "HALF_UP"`. Defaults to `"HALF_TO_EVEN"`.
		    The 'round_mode' attribute controls which rounding tie-breaking algorithm is
		    used when rounding float values to their quantized equivalents. The following
		    rounding modes are currently supported:
		
		    *   HALF_TO_EVEN: this is the default round_mode.
		    *   HALF_UP: round towards positive. In this mode 7.5 rounds up to 8 and -7.5
		        rounds up to -7.
		  narrow_range: An optional `bool`. Defaults to `False`.
		    If True, then the absolute value of the quantized minimum value is the same as
		    the quantized maximum value, instead of 1 greater.
		    i.e. for 8 bit quantization, the minimum value is -127 instead of -128.
		  axis: An optional `int`. Defaults to `-1`.
		    If specified, this axis is treated as a channel or slice axis, and a separate
		    quantization range is used for each channel or slice along this axis.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function QuantizeAndDequantizeV2(input:Dynamic, input_min:Dynamic, input_max:Dynamic, ?signed_input:Dynamic, ?num_bits:Dynamic, ?range_given:Dynamic, ?round_mode:Dynamic, ?narrow_range:Dynamic, ?axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Quantizes then dequantizes a tensor.
		
		This is almost identical to QuantizeAndDequantizeV2, except that num_bits is a
		tensor, so its value can change during training.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  input_min: A `Tensor`. Must have the same type as `input`.
		  input_max: A `Tensor`. Must have the same type as `input`.
		  num_bits: A `Tensor` of type `int32`.
		  signed_input: An optional `bool`. Defaults to `True`.
		  range_given: An optional `bool`. Defaults to `True`.
		  narrow_range: An optional `bool`. Defaults to `False`.
		  axis: An optional `int`. Defaults to `-1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function QuantizeAndDequantizeV3(input:Dynamic, input_min:Dynamic, input_max:Dynamic, num_bits:Dynamic, ?signed_input:Dynamic, ?range_given:Dynamic, ?narrow_range:Dynamic, ?axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Quantizes then dequantizes a tensor.
		
		This is almost identical to QuantizeAndDequantizeV2, except that it returns a
		gradient of 1 for inputs that are within the quantization range, or 0 otherwise.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		    Tensor to quantize and then dequantize.
		  input_min: A `Tensor`. Must have the same type as `input`.
		    If `range_given == True`, this specifies the minimum input value that needs to
		    be represented, otherwise it is determined from the min value of the `input`
		    tensor.
		  input_max: A `Tensor`. Must have the same type as `input`.
		    If `range_given == True`, this specifies the maximum input value that needs to
		    be represented, otherwise it is determined from the max value of the `input`
		    tensor.
		  signed_input: An optional `bool`. Defaults to `True`.
		    Whether the quantization is signed or unsigned. (actually this parameter should
		    have been called <b>`signed_output`</b>)
		  num_bits: An optional `int`. Defaults to `8`.
		    The bitwidth of the quantization.
		  range_given: An optional `bool`. Defaults to `False`.
		    Whether the range is given or should be determined from the `input` tensor.
		  round_mode: An optional `string` from: `"HALF_TO_EVEN", "HALF_UP"`. Defaults to `"HALF_TO_EVEN"`.
		    The 'round_mode' attribute controls which rounding tie-breaking algorithm is
		    used when rounding float values to their quantized equivalents. The following
		    rounding modes are currently supported:
		
		    *   HALF_TO_EVEN: this is the default round_mode.
		    *   HALF_UP: round towards positive. In this mode 7.5 rounds up to 8 and -7.5
		        rounds up to -7.
		  narrow_range: An optional `bool`. Defaults to `False`.
		    If True, then the absolute value of the quantized minimum value is the same as
		    the quantized maximum value, instead of 1 greater.
		    i.e. for 8 bit quantization, the minimum value is -127 instead of -128.
		  axis: An optional `int`. Defaults to `-1`.
		    If specified, this axis is treated as a channel or slice axis, and a separate
		    quantization range is used for each channel or slice along this axis.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function QuantizeAndDequantizeV4(input:Dynamic, input_min:Dynamic, input_max:Dynamic, ?signed_input:Dynamic, ?num_bits:Dynamic, ?range_given:Dynamic, ?round_mode:Dynamic, ?narrow_range:Dynamic, ?axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the gradient of `QuantizeAndDequantizeV4`.
		
		Returns a gradient of 1 for inputs that are within the quantization range,
		or 0 otherwise.
		
		Args:
		  gradients: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  input: A `Tensor`. Must have the same type as `gradients`.
		  input_min: A `Tensor`. Must have the same type as `gradients`.
		  input_max: A `Tensor`. Must have the same type as `gradients`.
		  axis: An optional `int`. Defaults to `-1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (input_backprop, input_min_backprop, input_max_backprop).
		
		  input_backprop: A `Tensor`. Has the same type as `gradients`.
		  input_min_backprop: A `Tensor`. Has the same type as `gradients`.
		  input_max_backprop: A `Tensor`. Has the same type as `gradients`.
	**/
	static public function QuantizeAndDequantizeV4Grad(gradients:Dynamic, input:Dynamic, input_min:Dynamic, input_max:Dynamic, ?axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Convert the quantized 'input' tensor into a lower-precision 'output', using the
		
		actual distribution of the values to maximize the usage of the lower bit depth
		and adjusting the output min and max ranges accordingly.
		
		[input_min, input_max] are scalar floats that specify the range for the float
		interpretation of the 'input' data. For example, if input_min is -1.0f and
		input_max is 1.0f, and we are dealing with quint16 quantized data, then a 0
		value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.
		
		This operator tries to squeeze as much precision as possible into an output with
		a lower bit depth by calculating the actual min and max values found in the
		data. For example, maybe that quint16 input has no values lower than 16,384 and
		none higher than 49,152. That means only half the range is actually needed, all
		the float interpretations are between -0.5f and 0.5f, so if we want to compress
		the data into a quint8 output, we can use that range rather than the theoretical
		-1.0f to 1.0f that is suggested by the input min and max.
		
		In practice, this is most useful for taking output from operations like
		QuantizedMatMul that can produce higher bit-depth outputs than their inputs and
		may have large potential output ranges, but in practice have a distribution of
		input values that only uses a small fraction of the possible range. By feeding
		that output into this operator, we can reduce it from 32 bits down to 8 with
		minimal loss of accuracy.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  input_min: A `Tensor` of type `float32`.
		    The float value that the minimum quantized input value represents.
		  input_max: A `Tensor` of type `float32`.
		    The float value that the maximum quantized input value represents.
		  out_type: A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`.
		    The type of the output. Should be a lower bit depth than Tinput.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, output_min, output_max).
		
		  output: A `Tensor` of type `out_type`.
		  output_min: A `Tensor` of type `float32`.
		  output_max: A `Tensor` of type `float32`.
	**/
	static public function QuantizeDownAndShrinkRange(input:Dynamic, input_min:Dynamic, input_max:Dynamic, out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.
		
		[min_range, max_range] are scalar floats that specify the range for
		the 'input' data. The 'mode' attribute controls exactly which calculations are
		used to convert the float values to their quantized equivalents.  The
		'round_mode' attribute controls which rounding tie-breaking algorithm is used
		when rounding float values to their quantized equivalents.
		
		In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:
		
		```
		out[i] = (in[i] - min_range) * range(T) / (max_range - min_range)
		if T == qint8: out[i] -= (range(T) + 1) / 2.0
		```
		
		here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`
		
		*MIN_COMBINED Mode Example*
		
		Assume the input is type float and has a possible range of [0.0, 6.0] and the
		output type is quint8 ([0, 255]). The min_range and max_range values should be
		specified as 0.0 and 6.0. Quantizing from float to quint8 will multiply each
		value of the input by 255/6 and cast to quint8.
		
		If the output type was qint8 ([-128, 127]), the operation will additionally
		subtract each value by 128 prior to casting, so that the range of values aligns
		with the range of qint8.
		
		If the mode is 'MIN_FIRST', then this approach is used:
		
		```
		num_discrete_values = 1 << (# of bits in T)
		range_adjust = num_discrete_values / (num_discrete_values - 1)
		range = (range_max - range_min) * range_adjust
		range_scale = num_discrete_values / range
		quantized = round(input * range_scale) - round(range_min * range_scale) +
		  numeric_limits<T>::min()
		quantized = max(quantized, numeric_limits<T>::min())
		quantized = min(quantized, numeric_limits<T>::max())
		```
		
		The biggest difference between this and MIN_COMBINED is that the minimum range
		is rounded first, before it's subtracted from the rounded value. With
		MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing
		and dequantizing will introduce a larger and larger error.
		
		*SCALED mode Example*
		
		`SCALED` mode matches the quantization approach used in
		`QuantizeAndDequantize{V2|V3}`.
		
		If the mode is `SCALED`, the quantization is performed by multiplying each
		input value by a scaling_factor.
		The scaling_factor is determined from `min_range` and `max_range` to be as large
		as possible such that the range from `min_range` to `max_range` is representable
		within values of type T.
		
		```c++
		
		  const int min_T = std::numeric_limits<T>::min();
		  const int max_T = std::numeric_limits<T>::max();
		  const float max_float = std::numeric_limits<float>::max();
		
		  const float scale_factor_from_min_side =
		      (min_T * min_range > 0) ? min_T / min_range : max_float;
		  const float scale_factor_from_max_side =
		      (max_T * max_range > 0) ? max_T / max_range : max_float;
		
		  const float scale_factor = std::min(scale_factor_from_min_side,
		                                      scale_factor_from_max_side);
		```
		
		We next use the scale_factor to adjust min_range and max_range as follows:
		
		```c++
		      min_range = min_T / scale_factor;
		      max_range = max_T / scale_factor;
		```
		
		
		e.g. if T = qint8, and initially min_range = -10, and max_range = 9, we would
		compare -128/-10.0 = 12.8 to 127/9.0 = 14.11, and set scaling_factor = 12.8
		In this case, min_range would remain -10, but max_range would be adjusted to
		127 / 12.8 = 9.921875
		
		So we will quantize input values in the range (-10, 9.921875) to (-128, 127).
		
		The input tensor can now be quantized by clipping values to the range
		`min_range` to `max_range`, then multiplying by scale_factor as follows:
		
		```c++
		result = round(min(max_range, max(min_range, input)) * scale_factor)
		```
		
		The adjusted `min_range` and `max_range` are returned as outputs 2 and 3 of
		this operation. These outputs should be used as the range for any further
		calculations.
		
		
		*narrow_range (bool) attribute*
		
		If true, we do not use the minimum quantized value.
		i.e. for int8 the quantized output, it would be restricted to the range
		-127..127 instead of the full -128..127 range.
		This is provided for compatibility with certain inference backends.
		(Only applies to SCALED mode)
		
		
		*axis (int) attribute*
		
		An optional `axis` attribute can specify a dimension index of the input tensor,
		such that quantization ranges will be calculated and applied separately for each
		slice of the tensor along that dimension. This is useful for per-channel
		quantization.
		
		If axis is specified, min_range and max_range
		
		if `axis`=None, per-tensor quantization is performed as normal.
		
		
		*ensure_minimum_range (float) attribute*
		
		Ensures the minimum quantization range is at least this value.
		The legacy default value for this is 0.01, but it is strongly suggested to
		set it to 0 for new uses.
		
		Args:
		  input: A `Tensor` of type `float32`.
		  min_range: A `Tensor` of type `float32`.
		    The minimum value of the quantization range. This value may be adjusted by the
		    op depending on other parameters. The adjusted value is written to `output_min`.
		    If the `axis` attribute is specified, this must be a 1-D tensor whose size
		    matches the `axis` dimension of the input and output tensors.
		  max_range: A `Tensor` of type `float32`.
		    The maximum value of the quantization range. This value may be adjusted by the
		    op depending on other parameters. The adjusted value is written to `output_max`.
		    If the `axis` attribute is specified, this must be a 1-D tensor whose size
		    matches the `axis` dimension of the input and output tensors.
		  T: A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`.
		  mode: An optional `string` from: `"MIN_COMBINED", "MIN_FIRST", "SCALED"`. Defaults to `"MIN_COMBINED"`.
		  round_mode: An optional `string` from: `"HALF_AWAY_FROM_ZERO", "HALF_TO_EVEN"`. Defaults to `"HALF_AWAY_FROM_ZERO"`.
		  narrow_range: An optional `bool`. Defaults to `False`.
		  axis: An optional `int`. Defaults to `-1`.
		  ensure_minimum_range: An optional `float`. Defaults to `0.01`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, output_min, output_max).
		
		  output: A `Tensor` of type `T`.
		  output_min: A `Tensor` of type `float32`.
		  output_max: A `Tensor` of type `float32`.
	**/
	static public function QuantizeV2(input:Dynamic, min_range:Dynamic, max_range:Dynamic, T:Dynamic, ?mode:Dynamic, ?round_mode:Dynamic, ?narrow_range:Dynamic, ?axis:Dynamic, ?ensure_minimum_range:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x + y element-wise, working on quantized buffers.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  y: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  min_x: A `Tensor` of type `float32`.
		    The float value that the lowest quantized `x` value represents.
		  max_x: A `Tensor` of type `float32`.
		    The float value that the highest quantized `x` value represents.
		  min_y: A `Tensor` of type `float32`.
		    The float value that the lowest quantized `y` value represents.
		  max_y: A `Tensor` of type `float32`.
		    The float value that the highest quantized `y` value represents.
		  Toutput: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (z, min_z, max_z).
		
		  z: A `Tensor` of type `Toutput`.
		  min_z: A `Tensor` of type `float32`.
		  max_z: A `Tensor` of type `float32`.
	**/
	static public function QuantizedAdd(x:Dynamic, y:Dynamic, min_x:Dynamic, max_x:Dynamic, min_y:Dynamic, max_y:Dynamic, ?Toutput:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Produces the average pool of the input tensor for quantized types.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    4-D with shape `[batch, height, width, channels]`.
		  min_input: A `Tensor` of type `float32`.
		    The float value that the lowest quantized input value represents.
		  max_input: A `Tensor` of type `float32`.
		    The float value that the highest quantized input value represents.
		  ksize: A list of `ints`.
		    The size of the window for each dimension of the input tensor.
		    The length must be 4 to match the number of dimensions of the input.
		  strides: A list of `ints`.
		    The stride of the sliding window for each dimension of the input
		    tensor.  The length must be 4 to match the number of dimensions of the input.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor`. Has the same type as `input`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedAvgPool(input:Dynamic, min_input:Dynamic, max_input:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Quantized Batch normalization.
		
		This op is deprecated and will be removed in the future. Prefer
		`tf.nn.batch_normalization`.
		
		Args:
		  t: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    A 4D input Tensor.
		  t_min: A `Tensor` of type `float32`.
		    The value represented by the lowest quantized input.
		  t_max: A `Tensor` of type `float32`.
		    The value represented by the highest quantized input.
		  m: A `Tensor`. Must have the same type as `t`.
		    A 1D mean Tensor with size matching the last dimension of t.
		    This is the first output from tf.nn.moments,
		    or a saved moving average thereof.
		  m_min: A `Tensor` of type `float32`.
		    The value represented by the lowest quantized mean.
		  m_max: A `Tensor` of type `float32`.
		    The value represented by the highest quantized mean.
		  v: A `Tensor`. Must have the same type as `t`.
		    A 1D variance Tensor with size matching the last dimension of t.
		    This is the second output from tf.nn.moments,
		    or a saved moving average thereof.
		  v_min: A `Tensor` of type `float32`.
		    The value represented by the lowest quantized variance.
		  v_max: A `Tensor` of type `float32`.
		    The value represented by the highest quantized variance.
		  beta: A `Tensor`. Must have the same type as `t`.
		    A 1D beta Tensor with size matching the last dimension of t.
		    An offset to be added to the normalized tensor.
		  beta_min: A `Tensor` of type `float32`.
		    The value represented by the lowest quantized offset.
		  beta_max: A `Tensor` of type `float32`.
		    The value represented by the highest quantized offset.
		  gamma: A `Tensor`. Must have the same type as `t`.
		    A 1D gamma Tensor with size matching the last dimension of t.
		    If "scale_after_normalization" is true, this tensor will be multiplied
		    with the normalized tensor.
		  gamma_min: A `Tensor` of type `float32`.
		    The value represented by the lowest quantized gamma.
		  gamma_max: A `Tensor` of type `float32`.
		    The value represented by the highest quantized gamma.
		  out_type: A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`.
		  variance_epsilon: A `float`. A small float number to avoid dividing by 0.
		  scale_after_normalization: A `bool`.
		    A bool indicating whether the resulted tensor
		    needs to be multiplied with gamma.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (result, result_min, result_max).
		
		  result: A `Tensor` of type `out_type`.
		  result_min: A `Tensor` of type `float32`.
		  result_max: A `Tensor` of type `float32`.
	**/
	static public function QuantizedBatchNormWithGlobalNormalization(t:Dynamic, t_min:Dynamic, t_max:Dynamic, m:Dynamic, m_min:Dynamic, m_max:Dynamic, v:Dynamic, v_min:Dynamic, v_max:Dynamic, beta:Dynamic, beta_min:Dynamic, beta_max:Dynamic, gamma:Dynamic, gamma_min:Dynamic, gamma_max:Dynamic, out_type:Dynamic, variance_epsilon:Dynamic, scale_after_normalization:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adds Tensor 'bias' to Tensor 'input' for Quantized types.
		
		Broadcasts the values of bias on dimensions 0..N-2 of 'input'.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  bias: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    A 1D bias Tensor with size matching the last dimension of 'input'.
		  min_input: A `Tensor` of type `float32`.
		    The float value that the lowest quantized input value represents.
		  max_input: A `Tensor` of type `float32`.
		    The float value that the highest quantized input value represents.
		  min_bias: A `Tensor` of type `float32`.
		    The float value that the lowest quantized bias value represents.
		  max_bias: A `Tensor` of type `float32`.
		    The float value that the highest quantized bias value represents.
		  out_type: A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_out, max_out).
		
		  output: A `Tensor` of type `out_type`.
		  min_out: A `Tensor` of type `float32`.
		  max_out: A `Tensor` of type `float32`.
	**/
	static public function QuantizedBiasAdd(input:Dynamic, bias:Dynamic, min_input:Dynamic, max_input:Dynamic, min_bias:Dynamic, max_bias:Dynamic, out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Concatenates quantized tensors along one dimension.
		
		Args:
		  concat_dim: A `Tensor` of type `int32`.
		    0-D.  The dimension along which to concatenate.  Must be in the
		    range [0, rank(values)).
		  values: A list of at least 2 `Tensor` objects with the same type.
		    The `N` Tensors to concatenate. Their ranks and types must match,
		    and their sizes must match in all dimensions except `concat_dim`.
		  input_mins: A list with the same length as `values` of `Tensor` objects with type `float32`.
		    The minimum scalar values for each of the input tensors.
		  input_maxes: A list with the same length as `values` of `Tensor` objects with type `float32`.
		    The maximum scalar values for each of the input tensors.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, output_min, output_max).
		
		  output: A `Tensor`. Has the same type as `values`.
		  output_min: A `Tensor` of type `float32`.
		  output_max: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConcat(concat_dim:Dynamic, values:Dynamic, input_mins:Dynamic, input_maxes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes a 2D convolution given quantized 4D input and filter tensors.
		
		The inputs are quantized tensors where the lowest value represents the real
		number of the associated minimum, and the highest represents the maximum.
		This means that you can only interpret the quantized output in the same way, by
		taking the returned minimum and maximum values into account.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    filter's input_depth dimension must match input's depth dimensions.
		  min_input: A `Tensor` of type `float32`.
		    The float value that the lowest quantized input value represents.
		  max_input: A `Tensor` of type `float32`.
		    The float value that the highest quantized input value represents.
		  min_filter: A `Tensor` of type `float32`.
		    The float value that the lowest quantized filter value represents.
		  max_filter: A `Tensor` of type `float32`.
		    The float value that the highest quantized filter value represents.
		  strides: A list of `ints`.
		    The stride of the sliding window for each dimension of the input
		    tensor.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    1-D tensor of length 4.  The dilation factor for each dimension of
		    `input`. If set to k > 1, there will be k-1 skipped cells between each
		    filter element on that dimension. The dimension order is determined by the
		    value of `data_format`, see above for details. Dilations in the batch and
		    depth dimensions must be 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2D(input:Dynamic, filter:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  min_input: A `Tensor` of type `float32`.
		  max_input: A `Tensor` of type `float32`.
		  min_filter: A `Tensor` of type `float32`.
		  max_filter: A `Tensor` of type `float32`.
		  strides: A list of `ints`.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2DAndRelu(input:Dynamic, filter:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  min_input: A `Tensor` of type `float32`.
		  max_input: A `Tensor` of type `float32`.
		  min_filter: A `Tensor` of type `float32`.
		  max_filter: A `Tensor` of type `float32`.
		  min_freezed_output: A `Tensor` of type `float32`.
		  max_freezed_output: A `Tensor` of type `float32`.
		  strides: A list of `ints`.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2DAndReluAndRequantize(input:Dynamic, filter:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, min_freezed_output:Dynamic, max_freezed_output:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  min_input: A `Tensor` of type `float32`.
		  max_input: A `Tensor` of type `float32`.
		  min_filter: A `Tensor` of type `float32`.
		  max_filter: A `Tensor` of type `float32`.
		  min_freezed_output: A `Tensor` of type `float32`.
		  max_freezed_output: A `Tensor` of type `float32`.
		  strides: A list of `ints`.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint8`.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2DAndRequantize(input:Dynamic, filter:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, min_freezed_output:Dynamic, max_freezed_output:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes QuantizedConv2D per channel.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original input tensor.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original filter tensor.
		  min_input: A `Tensor` of type `float32`.
		    The minimum value of the input tensor
		  max_input: A `Tensor` of type `float32`.
		    The maximum value of the input tensor.
		  min_filter: A `Tensor` of type `float32`.
		    The minimum value of the filter tensor.
		  max_filter: A `Tensor` of type `float32`.
		    The maximum value of the filter tensor.
		  strides: A list of `ints`. list of stride values.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		    The quantized type of output tensor that needs to be converted.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    list of dilation values.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2DPerChannel(input:Dynamic, filter:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  bias: A `Tensor` of type `float32`.
		  min_input: A `Tensor` of type `float32`.
		  max_input: A `Tensor` of type `float32`.
		  min_filter: A `Tensor` of type `float32`.
		  max_filter: A `Tensor` of type `float32`.
		  strides: A list of `ints`.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2DWithBias(input:Dynamic, filter:Dynamic, bias:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  bias: A `Tensor` of type `float32`.
		  min_input: A `Tensor` of type `float32`.
		  max_input: A `Tensor` of type `float32`.
		  min_filter: A `Tensor` of type `float32`.
		  max_filter: A `Tensor` of type `float32`.
		  strides: A list of `ints`.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2DWithBiasAndRelu(input:Dynamic, filter:Dynamic, bias:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  bias: A `Tensor`. Must be one of the following types: `float32`, `qint32`.
		  min_input: A `Tensor` of type `float32`.
		  max_input: A `Tensor` of type `float32`.
		  min_filter: A `Tensor` of type `float32`.
		  max_filter: A `Tensor` of type `float32`.
		  min_freezed_output: A `Tensor` of type `float32`.
		  max_freezed_output: A `Tensor` of type `float32`.
		  strides: A list of `ints`.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2DWithBiasAndReluAndRequantize(input:Dynamic, filter:Dynamic, bias:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, min_freezed_output:Dynamic, max_freezed_output:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  bias: A `Tensor`. Must be one of the following types: `float32`, `qint32`.
		  min_input: A `Tensor` of type `float32`.
		  max_input: A `Tensor` of type `float32`.
		  min_filter: A `Tensor` of type `float32`.
		  max_filter: A `Tensor` of type `float32`.
		  min_freezed_output: A `Tensor` of type `float32`.
		  max_freezed_output: A `Tensor` of type `float32`.
		  strides: A list of `ints`.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint8`.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2DWithBiasAndRequantize(input:Dynamic, filter:Dynamic, bias:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, min_freezed_output:Dynamic, max_freezed_output:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  bias: A `Tensor`. Must be one of the following types: `float32`, `qint32`.
		  min_input: A `Tensor` of type `float32`.
		  max_input: A `Tensor` of type `float32`.
		  min_filter: A `Tensor` of type `float32`.
		  max_filter: A `Tensor` of type `float32`.
		  min_freezed_output: A `Tensor` of type `float32`.
		  max_freezed_output: A `Tensor` of type `float32`.
		  summand: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  min_summand: A `Tensor` of type `float32`.
		  max_summand: A `Tensor` of type `float32`.
		  strides: A list of `ints`.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2DWithBiasSignedSumAndReluAndRequantize(input:Dynamic, filter:Dynamic, bias:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, min_freezed_output:Dynamic, max_freezed_output:Dynamic, summand:Dynamic, min_summand:Dynamic, max_summand:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  bias: A `Tensor` of type `float32`.
		  min_input: A `Tensor` of type `float32`.
		  max_input: A `Tensor` of type `float32`.
		  min_filter: A `Tensor` of type `float32`.
		  max_filter: A `Tensor` of type `float32`.
		  summand: A `Tensor` of type `float32`.
		  strides: A list of `ints`.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2DWithBiasSumAndRelu(input:Dynamic, filter:Dynamic, bias:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, summand:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  bias: A `Tensor`. Must be one of the following types: `float32`, `qint32`.
		  min_input: A `Tensor` of type `float32`.
		  max_input: A `Tensor` of type `float32`.
		  min_filter: A `Tensor` of type `float32`.
		  max_filter: A `Tensor` of type `float32`.
		  min_freezed_output: A `Tensor` of type `float32`.
		  max_freezed_output: A `Tensor` of type `float32`.
		  summand: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  min_summand: A `Tensor` of type `float32`.
		  max_summand: A `Tensor` of type `float32`.
		  strides: A list of `ints`.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedConv2DWithBiasSumAndReluAndRequantize(input:Dynamic, filter:Dynamic, bias:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, min_freezed_output:Dynamic, max_freezed_output:Dynamic, summand:Dynamic, min_summand:Dynamic, max_summand:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes quantized depthwise Conv2D.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original input tensor.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original filter tensor.
		  min_input: A `Tensor` of type `float32`.
		    The float value that the minimum quantized input value represents.
		  max_input: A `Tensor` of type `float32`.
		    The float value that the maximum quantized input value represents.
		  min_filter: A `Tensor` of type `float32`.
		    The float value that the minimum quantized filter value represents.
		  max_filter: A `Tensor` of type `float32`.
		    The float value that the maximum quantized filter value represents.
		  strides: A list of `ints`. List of stride values.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		    The type of the output.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    List of dilation values.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedDepthwiseConv2D(input:Dynamic, filter:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes quantized depthwise Conv2D with Bias.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original input tensor.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original filter tensor.
		  bias: A `Tensor` of type `float32`. The original bias tensor.
		  min_input: A `Tensor` of type `float32`.
		    The float value that the minimum quantized input value represents.
		  max_input: A `Tensor` of type `float32`.
		    The float value that the maximum quantized input value represents.
		  min_filter: A `Tensor` of type `float32`.
		    The float value that the minimum quantized filter value represents.
		  max_filter: A `Tensor` of type `float32`.
		    The float value that the maximum quantized filter value represents.
		  strides: A list of `ints`. List of stride values.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		    The type of the output.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    List of dilation values.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedDepthwiseConv2DWithBias(input:Dynamic, filter:Dynamic, bias:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes quantized depthwise Conv2D with Bias and Relu.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original input tensor.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original filter tensor.
		  bias: A `Tensor` of type `float32`. The original bias tensor.
		  min_input: A `Tensor` of type `float32`.
		    The float value that the minimum quantized input value represents.
		  max_input: A `Tensor` of type `float32`.
		    The float value that the maximum quantized input value represents.
		  min_filter: A `Tensor` of type `float32`.
		    The float value that the minimum quantized filter value represents.
		  max_filter: A `Tensor` of type `float32`.
		    The float value that the maximum quantized filter value represents.
		  strides: A list of `ints`. List of stride values.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		    The type of the output.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    List of dilation values.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedDepthwiseConv2DWithBiasAndRelu(input:Dynamic, filter:Dynamic, bias:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes quantized depthwise Conv2D with Bias, Relu and Requantize.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original input tensor.
		  filter: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original filter tensor.
		  bias: A `Tensor`. Must be one of the following types: `float32`, `qint32`.
		    The original bias tensor.
		  min_input: A `Tensor` of type `float32`.
		    The float value that the minimum quantized input value represents.
		  max_input: A `Tensor` of type `float32`.
		    The float value that the maximum quantized input value represents.
		  min_filter: A `Tensor` of type `float32`.
		    The float value that the minimum quantized filter value represents.
		  max_filter: A `Tensor` of type `float32`.
		    The float value that the maximum quantized filter value represents.
		  min_freezed_output: A `Tensor` of type `float32`.
		    The minimum float value of the output tensor.
		  max_freezed_output: A `Tensor` of type `float32`.
		    The maximum float value of the output tensor.
		  strides: A list of `ints`. List of stride values.
		  padding: A `string` from: `"SAME", "VALID"`.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		    The type of the output.
		  dilations: An optional list of `ints`. Defaults to `[1, 1, 1, 1]`.
		    List of dilation values.
		  padding_list: An optional list of `ints`. Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor` of type `out_type`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize(input:Dynamic, filter:Dynamic, bias:Dynamic, min_input:Dynamic, max_input:Dynamic, min_filter:Dynamic, max_filter:Dynamic, min_freezed_output:Dynamic, max_freezed_output:Dynamic, strides:Dynamic, padding:Dynamic, ?out_type:Dynamic, ?dilations:Dynamic, ?padding_list:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Quantized Instance normalization.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    A 4D input Tensor.
		  x_min: A `Tensor` of type `float32`.
		    The value represented by the lowest quantized input.
		  x_max: A `Tensor` of type `float32`.
		    The value represented by the highest quantized input.
		  output_range_given: An optional `bool`. Defaults to `False`.
		    If True, `given_y_min` and `given_y_min`
		    and `given_y_max` are used as the output range. Otherwise,
		    the implementation computes the output range.
		  given_y_min: An optional `float`. Defaults to `0`.
		    Output in `y_min` if `output_range_given` is True.
		  given_y_max: An optional `float`. Defaults to `0`.
		    Output in `y_max` if `output_range_given` is True.
		  variance_epsilon: An optional `float`. Defaults to `1e-05`.
		    A small float number to avoid dividing by 0.
		  min_separation: An optional `float`. Defaults to `0.001`.
		    Minimum value of `y_max - y_min`
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (y, y_min, y_max).
		
		  y: A `Tensor`. Has the same type as `x`.
		  y_min: A `Tensor` of type `float32`.
		  y_max: A `Tensor` of type `float32`.
	**/
	static public function QuantizedInstanceNorm(x:Dynamic, x_min:Dynamic, x_max:Dynamic, ?output_range_given:Dynamic, ?given_y_min:Dynamic, ?given_y_max:Dynamic, ?variance_epsilon:Dynamic, ?min_separation:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Perform a quantized matrix multiplication of  `a` by the matrix `b`.
		
		The inputs must be two-dimensional matrices and the inner dimension of
		`a` (after being transposed if `transpose_a` is non-zero) must match the
		outer dimension of `b` (after being transposed if `transposed_b` is
		non-zero).
		
		Args:
		  a: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    Must be a two-dimensional tensor.
		  b: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    Must be a two-dimensional tensor.
		  min_a: A `Tensor` of type `float32`.
		    The float value that the lowest quantized `a` value represents.
		  max_a: A `Tensor` of type `float32`.
		    The float value that the highest quantized `a` value represents.
		  min_b: A `Tensor` of type `float32`.
		    The float value that the lowest quantized `b` value represents.
		  max_b: A `Tensor` of type `float32`.
		    The float value that the highest quantized `b` value represents.
		  Toutput: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		  transpose_a: An optional `bool`. Defaults to `False`.
		    If true, `a` is transposed before multiplication.
		  transpose_b: An optional `bool`. Defaults to `False`.
		    If true, `b` is transposed before multiplication.
		  Tactivation: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		    The type of output produced by activation function
		    following this operation.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (out, min_out, max_out).
		
		  out: A `Tensor` of type `Toutput`.
		  min_out: A `Tensor` of type `float32`.
		  max_out: A `Tensor` of type `float32`.
	**/
	static public function QuantizedMatMul(a:Dynamic, b:Dynamic, min_a:Dynamic, max_a:Dynamic, min_b:Dynamic, max_b:Dynamic, ?Toutput:Dynamic, ?transpose_a:Dynamic, ?transpose_b:Dynamic, ?Tactivation:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs a quantized matrix multiplication of `a` by the matrix `b` with bias
		add.
		
		  The inputs must be two-dimensional matrices and 1D bias vector. And the inner
		  dimension of `a` (after being transposed if `transpose_a` is non-zero) must
		  match the outer dimension of `b` (after being transposed if `transposed_b` is
		  non-zero). Then do broadcast add operation with bias values on the matrix
		  multiplication result. The bias size must match inner dimension of `b`.
		
		  Args:
		    a: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		      A matrix to be multiplied. Must be a two-dimensional tensor of type `quint8`.
		    b: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		      A matrix to be multiplied and must be a two-dimensional tensor of type `qint8`.
		    bias: A `Tensor`. Must be one of the following types: `float32`, `qint32`.
		      A 1D bias tensor with size matching inner dimension of `b` (after being
		      transposed if `transposed_b` is non-zero).
		    min_a: A `Tensor` of type `float32`.
		      The float value that the lowest quantized `a` value represents.
		    max_a: A `Tensor` of type `float32`.
		      The float value that the highest quantized `a` value represents.
		    min_b: A `Tensor` of type `float32`.
		      The float value that the lowest quantized `b` value represents.
		    max_b: A `Tensor` of type `float32`.
		      The float value that the highest quantized `b` value represents.
		    Toutput: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		    transpose_a: An optional `bool`. Defaults to `False`.
		      If true, `a` is transposed before multiplication.
		    transpose_b: An optional `bool`. Defaults to `False`.
		      If true, `b` is transposed before multiplication.
		    input_quant_mode: An optional `string` from: `"MIN_FIRST", "SCALED"`. Defaults to `"MIN_FIRST"`.
		      Input data quantization mode. Either MIN_FIRST(default) or SCALED.
		    name: A name for the operation (optional).
		
		  Returns:
		    A tuple of `Tensor` objects (out, min_out, max_out).
		
		    out: A `Tensor` of type `Toutput`.
		    min_out: A `Tensor` of type `float32`.
		    max_out: A `Tensor` of type `float32`.
		  
	**/
	static public function QuantizedMatMulWithBias(a:Dynamic, b:Dynamic, bias:Dynamic, min_a:Dynamic, max_a:Dynamic, min_b:Dynamic, max_b:Dynamic, ?Toutput:Dynamic, ?transpose_a:Dynamic, ?transpose_b:Dynamic, ?input_quant_mode:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  a: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  b: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  bias: A `Tensor`. Must be one of the following types: `float32`, `qint32`.
		  min_a: A `Tensor` of type `float32`.
		  max_a: A `Tensor` of type `float32`.
		  min_b: A `Tensor` of type `float32`.
		  max_b: A `Tensor` of type `float32`.
		  min_freezed_output: A `Tensor` of type `float32`.
		  max_freezed_output: A `Tensor` of type `float32`.
		  Toutput: A `tf.DType` from: `tf.float32`.
		  transpose_a: An optional `bool`. Defaults to `False`.
		  transpose_b: An optional `bool`. Defaults to `False`.
		  input_quant_mode: An optional `string` from: `"MIN_FIRST", "SCALED"`. Defaults to `"MIN_FIRST"`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Toutput`.
	**/
	static public function QuantizedMatMulWithBiasAndDequantize(a:Dynamic, b:Dynamic, bias:Dynamic, min_a:Dynamic, max_a:Dynamic, min_b:Dynamic, max_b:Dynamic, min_freezed_output:Dynamic, max_freezed_output:Dynamic, Toutput:Dynamic, ?transpose_a:Dynamic, ?transpose_b:Dynamic, ?input_quant_mode:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Perform a quantized matrix multiplication of  `a` by the matrix `b` with bias
		add and relu fusion.
		
		  The inputs must be two-dimensional matrices and 1D bias vector. And the inner
		  dimension of `a` (after being transposed if `transpose_a` is non-zero) must
		  match the outer dimension of `b` (after being transposed if `transposed_b` is
		  non-zero). Then do broadcast add operation with bias values on the matrix
		  multiplication result. The bias size must match inner dimension of `b`. Then do
		  relu activation to get non-negative result.
		
		  Args:
		    a: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		      A matrix to be multiplied. Must be a two-dimensional tensor of type `quint8`.
		    b: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		      A matrix to be multiplied and must be a two-dimensional tensor of type `qint8`.
		    bias: A `Tensor` of type `float32`.
		      A 1D bias tensor with size matching with inner dimension of `b` (after being
		      transposed if `transposed_b` is non-zero).
		    min_a: A `Tensor` of type `float32`.
		      The float value that the lowest quantized `a` value represents.
		    max_a: A `Tensor` of type `float32`.
		      The float value that the highest quantized `a` value represents.
		    min_b: A `Tensor` of type `float32`.
		      The float value that the lowest quantized `b` value represents.
		    max_b: A `Tensor` of type `float32`.
		      The float value that the highest quantized `b` value represents.
		    Toutput: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		    transpose_a: An optional `bool`. Defaults to `False`.
		      If true, `a` is transposed before multiplication.
		    transpose_b: An optional `bool`. Defaults to `False`.
		      If true, `b` is transposed before multiplication.
		    input_quant_mode: An optional `string` from: `"MIN_FIRST", "SCALED"`. Defaults to `"MIN_FIRST"`.
		      Input data quantization mode. Either MIN_FIRST(default) or SCALED.
		    name: A name for the operation (optional).
		
		  Returns:
		    A tuple of `Tensor` objects (out, min_out, max_out).
		
		    out: A `Tensor` of type `Toutput`.
		    min_out: A `Tensor` of type `float32`.
		    max_out: A `Tensor` of type `float32`.
		  
	**/
	static public function QuantizedMatMulWithBiasAndRelu(a:Dynamic, b:Dynamic, bias:Dynamic, min_a:Dynamic, max_a:Dynamic, min_b:Dynamic, max_b:Dynamic, ?Toutput:Dynamic, ?transpose_a:Dynamic, ?transpose_b:Dynamic, ?input_quant_mode:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Perform a quantized matrix multiplication of  `a` by the matrix `b` with bias
		add and relu and requantize fusion.
		
		  The inputs must be two-dimensional matrices and 1D bias vector. And the inner
		  dimension of `a` (after being transposed if `transpose_a` is non-zero) must
		  match the outer dimension of `b` (after being transposed if `transposed_b` is
		  non-zero). Then do broadcast add operation with bias values on the matrix
		  multiplication result. The bias size must match inner dimension of `b`.  Then do
		  relu activation to get non-negative result. Then do requantize operation to get
		  final uint8 result.
		
		  Args:
		    a: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		      A matrix to be multiplied. Must be a two-dimensional tensor of type `quint8`.
		    b: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		      A matrix to be multiplied and must be a two-dimensional tensor of type `qint8`.
		    bias: A `Tensor`. Must be one of the following types: `float32`, `qint32`.
		      A 1D bias tensor with size matching with inner dimension of `b` (after being
		      transposed if `transposed_b` is non-zero).
		    min_a: A `Tensor` of type `float32`.
		      The float value that the lowest quantized `a` value represents.
		    max_a: A `Tensor` of type `float32`.
		      The float value that the highest quantized `a` value represents.
		    min_b: A `Tensor` of type `float32`.
		      The float value that the lowest quantized `b` value represents.
		    max_b: A `Tensor` of type `float32`.
		      The float value that the highest quantized `b` value represents.
		    min_freezed_output: A `Tensor` of type `float32`.
		      The float value that the highest quantized output value after requantize.
		    max_freezed_output: A `Tensor` of type `float32`.
		    Toutput: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		    transpose_a: An optional `bool`. Defaults to `False`.
		      If true, `a` is transposed before multiplication.
		    transpose_b: An optional `bool`. Defaults to `False`.
		      If true, `b` is transposed before multiplication.
		    input_quant_mode: An optional `string` from: `"MIN_FIRST", "SCALED"`. Defaults to `"MIN_FIRST"`.
		      Input data quantization mode. Either MIN_FIRST(default) or SCALED.
		    name: A name for the operation (optional).
		
		  Returns:
		    A tuple of `Tensor` objects (out, min_out, max_out).
		
		    out: A `Tensor` of type `Toutput`.
		    min_out: A `Tensor` of type `float32`.
		    max_out: A `Tensor` of type `float32`.
		  
	**/
	static public function QuantizedMatMulWithBiasAndReluAndRequantize(a:Dynamic, b:Dynamic, bias:Dynamic, min_a:Dynamic, max_a:Dynamic, min_b:Dynamic, max_b:Dynamic, min_freezed_output:Dynamic, max_freezed_output:Dynamic, ?Toutput:Dynamic, ?transpose_a:Dynamic, ?transpose_b:Dynamic, ?input_quant_mode:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  a: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  b: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  bias: A `Tensor`. Must be one of the following types: `float32`, `qint32`.
		  min_a: A `Tensor` of type `float32`.
		  max_a: A `Tensor` of type `float32`.
		  min_b: A `Tensor` of type `float32`.
		  max_b: A `Tensor` of type `float32`.
		  min_freezed_output: A `Tensor` of type `float32`.
		  max_freezed_output: A `Tensor` of type `float32`.
		  Toutput: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		  transpose_a: An optional `bool`. Defaults to `False`.
		  transpose_b: An optional `bool`. Defaults to `False`.
		  input_quant_mode: An optional `string` from: `"MIN_FIRST", "SCALED"`. Defaults to `"MIN_FIRST"`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (out, min_out, max_out).
		
		  out: A `Tensor` of type `Toutput`.
		  min_out: A `Tensor` of type `float32`.
		  max_out: A `Tensor` of type `float32`.
	**/
	static public function QuantizedMatMulWithBiasAndRequantize(a:Dynamic, b:Dynamic, bias:Dynamic, min_a:Dynamic, max_a:Dynamic, min_b:Dynamic, max_b:Dynamic, min_freezed_output:Dynamic, max_freezed_output:Dynamic, ?Toutput:Dynamic, ?transpose_a:Dynamic, ?transpose_b:Dynamic, ?input_quant_mode:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Produces the max pool of the input tensor for quantized types.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The 4D (batch x rows x cols x depth) Tensor to MaxReduce over.
		  min_input: A `Tensor` of type `float32`.
		    The float value that the lowest quantized input value represents.
		  max_input: A `Tensor` of type `float32`.
		    The float value that the highest quantized input value represents.
		  ksize: A list of `ints`.
		    The size of the window for each dimension of the input tensor.
		    The length must be 4 to match the number of dimensions of the input.
		  strides: A list of `ints`.
		    The stride of the sliding window for each dimension of the input
		    tensor. The length must be 4 to match the number of dimensions of the input.
		  padding: A `string` from: `"SAME", "VALID"`.
		    The type of padding algorithm to use.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, min_output, max_output).
		
		  output: A `Tensor`. Has the same type as `input`.
		  min_output: A `Tensor` of type `float32`.
		  max_output: A `Tensor` of type `float32`.
	**/
	static public function QuantizedMaxPool(input:Dynamic, min_input:Dynamic, max_input:Dynamic, ksize:Dynamic, strides:Dynamic, padding:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x * y element-wise, working on quantized buffers.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  y: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  min_x: A `Tensor` of type `float32`.
		    The float value that the lowest quantized `x` value represents.
		  max_x: A `Tensor` of type `float32`.
		    The float value that the highest quantized `x` value represents.
		  min_y: A `Tensor` of type `float32`.
		    The float value that the lowest quantized `y` value represents.
		  max_y: A `Tensor` of type `float32`.
		    The float value that the highest quantized `y` value represents.
		  Toutput: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.qint32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (z, min_z, max_z).
		
		  z: A `Tensor` of type `Toutput`.
		  min_z: A `Tensor` of type `float32`.
		  max_z: A `Tensor` of type `float32`.
	**/
	static public function QuantizedMul(x:Dynamic, y:Dynamic, min_x:Dynamic, max_x:Dynamic, min_y:Dynamic, max_y:Dynamic, ?Toutput:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes Quantized Rectified Linear: `max(features, 0)`
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  min_features: A `Tensor` of type `float32`.
		    The float value that the lowest quantized value represents.
		  max_features: A `Tensor` of type `float32`.
		    The float value that the highest quantized value represents.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (activations, min_activations, max_activations).
		
		  activations: A `Tensor` of type `out_type`.
		  min_activations: A `Tensor` of type `float32`.
		  max_activations: A `Tensor` of type `float32`.
	**/
	static public function QuantizedRelu(features:Dynamic, min_features:Dynamic, max_features:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes Quantized Rectified Linear 6: `min(max(features, 0), 6)`
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  min_features: A `Tensor` of type `float32`.
		    The float value that the lowest quantized value represents.
		  max_features: A `Tensor` of type `float32`.
		    The float value that the highest quantized value represents.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (activations, min_activations, max_activations).
		
		  activations: A `Tensor` of type `out_type`.
		  min_activations: A `Tensor` of type `float32`.
		  max_activations: A `Tensor` of type `float32`.
	**/
	static public function QuantizedRelu6(features:Dynamic, min_features:Dynamic, max_features:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes Quantized Rectified Linear X: `min(max(features, 0), max_value)`
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  max_value: A `Tensor` of type `float32`.
		  min_features: A `Tensor` of type `float32`.
		    The float value that the lowest quantized value represents.
		  max_features: A `Tensor` of type `float32`.
		    The float value that the highest quantized value represents.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (activations, min_activations, max_activations).
		
		  activations: A `Tensor` of type `out_type`.
		  min_activations: A `Tensor` of type `float32`.
		  max_activations: A `Tensor` of type `float32`.
	**/
	static public function QuantizedReluX(features:Dynamic, max_value:Dynamic, min_features:Dynamic, max_features:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reshapes a quantized tensor as per the Reshape op.
		
		```
		
		Args:
		  tensor: A `Tensor`.
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Defines the shape of the output tensor.
		  input_min: A `Tensor` of type `float32`. The minimum value of the input.
		  input_max: A `Tensor` of type `float32`. The maximum value of the input.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, output_min, output_max).
		
		  output: A `Tensor`. Has the same type as `tensor`.
		  output_min: A `Tensor` of type `float32`.
		  output_max: A `Tensor` of type `float32`.
	**/
	static public function QuantizedReshape(tensor:Dynamic, shape:Dynamic, input_min:Dynamic, input_max:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Resize quantized `images` to `size` using quantized bilinear interpolation.
		
		Input images and output images must be quantized types.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `quint8`, `qint32`, `float32`.
		    4-D with shape `[batch, height, width, channels]`.
		  size:  A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
		    new size for the images.
		  min: A `Tensor` of type `float32`.
		  max: A `Tensor` of type `float32`.
		  align_corners: An optional `bool`. Defaults to `False`.
		    If true, the centers of the 4 corner pixels of the input and output tensors are
		    aligned, preserving the values at the corner pixels. Defaults to false.
		  half_pixel_centers: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (resized_images, out_min, out_max).
		
		  resized_images: A `Tensor`. Has the same type as `images`.
		  out_min: A `Tensor` of type `float32`.
		  out_max: A `Tensor` of type `float32`.
	**/
	static public function QuantizedResizeBilinear(images:Dynamic, size:Dynamic, min:Dynamic, max:Dynamic, ?align_corners:Dynamic, ?half_pixel_centers:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Closes the given queue.
		
		This operation signals that no more elements will be enqueued in the
		given queue. Subsequent Enqueue(Many) operations will fail.
		Subsequent Dequeue(Many) operations will continue to succeed if
		sufficient elements remain in the queue. Subsequent Dequeue(Many)
		operations that would block will fail immediately.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a queue.
		  cancel_pending_enqueues: An optional `bool`. Defaults to `False`.
		    If true, all pending enqueue requests that are
		    blocked on the given queue will be canceled.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function QueueClose(handle:Dynamic, ?cancel_pending_enqueues:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Closes the given queue.
		
		This operation signals that no more elements will be enqueued in the
		given queue. Subsequent Enqueue(Many) operations will fail.
		Subsequent Dequeue(Many) operations will continue to succeed if
		sufficient elements remain in the queue. Subsequent Dequeue(Many)
		operations that would block will fail immediately.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a queue.
		  cancel_pending_enqueues: An optional `bool`. Defaults to `False`.
		    If true, all pending enqueue requests that are
		    blocked on the given queue will be canceled.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function QueueCloseV2(handle:Dynamic, ?cancel_pending_enqueues:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Dequeues a tuple of one or more tensors from the given queue.
		
		This operation has k outputs, where k is the number of components
		in the tuples stored in the given queue, and output i is the ith
		component of the dequeued tuple.
		
		N.B. If the queue is empty, this operation will block until an element
		has been dequeued (or 'timeout_ms' elapses, if specified).
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a queue.
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a tuple.
		  timeout_ms: An optional `int`. Defaults to `-1`.
		    If the queue is empty, this operation will block for up to
		    timeout_ms milliseconds.
		    Note: This option is not supported yet.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `component_types`.
	**/
	static public function QueueDequeue(handle:Dynamic, component_types:Dynamic, ?timeout_ms:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Dequeues `n` tuples of one or more tensors from the given queue.
		
		If the queue is closed and there are fewer than `n` elements, then an
		OutOfRange error is returned.
		
		This operation concatenates queue-element component tensors along the
		0th dimension to make a single component tensor.  All of the components
		in the dequeued tuple will have size `n` in the 0th dimension.
		
		This operation has `k` outputs, where `k` is the number of components in
		the tuples stored in the given queue, and output `i` is the ith
		component of the dequeued tuple.
		
		N.B. If the queue is empty, this operation will block until `n` elements
		have been dequeued (or 'timeout_ms' elapses, if specified).
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a queue.
		  n: A `Tensor` of type `int32`. The number of tuples to dequeue.
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a tuple.
		  timeout_ms: An optional `int`. Defaults to `-1`.
		    If the queue has fewer than n elements, this operation
		    will block for up to timeout_ms milliseconds.
		    Note: This option is not supported yet.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `component_types`.
	**/
	static public function QueueDequeueMany(handle:Dynamic, n:Dynamic, component_types:Dynamic, ?timeout_ms:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Dequeues `n` tuples of one or more tensors from the given queue.
		
		If the queue is closed and there are fewer than `n` elements, then an
		OutOfRange error is returned.
		
		This operation concatenates queue-element component tensors along the
		0th dimension to make a single component tensor.  All of the components
		in the dequeued tuple will have size `n` in the 0th dimension.
		
		This operation has `k` outputs, where `k` is the number of components in
		the tuples stored in the given queue, and output `i` is the ith
		component of the dequeued tuple.
		
		N.B. If the queue is empty, this operation will block until `n` elements
		have been dequeued (or 'timeout_ms' elapses, if specified).
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a queue.
		  n: A `Tensor` of type `int32`. The number of tuples to dequeue.
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a tuple.
		  timeout_ms: An optional `int`. Defaults to `-1`.
		    If the queue has fewer than n elements, this operation
		    will block for up to timeout_ms milliseconds.
		    Note: This option is not supported yet.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `component_types`.
	**/
	static public function QueueDequeueManyV2(handle:Dynamic, n:Dynamic, component_types:Dynamic, ?timeout_ms:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Dequeues `n` tuples of one or more tensors from the given queue.
		
		This operation is not supported by all queues.  If a queue does not support
		DequeueUpTo, then an Unimplemented error is returned.
		
		If the queue is closed and there are more than 0 but less than `n`
		elements remaining, then instead of returning an OutOfRange error like
		QueueDequeueMany, less than `n` elements are returned immediately.  If
		the queue is closed and there are 0 elements left in the queue, then
		an OutOfRange error is returned just like in QueueDequeueMany.
		Otherwise the behavior is identical to QueueDequeueMany:
		
		This operation concatenates queue-element component tensors along the
		0th dimension to make a single component tensor.  All of the components
		in the dequeued tuple will have size `n` in the 0th dimension.
		
		This operation has k outputs, where `k` is the number of components in
		the tuples stored in the given queue, and output `i` is the ith
		component of the dequeued tuple.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a queue.
		  n: A `Tensor` of type `int32`. The number of tuples to dequeue.
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a tuple.
		  timeout_ms: An optional `int`. Defaults to `-1`.
		    If the queue has fewer than n elements, this operation
		    will block for up to timeout_ms milliseconds.
		    Note: This option is not supported yet.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `component_types`.
	**/
	static public function QueueDequeueUpTo(handle:Dynamic, n:Dynamic, component_types:Dynamic, ?timeout_ms:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Dequeues `n` tuples of one or more tensors from the given queue.
		
		This operation is not supported by all queues.  If a queue does not support
		DequeueUpTo, then an Unimplemented error is returned.
		
		If the queue is closed and there are more than 0 but less than `n`
		elements remaining, then instead of returning an OutOfRange error like
		QueueDequeueMany, less than `n` elements are returned immediately.  If
		the queue is closed and there are 0 elements left in the queue, then
		an OutOfRange error is returned just like in QueueDequeueMany.
		Otherwise the behavior is identical to QueueDequeueMany:
		
		This operation concatenates queue-element component tensors along the
		0th dimension to make a single component tensor.  All of the components
		in the dequeued tuple will have size n in the 0th dimension.
		
		This operation has `k` outputs, where `k` is the number of components in
		the tuples stored in the given queue, and output `i` is the ith
		component of the dequeued tuple.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a queue.
		  n: A `Tensor` of type `int32`. The number of tuples to dequeue.
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a tuple.
		  timeout_ms: An optional `int`. Defaults to `-1`.
		    If the queue has fewer than n elements, this operation
		    will block for up to timeout_ms milliseconds.
		    Note: This option is not supported yet.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `component_types`.
	**/
	static public function QueueDequeueUpToV2(handle:Dynamic, n:Dynamic, component_types:Dynamic, ?timeout_ms:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Dequeues a tuple of one or more tensors from the given queue.
		
		This operation has k outputs, where k is the number of components
		in the tuples stored in the given queue, and output i is the ith
		component of the dequeued tuple.
		
		N.B. If the queue is empty, this operation will block until an element
		has been dequeued (or 'timeout_ms' elapses, if specified).
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a queue.
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a tuple.
		  timeout_ms: An optional `int`. Defaults to `-1`.
		    If the queue is empty, this operation will block for up to
		    timeout_ms milliseconds.
		    Note: This option is not supported yet.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `component_types`.
	**/
	static public function QueueDequeueV2(handle:Dynamic, component_types:Dynamic, ?timeout_ms:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Enqueues a tuple of one or more tensors in the given queue.
		
		The components input has k elements, which correspond to the components of
		tuples stored in the given queue.
		
		N.B. If the queue is full, this operation will block until the given
		element has been enqueued (or 'timeout_ms' elapses, if specified).
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a queue.
		  components: A list of `Tensor` objects.
		    One or more tensors from which the enqueued tensors should be taken.
		  timeout_ms: An optional `int`. Defaults to `-1`.
		    If the queue is full, this operation will block for up to
		    timeout_ms milliseconds.
		    Note: This option is not supported yet.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function QueueEnqueue(handle:Dynamic, components:Dynamic, ?timeout_ms:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Enqueues zero or more tuples of one or more tensors in the given queue.
		
		This operation slices each component tensor along the 0th dimension to
		make multiple queue elements. All of the tuple components must have the
		same size in the 0th dimension.
		
		The components input has k elements, which correspond to the components of
		tuples stored in the given queue.
		
		N.B. If the queue is full, this operation will block until the given
		elements have been enqueued (or 'timeout_ms' elapses, if specified).
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a queue.
		  components: A list of `Tensor` objects.
		    One or more tensors from which the enqueued tensors should
		    be taken.
		  timeout_ms: An optional `int`. Defaults to `-1`.
		    If the queue is too full, this operation will block for up
		    to timeout_ms milliseconds.
		    Note: This option is not supported yet.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function QueueEnqueueMany(handle:Dynamic, components:Dynamic, ?timeout_ms:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Enqueues zero or more tuples of one or more tensors in the given queue.
		
		This operation slices each component tensor along the 0th dimension to
		make multiple queue elements. All of the tuple components must have the
		same size in the 0th dimension.
		
		The components input has k elements, which correspond to the components of
		tuples stored in the given queue.
		
		N.B. If the queue is full, this operation will block until the given
		elements have been enqueued (or 'timeout_ms' elapses, if specified).
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a queue.
		  components: A list of `Tensor` objects.
		    One or more tensors from which the enqueued tensors should
		    be taken.
		  timeout_ms: An optional `int`. Defaults to `-1`.
		    If the queue is too full, this operation will block for up
		    to timeout_ms milliseconds.
		    Note: This option is not supported yet.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function QueueEnqueueManyV2(handle:Dynamic, components:Dynamic, ?timeout_ms:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Enqueues a tuple of one or more tensors in the given queue.
		
		The components input has k elements, which correspond to the components of
		tuples stored in the given queue.
		
		N.B. If the queue is full, this operation will block until the given
		element has been enqueued (or 'timeout_ms' elapses, if specified).
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a queue.
		  components: A list of `Tensor` objects.
		    One or more tensors from which the enqueued tensors should be taken.
		  timeout_ms: An optional `int`. Defaults to `-1`.
		    If the queue is full, this operation will block for up to
		    timeout_ms milliseconds.
		    Note: This option is not supported yet.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function QueueEnqueueV2(handle:Dynamic, components:Dynamic, ?timeout_ms:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns true if queue is closed.
		
		This operation returns true if the queue is closed and false if the queue
		is open.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a queue.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function QueueIsClosed(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns true if queue is closed.
		
		This operation returns true if the queue is closed and false if the queue
		is open.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a queue.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function QueueIsClosedV2(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the number of elements in the given queue.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a queue.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function QueueSize(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the number of elements in the given queue.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a queue.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function QueueSizeV2(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Real-valued fast Fourier transform.
		
		Computes the 1-dimensional discrete Fourier transform of a real-valued signal
		over the inner-most dimension of `input`.
		
		Since the DFT of a real signal is Hermitian-symmetric, `RFFT` only returns the
		`fft_length / 2 + 1` unique components of the FFT: the zero-frequency term,
		followed by the `fft_length / 2` positive-frequency terms.
		
		Along the axis `RFFT` is computed on, if `fft_length` is smaller than the
		corresponding dimension of `input`, the dimension is cropped. If it is larger,
		the dimension is padded with zeros.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		    A float32 tensor.
		  fft_length: A `Tensor` of type `int32`.
		    An int32 tensor of shape [1]. The FFT length.
		  Tcomplex: An optional `tf.DType` from: `tf.complex64, tf.complex128`. Defaults to `tf.complex64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Tcomplex`.
	**/
	static public function RFFT(input:Dynamic, fft_length:Dynamic, ?Tcomplex:Dynamic, ?name:Dynamic):Dynamic;
	/**
		2D real-valued fast Fourier transform.
		
		Computes the 2-dimensional discrete Fourier transform of a real-valued signal
		over the inner-most 2 dimensions of `input`.
		
		Since the DFT of a real signal is Hermitian-symmetric, `RFFT2D` only returns the
		`fft_length / 2 + 1` unique components of the FFT for the inner-most dimension
		of `output`: the zero-frequency term, followed by the `fft_length / 2`
		positive-frequency terms.
		
		Along each axis `RFFT2D` is computed on, if `fft_length` is smaller than the
		corresponding dimension of `input`, the dimension is cropped. If it is larger,
		the dimension is padded with zeros.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		    A float32 tensor.
		  fft_length: A `Tensor` of type `int32`.
		    An int32 tensor of shape [2]. The FFT length for each dimension.
		  Tcomplex: An optional `tf.DType` from: `tf.complex64, tf.complex128`. Defaults to `tf.complex64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Tcomplex`.
	**/
	static public function RFFT2D(input:Dynamic, fft_length:Dynamic, ?Tcomplex:Dynamic, ?name:Dynamic):Dynamic;
	/**
		3D real-valued fast Fourier transform.
		
		Computes the 3-dimensional discrete Fourier transform of a real-valued signal
		over the inner-most 3 dimensions of `input`.
		
		Since the DFT of a real signal is Hermitian-symmetric, `RFFT3D` only returns the
		`fft_length / 2 + 1` unique components of the FFT for the inner-most dimension
		of `output`: the zero-frequency term, followed by the `fft_length / 2`
		positive-frequency terms.
		
		Along each axis `RFFT3D` is computed on, if `fft_length` is smaller than the
		corresponding dimension of `input`, the dimension is cropped. If it is larger,
		the dimension is padded with zeros.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		    A float32 tensor.
		  fft_length: A `Tensor` of type `int32`.
		    An int32 tensor of shape [3]. The FFT length for each dimension.
		  Tcomplex: An optional `tf.DType` from: `tf.complex64, tf.complex128`. Defaults to `tf.complex64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Tcomplex`.
	**/
	static public function RFFT3D(input:Dynamic, fft_length:Dynamic, ?Tcomplex:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts one or more images from RGB to HSV.
		
		Outputs a tensor of the same shape as the `images` tensor, containing the HSV
		value of the pixels. The output is only well defined if the value in `images`
		are in `[0,1]`.
		
		`output[..., 0]` contains hue, `output[..., 1]` contains saturation, and
		`output[..., 2]` contains value. All HSV values are in `[0,1]`. A hue of 0
		corresponds to pure red, hue 1/3 is pure green, and 2/3 is pure blue.
		
		Usage Example:
		
		>>> blue_image = tf.stack([
		...    tf.zeros([5,5]),
		...    tf.zeros([5,5]),
		...    tf.ones([5,5])],
		...    axis=-1)
		>>> blue_hsv_image = tf.image.rgb_to_hsv(blue_image)
		>>> blue_hsv_image[0,0].numpy()
		array([0.6666667, 1. , 1. ], dtype=float32)
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    1-D or higher rank. RGB data to convert. Last dimension must be size 3.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `images`.
	**/
	static public function RGBToHSV(images:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Counts the number of occurrences of each value in an integer array.
		
		Outputs a vector with length `size` and the same dtype as `weights`. If
		`weights` are empty, then index `i` stores the number of times the value `i` is
		counted in `arr`. If `weights` are non-empty, then index `i` stores the sum of
		the value in `weights` at each index where the corresponding value in `arr` is
		`i`.
		
		Values in `arr` outside of the range [0, size) are ignored.
		
		Args:
		  splits: A `Tensor` of type `int64`. 1D int64 `Tensor`.
		  values: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2D int `Tensor`.
		  size: A `Tensor`. Must have the same type as `values`.
		    non-negative int scalar `Tensor`.
		  weights: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.
		    is an int32, int64, float32, or float64 `Tensor` with the same
		    shape as `input`, or a length-0 `Tensor`, in which case it acts as all weights
		    equal to 1.
		  binary_output: An optional `bool`. Defaults to `False`.
		    bool; Whether the kernel should count the appearance or number of occurrences.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `weights`.
	**/
	static public function RaggedBincount(splits:Dynamic, values:Dynamic, size:Dynamic, weights:Dynamic, ?binary_output:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs sparse-output bin counting for a ragged tensor input.
		
		  Counts the number of times each value occurs in the input.
		
		Args:
		  splits: A `Tensor` of type `int64`.
		    Tensor containing the row splits of the ragged tensor to count.
		  values: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Tensor containing values of the sparse tensor to count.
		  weights: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.
		    A Tensor of the same shape as indices containing per-index weight values.
		    May also be the empty tensor if no weights are used.
		  binary_output: A `bool`.
		    Whether to output the number of occurrences of each value or 1.
		  minlength: An optional `int` that is `>= -1`. Defaults to `-1`.
		    Minimum value to count. Can be set to -1 for no minimum.
		  maxlength: An optional `int` that is `>= -1`. Defaults to `-1`.
		    Maximum value to count. Can be set to -1 for no maximum.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, output_dense_shape).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor`. Has the same type as `weights`.
		  output_dense_shape: A `Tensor` of type `int64`.
	**/
	static public function RaggedCountSparseOutput(splits:Dynamic, values:Dynamic, weights:Dynamic, binary_output:Dynamic, ?minlength:Dynamic, ?maxlength:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates a feature cross from a list of tensors, and returns it as a
		RaggedTensor.  See `tf.ragged.cross` for more details.
		
		  Args:
		    ragged_values: A list of `Tensor` objects with types from: `int64`, `string`.
		      The values tensor for each RaggedTensor input.
		    ragged_row_splits: A list of `Tensor` objects with types from: `int32`, `int64`.
		      The row_splits tensor for each RaggedTensor input.
		    sparse_indices: A list of `Tensor` objects with type `int64`.
		      The indices tensor for each SparseTensor input.
		    sparse_values: A list of `Tensor` objects with types from: `int64`, `string`.
		      The values tensor for each SparseTensor input.
		    sparse_shape: A list with the same length as `sparse_indices` of `Tensor` objects with type `int64`.
		      The dense_shape tensor for each SparseTensor input.
		    dense_inputs: A list of `Tensor` objects with types from: `int64`, `string`.
		      The tf.Tensor inputs.
		    input_order: A `string`.
		      String specifying the tensor type for each input.  The `i`th character in
		      this string specifies the type of the `i`th input, and is one of: 'R' (ragged),
		      'D' (dense), or 'S' (sparse).  This attr is used to ensure that the crossed
		      values are combined in the order of the inputs from the call to tf.ragged.cross.
		    hashed_output: A `bool`.
		    num_buckets: An `int` that is `>= 0`.
		    hash_key: An `int`.
		    out_values_type: A `tf.DType` from: `tf.int64, tf.string`.
		    out_row_splits_type: A `tf.DType` from: `tf.int32, tf.int64`.
		    name: A name for the operation (optional).
		
		  Returns:
		    A tuple of `Tensor` objects (output_values, output_row_splits).
		
		    output_values: A `Tensor` of type `out_values_type`.
		    output_row_splits: A `Tensor` of type `out_row_splits_type`.
		  
	**/
	static public function RaggedCross(ragged_values:Dynamic, ragged_row_splits:Dynamic, sparse_indices:Dynamic, sparse_values:Dynamic, sparse_shape:Dynamic, dense_inputs:Dynamic, input_order:Dynamic, hashed_output:Dynamic, num_buckets:Dynamic, hash_key:Dynamic, out_values_type:Dynamic, out_row_splits_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gather ragged slices from `params` axis `0` according to `indices`.
		
		Outputs a `RaggedTensor` output composed from `output_dense_values` and
		`output_nested_splits`, such that:
		
		```python
		output.shape = indices.shape + params.shape[1:]
		output.ragged_rank = indices.shape.ndims + params.ragged_rank
		output[i...j, d0...dn] = params[indices[i...j], d0...dn]
		```
		
		where
		
		* `params =
		   ragged.from_nested_row_splits(params_dense_values, params_nested_splits)`
		   provides the values that should be gathered.
		* `indices` ia a dense tensor with dtype `int32` or `int64`, indicating which
		   values should be gathered.
		* `output =
		   ragged.from_nested_row_splits(output_dense_values, output_nested_splits)`
		   is the output tensor.
		
		(Note: This c++ op is used to implement the higher-level python
		`tf.ragged.gather` op, which also supports ragged indices.)
		
		Args:
		  params_nested_splits: A list of at least 1 `Tensor` objects with the same type in: `int32`, `int64`.
		    The `nested_row_splits` tensors that define the row-partitioning for the
		    `params` RaggedTensor input.
		  params_dense_values: A `Tensor`.
		    The `flat_values` for the `params` RaggedTensor. There was a terminology change
		    at the python level from dense_values to flat_values, so dense_values is the
		    deprecated name.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Indices in the outermost dimension of `params` of the values that should be
		    gathered.
		  OUTPUT_RAGGED_RANK: An `int` that is `>= 0`.
		    The ragged rank of the output RaggedTensor. `output_nested_splits` will contain
		    this number of `row_splits` tensors. This value should equal
		    `indices.shape.ndims + params.ragged_rank - 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_nested_splits, output_dense_values).
		
		  output_nested_splits: A list of `OUTPUT_RAGGED_RANK` `Tensor` objects with the same type as `params_nested_splits`.
		  output_dense_values: A `Tensor`. Has the same type as `params_dense_values`.
	**/
	static public function RaggedGather(params_nested_splits:Dynamic, params_dense_values:Dynamic, indices:Dynamic, OUTPUT_RAGGED_RANK:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a `RaggedTensor` containing the specified sequences of numbers.
		
		
		Returns a `RaggedTensor` `result` composed from `rt_dense_values` and
		`rt_nested_splits`, such that
		`result[i] = range(starts[i], limits[i], deltas[i])`.
		
		```python
		(rt_nested_splits, rt_dense_values) = ragged_range(
		      starts=[2, 5, 8], limits=[3, 5, 12], deltas=1)
		result = tf.ragged.from_row_splits(rt_dense_values, rt_nested_splits)
		print(result)
		<tf.RaggedTensor [[2], [], [8, 9, 10, 11]] >
		```
		
		The input tensors `starts`, `limits`, and `deltas` may be scalars or vectors.
		The vector inputs must all have the same size.  Scalar inputs are broadcast
		to match the size of the vector inputs.
		
		Args:
		  starts: A `Tensor`. Must be one of the following types: `bfloat16`, `float32`, `float64`, `int32`, `int64`.
		    The starts of each range.
		  limits: A `Tensor`. Must have the same type as `starts`.
		    The limits of each range.
		  deltas: A `Tensor`. Must have the same type as `starts`.
		    The deltas of each range.
		  Tsplits: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (rt_nested_splits, rt_dense_values).
		
		  rt_nested_splits: A `Tensor` of type `Tsplits`.
		  rt_dense_values: A `Tensor`. Has the same type as `starts`.
	**/
	static public function RaggedRange(starts:Dynamic, limits:Dynamic, deltas:Dynamic, ?Tsplits:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decodes a `variant` Tensor into a `RaggedTensor`.
		
		Decodes the given `variant` Tensor and returns a `RaggedTensor`. The input
		could be a scalar, meaning it encodes a single `RaggedTensor` with ragged_rank
		`output_ragged_rank`. It could also have an arbitrary rank, in which case each
		element is decoded into a `RaggedTensor` with ragged_rank `input_ragged_rank`
		and these are then stacked according to the input shape to output a single
		`RaggedTensor` with ragged_rank `output_ragged_rank`. Each `variant` element in
		the input Tensor is decoded by retrieving from the element a 1-D `variant`
		Tensor with `input_ragged_rank + 1` Tensors, corresponding to the splits and
		values of the decoded `RaggedTensor`. If `input_ragged_rank` is -1, then it is
		inferred as `output_ragged_rank` - `rank(encoded_ragged)`. See
		`RaggedTensorToVariant` for the corresponding encoding logic.
		
		Args:
		  encoded_ragged: A `Tensor` of type `variant`.
		    A `variant` Tensor containing encoded `RaggedTensor`s.
		  input_ragged_rank: An `int` that is `>= -1`.
		    The ragged rank of each encoded `RaggedTensor` component in the input. If set to
		    -1, this is inferred as `output_ragged_rank` - `rank(encoded_ragged)`
		  output_ragged_rank: An `int` that is `>= 0`.
		    The expected ragged rank of the output `RaggedTensor`. The following must hold:
		    `output_ragged_rank = rank(encoded_ragged) + input_ragged_rank`.
		  Tvalues: A `tf.DType`.
		  Tsplits: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_nested_splits, output_dense_values).
		
		  output_nested_splits: A list of `output_ragged_rank` `Tensor` objects with type `Tsplits`.
		  output_dense_values: A `Tensor` of type `Tvalues`.
	**/
	static public function RaggedTensorFromVariant(encoded_ragged:Dynamic, input_ragged_rank:Dynamic, output_ragged_rank:Dynamic, Tvalues:Dynamic, ?Tsplits:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts a `RaggedTensor` into a `SparseTensor` with the same values.
		
		input=ragged.from_nested_row_splits(rt_dense_values, rt_nested_splits)
		output=SparseTensor(indices=sparse_indices, values=sparse_values,
		                    dense_shape=sparse_dense_shape)
		
		Args:
		  rt_nested_splits: A list of at least 1 `Tensor` objects with the same type in: `int32`, `int64`.
		    The `row_splits` for the `RaggedTensor`.
		  rt_dense_values: A `Tensor`. The `flat_values` for the `RaggedTensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sparse_indices, sparse_values, sparse_dense_shape).
		
		  sparse_indices: A `Tensor` of type `int64`.
		  sparse_values: A `Tensor`. Has the same type as `rt_dense_values`.
		  sparse_dense_shape: A `Tensor` of type `int64`.
	**/
	static public function RaggedTensorToSparse(rt_nested_splits:Dynamic, rt_dense_values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Create a dense tensor from a ragged tensor, possibly altering its shape.
		
		The `ragged_to_dense` op creates a dense tensor from a list of row partition
		tensors, a value vector, and default values. If the shape is unspecified, the
		minimal shape required to contain all the elements in the ragged tensor (the
		natural shape) will be used. If some dimensions are left unspecified, then the
		size of the natural shape is used in that dimension.
		
		The default_value will be broadcast to the output shape. After that, the values
		from the ragged tensor overwrite the default values. Note that the default_value
		must have less dimensions than the value.
		
		The row partition tensors are in the order of the dimensions.
		At present, the types can be:
		* "ROW_SPLITS": the row_splits tensor from the ragged tensor.
		* "VALUE_ROWIDS": the value_rowids tensor from the ragged tensor.
		* "FIRST_DIM_SIZE": if value_rowids is used for the first dimension, then it
		  is preceded by "FIRST_DIM_SIZE".
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int64`, `int32`.
		    The desired shape of the output tensor. If left unspecified (empty),
		    the minimal shape required to contain all the elements in the ragged tensor
		    (the natural shape) will be used. If some dimensions are left unspecified, then
		    the size of the natural shape is used in that dimension.
		
		    Note that dense dimensions cannot be modified by the shape argument. Trying to
		    change the size of a dense dimension will cause the op to fail.
		    Examples:
		    natural shape: [4, 5, 6]
		    shape: -1
		    output shape: [4, 5, 6]
		
		    natural shape: [4, 5, 6]
		    shape: [3, -1, 2]
		    output shape: [3, 5, 2]
		
		    natural shape: [4, 5, 6]
		    shape: [3, 7, 2]
		    output shape: [3, 7, 2]
		  values: A `Tensor`.
		    A 1D tensor representing the values of the ragged tensor.
		  default_value: A `Tensor`. Must have the same type as `values`.
		    The default_value when the shape is larger than the ragged tensor. The
		    default_value is broadcast until it is the shape of the output tensor, and
		    then overwritten by values in the ragged tensor. The default value must be
		    compatible with this broadcast operation, and must have fewer dimensions than
		    the value tensor.
		  row_partition_tensors: A list of at least 1 `Tensor` objects with the same type in: `int64`, `int32`.
		  row_partition_types: A list of `strings`.
		    The types of the row partition tensors. At present, these can be:
		    * "ROW_SPLITS": the row_splits tensor from the ragged tensor.
		    * "VALUE_ROWIDS": the value_rowids tensor from the ragged tensor.
		    * "FIRST_DIM_SIZE": if value_rowids is used for the first dimension, then it
		      is preceeded by "FIRST_DIM_SIZE".
		    The tensors are in the order of the dimensions.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `values`.
	**/
	static public function RaggedTensorToTensor(shape:Dynamic, values:Dynamic, default_value:Dynamic, row_partition_tensors:Dynamic, row_partition_types:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Encodes a `RaggedTensor` into a `variant` Tensor.
		
		
		Encodes the given `RaggedTensor` and returns a `variant` Tensor. If
		`batched_input` is True, then input `RaggedTensor` is unbatched along the
		zero-th dimension, each component `RaggedTensor` is encoded into a scalar
		`variant` Tensor, and these are stacked to return a 1-D `variant` Tensor.
		If `batched_input` is False, then the input `RaggedTensor` is encoded as is and
		a scalar `variant` Tensor is returned. A `RaggedTensor` is encoded by first
		creating a 1-D `variant` Tensor with `ragged_rank + 1` elements, containing the
		splits and values Tensors of the `RaggedTensor`. Then the 1-D `variant` Tensor
		is wrapped in a scalar `variant` Tensor. See `RaggedTensorFromVariant` for the
		corresponding decoding logic.
		
		Args:
		  rt_nested_splits: A list of `Tensor` objects with the same type in: `int32`, `int64`.
		    A list of one or more Tensors representing the splits of the input
		    `RaggedTensor`.
		  rt_dense_values: A `Tensor`.
		    A Tensor representing the values of the input `RaggedTensor`.
		  batched_input: A `bool`.
		    A `bool` denoting whether the input is a batched `RaggedTensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function RaggedTensorToVariant(rt_nested_splits:Dynamic, rt_dense_values:Dynamic, batched_input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Helper used to compute the gradient for `RaggedTensorToVariant`.
		
		Computes the gradient for the dense_values input to the RaggedTensorToVariant
		op, given the variant-encoded ragged gradients of the outputs, along with
		the outer row-splits and the shape of the dense-values that were provided as
		inputs to the RaggedTensorToVariant op.
		
		Args:
		  encoded_ragged_grad: A `Tensor` of type `variant`.
		    A `variant` Tensor containing encoded `RaggedTensor` gradients.
		  row_splits: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Outermost row-splits that were used as input to the RaggedTensorToVariant op.
		  dense_values_shape: A `Tensor` of type `int32`.
		    Shape of the dense_values that was used as an input to the
		    RaggedTensorToVariant op.
		  Tvalues: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Tvalues`.
	**/
	static public function RaggedTensorToVariantGradient(encoded_ragged_grad:Dynamic, row_splits:Dynamic, dense_values_shape:Dynamic, Tvalues:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Randomly crop `image`.
		
		`size` is a 1-D int64 tensor with 2 elements representing the crop height and
		width.  The values must be non negative.
		
		This Op picks a random location in `image` and crops a `height` by `width`
		rectangle from that location.  The random location is picked so the cropped
		area will fit inside the original image.
		
		Args:
		  image: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `int16`, `int32`, `int64`, `float32`, `float64`.
		    3-D of shape `[height, width, channels]`.
		  size: A `Tensor` of type `int64`.
		    1-D of length 2 containing: `crop_height`, `crop_width`..
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    An second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `image`.
	**/
	static public function RandomCrop(image:Dynamic, size:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a Dataset that returns pseudorandom numbers.
		
		Creates a Dataset that returns a stream of uniformly distributed
		pseudorandom 64-bit signed integers.
		
		In the TensorFlow Python API, you can instantiate this dataset via the
		class `tf.data.experimental.RandomDataset`.
		
		Instances of this dataset are also created as a result of the
		`hoist_random_uniform` static optimization. Whether this optimization is
		performed is determined by the `experimental_optimization.hoist_random_uniform`
		option of `tf.data.Options`.
		
		Args:
		  seed: A `Tensor` of type `int64`.
		    A scalar seed for the random number generator. If either seed or
		    seed2 is set to be non-zero, the random number generator is seeded
		    by the given seed.  Otherwise, a random seed is used.
		  seed2: A `Tensor` of type `int64`.
		    A second scalar seed to avoid seed collision.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function RandomDataset(seed:Dynamic, seed2:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random values from the Gamma distribution(s) described by alpha.
		
		This op uses the algorithm by Marsaglia et al. to acquire samples via
		transformation-rejection from pairs of uniform and normal random variables.
		See http://dl.acm.org/citation.cfm?id=358414
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    1-D integer tensor. Shape of independent samples to draw from each
		    distribution described by the shape parameters given in alpha.
		  alpha: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		    A tensor in which each scalar is a "shape" parameter describing the
		    associated gamma distribution.
		  seed: An optional `int`. Defaults to `0`.
		    If either `seed` or `seed2` are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `alpha`.
	**/
	static public function RandomGamma(shape:Dynamic, alpha:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the derivative of a Gamma random sample w.r.t. `alpha`.
		
		Args:
		  alpha: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		  sample: A `Tensor`. Must have the same type as `alpha`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `alpha`.
	**/
	static public function RandomGammaGrad(alpha:Dynamic, sample:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Use RandomPoissonV2 instead.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  rate: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `rate`.
	**/
	static public function RandomPoisson(shape:Dynamic, rate:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random values from the Poisson distribution(s) described by rate.
		
		This op uses two algorithms, depending on rate. If rate >= 10, then
		the algorithm by Hormann is used to acquire samples via
		transformation-rejection.
		See http://www.sciencedirect.com/science/article/pii/0167668793909974.
		
		Otherwise, Knuth's algorithm is used to acquire samples via multiplying uniform
		random variables.
		See Donald E. Knuth (1969). Seminumerical Algorithms. The Art of Computer
		Programming, Volume 2. Addison Wesley
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    1-D integer tensor. Shape of independent samples to draw from each
		    distribution described by the shape parameters given in rate.
		  rate: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `int32`, `int64`.
		    A tensor in which each scalar is a "rate" parameter describing the
		    associated poisson distribution.
		  seed: An optional `int`. Defaults to `0`.
		    If either `seed` or `seed2` are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  dtype: An optional `tf.DType` from: `tf.half, tf.float32, tf.float64, tf.int32, tf.int64`. Defaults to `tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function RandomPoissonV2(shape:Dynamic, rate:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Randomly shuffles a tensor along its first dimension.
		
		  The tensor is shuffled along dimension 0, such that each `value[j]` is mapped
		  to one and only one `output[i]`. For example, a mapping that might occur for a
		  3x2 tensor is:
		
		```
		[[1, 2],       [[5, 6],
		 [3, 4],  ==>   [1, 2],
		 [5, 6]]        [3, 4]]
		```
		
		Args:
		  value: A `Tensor`. The tensor to be shuffled.
		  seed: An optional `int`. Defaults to `0`.
		    If either `seed` or `seed2` are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `value`.
	**/
	static public function RandomShuffle(value:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A queue that randomizes the order of elements.
		
		Args:
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a value.
		  shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    The shape of each component in a value. The length of this attr must
		    be either 0 or the same as the length of component_types. If the length of
		    this attr is 0, the shapes of queue elements are not constrained, and
		    only one element may be dequeued at a time.
		  capacity: An optional `int`. Defaults to `-1`.
		    The upper bound on the number of elements in this queue.
		    Negative numbers mean no limit.
		  min_after_dequeue: An optional `int`. Defaults to `0`.
		    Dequeue will block unless there would be this
		    many elements after the dequeue or the queue is closed. This
		    ensures a minimum level of mixing of elements.
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 is set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, a random seed is used.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this queue is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this queue will be shared under the given name
		    across multiple sessions.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function RandomShuffleQueue(component_types:Dynamic, ?shapes:Dynamic, ?capacity:Dynamic, ?min_after_dequeue:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A queue that randomizes the order of elements.
		
		Args:
		  component_types: A list of `tf.DTypes` that has length `>= 1`.
		    The type of each component in a value.
		  shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		    The shape of each component in a value. The length of this attr must
		    be either 0 or the same as the length of component_types. If the length of
		    this attr is 0, the shapes of queue elements are not constrained, and
		    only one element may be dequeued at a time.
		  capacity: An optional `int`. Defaults to `-1`.
		    The upper bound on the number of elements in this queue.
		    Negative numbers mean no limit.
		  min_after_dequeue: An optional `int`. Defaults to `0`.
		    Dequeue will block unless there would be this
		    many elements after the dequeue or the queue is closed. This
		    ensures a minimum level of mixing of elements.
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 is set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, a random seed is used.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this queue is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this queue will be shared under the given name
		    across multiple sessions.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function RandomShuffleQueueV2(component_types:Dynamic, ?shapes:Dynamic, ?capacity:Dynamic, ?min_after_dequeue:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random values from a normal distribution.
		
		The generated values will have mean 0 and standard deviation 1.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  dtype: A `tf.DType` from: `tf.half, tf.bfloat16, tf.float32, tf.float64`.
		    The type of the output.
		  seed: An optional `int`. Defaults to `0`.
		    If either `seed` or `seed2` are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function RandomStandardNormal(shape:Dynamic, dtype:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random values from a uniform distribution.
		
		The generated values follow a uniform distribution in the range `[0, 1)`. The
		lower bound 0 is included in the range, while the upper bound 1 is excluded.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  dtype: A `tf.DType` from: `tf.half, tf.bfloat16, tf.float32, tf.float64`.
		    The type of the output.
		  seed: An optional `int`. Defaults to `0`.
		    If either `seed` or `seed2` are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function RandomUniform(shape:Dynamic, dtype:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random integers from a uniform distribution.
		
		The generated values are uniform integers in the range `[minval, maxval)`.
		The lower bound `minval` is included in the range, while the upper bound
		`maxval` is excluded.
		
		The random integers are slightly biased unless `maxval - minval` is an exact
		power of two.  The bias is small for values of `maxval - minval` significantly
		smaller than the range of the output (either `2^32` or `2^64`).
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  minval: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    0-D.  Inclusive lower bound on the generated integers.
		  maxval: A `Tensor`. Must have the same type as `minval`.
		    0-D.  Exclusive upper bound on the generated integers.
		  seed: An optional `int`. Defaults to `0`.
		    If either `seed` or `seed2` are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `minval`.
	**/
	static public function RandomUniformInt(shape:Dynamic, minval:Dynamic, maxval:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a sequence of numbers.
		
		This operation creates a sequence of numbers that begins at `start` and
		extends by increments of `delta` up to but not including `limit`.
		
		For example:
		
		```
		# 'start' is 3
		# 'limit' is 18
		# 'delta' is 3
		tf.range(start, limit, delta) ==> [3, 6, 9, 12, 15]
		```
		
		Args:
		  start: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `uint32`.
		    0-D (scalar). First entry in the sequence.
		  limit: A `Tensor`. Must have the same type as `start`.
		    0-D (scalar). Upper limit of sequence, exclusive.
		  delta: A `Tensor`. Must have the same type as `start`.
		    0-D (scalar). Optional. Default is 1. Number that increments `start`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `start`.
	**/
	static public function Range(start:Dynamic, limit:Dynamic, delta:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset with a range of values. Corresponds to python's xrange.
		
		Args:
		  start: A `Tensor` of type `int64`.
		    corresponds to start in python's xrange().
		  stop: A `Tensor` of type `int64`.
		    corresponds to stop in python's xrange().
		  step: A `Tensor` of type `int64`.
		    corresponds to step in python's xrange().
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function RangeDataset(start:Dynamic, stop:Dynamic, step:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the rank of a tensor.
		
		This operation returns an integer representing the rank of `input`.
		
		For example:
		
		```
		# 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
		# shape of tensor 't' is [2, 2, 3]
		rank(t) ==> 3
		```
		
		**Note**: The rank of a tensor is not the same as the rank of a matrix. The rank
		of a tensor is the number of indices required to uniquely select each element
		of the tensor. Rank is also known as "order", "degree", or "ndims."
		
		Args:
		  input: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function Rank(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reads and outputs the entire contents of the input filename.
		
		Args:
		  filename: A `Tensor` of type `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function ReadFile(filename:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reads the value of a variable.
		
		The tensor returned by this operation is immutable.
		
		The value returned by this operation is guaranteed to be influenced by all the
		writes on which this operation depends directly or indirectly, and to not be
		influenced by any of the writes which depend directly or indirectly on this
		operation.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    handle to the resource in which to store the variable.
		  dtype: A `tf.DType`. the dtype of the value.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function ReadVariableOp(resource:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Splits resource variable input tensor across all dimensions.
		
		An op which splits the resource variable input tensor based on the given
		num_splits attribute, pads slices optionally, and returned the slices. Slices
		are returned in row-major order.
		
		This op may be generated via the TPU bridge.
		
		For example, with `input` tensor:
		```
		[[0, 1, 2],
		 [3, 4, 5],
		 [6, 7, 8]]
		```
		`num_splits`:
		```
		[2, 2]
		```
		and `paddings`:
		```
		[1, 1]
		```
		the expected `outputs` is:
		```
		[[0, 1],
		 [3, 4]]
		[[2, 0],
		 [5, 0]]
		[[6, 7],
		 [0, 0]]
		[[8, 0],
		 [0, 0]]
		```
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    Resource variable of input tensor to split across all dimensions.
		      }
		      out_arg {
		        name: "outputs"
		        description: <<END
		    Output slices based on input and num_splits defined, in row-major order.
		  T: A `tf.DType`.
		  N: An `int` that is `>= 1`.
		  num_splits: A list of `ints`.
		    Number of ways to split per dimension. Shape dimensions must be evenly
		    divisible.
		  paddings: An optional list of `ints`. Defaults to `[]`.
		    Optional list of right paddings per dimension of input tensor to apply before
		    splitting. This can be used to make a dimension evenly divisible.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `N` `Tensor` objects with type `T`.
	**/
	static public function ReadVariableXlaSplitND(resource:Dynamic, T:Dynamic, N:Dynamic, num_splits:Dynamic, ?paddings:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the number of records this Reader has produced.
		
		This is the same as the number of ReaderRead executions that have
		succeeded.
		
		Args:
		  reader_handle: A `Tensor` of type mutable `string`. Handle to a Reader.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function ReaderNumRecordsProduced(reader_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the number of records this Reader has produced.
		
		This is the same as the number of ReaderRead executions that have
		succeeded.
		
		Args:
		  reader_handle: A `Tensor` of type `resource`. Handle to a Reader.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function ReaderNumRecordsProducedV2(reader_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the number of work units this Reader has finished processing.
		
		Args:
		  reader_handle: A `Tensor` of type mutable `string`. Handle to a Reader.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function ReaderNumWorkUnitsCompleted(reader_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the number of work units this Reader has finished processing.
		
		Args:
		  reader_handle: A `Tensor` of type `resource`. Handle to a Reader.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function ReaderNumWorkUnitsCompletedV2(reader_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the next record (key, value pair) produced by a Reader.
		
		Will dequeue from the input queue if necessary (e.g. when the
		Reader needs to start reading from a new file since it has finished
		with the previous file).
		
		Args:
		  reader_handle: A `Tensor` of type mutable `string`. Handle to a Reader.
		  queue_handle: A `Tensor` of type mutable `string`.
		    Handle to a Queue, with string work items.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (key, value).
		
		  key: A `Tensor` of type `string`.
		  value: A `Tensor` of type `string`.
	**/
	static public function ReaderRead(reader_handle:Dynamic, queue_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns up to `num_records` (key, value) pairs produced by a Reader.
		
		Will dequeue from the input queue if necessary (e.g. when the
		Reader needs to start reading from a new file since it has finished
		with the previous file).
		It may return less than `num_records` even before the last batch.
		
		Args:
		  reader_handle: A `Tensor` of type mutable `string`. Handle to a `Reader`.
		  queue_handle: A `Tensor` of type mutable `string`.
		    Handle to a `Queue`, with string work items.
		  num_records: A `Tensor` of type `int64`.
		    number of records to read from `Reader`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (keys, values).
		
		  keys: A `Tensor` of type `string`.
		  values: A `Tensor` of type `string`.
	**/
	static public function ReaderReadUpTo(reader_handle:Dynamic, queue_handle:Dynamic, num_records:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns up to `num_records` (key, value) pairs produced by a Reader.
		
		Will dequeue from the input queue if necessary (e.g. when the
		Reader needs to start reading from a new file since it has finished
		with the previous file).
		It may return less than `num_records` even before the last batch.
		
		Args:
		  reader_handle: A `Tensor` of type `resource`. Handle to a `Reader`.
		  queue_handle: A `Tensor` of type `resource`.
		    Handle to a `Queue`, with string work items.
		  num_records: A `Tensor` of type `int64`.
		    number of records to read from `Reader`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (keys, values).
		
		  keys: A `Tensor` of type `string`.
		  values: A `Tensor` of type `string`.
	**/
	static public function ReaderReadUpToV2(reader_handle:Dynamic, queue_handle:Dynamic, num_records:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the next record (key, value pair) produced by a Reader.
		
		Will dequeue from the input queue if necessary (e.g. when the
		Reader needs to start reading from a new file since it has finished
		with the previous file).
		
		Args:
		  reader_handle: A `Tensor` of type `resource`. Handle to a Reader.
		  queue_handle: A `Tensor` of type `resource`.
		    Handle to a Queue, with string work items.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (key, value).
		
		  key: A `Tensor` of type `string`.
		  value: A `Tensor` of type `string`.
	**/
	static public function ReaderReadV2(reader_handle:Dynamic, queue_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Restore a Reader to its initial clean state.
		
		Args:
		  reader_handle: A `Tensor` of type mutable `string`. Handle to a Reader.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ReaderReset(reader_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Restore a Reader to its initial clean state.
		
		Args:
		  reader_handle: A `Tensor` of type `resource`. Handle to a Reader.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ReaderResetV2(reader_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Restore a reader to a previously saved state.
		
		Not all Readers support being restored, so this can produce an
		Unimplemented error.
		
		Args:
		  reader_handle: A `Tensor` of type mutable `string`. Handle to a Reader.
		  state: A `Tensor` of type `string`.
		    Result of a ReaderSerializeState of a Reader with type
		    matching reader_handle.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ReaderRestoreState(reader_handle:Dynamic, state:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Restore a reader to a previously saved state.
		
		Not all Readers support being restored, so this can produce an
		Unimplemented error.
		
		Args:
		  reader_handle: A `Tensor` of type `resource`. Handle to a Reader.
		  state: A `Tensor` of type `string`.
		    Result of a ReaderSerializeState of a Reader with type
		    matching reader_handle.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ReaderRestoreStateV2(reader_handle:Dynamic, state:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Produce a string tensor that encodes the state of a Reader.
		
		Not all Readers support being serialized, so this can produce an
		Unimplemented error.
		
		Args:
		  reader_handle: A `Tensor` of type mutable `string`. Handle to a Reader.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function ReaderSerializeState(reader_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Produce a string tensor that encodes the state of a Reader.
		
		Not all Readers support being serialized, so this can produce an
		Unimplemented error.
		
		Args:
		  reader_handle: A `Tensor` of type `resource`. Handle to a Reader.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function ReaderSerializeStateV2(reader_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the real part of a complex number.
		
		Given a tensor `input` of complex numbers, this operation returns a tensor of
		type `float` that is the real part of each element in `input`. All elements in
		`input` must be complex numbers of the form \\(a + bj\\), where *a* is the real
		 part returned by this operation and *b* is the imaginary part.
		
		For example:
		
		```
		# tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]
		tf.real(input) ==> [-2.25, 3.25]
		```
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.
		  Tout: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `Tout`.
	**/
	static public function Real(input:Dynamic, ?Tout:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x / y element-wise for real types.
		
		If `x` and `y` are reals, this will return the floating-point division.
		
		*NOTE*: `Div` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function RealDiv(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that changes the batch size.
		
		Creates a dataset that changes the batch size of the dataset to current batch
		size // num_workers.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  num_replicas: A `Tensor` of type `int64`.
		    A scalar representing the number of replicas to distribute this batch across. As
		    a result of this transformation the current batch size would end up being
		    divided  by this parameter.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  use_fallback: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function RebatchDataset(input_dataset:Dynamic, num_replicas:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?use_fallback:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that changes the batch size.
		
		Creates a dataset that rebatches elements from `input_dataset` into new batch
		sizes.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  batch_sizes: A `Tensor` of type `int64`.
		    A vector of integers representing the size of batches to produce. These values
		    are cycled through in order.
		  drop_remainder: A `Tensor` of type `bool`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function RebatchDatasetV2(input_dataset:Dynamic, batch_sizes:Dynamic, drop_remainder:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the reciprocal of x element-wise.
		
		I.e., \\(y = 1 / x\\).
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Reciprocal(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient for the inverse of `x` wrt its input.
		
		Specifically, `grad = -dy * y*y`, where `y = 1/x`, and `dy`
		is the corresponding input gradient.
		
		Args:
		  y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  dy: A `Tensor`. Must have the same type as `y`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `y`.
	**/
	static public function ReciprocalGrad(y:Dynamic, dy:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Emits randomized records.
		
		Args:
		  file_pattern: A `string`. Glob pattern for the data files.
		  file_random_seed: An optional `int`. Defaults to `301`.
		    Random seeds used to produce randomized records.
		  file_shuffle_shift_ratio: An optional `float`. Defaults to `0`.
		    Shifts the list of files after the list is randomly
		    shuffled.
		  file_buffer_size: An optional `int`. Defaults to `10000`.
		    The randomization shuffling buffer.
		  file_parallelism: An optional `int`. Defaults to `16`.
		    How many sstables are opened and concurrently iterated over.
		  batch_size: An optional `int`. Defaults to `32`. The batch size.
		  compression_type: An optional `string`. Defaults to `""`.
		    The type of compression for the file. Currently ZLIB and
		    GZIP are supported. Defaults to none.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function RecordInput(file_pattern:Dynamic, ?file_random_seed:Dynamic, ?file_shuffle_shift_ratio:Dynamic, ?file_buffer_size:Dynamic, ?file_parallelism:Dynamic, ?batch_size:Dynamic, ?compression_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Receives the named tensor from send_device on recv_device.
		
		Args:
		  tensor_type: A `tf.DType`.
		  tensor_name: A `string`. The name of the tensor to receive.
		  send_device: A `string`. The name of the device sending the tensor.
		  send_device_incarnation: An `int`. The current incarnation of send_device.
		  recv_device: A `string`. The name of the device receiving the tensor.
		  client_terminated: An optional `bool`. Defaults to `False`.
		    If set to true, this indicates that the node was added
		    to the graph as a result of a client-side feed or fetch of Tensor data,
		    in which case the corresponding send or recv is expected to be managed
		    locally by the caller.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `tensor_type`.
	**/
	static public function Recv(tensor_type:Dynamic, tensor_name:Dynamic, send_device:Dynamic, send_device_incarnation:Dynamic, recv_device:Dynamic, ?client_terminated:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An op that receives embedding activations on the TPU.
		
		The TPU system performs the embedding lookups and aggregations specified by
		the arguments to TPUEmbeddingEnqueue(Integer/Sparse/SparseTensor)Batch. The
		results of these aggregations are visible to the Tensorflow Graph as the
		outputs of a RecvTPUEmbeddingActivations op. This op returns a list containing
		one Tensor of activations per table specified in the model. There can be at
		most one RecvTPUEmbeddingActivations op in the TPU graph.
		
		Args:
		  num_outputs: An `int` that is `>= 1`.
		    The number of output activation tensors, equal to the number of
		    embedding tables in the model.
		  config: A `string`. Serialized TPUEmbeddingConfiguration proto.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `num_outputs` `Tensor` objects with type `float32`.
	**/
	static public function RecvTPUEmbeddingActivations(num_outputs:Dynamic, config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reduces the input dataset to a singleton using a reduce function.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  initial_state: A list of `Tensor` objects.
		    A nested structure of tensors, representing the initial state of the
		    transformation.
		  other_arguments: A list of `Tensor` objects.
		  f: A function decorated with @Defun.
		    A function that maps `(old_state, input_element)` to `new_state`. It must take
		    two arguments and return a nested structures of tensors. The structure of
		    `new_state` must match the structure of `initial_state`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  use_inter_op_parallelism: An optional `bool`. Defaults to `True`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `output_types`.
	**/
	static public function ReduceDataset(input_dataset:Dynamic, initial_state:Dynamic, other_arguments:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?use_inter_op_parallelism:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Joins a string Tensor across the given dimensions.
		
		Computes the string join across dimensions in the given string Tensor of shape
		`[\\(d_0, d_1, ..., d_{n-1}\\)]`.  Returns a new Tensor created by joining the input
		strings with the given separator (default: empty string).  Negative indices are
		counted backwards from the end, with `-1` being equivalent to `n - 1`.  If
		indices are not specified, joins across all dimensions beginning from `n - 1`
		through `0`.
		
		For example:
		
		```python
		# tensor `a` is [["a", "b"], ["c", "d"]]
		tf.reduce_join(a, 0) ==> ["ac", "bd"]
		tf.reduce_join(a, 1) ==> ["ab", "cd"]
		tf.reduce_join(a, -2) = tf.reduce_join(a, 0) ==> ["ac", "bd"]
		tf.reduce_join(a, -1) = tf.reduce_join(a, 1) ==> ["ab", "cd"]
		tf.reduce_join(a, 0, keep_dims=True) ==> [["ac", "bd"]]
		tf.reduce_join(a, 1, keep_dims=True) ==> [["ab"], ["cd"]]
		tf.reduce_join(a, 0, separator=".") ==> ["a.c", "b.d"]
		tf.reduce_join(a, [0, 1]) ==> "acbd"
		tf.reduce_join(a, [1, 0]) ==> "abcd"
		tf.reduce_join(a, []) ==> [["a", "b"], ["c", "d"]]
		tf.reduce_join(a) = tf.reduce_join(a, [1, 0]) ==> "abcd"
		```
		
		Args:
		  inputs: A `Tensor` of type `string`.
		    The input to be joined.  All reduced indices must have non-zero size.
		  reduction_indices: A `Tensor` of type `int32`.
		    The dimensions to reduce over.  Dimensions are reduced in the
		    order specified.  Omitting `reduction_indices` is equivalent to passing
		    `[n-1, n-2, ..., 0]`.  Negative indices from `-n` to `-1` are supported.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If `True`, retain reduced dimensions with length `1`.
		  separator: An optional `string`. Defaults to `""`.
		    The separator to use when joining.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function ReduceJoin(inputs:Dynamic, reduction_indices:Dynamic, ?keep_dims:Dynamic, ?separator:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates or finds a child frame, and makes `data` available to the child frame.
		
		The unique `frame_name` is used by the `Executor` to identify frames. If
		`is_constant` is true, `output` is a constant in the child frame; otherwise
		it may be changed in the child frame. At most `parallel_iterations` iterations
		are run in parallel in the child frame.
		
		Args:
		  data: A mutable `Tensor`.
		    The tensor to be made available to the child frame.
		  frame_name: A `string`. The name of the child frame.
		  is_constant: An optional `bool`. Defaults to `False`.
		    If true, the output is constant within the child frame.
		  parallel_iterations: An optional `int`. Defaults to `10`.
		    The number of iterations allowed to run in parallel.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `data`.
	**/
	static public function RefEnter(data:Dynamic, frame_name:Dynamic, ?is_constant:Dynamic, ?parallel_iterations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Exits the current frame to its parent frame.
		
		Exit makes its input `data` available to the parent frame.
		
		Args:
		  data: A mutable `Tensor`.
		    The tensor to be made available to the parent frame.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `data`.
	**/
	static public function RefExit(data:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return the same ref tensor as the input ref tensor.
		
		Args:
		  input: A mutable `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `input`.
	**/
	static public function RefIdentity(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Forwards the value of an available tensor from `inputs` to `output`.
		
		`Merge` waits for at least one of the tensors in `inputs` to become available.
		It is usually combined with `Switch` to implement branching.
		
		`Merge` forwards the first tensor for become available to `output`, and sets
		`value_index` to its index in `inputs`.
		
		Args:
		  inputs: A list of at least 1 mutable `Tensor` objects with the same type.
		    The input tensors, exactly one of which will become available.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, value_index).
		
		  output: A mutable `Tensor`. Has the same type as `inputs`.
		  value_index: A `Tensor` of type `int32`.
	**/
	static public function RefMerge(inputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Makes its input available to the next iteration.
		
		Args:
		  data: A mutable `Tensor`.
		    The tensor to be made available to the next iteration.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `data`.
	**/
	static public function RefNextIteration(data:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Forwards the `index`th element of `inputs` to `output`.
		
		Args:
		  index: A `Tensor` of type `int32`.
		    A scalar that determines the input that gets selected.
		  inputs: A list of at least 1 mutable `Tensor` objects with the same type.
		    A list of ref tensors, one of which will be forwarded to `output`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `inputs`.
	**/
	static public function RefSelect(index:Dynamic, inputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Forwards the ref tensor `data` to the output port determined by `pred`.
		
		If `pred` is true, the `data` input is forwarded to `output_true`. Otherwise,
		the data goes to `output_false`.
		
		See also `Switch` and `Merge`.
		
		Args:
		  data: A mutable `Tensor`.
		    The ref tensor to be forwarded to the appropriate output.
		  pred: A `Tensor` of type `bool`.
		    A scalar that specifies which output port will receive data.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_false, output_true).
		
		  output_false: A mutable `Tensor`. Has the same type as `data`.
		  output_true: A mutable `Tensor`. Has the same type as `data`.
	**/
	static public function RefSwitch(data:Dynamic, pred:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Check if the input matches the regex pattern.
		
		The input is a string tensor of any shape. The pattern is a scalar
		string tensor which is applied to every element of the input tensor.
		The boolean values (True or False) of the output tensor indicate
		if the input matches the regex pattern provided.
		
		The pattern follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)
		
		Examples:
		
		>>> tf.strings.regex_full_match(["TF lib", "lib TF"], ".*lib$")
		<tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>
		>>> tf.strings.regex_full_match(["TF lib", "lib TF"], ".*TF$")
		<tf.Tensor: shape=(2,), dtype=bool, numpy=array([False,  True])>
		
		Args:
		  input: A `Tensor` of type `string`.
		    A string tensor of the text to be processed.
		  pattern: A `Tensor` of type `string`.
		    A scalar string tensor containing the regular expression to match the input.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function RegexFullMatch(input:Dynamic, pattern:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Replaces matches of the `pattern` regular expression in `input` with the
		replacement string provided in `rewrite`.
		
		  It follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)
		
		  Args:
		    input: A `Tensor` of type `string`. The text to be processed.
		    pattern: A `Tensor` of type `string`.
		      The regular expression to be matched in the `input` strings.
		    rewrite: A `Tensor` of type `string`.
		      The rewrite string to be substituted for the `pattern` expression where it is
		      matched in the `input` strings.
		    replace_global: An optional `bool`. Defaults to `True`.
		      If True, the replacement is global (that is, all matches of the `pattern` regular
		      expression in each input string are rewritten), otherwise the `rewrite`
		      substitution is only made for the first `pattern` match.
		    name: A name for the operation (optional).
		
		  Returns:
		    A `Tensor` of type `string`.
		  
	**/
	static public function RegexReplace(input:Dynamic, pattern:Dynamic, rewrite:Dynamic, ?replace_global:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Registers a dataset with the tf.data service.
		
		Args:
		  dataset: A `Tensor` of type `variant`.
		  address: A `Tensor` of type `string`.
		  protocol: A `Tensor` of type `string`.
		  external_state_policy: An `int`.
		  element_spec: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function RegisterDataset(dataset:Dynamic, address:Dynamic, protocol:Dynamic, external_state_policy:Dynamic, ?element_spec:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes rectified linear: `max(features, 0)`.
		
		See: https://en.wikipedia.org/wiki/Rectifier_(neural_networks)
		Example usage:
		>>> tf.nn.relu([-2., 0., 3.]).numpy()
		array([0., 0., 3.], dtype=float32)
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `qint8`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `features`.
	**/
	static public function Relu(features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes rectified linear 6: `min(max(features, 0), 6)`.
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `features`.
	**/
	static public function Relu6(features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes rectified linear 6 gradients for a Relu6 operation.
		
		Args:
		  gradients: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    The backpropagated gradients to the corresponding Relu6 operation.
		  features: A `Tensor`. Must have the same type as `gradients`.
		    The features passed as input to the corresponding Relu6 operation, or
		    its output; using either one produces the same result.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `gradients`.
	**/
	static public function Relu6Grad(gradients:Dynamic, features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes rectified linear gradients for a Relu operation.
		
		Args:
		  gradients: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    The backpropagated gradients to the corresponding Relu operation.
		  features: A `Tensor`. Must have the same type as `gradients`.
		    The features passed as input to the corresponding Relu operation, OR
		    the outputs of that operation (both work equivalently).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `gradients`.
	**/
	static public function ReluGrad(gradients:Dynamic, features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Runs function `f` on a remote device indicated by `target`.
		
		Args:
		  target: A `Tensor` of type `string`.
		    A fully specified device name where we want to run the function.
		  args: A list of `Tensor` objects. A list of arguments for the function.
		  Tout: A list of `tf.DTypes` that has length `>= 1`.
		    The type list for the return values.
		  f: A function decorated with @Defun. The function to run remotely.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function RemoteCall(target:Dynamic, args:Dynamic, Tout:Dynamic, f:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that emits the outputs of `input_dataset` `count` times.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  count: A `Tensor` of type `int64`.
		    A scalar representing the number of times that `input_dataset` should
		    be repeated. A value of `-1` indicates that it should be repeated infinitely.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function RepeatDataset(input_dataset:Dynamic, count:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes a range that covers the actual values present in a quantized tensor.
		
		Given a quantized tensor described by `(input, input_min, input_max)`, outputs a
		range that covers the actual values present in that tensor. This op is typically
		used to produce the `requested_output_min` and `requested_output_max` for
		`Requantize`.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  input_min: A `Tensor` of type `float32`.
		    The float value that the minimum quantized input value represents.
		  input_max: A `Tensor` of type `float32`.
		    The float value that the maximum quantized input value represents.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_min, output_max).
		
		  output_min: A `Tensor` of type `float32`.
		  output_max: A `Tensor` of type `float32`.
	**/
	static public function RequantizationRange(input:Dynamic, input_min:Dynamic, input_max:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes requantization range per channel.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original input tensor.
		  input_min: A `Tensor` of type `float32`.
		    The minimum value of the input tensor
		  input_max: A `Tensor` of type `float32`.
		    The maximum value of the input tensor.
		  clip_value_max: A `float`.
		    The maximum value of the output that needs to be clipped.
		    Example: set this to 6 for Relu6.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_min, output_max).
		
		  output_min: A `Tensor` of type `float32`.
		  output_max: A `Tensor` of type `float32`.
	**/
	static public function RequantizationRangePerChannel(input:Dynamic, input_min:Dynamic, input_max:Dynamic, clip_value_max:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts the quantized `input` tensor into a lower-precision `output`.
		
		Converts the quantized `input` tensor into a lower-precision `output`, using the
		output range specified with `requested_output_min` and `requested_output_max`.
		
		`[input_min, input_max]` are scalar floats that specify the range for the float
		interpretation of the `input` data. For example, if `input_min` is -1.0f and
		`input_max` is 1.0f, and we are dealing with `quint16` quantized data, then a 0
		value in the 16-bit data should be interpreted as -1.0f, and a 65535 means 1.0f.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		  input_min: A `Tensor` of type `float32`.
		    The float value that the minimum quantized input value represents.
		  input_max: A `Tensor` of type `float32`.
		    The float value that the maximum quantized input value represents.
		  requested_output_min: A `Tensor` of type `float32`.
		    The float value that the minimum quantized output value represents.
		  requested_output_max: A `Tensor` of type `float32`.
		    The float value that the maximum quantized output value represents.
		  out_type: A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`.
		    The type of the output. Should be a lower bit depth than Tinput.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, output_min, output_max).
		
		  output: A `Tensor` of type `out_type`.
		  output_min: A `Tensor` of type `float32`.
		  output_max: A `Tensor` of type `float32`.
	**/
	static public function Requantize(input:Dynamic, input_min:Dynamic, input_max:Dynamic, requested_output_min:Dynamic, requested_output_max:Dynamic, out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Requantizes input with min and max values known per channel.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.
		    The original input tensor.
		  input_min: A `Tensor` of type `float32`.
		    The minimum value of the input tensor
		  input_max: A `Tensor` of type `float32`.
		    The maximum value of the input tensor.
		  requested_output_min: A `Tensor` of type `float32`.
		    The minimum value of the output tensor requested.
		  requested_output_max: A `Tensor` of type `float32`.
		    The maximum value of the output tensor requested.
		  out_type: An optional `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`. Defaults to `tf.quint8`.
		    The quantized type of output tensor that needs to be converted.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output, output_min, output_max).
		
		  output: A `Tensor` of type `out_type`.
		  output_min: A `Tensor` of type `float32`.
		  output_max: A `Tensor` of type `float32`.
	**/
	static public function RequantizePerChannel(input:Dynamic, input_min:Dynamic, input_max:Dynamic, requested_output_min:Dynamic, requested_output_max:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reshapes a tensor.
		
		Given `tensor`, this operation returns a tensor that has the same values
		as `tensor` with shape `shape`.
		
		If one component of 1-D tensor `shape` is the special value -1, the size of that
		dimension is computed so that the total size remains constant.  In particular, a
		`shape` of `[-1]` flattens into 1-D.  At most one component of `shape` may be
		unknown.
		
		The `shape` must be 1-D and the operation returns a tensor with shape
		`shape` filled with the values of `tensor`. In this case, the number of elements
		implied by `shape` must be the same as the number of elements in `tensor`.
		
		It is an error if `shape` is not 1-D.
		
		For example:
		
		```
		# tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]
		# tensor 't' has shape [9]
		reshape(t, [3, 3]) ==> [[1, 2, 3],
		                        [4, 5, 6],
		                        [7, 8, 9]]
		
		# tensor 't' is [[[1, 1], [2, 2]],
		#                [[3, 3], [4, 4]]]
		# tensor 't' has shape [2, 2, 2]
		reshape(t, [2, 4]) ==> [[1, 1, 2, 2],
		                        [3, 3, 4, 4]]
		
		# tensor 't' is [[[1, 1, 1],
		#                 [2, 2, 2]],
		#                [[3, 3, 3],
		#                 [4, 4, 4]],
		#                [[5, 5, 5],
		#                 [6, 6, 6]]]
		# tensor 't' has shape [3, 2, 3]
		# pass '[-1]' to flatten 't'
		reshape(t, [-1]) ==> [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]
		
		# -1 can also be used to infer the shape
		
		# -1 is inferred to be 9:
		reshape(t, [2, -1]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],
		                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]
		# -1 is inferred to be 2:
		reshape(t, [-1, 9]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],
		                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]
		# -1 is inferred to be 3:
		reshape(t, [ 2, -1, 3]) ==> [[[1, 1, 1],
		                              [2, 2, 2],
		                              [3, 3, 3]],
		                             [[4, 4, 4],
		                              [5, 5, 5],
		                              [6, 6, 6]]]
		
		# tensor 't' is [7]
		# shape `[]` reshapes to a scalar
		reshape(t, []) ==> 7
		```
		
		Args:
		  tensor: A `Tensor`.
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Defines the shape of the output tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `tensor`.
	**/
	static public function Reshape(tensor:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Resize `images` to `size` using area interpolation.
		
		Input images can be of different types but output images are always float.
		
		The range of pixel values for the output image might be slightly different
		from the range for the input image because of limited numerical precision.
		To guarantee an output range, for example `[0.0, 1.0]`, apply
		`tf.clip_by_value` to the output.
		
		Each output pixel is computed by first transforming the pixel's footprint into
		the input tensor and then averaging the pixels that intersect the footprint. An
		input pixel's contribution to the average is weighted by the fraction of its
		area that intersects the footprint.  This is the same as OpenCV's INTER_AREA.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`, `half`, `float32`, `float64`, `bfloat16`.
		    4-D with shape `[batch, height, width, channels]`.
		  size:  A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
		    new size for the images.
		  align_corners: An optional `bool`. Defaults to `False`.
		    If true, the centers of the 4 corner pixels of the input and output tensors are
		    aligned, preserving the values at the corner pixels. Defaults to false.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function ResizeArea(images:Dynamic, size:Dynamic, ?align_corners:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Resize `images` to `size` using bicubic interpolation.
		
		Input images can be of different types but output images are always float.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`, `half`, `float32`, `float64`, `bfloat16`.
		    4-D with shape `[batch, height, width, channels]`.
		  size:  A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
		    new size for the images.
		  align_corners: An optional `bool`. Defaults to `False`.
		    If true, the centers of the 4 corner pixels of the input and output tensors are
		    aligned, preserving the values at the corner pixels. Defaults to false.
		  half_pixel_centers: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function ResizeBicubic(images:Dynamic, size:Dynamic, ?align_corners:Dynamic, ?half_pixel_centers:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient of bicubic interpolation.
		
		Args:
		  grads: A `Tensor` of type `float32`.
		    4-D with shape `[batch, height, width, channels]`.
		  original_image: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		    4-D with shape `[batch, orig_height, orig_width, channels]`,
		    The image tensor that was resized.
		  align_corners: An optional `bool`. Defaults to `False`.
		    If true, the centers of the 4 corner pixels of the input and grad tensors are
		    aligned. Defaults to false.
		  half_pixel_centers: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `original_image`.
	**/
	static public function ResizeBicubicGrad(grads:Dynamic, original_image:Dynamic, ?align_corners:Dynamic, ?half_pixel_centers:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Resize `images` to `size` using bilinear interpolation.
		
		Input images can be of different types but output images are always float.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`, `bfloat16`.
		    4-D with shape `[batch, height, width, channels]`.
		  size:  A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
		    new size for the images.
		  align_corners: An optional `bool`. Defaults to `False`.
		    If true, the centers of the 4 corner pixels of the input and output tensors are
		    aligned, preserving the values at the corner pixels. Defaults to false.
		  half_pixel_centers: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function ResizeBilinear(images:Dynamic, size:Dynamic, ?align_corners:Dynamic, ?half_pixel_centers:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient of bilinear interpolation.
		
		Args:
		  grads: A `Tensor` of type `float32`.
		    4-D with shape `[batch, height, width, channels]`.
		  original_image: A `Tensor`. Must be one of the following types: `float32`, `bfloat16`, `half`, `float64`.
		    4-D with shape `[batch, orig_height, orig_width, channels]`,
		    The image tensor that was resized.
		  align_corners: An optional `bool`. Defaults to `False`.
		    If true, the centers of the 4 corner pixels of the input and grad tensors are
		    aligned. Defaults to false.
		  half_pixel_centers: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `original_image`.
	**/
	static public function ResizeBilinearGrad(grads:Dynamic, original_image:Dynamic, ?align_corners:Dynamic, ?half_pixel_centers:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Resize `images` to `size` using nearest neighbor interpolation.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`, `half`, `float32`, `float64`, `bfloat16`.
		    4-D with shape `[batch, height, width, channels]`.
		  size:  A 1-D int32 Tensor of 2 elements: `new_height, new_width`.  The
		    new size for the images.
		  align_corners: An optional `bool`. Defaults to `False`.
		    If true, the centers of the 4 corner pixels of the input and output tensors are
		    aligned, preserving the values at the corner pixels. Defaults to false.
		  half_pixel_centers: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `images`.
	**/
	static public function ResizeNearestNeighbor(images:Dynamic, size:Dynamic, ?align_corners:Dynamic, ?half_pixel_centers:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient of nearest neighbor interpolation.
		
		Args:
		  grads: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `int32`, `half`, `float32`, `float64`, `bfloat16`.
		    4-D with shape `[batch, height, width, channels]`.
		  size:  A 1-D int32 Tensor of 2 elements: `orig_height, orig_width`. The
		    original input size.
		  align_corners: An optional `bool`. Defaults to `False`.
		    If true, the centers of the 4 corner pixels of the input and grad tensors are
		    aligned. Defaults to false.
		  half_pixel_centers: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `grads`.
	**/
	static public function ResizeNearestNeighborGrad(grads:Dynamic, size:Dynamic, ?align_corners:Dynamic, ?half_pixel_centers:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies a gradient to a given accumulator.
		
		Does not add if local_step is lesser than the accumulator's global_step.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a accumulator.
		  local_step: A `Tensor` of type `int64`.
		    The local_step value at which the gradient was computed.
		  gradient: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A tensor of the gradient to be accumulated.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceAccumulatorApplyGradient(handle:Dynamic, local_step:Dynamic, gradient:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the number of gradients aggregated in the given accumulators.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to an accumulator.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function ResourceAccumulatorNumAccumulated(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Updates the accumulator with a new value for global_step.
		
		Logs warning if the accumulator's value is already higher than
		new_global_step.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to an accumulator.
		  new_global_step: A `Tensor` of type `int64`.
		    The new global_step value to set.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceAccumulatorSetGlobalStep(handle:Dynamic, new_global_step:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Extracts the average gradient in the given ConditionalAccumulator.
		
		The op blocks until sufficient (i.e., more than num_required)
		gradients have been accumulated.  If the accumulator has already
		aggregated more than num_required gradients, it returns the average of
		the accumulated gradients.  Also automatically increments the recorded
		global_step in the accumulator by 1, and resets the aggregate to 0.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to an accumulator.
		  num_required: A `Tensor` of type `int32`.
		    Number of gradients required before we return an aggregate.
		  dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
		    The data type of accumulated gradients. Needs to correspond to the type
		    of the accumulator.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function ResourceAccumulatorTakeGradient(handle:Dynamic, num_required:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the AdaMax algorithm.
		
		m_t <- beta1 * m_{t-1} + (1 - beta1) * g
		v_t <- max(beta2 * v_{t-1}, abs(g))
		variable <- variable - learning_rate / (1 - beta1^t) * m_t / (v_t + epsilon)
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  m: A `Tensor` of type `resource`. Should be from a Variable().
		  v: A `Tensor` of type `resource`. Should be from a Variable().
		  beta1_power: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Must be a scalar.
		  lr: A `Tensor`. Must have the same type as `beta1_power`.
		    Scaling factor. Must be a scalar.
		  beta1: A `Tensor`. Must have the same type as `beta1_power`.
		    Momentum factor. Must be a scalar.
		  beta2: A `Tensor`. Must have the same type as `beta1_power`.
		    Momentum factor. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `beta1_power`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `beta1_power`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, m, and v tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyAdaMax(_var:Dynamic, m:Dynamic, v:Dynamic, beta1_power:Dynamic, lr:Dynamic, beta1:Dynamic, beta2:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the adadelta scheme.
		
		accum = rho() * accum + (1 - rho()) * grad.square();
		update = (update_accum + epsilon).sqrt() * (accum + epsilon()).rsqrt() * grad;
		update_accum = rho() * update_accum + (1 - rho()) * update.square();
		var -= update;
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  accum_update: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `lr`.
		    Decay factor. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `lr`.
		    Constant factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var, accum and update_accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyAdadelta(_var:Dynamic, accum:Dynamic, accum_update:Dynamic, lr:Dynamic, rho:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the adagrad scheme.
		
		accum += grad * grad
		var -= lr * grad * (1 / sqrt(accum))
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  update_slots: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyAdagrad(_var:Dynamic, accum:Dynamic, lr:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?update_slots:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the proximal adagrad scheme.
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  gradient_accumulator: A `Tensor` of type `resource`.
		    Should be from a Variable().
		  gradient_squared_accumulator: A `Tensor` of type `resource`.
		    Should be from a Variable().
		  grad: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    The gradient.
		  lr: A `Tensor`. Must have the same type as `grad`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `grad`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `grad`.
		    L2 regularization. Must be a scalar.
		  global_step: A `Tensor` of type `int64`.
		    Training step number. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var and accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyAdagradDA(_var:Dynamic, gradient_accumulator:Dynamic, gradient_squared_accumulator:Dynamic, grad:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, global_step:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the adagrad scheme.
		
		accum += grad * grad
		var -= lr * grad * (1 / (sqrt(accum) + epsilon))
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `lr`.
		    Constant factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  update_slots: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyAdagradV2(_var:Dynamic, accum:Dynamic, lr:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?update_slots:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the Adam algorithm.
		
		$$\text{lr}_t := \mathrm{lr} \cdot \frac{\sqrt{1 - \beta_2^t}}{1 - \beta_1^t}$$
		$$m_t := \beta_1 \cdot m_{t-1} + (1 - \beta_1) \cdot g$$
		$$v_t := \beta_2 \cdot v_{t-1} + (1 - \beta_2) \cdot g^2$$
		$$\text{var} := \begin{cases} \text{var} - (m_t \beta_1 + g \cdot (1 - \beta_1))\cdot\text{lr}_t/(\sqrt{v_t} + \epsilon), &\text{if use_nesterov}\\\\  \text{var} - m_t \cdot \text{lr}_t /(\sqrt{v_t} + \epsilon), &\text{otherwise} \end{cases}$$
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  m: A `Tensor` of type `resource`. Should be from a Variable().
		  v: A `Tensor` of type `resource`. Should be from a Variable().
		  beta1_power: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Must be a scalar.
		  beta2_power: A `Tensor`. Must have the same type as `beta1_power`.
		    Must be a scalar.
		  lr: A `Tensor`. Must have the same type as `beta1_power`.
		    Scaling factor. Must be a scalar.
		  beta1: A `Tensor`. Must have the same type as `beta1_power`.
		    Momentum factor. Must be a scalar.
		  beta2: A `Tensor`. Must have the same type as `beta1_power`.
		    Momentum factor. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `beta1_power`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `beta1_power`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, m, and v tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  use_nesterov: An optional `bool`. Defaults to `False`.
		    If `True`, uses the nesterov update.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyAdam(_var:Dynamic, m:Dynamic, v:Dynamic, beta1_power:Dynamic, beta2_power:Dynamic, lr:Dynamic, beta1:Dynamic, beta2:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?use_nesterov:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the Adam algorithm.
		
		$$\text{lr}_t := \mathrm{learning_rate} * \sqrt{1 - \beta_2^t} / (1 - \beta_1^t)$$
		$$m_t := \beta_1 * m_{t-1} + (1 - \beta_1) * g$$
		$$v_t := \beta_2 * v_{t-1} + (1 - \beta_2) * g * g$$
		$$\hat{v}_t := max{\hat{v}_{t-1}, v_t}$$
		$$\text{variable} := \text{variable} - \text{lr}_t * m_t / (\sqrt{\hat{v}_t} + \epsilon)$$
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  m: A `Tensor` of type `resource`. Should be from a Variable().
		  v: A `Tensor` of type `resource`. Should be from a Variable().
		  vhat: A `Tensor` of type `resource`. Should be from a Variable().
		  beta1_power: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Must be a scalar.
		  beta2_power: A `Tensor`. Must have the same type as `beta1_power`.
		    Must be a scalar.
		  lr: A `Tensor`. Must have the same type as `beta1_power`.
		    Scaling factor. Must be a scalar.
		  beta1: A `Tensor`. Must have the same type as `beta1_power`.
		    Momentum factor. Must be a scalar.
		  beta2: A `Tensor`. Must have the same type as `beta1_power`.
		    Momentum factor. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `beta1_power`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `beta1_power`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, m, and v tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyAdamWithAmsgrad(_var:Dynamic, m:Dynamic, v:Dynamic, vhat:Dynamic, beta1_power:Dynamic, beta2_power:Dynamic, lr:Dynamic, beta1:Dynamic, beta2:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the AddSign update.
		
		m_t <- beta1 * m_{t-1} + (1 - beta1) * g
		update <- (alpha + sign_decay * sign(g) *sign(m)) * g
		variable <- variable - lr_t * update
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  m: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  alpha: A `Tensor`. Must have the same type as `lr`. Must be a scalar.
		  sign_decay: A `Tensor`. Must have the same type as `lr`. Must be a scalar.
		  beta: A `Tensor`. Must have the same type as `lr`. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and m tensors is
		    protected by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyAddSign(_var:Dynamic, m:Dynamic, lr:Dynamic, alpha:Dynamic, sign_decay:Dynamic, beta:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the centered RMSProp algorithm.
		
		The centered RMSProp algorithm uses an estimate of the centered second moment
		(i.e., the variance) for normalization, as opposed to regular RMSProp, which
		uses the (uncentered) second moment. This often helps with training, but is
		slightly more expensive in terms of computation and memory.
		
		Note that in dense implementation of this algorithm, mg, ms, and mom will
		update even if the grad is zero, but in this sparse implementation, mg, ms,
		and mom will not update in iterations during which the grad is zero.
		
		mean_square = decay * mean_square + (1-decay) * gradient ** 2
		mean_grad = decay * mean_grad + (1-decay) * gradient
		
		Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
		
		mg <- rho * mg_{t-1} + (1-rho) * grad
		ms <- rho * ms_{t-1} + (1-rho) * grad * grad
		mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms - mg * mg + epsilon)
		var <- var - mom
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  mg: A `Tensor` of type `resource`. Should be from a Variable().
		  ms: A `Tensor` of type `resource`. Should be from a Variable().
		  mom: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `lr`.
		    Decay rate. Must be a scalar.
		  momentum: A `Tensor`. Must have the same type as `lr`.
		    Momentum Scale. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `lr`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, mg, ms, and mom tensors is
		    protected by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyCenteredRMSProp(_var:Dynamic, mg:Dynamic, ms:Dynamic, mom:Dynamic, lr:Dynamic, rho:Dynamic, momentum:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the Ftrl-proximal scheme.
		
		accum_new = accum + grad * grad
		linear += grad - (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
		quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
		var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
		accum = accum_new
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  linear: A `Tensor` of type `resource`. Should be from a Variable().
		  grad: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    The gradient.
		  lr: A `Tensor`. Must have the same type as `grad`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `grad`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `grad`.
		    L2 regularization. Must be a scalar.
		  lr_power: A `Tensor`. Must have the same type as `grad`.
		    Scaling factor. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  multiply_linear_by_lr: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyFtrl(_var:Dynamic, accum:Dynamic, linear:Dynamic, grad:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, lr_power:Dynamic, ?use_locking:Dynamic, ?multiply_linear_by_lr:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the Ftrl-proximal scheme.
		
		accum_new = accum + grad * grad
		grad_with_shrinkage = grad + 2 * l2_shrinkage * var
		linear += grad_with_shrinkage +
		    (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
		quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
		var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
		accum = accum_new
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  linear: A `Tensor` of type `resource`. Should be from a Variable().
		  grad: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    The gradient.
		  lr: A `Tensor`. Must have the same type as `grad`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `grad`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `grad`.
		    L2 shrinkage regularization. Must be a scalar.
		  l2_shrinkage: A `Tensor`. Must have the same type as `grad`.
		  lr_power: A `Tensor`. Must have the same type as `grad`.
		    Scaling factor. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  multiply_linear_by_lr: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyFtrlV2(_var:Dynamic, accum:Dynamic, linear:Dynamic, grad:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, l2_shrinkage:Dynamic, lr_power:Dynamic, ?use_locking:Dynamic, ?multiply_linear_by_lr:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' by subtracting 'alpha' * 'delta' from it.
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  alpha: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  delta: A `Tensor`. Must have the same type as `alpha`. The change.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, the subtraction will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyGradientDescent(_var:Dynamic, alpha:Dynamic, delta:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the momentum scheme.
		
		Set use_nesterov = True if you want to use Nesterov momentum.
		
		accum = accum * momentum - lr * grad
		var += accum
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  momentum: A `Tensor`. Must have the same type as `lr`.
		    Momentum. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  use_nesterov: An optional `bool`. Defaults to `False`.
		    If `True`, the tensor passed to compute grad will be
		    var + momentum * accum, so in the end, the var you get is actually
		    var + momentum * accum.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyKerasMomentum(_var:Dynamic, accum:Dynamic, lr:Dynamic, grad:Dynamic, momentum:Dynamic, ?use_locking:Dynamic, ?use_nesterov:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the momentum scheme.
		
		Set use_nesterov = True if you want to use Nesterov momentum.
		
		accum = accum * momentum + grad
		var -= lr * accum
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  momentum: A `Tensor`. Must have the same type as `lr`.
		    Momentum. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  use_nesterov: An optional `bool`. Defaults to `False`.
		    If `True`, the tensor passed to compute grad will be
		    var - lr * momentum * accum, so in the end, the var you get is actually
		    var - lr * momentum * accum.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyMomentum(_var:Dynamic, accum:Dynamic, lr:Dynamic, grad:Dynamic, momentum:Dynamic, ?use_locking:Dynamic, ?use_nesterov:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the AddSign update.
		
		m_t <- beta1 * m_{t-1} + (1 - beta1) * g
		update <- exp(logbase * sign_decay * sign(g) * sign(m_t)) * g
		variable <- variable - lr_t * update
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  m: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  logbase: A `Tensor`. Must have the same type as `lr`. Must be a scalar.
		  sign_decay: A `Tensor`. Must have the same type as `lr`. Must be a scalar.
		  beta: A `Tensor`. Must have the same type as `lr`. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and m tensors is
		    protected by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyPowerSign(_var:Dynamic, m:Dynamic, lr:Dynamic, logbase:Dynamic, sign_decay:Dynamic, beta:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' and '*accum' according to FOBOS with Adagrad learning rate.
		
		accum += grad * grad
		prox_v = var - lr * grad * (1 / sqrt(accum))
		var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `lr`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `lr`.
		    L2 regularization. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var and accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyProximalAdagrad(_var:Dynamic, accum:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' as FOBOS algorithm with fixed learning rate.
		
		prox_v = var - alpha * delta
		var = sign(prox_v)/(1+alpha*l2) * max{|prox_v|-alpha*l1,0}
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  alpha: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `alpha`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `alpha`.
		    L2 regularization. Must be a scalar.
		  delta: A `Tensor`. Must have the same type as `alpha`. The change.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the subtraction will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyProximalGradientDescent(_var:Dynamic, alpha:Dynamic, l1:Dynamic, l2:Dynamic, delta:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the RMSProp algorithm.
		
		Note that in dense implementation of this algorithm, ms and mom will
		update even if the grad is zero, but in this sparse implementation, ms
		and mom will not update in iterations during which the grad is zero.
		
		mean_square = decay * mean_square + (1-decay) * gradient ** 2
		Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
		
		ms <- rho * ms_{t-1} + (1-rho) * grad * grad
		mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
		var <- var - mom
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  ms: A `Tensor` of type `resource`. Should be from a Variable().
		  mom: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `lr`.
		    Decay rate. Must be a scalar.
		  momentum: A `Tensor`. Must have the same type as `lr`.
		  epsilon: A `Tensor`. Must have the same type as `lr`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, ms, and mom tensors is protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceApplyRMSProp(_var:Dynamic, ms:Dynamic, mom:Dynamic, lr:Dynamic, rho:Dynamic, momentum:Dynamic, epsilon:Dynamic, grad:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A conditional accumulator for aggregating gradients.
		
		The accumulator accepts gradients marked with local_step greater or
		equal to the most recent global_step known to the accumulator. The
		average can be extracted from the accumulator, provided sufficient
		gradients have been accumulated. Extracting the average automatically
		resets the aggregate to 0, and increments the global_step recorded by
		the accumulator.
		This is a resource version of ConditionalAccumulator that will work in TF2.0
		with tf.cond version 2.
		
		Args:
		  dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
		    The type of the value being accumulated.
		  shape: A `tf.TensorShape` or list of `ints`.
		    The shape of the values, can be [], in which case shape is unknown.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this accumulator is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this accumulator will be shared under the
		    given name across multiple sessions.
		  reduction_type: An optional `string` from: `"MEAN", "SUM"`. Defaults to `"MEAN"`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function ResourceConditionalAccumulator(dtype:Dynamic, shape:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?reduction_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Increments variable pointed to by 'resource' until it reaches 'limit'.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    Should be from a scalar `Variable` node.
		  limit: An `int`.
		    If incrementing ref would bring it above limit, instead generates an
		    'OutOfRange' error.
		  T: A `tf.DType` from: `tf.int32, tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `T`.
	**/
	static public function ResourceCountUpTo(resource:Dynamic, limit:Dynamic, T:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gather slices from the variable pointed to by `resource` according to `indices`.
		
		`indices` must be an integer tensor of any dimension (usually 0-D or 1-D).
		Produces an output tensor with shape `indices.shape + params.shape[1:]` where:
		
		```python
		    # Scalar indices
		    output[:, ..., :] = params[indices, :, ... :]
		
		    # Vector indices
		    output[i, :, ..., :] = params[indices[i], :, ... :]
		
		    # Higher rank indices
		    output[i, ..., j, :, ... :] = params[indices[i, ..., j], :, ..., :]
		```
		
		Args:
		  resource: A `Tensor` of type `resource`.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  dtype: A `tf.DType`.
		  batch_dims: An optional `int`. Defaults to `0`.
		  validate_indices: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function ResourceGather(resource:Dynamic, indices:Dynamic, dtype:Dynamic, ?batch_dims:Dynamic, ?validate_indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  dtype: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function ResourceGatherNd(resource:Dynamic, indices:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adds sparse updates to the variable referenced by `resource`.
		
		This operation computes
		
		    # Scalar indices
		    ref[indices, ...] += updates[...]
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] += updates[i, ...]
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their contributions add.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
		</div>
		
		Args:
		  resource: A `Tensor` of type `resource`. Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A tensor of updated values to add to `ref`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterAdd(resource:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Divides sparse updates into the variable referenced by `resource`.
		
		This operation computes
		
		    # Scalar indices
		    ref[indices, ...] /= updates[...]
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] /= updates[i, ...]
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] /= updates[i, ..., j, ...]
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their contributions multiply.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
		</div>
		
		Args:
		  resource: A `Tensor` of type `resource`. Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A tensor of updated values to add to `ref`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterDiv(resource:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reduces sparse updates into the variable referenced by `resource` using the `max` operation.
		
		This operation computes
		
		    # Scalar indices
		    ref[indices, ...] = max(ref[indices, ...], updates[...])
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] = max(ref[indices[i], ...], updates[i, ...])
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] = max(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their contributions are combined.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
		</div>
		
		Args:
		  resource: A `Tensor` of type `resource`. Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A tensor of updated values to add to `ref`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterMax(resource:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reduces sparse updates into the variable referenced by `resource` using the `min` operation.
		
		This operation computes
		
		    # Scalar indices
		    ref[indices, ...] = min(ref[indices, ...], updates[...])
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] = min(ref[indices[i], ...], updates[i, ...])
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] = min(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their contributions are combined.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
		</div>
		
		Args:
		  resource: A `Tensor` of type `resource`. Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A tensor of updated values to add to `ref`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterMin(resource:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Multiplies sparse updates into the variable referenced by `resource`.
		
		This operation computes
		
		    # Scalar indices
		    ref[indices, ...] *= updates[...]
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] *= updates[i, ...]
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] *= updates[i, ..., j, ...]
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their contributions multiply.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
		</div>
		
		Args:
		  resource: A `Tensor` of type `resource`. Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A tensor of updated values to add to `ref`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterMul(resource:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies sparse addition to individual values or slices in a Variable.
		
		`ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
		
		`indices` must be integer tensor, containing indices into `ref`.
		It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.
		
		The innermost dimension of `indices` (with length `K`) corresponds to
		indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th
		dimension of `ref`.
		
		`updates` is `Tensor` of rank `Q-1+P-K` with shape:
		
		```
		[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]]
		```
		
		For example, say we want to add 4 scattered elements to a rank-1 tensor to
		8 elements. In Python, that addition would look like this:
		
		```python
		ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8], use_resource=True)
		indices = tf.constant([[4], [3], [1], [7]])
		updates = tf.constant([9, 10, 11, 12])
		add = tf.scatter_nd_add(ref, indices, updates)
		with tf.Session() as sess:
		  print sess.run(add)
		```
		
		The resulting update to ref would look like this:
		
		    [1, 13, 3, 14, 14, 6, 7, 20]
		
		See `tf.scatter_nd` for more details about how to make updates to
		slices.
		
		Args:
		  ref: A `Tensor` of type `resource`.
		    A resource handle. Must be from a VarHandleOp.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor. Must be one of the following types: int32, int64.
		    A tensor of indices into ref.
		  updates: A `Tensor`. A Tensor. Must have the same type as ref. A tensor of
		    values to add to ref.
		  use_locking: An optional `bool`. Defaults to `True`.
		    An optional bool. Defaults to True. If True, the assignment will
		    be protected by a lock; otherwise the behavior is undefined,
		    but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterNdAdd(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  ref: A `Tensor` of type `resource`.
		    A resource handle. Must be from a VarHandleOp.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor. Must be one of the following types: int32, int64.
		    A tensor of indices into ref.
		  updates: A `Tensor`. A Tensor. Must have the same type as ref. A tensor of
		    values whose element wise max is taken with ref
		  use_locking: An optional `bool`. Defaults to `True`.
		    An optional bool. Defaults to True. If True, the assignment will
		    be protected by a lock; otherwise the behavior is undefined,
		    but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterNdMax(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  ref: A `Tensor` of type `resource`.
		    A resource handle. Must be from a VarHandleOp.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor. Must be one of the following types: int32, int64.
		    A tensor of indices into ref.
		  updates: A `Tensor`. A Tensor. Must have the same type as ref. A tensor of
		    values whose element wise min is taken with ref.
		  use_locking: An optional `bool`. Defaults to `True`.
		    An optional bool. Defaults to True. If True, the assignment will
		    be protected by a lock; otherwise the behavior is undefined,
		    but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterNdMin(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies sparse subtraction to individual values or slices in a Variable.
		
		`ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
		
		`indices` must be integer tensor, containing indices into `ref`.
		It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.
		
		The innermost dimension of `indices` (with length `K`) corresponds to
		indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th
		dimension of `ref`.
		
		`updates` is `Tensor` of rank `Q-1+P-K` with shape:
		
		```
		[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]]
		```
		
		For example, say we want to subtract 4 scattered elements from a rank-1 tensor
		with 8 elements. In Python, that subtraction would look like this:
		
		```python
		ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8], use_resource=True)
		indices = tf.constant([[4], [3], [1], [7]])
		updates = tf.constant([9, 10, 11, 12])
		sub = tf.scatter_nd_sub(ref, indices, updates)
		with tf.Session() as sess:
		  print sess.run(sub)
		```
		
		The resulting update to ref would look like this:
		
		    [1, -9, 3, -6, -4, 6, 7, -4]
		
		See `tf.scatter_nd` for more details about how to make updates to
		slices.
		
		Args:
		  ref: A `Tensor` of type `resource`.
		    A resource handle. Must be from a VarHandleOp.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor. Must be one of the following types: int32, int64.
		    A tensor of indices into ref.
		  updates: A `Tensor`. A Tensor. Must have the same type as ref. A tensor of
		    values to add to ref.
		  use_locking: An optional `bool`. Defaults to `True`.
		    An optional bool. Defaults to True. If True, the assignment will
		    be protected by a lock; otherwise the behavior is undefined,
		    but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterNdSub(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies sparse `updates` to individual values or slices within a given
		
		variable according to `indices`.
		
		`ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
		
		`indices` must be integer tensor, containing indices into `ref`.
		It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.
		
		The innermost dimension of `indices` (with length `K`) corresponds to
		indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th
		dimension of `ref`.
		
		`updates` is `Tensor` of rank `Q-1+P-K` with shape:
		
		```
		[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].
		```
		
		For example, say we want to update 4 scattered elements to a rank-1 tensor to
		8 elements. In Python, that update would look like this:
		
		```python
		    ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
		    indices = tf.constant([[4], [3], [1] ,[7]])
		    updates = tf.constant([9, 10, 11, 12])
		    update = tf.scatter_nd_update(ref, indices, updates)
		    with tf.Session() as sess:
		      print sess.run(update)
		```
		
		The resulting update to ref would look like this:
		
		    [1, 11, 3, 10, 9, 6, 7, 12]
		
		See `tf.scatter_nd` for more details about how to make updates to
		slices.
		
		Args:
		  ref: A `Tensor` of type `resource`.
		    A resource handle. Must be from a VarHandleOp.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor. Must be one of the following types: int32, int64.
		    A tensor of indices into ref.
		  updates: A `Tensor`.
		    A Tensor. Must have the same type as ref. A tensor of updated
		    values to add to ref.
		  use_locking: An optional `bool`. Defaults to `True`.
		    An optional bool. Defaults to True. If True, the assignment will
		    be protected by a lock; otherwise the behavior is undefined,
		    but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterNdUpdate(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Subtracts sparse updates from the variable referenced by `resource`.
		
		This operation computes
		
		    # Scalar indices
		    ref[indices, ...] -= updates[...]
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] -= updates[i, ...]
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their contributions add.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>
		</div>
		
		Args:
		  resource: A `Tensor` of type `resource`. Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A tensor of updated values to add to `ref`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterSub(resource:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Assigns sparse updates to the variable referenced by `resource`.
		
		This operation computes
		
		    # Scalar indices
		    ref[indices, ...] = updates[...]
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] = updates[i, ...]
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]
		
		Args:
		  resource: A `Tensor` of type `resource`. Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. A tensor of updated values to add to `ref`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceScatterUpdate(resource:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		var: Should be from a Variable().
		
		Args:
		  var: A `Tensor` of type `resource`.
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  accum_update: A `Tensor` of type `resource`.
		    : Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Learning rate. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `lr`.
		    Decay factor. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `lr`.
		    Constant factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var and accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyAdadelta(_var:Dynamic, accum:Dynamic, accum_update:Dynamic, lr:Dynamic, rho:Dynamic, epsilon:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update relevant entries in '*var' and '*accum' according to the adagrad scheme.
		
		That is for rows we have grad for, we update var and accum as follows:
		accum += grad * grad
		var -= lr * grad * (1 / sqrt(accum))
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Learning rate. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  update_slots: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyAdagrad(_var:Dynamic, accum:Dynamic, lr:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?update_slots:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update entries in '*var' and '*accum' according to the proximal adagrad scheme.
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  gradient_accumulator: A `Tensor` of type `resource`.
		    Should be from a Variable().
		  gradient_squared_accumulator: A `Tensor` of type `resource`.
		    Should be from a Variable().
		  grad: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  lr: A `Tensor`. Must have the same type as `grad`.
		    Learning rate. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `grad`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `grad`.
		    L2 regularization. Must be a scalar.
		  global_step: A `Tensor` of type `int64`.
		    Training step number. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var and accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyAdagradDA(_var:Dynamic, gradient_accumulator:Dynamic, gradient_squared_accumulator:Dynamic, grad:Dynamic, indices:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, global_step:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update relevant entries in '*var' and '*accum' according to the adagrad scheme.
		
		That is for rows we have grad for, we update var and accum as follows:
		accum += grad * grad
		var -= lr * grad * (1 / sqrt(accum))
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Learning rate. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `lr`.
		    Constant factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  update_slots: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyAdagradV2(_var:Dynamic, accum:Dynamic, lr:Dynamic, epsilon:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?update_slots:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the centered RMSProp algorithm.
		
		The centered RMSProp algorithm uses an estimate of the centered second moment
		(i.e., the variance) for normalization, as opposed to regular RMSProp, which
		uses the (uncentered) second moment. This often helps with training, but is
		slightly more expensive in terms of computation and memory.
		
		Note that in dense implementation of this algorithm, mg, ms, and mom will
		update even if the grad is zero, but in this sparse implementation, mg, ms,
		and mom will not update in iterations during which the grad is zero.
		
		mean_square = decay * mean_square + (1-decay) * gradient ** 2
		mean_grad = decay * mean_grad + (1-decay) * gradient
		Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
		
		ms <- rho * ms_{t-1} + (1-rho) * grad * grad
		mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
		var <- var - mom
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  mg: A `Tensor` of type `resource`. Should be from a Variable().
		  ms: A `Tensor` of type `resource`. Should be from a Variable().
		  mom: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `lr`.
		    Decay rate. Must be a scalar.
		  momentum: A `Tensor`. Must have the same type as `lr`.
		  epsilon: A `Tensor`. Must have the same type as `lr`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var, ms and mom.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, mg, ms, and mom tensors is
		    protected by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyCenteredRMSProp(_var:Dynamic, mg:Dynamic, ms:Dynamic, mom:Dynamic, lr:Dynamic, rho:Dynamic, momentum:Dynamic, epsilon:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update relevant entries in '*var' according to the Ftrl-proximal scheme.
		
		That is for rows we have grad for, we update var, accum and linear as follows:
		accum_new = accum + grad * grad
		linear += grad - (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
		quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
		var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
		accum = accum_new
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  linear: A `Tensor` of type `resource`. Should be from a Variable().
		  grad: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  lr: A `Tensor`. Must have the same type as `grad`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `grad`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `grad`.
		    L2 regularization. Must be a scalar.
		  lr_power: A `Tensor`. Must have the same type as `grad`.
		    Scaling factor. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  multiply_linear_by_lr: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyFtrl(_var:Dynamic, accum:Dynamic, linear:Dynamic, grad:Dynamic, indices:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, lr_power:Dynamic, ?use_locking:Dynamic, ?multiply_linear_by_lr:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update relevant entries in '*var' according to the Ftrl-proximal scheme.
		
		That is for rows we have grad for, we update var, accum and linear as follows:
		grad_with_shrinkage = grad + 2 * l2_shrinkage * var
		accum_new = accum + grad_with_shrinkage * grad_with_shrinkage
		linear += grad_with_shrinkage +
		    (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
		quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
		var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
		accum = accum_new
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  linear: A `Tensor` of type `resource`. Should be from a Variable().
		  grad: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  lr: A `Tensor`. Must have the same type as `grad`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `grad`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `grad`.
		    L2 shrinkage regularization. Must be a scalar.
		  l2_shrinkage: A `Tensor`. Must have the same type as `grad`.
		  lr_power: A `Tensor`. Must have the same type as `grad`.
		    Scaling factor. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  multiply_linear_by_lr: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyFtrlV2(_var:Dynamic, accum:Dynamic, linear:Dynamic, grad:Dynamic, indices:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, l2_shrinkage:Dynamic, lr_power:Dynamic, ?use_locking:Dynamic, ?multiply_linear_by_lr:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update relevant entries in '*var' and '*accum' according to the momentum scheme.
		
		Set use_nesterov = True if you want to use Nesterov momentum.
		
		That is for rows we have grad for, we update var and accum as follows:
		
		accum = accum * momentum - lr * grad
		var += accum
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Learning rate. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  momentum: A `Tensor`. Must have the same type as `lr`.
		    Momentum. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  use_nesterov: An optional `bool`. Defaults to `False`.
		    If `True`, the tensor passed to compute grad will be
		    var + momentum * accum, so in the end, the var you get is actually
		    var + momentum * accum.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyKerasMomentum(_var:Dynamic, accum:Dynamic, lr:Dynamic, grad:Dynamic, indices:Dynamic, momentum:Dynamic, ?use_locking:Dynamic, ?use_nesterov:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update relevant entries in '*var' and '*accum' according to the momentum scheme.
		
		Set use_nesterov = True if you want to use Nesterov momentum.
		
		That is for rows we have grad for, we update var and accum as follows:
		
		accum = accum * momentum + grad
		var -= lr * accum
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Learning rate. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  momentum: A `Tensor`. Must have the same type as `lr`.
		    Momentum. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  use_nesterov: An optional `bool`. Defaults to `False`.
		    If `True`, the tensor passed to compute grad will be
		    var - lr * momentum * accum, so in the end, the var you get is actually
		    var - lr * momentum * accum.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyMomentum(_var:Dynamic, accum:Dynamic, lr:Dynamic, grad:Dynamic, indices:Dynamic, momentum:Dynamic, ?use_locking:Dynamic, ?use_nesterov:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Sparse update entries in '*var' and '*accum' according to FOBOS algorithm.
		
		That is for rows we have grad for, we update var and accum as follows:
		accum += grad * grad
		prox_v = var
		prox_v -= lr * grad * (1 / sqrt(accum))
		var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  accum: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Learning rate. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `lr`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `lr`.
		    L2 regularization. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var and accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyProximalAdagrad(_var:Dynamic, accum:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Sparse update '*var' as FOBOS algorithm with fixed learning rate.
		
		That is for rows we have grad for, we update var as follows:
		prox_v = var - alpha * grad
		var = sign(prox_v)/(1+alpha*l2) * max{|prox_v|-alpha*l1,0}
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  alpha: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `alpha`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `alpha`.
		    L2 regularization. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `alpha`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the subtraction will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyProximalGradientDescent(_var:Dynamic, alpha:Dynamic, l1:Dynamic, l2:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the RMSProp algorithm.
		
		Note that in dense implementation of this algorithm, ms and mom will
		update even if the grad is zero, but in this sparse implementation, ms
		and mom will not update in iterations during which the grad is zero.
		
		mean_square = decay * mean_square + (1-decay) * gradient ** 2
		Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
		
		ms <- rho * ms_{t-1} + (1-rho) * grad * grad
		mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)
		var <- var - mom
		
		Args:
		  var: A `Tensor` of type `resource`. Should be from a Variable().
		  ms: A `Tensor` of type `resource`. Should be from a Variable().
		  mom: A `Tensor` of type `resource`. Should be from a Variable().
		  lr: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Scaling factor. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `lr`.
		    Decay rate. Must be a scalar.
		  momentum: A `Tensor`. Must have the same type as `lr`.
		  epsilon: A `Tensor`. Must have the same type as `lr`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `lr`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var, ms and mom.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, ms, and mom tensors is protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceSparseApplyRMSProp(_var:Dynamic, ms:Dynamic, mom:Dynamic, lr:Dynamic, rho:Dynamic, momentum:Dynamic, epsilon:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Assign `value` to the sliced l-value reference of `ref`.
		
		The values of `value` are assigned to the positions in the variable
		`ref` that are selected by the slice parameters. The slice parameters
		`begin, `end`, `strides`, etc. work exactly as in `StridedSlice`.
		
		NOTE this op currently does not support broadcasting and so `value`'s
		shape must be exactly the shape produced by the slice of `ref`.
		
		Args:
		  ref: A `Tensor` of type `resource`.
		  begin: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  end: A `Tensor`. Must have the same type as `begin`.
		  strides: A `Tensor`. Must have the same type as `begin`.
		  value: A `Tensor`.
		  begin_mask: An optional `int`. Defaults to `0`.
		  end_mask: An optional `int`. Defaults to `0`.
		  ellipsis_mask: An optional `int`. Defaults to `0`.
		  new_axis_mask: An optional `int`. Defaults to `0`.
		  shrink_axis_mask: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ResourceStridedSliceAssign(ref:Dynamic, begin:Dynamic, end:Dynamic, strides:Dynamic, value:Dynamic, ?begin_mask:Dynamic, ?end_mask:Dynamic, ?ellipsis_mask:Dynamic, ?new_axis_mask:Dynamic, ?shrink_axis_mask:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Restores a tensor from checkpoint files.
		
		Reads a tensor stored in one or several files. If there are several files (for
		instance because a tensor was saved as slices), `file_pattern` may contain
		wildcard symbols (`*` and `?`) in the filename portion only, not in the
		directory portion.
		
		If a `file_pattern` matches several files, `preferred_shard` can be used to hint
		in which file the requested tensor is likely to be found. This op will first
		open the file at index `preferred_shard` in the list of matching files and try
		to restore tensors from that file.  Only if some tensors or tensor slices are
		not found in that first file, then the Op opens all the files. Setting
		`preferred_shard` to match the value passed as the `shard` input
		of a matching `Save` Op may speed up Restore.  This attribute only affects
		performance, not correctness.  The default value -1 means files are processed in
		order.
		
		See also `RestoreSlice`.
		
		Args:
		  file_pattern: A `Tensor` of type `string`.
		    Must have a single element. The pattern of the files from
		    which we read the tensor.
		  tensor_name: A `Tensor` of type `string`.
		    Must have a single element. The name of the tensor to be
		    restored.
		  dt: A `tf.DType`. The type of the tensor to be restored.
		  preferred_shard: An optional `int`. Defaults to `-1`.
		    Index of file to open first if multiple files match
		    `file_pattern`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dt`.
	**/
	static public function Restore(file_pattern:Dynamic, tensor_name:Dynamic, dt:Dynamic, ?preferred_shard:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Restores a tensor from checkpoint files.
		
		This is like `Restore` except that restored tensor can be listed as filling
		only a slice of a larger tensor.  `shape_and_slice` specifies the shape of the
		larger tensor and the slice that the restored tensor covers.
		
		The `shape_and_slice` input has the same format as the
		elements of the `shapes_and_slices` input of the `SaveSlices` op.
		
		Args:
		  file_pattern: A `Tensor` of type `string`.
		    Must have a single element. The pattern of the files from
		    which we read the tensor.
		  tensor_name: A `Tensor` of type `string`.
		    Must have a single element. The name of the tensor to be
		    restored.
		  shape_and_slice: A `Tensor` of type `string`.
		    Scalar. The shapes and slice specifications to use when
		    restoring a tensors.
		  dt: A `tf.DType`. The type of the tensor to be restored.
		  preferred_shard: An optional `int`. Defaults to `-1`.
		    Index of file to open first if multiple files match
		    `file_pattern`. See the documentation for `Restore`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dt`.
	**/
	static public function RestoreSlice(file_pattern:Dynamic, tensor_name:Dynamic, shape_and_slice:Dynamic, dt:Dynamic, ?preferred_shard:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Restores tensors from a V2 checkpoint.
		
		For backward compatibility with the V1 format, this Op currently allows
		restoring from a V1 checkpoint as well:
		  - This Op first attempts to find the V2 index file pointed to by "prefix", and
		    if found proceed to read it as a V2 checkpoint;
		  - Otherwise the V1 read path is invoked.
		Relying on this behavior is not recommended, as the ability to fall back to read
		V1 might be deprecated and eventually removed.
		
		By default, restores the named tensors in full.  If the caller wishes to restore
		specific slices of stored tensors, "shape_and_slices" should be non-empty
		strings and correspondingly well-formed.
		
		Callers must ensure all the named tensors are indeed stored in the checkpoint.
		
		Args:
		  prefix: A `Tensor` of type `string`.
		    Must have a single element.  The prefix of a V2 checkpoint.
		  tensor_names: A `Tensor` of type `string`.
		    shape {N}.  The names of the tensors to be restored.
		  shape_and_slices: A `Tensor` of type `string`.
		    shape {N}.  The slice specs of the tensors to be restored.
		    Empty strings indicate that they are non-partitioned tensors.
		  dtypes: A list of `tf.DTypes` that has length `>= 1`.
		    shape {N}.  The list of expected dtype for the tensors.  Must match
		    those stored in the checkpoint.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `dtypes`.
	**/
	static public function RestoreV2(prefix:Dynamic, tensor_names:Dynamic, shape_and_slices:Dynamic, dtypes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve ADAM embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, momenta, velocities).
		
		  parameters: A `Tensor` of type `float32`.
		  momenta: A `Tensor` of type `float32`.
		  velocities: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingADAMParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve Adadelta embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, accumulators, updates).
		
		  parameters: A `Tensor` of type `float32`.
		  accumulators: A `Tensor` of type `float32`.
		  updates: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingAdadeltaParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve Adagrad Momentum embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, accumulators, momenta).
		
		  parameters: A `Tensor` of type `float32`.
		  accumulators: A `Tensor` of type `float32`.
		  momenta: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingAdagradMomentumParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve Adagrad embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, accumulators).
		
		  parameters: A `Tensor` of type `float32`.
		  accumulators: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingAdagradParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve centered RMSProp embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, ms, mom, mg).
		
		  parameters: A `Tensor` of type `float32`.
		  ms: A `Tensor` of type `float32`.
		  mom: A `Tensor` of type `float32`.
		  mg: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingCenteredRMSPropParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve FTRL embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, accumulators, linears).
		
		  parameters: A `Tensor` of type `float32`.
		  accumulators: A `Tensor` of type `float32`.
		  linears: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingFTRLParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve frequency estimator embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, last_hit_step).
		
		  parameters: A `Tensor` of type `float32`.
		  last_hit_step: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingFrequencyEstimatorParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve MDL Adagrad Light embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, accumulators, weights, benefits).
		
		  parameters: A `Tensor` of type `float32`.
		  accumulators: A `Tensor` of type `float32`.
		  weights: A `Tensor` of type `float32`.
		  benefits: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingMDLAdagradLightParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve Momentum embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, momenta).
		
		  parameters: A `Tensor` of type `float32`.
		  momenta: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingMomentumParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve proximal Adagrad embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, accumulators).
		
		  parameters: A `Tensor` of type `float32`.
		  accumulators: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingProximalAdagradParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, v, m).
		
		  parameters: A `Tensor` of type `float32`.
		  v: A `Tensor` of type `float32`.
		  m: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingProximalYogiParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve RMSProp embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (parameters, ms, mom).
		
		  parameters: A `Tensor` of type `float32`.
		  ms: A `Tensor` of type `float32`.
		  mom: A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingRMSPropParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Retrieve SGD embedding parameters.
		
		An op that retrieves optimization parameters from embedding to host
		memory. Must be preceded by a ConfigureTPUEmbeddingHost op that sets up
		the correct embedding table configuration. For example, this op is
		used to retrieve updated parameters before saving a checkpoint.
		
		Args:
		  num_shards: An `int`.
		  shard_id: An `int`.
		  table_id: An optional `int`. Defaults to `-1`.
		  table_name: An optional `string`. Defaults to `""`.
		  config: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function RetrieveTPUEmbeddingStochasticGradientDescentParameters(num_shards:Dynamic, shard_id:Dynamic, ?table_id:Dynamic, ?table_name:Dynamic, ?config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reverses specific dimensions of a tensor.
		
		Given a `tensor`, and a `bool` tensor `dims` representing the dimensions
		of `tensor`, this operation reverses each dimension i of `tensor` where
		`dims[i]` is `True`.
		
		`tensor` can have up to 8 dimensions. The number of dimensions
		of `tensor` must equal the number of elements in `dims`. In other words:
		
		`rank(tensor) = size(dims)`
		
		For example:
		
		```
		# tensor 't' is [[[[ 0,  1,  2,  3],
		#                  [ 4,  5,  6,  7],
		#                  [ 8,  9, 10, 11]],
		#                 [[12, 13, 14, 15],
		#                  [16, 17, 18, 19],
		#                  [20, 21, 22, 23]]]]
		# tensor 't' shape is [1, 2, 3, 4]
		
		# 'dims' is [False, False, False, True]
		reverse(t, dims) ==> [[[[ 3,  2,  1,  0],
		                        [ 7,  6,  5,  4],
		                        [ 11, 10, 9, 8]],
		                       [[15, 14, 13, 12],
		                        [19, 18, 17, 16],
		                        [23, 22, 21, 20]]]]
		
		# 'dims' is [False, True, False, False]
		reverse(t, dims) ==> [[[[12, 13, 14, 15],
		                        [16, 17, 18, 19],
		                        [20, 21, 22, 23]
		                       [[ 0,  1,  2,  3],
		                        [ 4,  5,  6,  7],
		                        [ 8,  9, 10, 11]]]]
		
		# 'dims' is [False, False, True, False]
		reverse(t, dims) ==> [[[[8, 9, 10, 11],
		                        [4, 5, 6, 7],
		                        [0, 1, 2, 3]]
		                       [[20, 21, 22, 23],
		                        [16, 17, 18, 19],
		                        [12, 13, 14, 15]]]]
		```
		
		Args:
		  tensor: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `uint16`, `int16`, `uint32`, `int32`, `uint64`, `int64`, `bool`, `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`, `string`.
		    Up to 8-D.
		  dims: A `Tensor` of type `bool`. 1-D. The dimensions to reverse.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `tensor`.
	**/
	static public function Reverse(tensor:Dynamic, dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reverses variable length slices.
		
		This op first slices `input` along the dimension `batch_dim`, and for each
		slice `i`, reverses the first `seq_lengths[i]` elements along
		the dimension `seq_dim`.
		
		The elements of `seq_lengths` must obey `seq_lengths[i] <= input.dims[seq_dim]`,
		and `seq_lengths` must be a vector of length `input.dims[batch_dim]`.
		
		The output slice `i` along dimension `batch_dim` is then given by input
		slice `i`, with the first `seq_lengths[i]` slices along dimension
		`seq_dim` reversed.
		
		For example:
		
		```
		# Given this:
		batch_dim = 0
		seq_dim = 1
		input.dims = (4, 8, ...)
		seq_lengths = [7, 2, 3, 5]
		
		# then slices of input are reversed on seq_dim, but only up to seq_lengths:
		output[0, 0:7, :, ...] = input[0, 7:0:-1, :, ...]
		output[1, 0:2, :, ...] = input[1, 2:0:-1, :, ...]
		output[2, 0:3, :, ...] = input[2, 3:0:-1, :, ...]
		output[3, 0:5, :, ...] = input[3, 5:0:-1, :, ...]
		
		# while entries past seq_lens are copied through:
		output[0, 7:, :, ...] = input[0, 7:, :, ...]
		output[1, 2:, :, ...] = input[1, 2:, :, ...]
		output[2, 3:, :, ...] = input[2, 3:, :, ...]
		output[3, 2:, :, ...] = input[3, 2:, :, ...]
		```
		
		In contrast, if:
		
		```
		# Given this:
		batch_dim = 2
		seq_dim = 0
		input.dims = (8, ?, 4, ...)
		seq_lengths = [7, 2, 3, 5]
		
		# then slices of input are reversed on seq_dim, but only up to seq_lengths:
		output[0:7, :, 0, :, ...] = input[7:0:-1, :, 0, :, ...]
		output[0:2, :, 1, :, ...] = input[2:0:-1, :, 1, :, ...]
		output[0:3, :, 2, :, ...] = input[3:0:-1, :, 2, :, ...]
		output[0:5, :, 3, :, ...] = input[5:0:-1, :, 3, :, ...]
		
		# while entries past seq_lens are copied through:
		output[7:, :, 0, :, ...] = input[7:, :, 0, :, ...]
		output[2:, :, 1, :, ...] = input[2:, :, 1, :, ...]
		output[3:, :, 2, :, ...] = input[3:, :, 2, :, ...]
		output[2:, :, 3, :, ...] = input[2:, :, 3, :, ...]
		```
		
		Args:
		  input: A `Tensor`. The input to reverse.
		  seq_lengths: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    1-D with length `input.dims(batch_dim)` and
		    `max(seq_lengths) <= input.dims(seq_dim)`
		  seq_dim: An `int`. The dimension which is partially reversed.
		  batch_dim: An optional `int`. Defaults to `0`.
		    The dimension along which reversal is performed.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function ReverseSequence(input:Dynamic, seq_lengths:Dynamic, seq_dim:Dynamic, ?batch_dim:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reverses specific dimensions of a tensor.
		
		Given a `tensor`, and a `int32` tensor `axis` representing the set of
		dimensions of `tensor` to reverse. This operation reverses each dimension
		`i` for which there exists `j` s.t. `axis[j] == i`.
		
		`tensor` can have up to 8 dimensions. The number of dimensions specified
		in `axis` may be 0 or more entries. If an index is specified more than
		once, a InvalidArgument error is raised.
		
		For example:
		
		```
		# tensor 't' is [[[[ 0,  1,  2,  3],
		#                  [ 4,  5,  6,  7],
		#                  [ 8,  9, 10, 11]],
		#                 [[12, 13, 14, 15],
		#                  [16, 17, 18, 19],
		#                  [20, 21, 22, 23]]]]
		# tensor 't' shape is [1, 2, 3, 4]
		
		# 'dims' is [3] or 'dims' is [-1]
		reverse(t, dims) ==> [[[[ 3,  2,  1,  0],
		                        [ 7,  6,  5,  4],
		                        [ 11, 10, 9, 8]],
		                       [[15, 14, 13, 12],
		                        [19, 18, 17, 16],
		                        [23, 22, 21, 20]]]]
		
		# 'dims' is '[1]' (or 'dims' is '[-3]')
		reverse(t, dims) ==> [[[[12, 13, 14, 15],
		                        [16, 17, 18, 19],
		                        [20, 21, 22, 23]
		                       [[ 0,  1,  2,  3],
		                        [ 4,  5,  6,  7],
		                        [ 8,  9, 10, 11]]]]
		
		# 'dims' is '[2]' (or 'dims' is '[-2]')
		reverse(t, dims) ==> [[[[8, 9, 10, 11],
		                        [4, 5, 6, 7],
		                        [0, 1, 2, 3]]
		                       [[20, 21, 22, 23],
		                        [16, 17, 18, 19],
		                        [12, 13, 14, 15]]]]
		```
		
		Args:
		  tensor: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `int64`, `uint64`, `bool`, `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`, `string`.
		    Up to 8-D.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    1-D. The indices of the dimensions to reverse. Must be in the range
		    `[-rank(tensor), rank(tensor))`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `tensor`.
	**/
	static public function ReverseV2(tensor:Dynamic, axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Elementwise computes the bitwise right-shift of `x` and `y`.
		
		Performs a logical shift for unsigned integer types, and an arithmetic shift
		for signed integer types.
		
		If `y` is negative, or greater than or equal to than the width of `x` in bits
		the result is implementation defined.
		
		Example:
		
		```python
		import tensorflow as tf
		from tensorflow.python.ops import bitwise_ops
		import numpy as np
		dtype_list = [tf.int8, tf.int16, tf.int32, tf.int64]
		
		for dtype in dtype_list:
		  lhs = tf.constant([-1, -5, -3, -14], dtype=dtype)
		  rhs = tf.constant([5, 0, 7, 11], dtype=dtype)
		
		  right_shift_result = bitwise_ops.right_shift(lhs, rhs)
		
		  print(right_shift_result)
		
		# This will print:
		# tf.Tensor([-1 -5 -1 -1], shape=(4,), dtype=int8)
		# tf.Tensor([-1 -5 -1 -1], shape=(4,), dtype=int16)
		# tf.Tensor([-1 -5 -1 -1], shape=(4,), dtype=int32)
		# tf.Tensor([-1 -5 -1 -1], shape=(4,), dtype=int64)
		
		lhs = np.array([-2, 64, 101, 32], dtype=np.int8)
		rhs = np.array([-1, -5, -3, -14], dtype=np.int8)
		bitwise_ops.right_shift(lhs, rhs)
		# <tf.Tensor: shape=(4,), dtype=int8, numpy=array([ -2,  64, 101,  32], dtype=int8)>
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function RightShift(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns element-wise integer closest to x.
		
		If the result is midway between two representable values,
		the even representable is chosen.
		For example:
		
		```
		rint(-1.5) ==> -2.0
		rint(0.5000001) ==> 1.0
		rint([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0]) ==> [-2., -2., -0., 0., 2., 2., 2.]
		```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Rint(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Advance the counter of a counter-based RNG.
		
		The state of the RNG after
		`rng_read_and_skip(n)` will be the same as that after `uniform([n])`
		(or any other distribution). The actual increment added to the
		counter is an unspecified implementation choice.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    The handle of the resource variable that stores the state of the RNG.
		  alg: A `Tensor` of type `int32`. The RNG algorithm.
		  delta: A `Tensor` of type `uint64`. The amount of advancement.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function RngReadAndSkip(resource:Dynamic, alg:Dynamic, delta:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Advance the counter of a counter-based RNG.
		
		The state of the RNG after
		`rng_skip(n)` will be the same as that after `stateful_uniform([n])`
		(or any other distribution). The actual increment added to the
		counter is an unspecified implementation detail.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    The handle of the resource variable that stores the state of the RNG.
		  algorithm: A `Tensor` of type `int64`. The RNG algorithm.
		  delta: A `Tensor` of type `int64`. The amount of advancement.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function RngSkip(resource:Dynamic, algorithm:Dynamic, delta:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Rolls the elements of a tensor along an axis.
		
		The elements are shifted positively (towards larger indices) by the offset of
		`shift` along the dimension of `axis`. Negative `shift` values will shift
		elements in the opposite direction. Elements that roll passed the last position
		will wrap around to the first and vice versa. Multiple shifts along multiple
		axes may be specified.
		
		For example:
		
		```
		# 't' is [0, 1, 2, 3, 4]
		roll(t, shift=2, axis=0) ==> [3, 4, 0, 1, 2]
		
		# shifting along multiple dimensions
		# 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]
		roll(t, shift=[1, -2], axis=[0, 1]) ==> [[7, 8, 9, 5, 6], [2, 3, 4, 0, 1]]
		
		# shifting along the same axis multiple times
		# 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]
		roll(t, shift=[2, -3], axis=[1, 1]) ==> [[1, 2, 3, 4, 0], [6, 7, 8, 9, 5]]
		```
		
		Args:
		  input: A `Tensor`.
		  shift: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Dimension must be 0-D or 1-D. `shift[i]` specifies the number of places by which
		    elements are shifted positively (towards larger indices) along the dimension
		    specified by `axis[i]`. Negative shifts will roll the elements in the opposite
		    direction.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Dimension must be 0-D or 1-D. `axis[i]` specifies the dimension that the shift
		    `shift[i]` should occur. If the same axis is referenced more than once, the
		    total shift for that axis will be the sum of all the shifts that belong to that
		    axis.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Roll(input:Dynamic, shift:Dynamic, axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Rounds the values of a tensor to the nearest integer, element-wise.
		
		Rounds half to even.  Also known as bankers rounding. If you want to round
		according to the current system rounding mode use std::cint.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Round(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes reciprocal of square root of x element-wise.
		
		I.e., \\(y = 1 / \sqrt{x}\\).
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Rsqrt(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient for the rsqrt of `x` wrt its input.
		
		Specifically, `grad = dy * -0.5 * y^3`, where `y = rsqrt(x)`, and `dy`
		is the corresponding input gradient.
		
		Args:
		  y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  dy: A `Tensor`. Must have the same type as `y`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `y`.
	**/
	static public function RsqrtGrad(y:Dynamic, dy:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generate a single randomly distorted bounding box for an image.
		
		Bounding box annotations are often supplied in addition to ground-truth labels
		in image recognition or object localization tasks. A common technique for
		training such a system is to randomly distort an image while preserving
		its content, i.e. *data augmentation*. This Op outputs a randomly distorted
		localization of an object, i.e. bounding box, given an `image_size`,
		`bounding_boxes` and a series of constraints.
		
		The output of this Op is a single bounding box that may be used to crop the
		original image. The output is returned as 3 tensors: `begin`, `size` and
		`bboxes`. The first 2 tensors can be fed directly into `tf.slice` to crop the
		image. The latter may be supplied to `tf.image.draw_bounding_boxes` to visualize
		what the bounding box looks like.
		
		Bounding boxes are supplied and returned as `[y_min, x_min, y_max, x_max]`. The
		bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
		height of the underlying image.
		
		For example,
		
		```python
		    # Generate a single distorted bounding box.
		    begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
		        tf.shape(image),
		        bounding_boxes=bounding_boxes)
		
		    # Draw the bounding box in an image summary.
		    image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),
		                                                  bbox_for_draw)
		    tf.summary.image('images_with_box', image_with_box)
		
		    # Employ the bounding box to distort the image.
		    distorted_image = tf.slice(image, begin, size)
		```
		
		Note that if no bounding box information is available, setting
		`use_image_if_no_bounding_boxes = true` will assume there is a single implicit
		bounding box covering the whole image. If `use_image_if_no_bounding_boxes` is
		false and no bounding boxes are supplied, an error is raised.
		
		Args:
		  image_size: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `int16`, `int32`, `int64`.
		    1-D, containing `[height, width, channels]`.
		  bounding_boxes: A `Tensor` of type `float32`.
		    3-D with shape `[batch, N, 4]` describing the N bounding boxes
		    associated with the image.
		  seed: An optional `int`. Defaults to `0`.
		    If either `seed` or `seed2` are set to non-zero, the random number
		    generator is seeded by the given `seed`.  Otherwise, it is seeded by a random
		    seed.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  min_object_covered: An optional `float`. Defaults to `0.1`.
		    The cropped area of the image must contain at least this
		    fraction of any bounding box supplied. The value of this parameter should be
		    non-negative. In the case of 0, the cropped area does not need to overlap
		    any of the bounding boxes supplied.
		  aspect_ratio_range: An optional list of `floats`. Defaults to `[0.75, 1.33]`.
		    The cropped area of the image must have an aspect ratio =
		    width / height within this range.
		  area_range: An optional list of `floats`. Defaults to `[0.05, 1]`.
		    The cropped area of the image must contain a fraction of the
		    supplied image within this range.
		  max_attempts: An optional `int`. Defaults to `100`.
		    Number of attempts at generating a cropped region of the image
		    of the specified constraints. After `max_attempts` failures, return the entire
		    image.
		  use_image_if_no_bounding_boxes: An optional `bool`. Defaults to `False`.
		    Controls behavior if no bounding boxes supplied.
		    If true, assume an implicit bounding box covering the whole input. If false,
		    raise an error.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (begin, size, bboxes).
		
		  begin: A `Tensor`. Has the same type as `image_size`.
		  size: A `Tensor`. Has the same type as `image_size`.
		  bboxes: A `Tensor` of type `float32`.
	**/
	static public function SampleDistortedBoundingBox(image_size:Dynamic, bounding_boxes:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?min_object_covered:Dynamic, ?aspect_ratio_range:Dynamic, ?area_range:Dynamic, ?max_attempts:Dynamic, ?use_image_if_no_bounding_boxes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generate a single randomly distorted bounding box for an image.
		
		Bounding box annotations are often supplied in addition to ground-truth labels
		in image recognition or object localization tasks. A common technique for
		training such a system is to randomly distort an image while preserving
		its content, i.e. *data augmentation*. This Op outputs a randomly distorted
		localization of an object, i.e. bounding box, given an `image_size`,
		`bounding_boxes` and a series of constraints.
		
		The output of this Op is a single bounding box that may be used to crop the
		original image. The output is returned as 3 tensors: `begin`, `size` and
		`bboxes`. The first 2 tensors can be fed directly into `tf.slice` to crop the
		image. The latter may be supplied to `tf.image.draw_bounding_boxes` to visualize
		what the bounding box looks like.
		
		Bounding boxes are supplied and returned as `[y_min, x_min, y_max, x_max]`. The
		bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
		height of the underlying image.
		
		For example,
		
		```python
		    # Generate a single distorted bounding box.
		    begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
		        tf.shape(image),
		        bounding_boxes=bounding_boxes)
		
		    # Draw the bounding box in an image summary.
		    image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),
		                                                  bbox_for_draw)
		    tf.summary.image('images_with_box', image_with_box)
		
		    # Employ the bounding box to distort the image.
		    distorted_image = tf.slice(image, begin, size)
		```
		
		Note that if no bounding box information is available, setting
		`use_image_if_no_bounding_boxes = true` will assume there is a single implicit
		bounding box covering the whole image. If `use_image_if_no_bounding_boxes` is
		false and no bounding boxes are supplied, an error is raised.
		
		Args:
		  image_size: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `int16`, `int32`, `int64`.
		    1-D, containing `[height, width, channels]`.
		  bounding_boxes: A `Tensor` of type `float32`.
		    3-D with shape `[batch, N, 4]` describing the N bounding boxes
		    associated with the image.
		  min_object_covered: A `Tensor` of type `float32`.
		    The cropped area of the image must contain at least this
		    fraction of any bounding box supplied. The value of this parameter should be
		    non-negative. In the case of 0, the cropped area does not need to overlap
		    any of the bounding boxes supplied.
		  seed: An optional `int`. Defaults to `0`.
		    If either `seed` or `seed2` are set to non-zero, the random number
		    generator is seeded by the given `seed`.  Otherwise, it is seeded by a random
		    seed.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  aspect_ratio_range: An optional list of `floats`. Defaults to `[0.75, 1.33]`.
		    The cropped area of the image must have an aspect ratio =
		    width / height within this range.
		  area_range: An optional list of `floats`. Defaults to `[0.05, 1]`.
		    The cropped area of the image must contain a fraction of the
		    supplied image within this range.
		  max_attempts: An optional `int`. Defaults to `100`.
		    Number of attempts at generating a cropped region of the image
		    of the specified constraints. After `max_attempts` failures, return the entire
		    image.
		  use_image_if_no_bounding_boxes: An optional `bool`. Defaults to `False`.
		    Controls behavior if no bounding boxes supplied.
		    If true, assume an implicit bounding box covering the whole input. If false,
		    raise an error.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (begin, size, bboxes).
		
		  begin: A `Tensor`. Has the same type as `image_size`.
		  size: A `Tensor`. Has the same type as `image_size`.
		  bboxes: A `Tensor` of type `float32`.
	**/
	static public function SampleDistortedBoundingBoxV2(image_size:Dynamic, bounding_boxes:Dynamic, min_object_covered:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?aspect_ratio_range:Dynamic, ?area_range:Dynamic, ?max_attempts:Dynamic, ?use_image_if_no_bounding_boxes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that takes a Bernoulli sample of the contents of another dataset.
		
		There is no transformation in the `tf.data` Python API for creating this dataset.
		Instead, it is created as a result of the `filter_with_random_uniform_fusion`
		static optimization. Whether this optimization is performed is determined by the
		`experimental_optimization.filter_with_random_uniform_fusion` option of
		`tf.data.Options`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  rate: A `Tensor` of type `float32`.
		    A scalar representing the sample rate. Each element of `input_dataset` is
		    retained with this probability, independent of all other elements.
		  seed: A `Tensor` of type `int64`.
		    A scalar representing seed of random number generator.
		  seed2: A `Tensor` of type `int64`.
		    A scalar representing seed2 of random number generator.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SamplingDataset(input_dataset:Dynamic, rate:Dynamic, seed:Dynamic, seed2:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Saves the input tensors to disk.
		
		The size of `tensor_names` must match the number of tensors in `data`. `data[i]`
		is written to `filename` with name `tensor_names[i]`.
		
		See also `SaveSlices`.
		
		Args:
		  filename: A `Tensor` of type `string`.
		    Must have a single element. The name of the file to which we write
		    the tensor.
		  tensor_names: A `Tensor` of type `string`.
		    Shape `[N]`. The names of the tensors to be saved.
		  data: A list of `Tensor` objects. `N` tensors to save.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function Save(filename:Dynamic, tensor_names:Dynamic, data:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  path: A `Tensor` of type `string`.
		  shard_func_other_args: A list of `Tensor` objects.
		  shard_func: A function decorated with @Defun.
		  compression: An optional `string`. Defaults to `""`.
		  use_shard_func: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function SaveDataset(input_dataset:Dynamic, path:Dynamic, shard_func_other_args:Dynamic, shard_func:Dynamic, ?compression:Dynamic, ?use_shard_func:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  path: A `Tensor` of type `string`.
		  shard_func_other_args: A list of `Tensor` objects.
		  shard_func: A function decorated with @Defun.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  compression: An optional `string`. Defaults to `""`.
		  use_shard_func: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SaveDatasetV2(input_dataset:Dynamic, path:Dynamic, shard_func_other_args:Dynamic, shard_func:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?compression:Dynamic, ?use_shard_func:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Saves input tensors slices to disk.
		
		This is like `Save` except that tensors can be listed in the saved file as being
		a slice of a larger tensor.  `shapes_and_slices` specifies the shape of the
		larger tensor and the slice that this tensor covers. `shapes_and_slices` must
		have as many elements as `tensor_names`.
		
		Elements of the `shapes_and_slices` input must either be:
		
		*  The empty string, in which case the corresponding tensor is
		   saved normally.
		*  A string of the form `dim0 dim1 ... dimN-1 slice-spec` where the
		   `dimI` are the dimensions of the larger tensor and `slice-spec`
		   specifies what part is covered by the tensor to save.
		
		`slice-spec` itself is a `:`-separated list: `slice0:slice1:...:sliceN-1`
		where each `sliceI` is either:
		
		*  The string `-` meaning that the slice covers all indices of this dimension
		*  `start,length` where `start` and `length` are integers.  In that
		   case the slice covers `length` indices starting at `start`.
		
		See also `Save`.
		
		Args:
		  filename: A `Tensor` of type `string`.
		    Must have a single element. The name of the file to which we write the
		    tensor.
		  tensor_names: A `Tensor` of type `string`.
		    Shape `[N]`. The names of the tensors to be saved.
		  shapes_and_slices: A `Tensor` of type `string`.
		    Shape `[N]`.  The shapes and slice specifications to use when
		    saving the tensors.
		  data: A list of `Tensor` objects. `N` tensors to save.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function SaveSlices(filename:Dynamic, tensor_names:Dynamic, shapes_and_slices:Dynamic, data:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Saves tensors in V2 checkpoint format.
		
		By default, saves the named tensors in full.  If the caller wishes to save
		specific slices of full tensors, "shape_and_slices" should be non-empty strings
		and correspondingly well-formed.
		
		Args:
		  prefix: A `Tensor` of type `string`.
		    Must have a single element. The prefix of the V2 checkpoint to which we
		    write the tensors.
		  tensor_names: A `Tensor` of type `string`.
		    shape {N}. The names of the tensors to be saved.
		  shape_and_slices: A `Tensor` of type `string`.
		    shape {N}.  The slice specs of the tensors to be saved.
		    Empty strings indicate that they are non-partitioned tensors.
		  tensors: A list of `Tensor` objects. `N` tensors to save.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function SaveV2(prefix:Dynamic, tensor_names:Dynamic, shape_and_slices:Dynamic, tensors:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs a `Summary` protocol buffer with scalar values.
		
		The input `tags` and `values` must have the same shape.  The generated summary
		has a summary value for each tag-value pair in `tags` and `values`.
		
		Args:
		  tags: A `Tensor` of type `string`. Tags for the summary.
		  values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    Same shape as `tags.  Values for the summary.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function ScalarSummary(tags:Dynamic, values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  images: A `Tensor`. Must be one of the following types: `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.
		  size: A `Tensor` of type `int32`.
		  scale: A `Tensor` of type `float32`.
		  translation: A `Tensor` of type `float32`.
		  kernel_type: An optional `string`. Defaults to `"lanczos3"`.
		  antialias: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function ScaleAndTranslate(images:Dynamic, size:Dynamic, scale:Dynamic, translation:Dynamic, ?kernel_type:Dynamic, ?antialias:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  grads: A `Tensor`. Must be one of the following types: `float32`.
		  original_image: A `Tensor`. Must have the same type as `grads`.
		  scale: A `Tensor` of type `float32`.
		  translation: A `Tensor` of type `float32`.
		  kernel_type: An optional `string`. Defaults to `"lanczos3"`.
		  antialias: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `grads`.
	**/
	static public function ScaleAndTranslateGrad(grads:Dynamic, original_image:Dynamic, scale:Dynamic, translation:Dynamic, ?kernel_type:Dynamic, ?antialias:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset successively reduces `f` over the elements of `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  initial_state: A list of `Tensor` objects.
		  other_arguments: A list of `Tensor` objects.
		  f: A function decorated with @Defun.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  preserve_cardinality: An optional `bool`. Defaults to `False`.
		  use_default_device: An optional `bool`. Defaults to `True`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ScanDataset(input_dataset:Dynamic, initial_state:Dynamic, other_arguments:Dynamic, f:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?preserve_cardinality:Dynamic, ?use_default_device:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adds sparse updates to a variable reference.
		
		This operation computes
		
		    # Scalar indices
		    ref[indices, ...] += updates[...]
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] += updates[i, ...]
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]
		
		This operation outputs `ref` after the update is done.
		This makes it easier to chain operations that need to use the reset value.
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their contributions add.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/ScatterAdd.png" alt>
		</div>
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A tensor of updated values to add to `ref`.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the addition will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterAdd(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Divides a variable reference by sparse updates.
		
		This operation computes
		
		```python
		    # Scalar indices
		    ref[indices, ...] /= updates[...]
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] /= updates[i, ...]
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] /= updates[i, ..., j, ...]
		```
		
		This operation outputs `ref` after the update is done.
		This makes it easier to chain operations that need to use the reset value.
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their contributions divide.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A tensor of values that `ref` is divided by.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the operation will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterDiv(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reduces sparse updates into a variable reference using the `max` operation.
		
		This operation computes
		
		    # Scalar indices
		    ref[indices, ...] = max(ref[indices, ...], updates[...])
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] = max(ref[indices[i], ...], updates[i, ...])
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] = max(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
		
		This operation outputs `ref` after the update is done.
		This makes it easier to chain operations that need to use the reset value.
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their contributions combine.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/ScatterAdd.png" alt>
		</div>
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`, `int64`.
		    Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A tensor of updated values to reduce into `ref`.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the update will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterMax(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reduces sparse updates into a variable reference using the `min` operation.
		
		This operation computes
		
		    # Scalar indices
		    ref[indices, ...] = min(ref[indices, ...], updates[...])
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] = min(ref[indices[i], ...], updates[i, ...])
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] = min(ref[indices[i, ..., j], ...], updates[i, ..., j, ...])
		
		This operation outputs `ref` after the update is done.
		This makes it easier to chain operations that need to use the reset value.
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their contributions combine.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/ScatterAdd.png" alt>
		</div>
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`, `int32`, `int64`.
		    Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A tensor of updated values to reduce into `ref`.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the update will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterMin(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Multiplies sparse updates into a variable reference.
		
		This operation computes
		
		```python
		    # Scalar indices
		    ref[indices, ...] *= updates[...]
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] *= updates[i, ...]
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] *= updates[i, ..., j, ...]
		```
		
		This operation outputs `ref` after the update is done.
		This makes it easier to chain operations that need to use the reset value.
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their contributions multiply.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A tensor of updated values to multiply to `ref`.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the operation will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterMul(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Scatters `updates` into a tensor of shape `shape` according to `indices`.
		
		Update the input tensor by scattering sparse `updates` according to individual values at the specified `indices`.
		This op returns an `output` tensor with the `shape` you specify. This op is the
		inverse of the `tf.gather_nd` operator which extracts values or slices from a
		given tensor.
		
		This operation is similar to `tf.tensor_scatter_add`, except that the tensor is
		zero-initialized. Calling `tf.scatter_nd(indices, values, shape)`
		is identical to calling
		`tf.tensor_scatter_add(tf.zeros(shape, values.dtype), indices, values)`.
		
		If `indices` contains duplicates, the duplicate `values` are accumulated
		(summed).
		
		**WARNING**: The order in which updates are applied is nondeterministic, so the
		output will be nondeterministic if `indices` contains duplicates;
		numbers summed in different order may yield different results because of some
		numerical approximation issues.
		
		`indices` is an integer tensor of shape `shape`. The last dimension
		of `indices` can be at most the rank of `shape`:
		
		    indices.shape[-1] <= shape.rank
		
		The last dimension of `indices` corresponds to indices of elements
		(if `indices.shape[-1] = shape.rank`) or slices
		(if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of
		`shape`.
		
		`updates` is a tensor with shape:
		
		    indices.shape[:-1] + shape[indices.shape[-1]:]
		
		The simplest form of the scatter op is to insert individual elements in
		a tensor by index. Consider an example where you want to insert 4 scattered
		elements in a rank-1 tensor with 8 elements.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/ScatterNd1.png" alt>
		</div>
		
		In Python, this scatter operation would look like this:
		
		```python
		    indices = tf.constant([[4], [3], [1], [7]])
		    updates = tf.constant([9, 10, 11, 12])
		    shape = tf.constant([8])
		    scatter = tf.scatter_nd(indices, updates, shape)
		    print(scatter)
		```
		
		The resulting tensor would look like this:
		
		    [0, 11, 0, 10, 9, 0, 0, 12]
		
		You can also insert entire slices of a higher rank tensor all at once. For
		example, you can insert two slices in the first dimension of a rank-3 tensor
		with two matrices of new values.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/ScatterNd2.png" alt>
		</div>
		
		In Python, this scatter operation would look like this:
		
		```python
		    indices = tf.constant([[0], [2]])
		    updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],
		                            [7, 7, 7, 7], [8, 8, 8, 8]],
		                           [[5, 5, 5, 5], [6, 6, 6, 6],
		                            [7, 7, 7, 7], [8, 8, 8, 8]]])
		    shape = tf.constant([4, 4, 4])
		    scatter = tf.scatter_nd(indices, updates, shape)
		    print(scatter)
		```
		
		The resulting tensor would look like this:
		
		    [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],
		     [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],
		     [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],
		     [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]]
		
		Note that on CPU, if an out of bound index is found, an error is returned.
		On GPU, if an out of bound index is found, the index is ignored.
		
		Args:
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Tensor of indices.
		  updates: A `Tensor`. Values to scatter into the output tensor.
		  shape: A `Tensor`. Must have the same type as `indices`.
		    1-D. The shape of the output tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `updates`.
	**/
	static public function ScatterNd(indices:Dynamic, updates:Dynamic, shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies sparse addition to individual values or slices in a Variable.
		
		`ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
		
		`indices` must be integer tensor, containing indices into `ref`.
		It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.
		
		The innermost dimension of `indices` (with length `K`) corresponds to
		indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th
		dimension of `ref`.
		
		`updates` is `Tensor` of rank `Q-1+P-K` with shape:
		
		```
		[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]]
		```
		
		For example, say we want to add 4 scattered elements to a rank-1 tensor to
		8 elements. In Python, that addition would look like this:
		
		```python
		ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
		indices = tf.constant([[4], [3], [1], [7]])
		updates = tf.constant([9, 10, 11, 12])
		add = tf.scatter_nd_add(ref, indices, updates)
		with tf.Session() as sess:
		  print sess.run(add)
		```
		
		The resulting update to ref would look like this:
		
		    [1, 13, 3, 14, 14, 6, 7, 20]
		
		See `tf.scatter_nd` for more details about how to make updates to
		slices.
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A mutable Tensor. Should be from a Variable node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor. Must be one of the following types: int32, int64.
		    A tensor of indices into ref.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A Tensor. Must have the same type as ref. A tensor of updated values
		    to add to ref.
		  use_locking: An optional `bool`. Defaults to `False`.
		    An optional bool. Defaults to True. If True, the assignment will
		    be protected by a lock; otherwise the behavior is undefined,
		    but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterNdAdd(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes element-wise maximum.
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A mutable Tensor. Should be from a Variable node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor. Must be one of the following types: int32, int64.
		    A tensor of indices into ref.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A Tensor. Must have the same type as ref. A tensor of updated values
		    to add to ref.
		  use_locking: An optional `bool`. Defaults to `False`.
		    An optional bool. Defaults to True. If True, the assignment will
		    be protected by a lock; otherwise the behavior is undefined,
		    but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterNdMax(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes element-wise minimum.
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A mutable Tensor. Should be from a Variable node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor. Must be one of the following types: int32, int64.
		    A tensor of indices into ref.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A Tensor. Must have the same type as ref. A tensor of updated values
		    to add to ref.
		  use_locking: An optional `bool`. Defaults to `False`.
		    An optional bool. Defaults to True. If True, the assignment will
		    be protected by a lock; otherwise the behavior is undefined,
		    but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterNdMin(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies sparse addition to `input` using individual values or slices
		
		from `updates` according to indices `indices`.  The updates are non-aliasing:
		`input` is only modified in-place if no other operations will use it.
		Otherwise, a copy of `input` is made.  This operation has a gradient with
		respect to both `input` and `updates`.
		
		`input` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
		
		`indices` must be integer tensor, containing indices into `input`.
		It must be shape \\([d_0, ..., d_{Q-2}, K]\\) where `0 < K <= P`.
		
		The innermost dimension of `indices` (with length `K`) corresponds to
		indices into elements (if `K = P`) or `(P-K)`-dimensional slices
		(if `K < P`) along the `K`th dimension of `input`.
		
		`updates` is `Tensor` of rank `Q-1+P-K` with shape:
		
		$$[d_0, ..., d_{Q-2}, input.shape[K], ..., input.shape[P-1]].$$
		
		For example, say we want to add 4 scattered elements to a rank-1 tensor to 8
		elements. In Python, that addition would look like this:
		
		    input = tf.constant([1, 2, 3, 4, 5, 6, 7, 8])
		    indices = tf.constant([[4], [3], [1], [7]])
		    updates = tf.constant([9, 10, 11, 12])
		    output = tf.scatter_nd_non_aliasing_add(input, indices, updates)
		    with tf.Session() as sess:
		      print(sess.run(output))
		
		The resulting value `output` would look like this:
		
		    [1, 13, 3, 14, 14, 6, 7, 20]
		
		See `tf.scatter_nd` for more details about how to make updates to slices.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`, `bool`.
		    A Tensor.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into `input`.
		  updates: A `Tensor`. Must have the same type as `input`.
		    A Tensor. Must have the same type as ref. A tensor of updated values
		    to add to `input`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function ScatterNdNonAliasingAdd(input:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies sparse subtraction to individual values or slices in a Variable.
		
		within a given variable according to `indices`.
		
		`ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
		
		`indices` must be integer tensor, containing indices into `ref`.
		It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.
		
		The innermost dimension of `indices` (with length `K`) corresponds to
		indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th
		dimension of `ref`.
		
		`updates` is `Tensor` of rank `Q-1+P-K` with shape:
		
		```
		[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]]
		```
		
		For example, say we want to subtract 4 scattered elements from a rank-1 tensor
		with 8 elements. In Python, that subtraction would look like this:
		
		```python
		ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
		indices = tf.constant([[4], [3], [1], [7]])
		updates = tf.constant([9, 10, 11, 12])
		sub = tf.scatter_nd_sub(ref, indices, updates)
		with tf.Session() as sess:
		  print sess.run(sub)
		```
		
		The resulting update to ref would look like this:
		
		    [1, -9, 3, -6, -4, 6, 7, -4]
		
		See `tf.scatter_nd` for more details about how to make updates to
		slices.
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    A mutable Tensor. Should be from a Variable node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor. Must be one of the following types: int32, int64.
		    A tensor of indices into ref.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A Tensor. Must have the same type as ref. A tensor of updated values
		    to subtract from ref.
		  use_locking: An optional `bool`. Defaults to `False`.
		    An optional bool. Defaults to True. If True, the assignment will
		    be protected by a lock; otherwise the behavior is undefined,
		    but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterNdSub(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies sparse `updates` to individual values or slices within a given
		
		variable according to `indices`.
		
		`ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.
		
		`indices` must be integer tensor, containing indices into `ref`.
		It must be shape \\([d_0, ..., d_{Q-2}, K]\\) where `0 < K <= P`.
		
		The innermost dimension of `indices` (with length `K`) corresponds to
		indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th
		dimension of `ref`.
		
		`updates` is `Tensor` of rank `Q-1+P-K` with shape:
		
		$$[d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].$$
		
		For example, say we want to update 4 scattered elements to a rank-1 tensor to
		8 elements. In Python, that update would look like this:
		
		```python
		    ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
		    indices = tf.constant([[4], [3], [1] ,[7]])
		    updates = tf.constant([9, 10, 11, 12])
		    update = tf.scatter_nd_update(ref, indices, updates)
		    with tf.Session() as sess:
		      print sess.run(update)
		```
		
		The resulting update to ref would look like this:
		
		    [1, 11, 3, 10, 9, 6, 7, 12]
		
		See `tf.scatter_nd` for more details about how to make updates to
		slices.
		
		See also `tf.scatter_update` and `tf.batch_scatter_update`.
		
		Args:
		  ref: A mutable `Tensor`. A mutable Tensor. Should be from a Variable node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A Tensor. Must be one of the following types: int32, int64.
		    A tensor of indices into ref.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A Tensor. Must have the same type as ref. A tensor of updated
		    values to add to ref.
		  use_locking: An optional `bool`. Defaults to `True`.
		    An optional bool. Defaults to True. If True, the assignment will
		    be protected by a lock; otherwise the behavior is undefined,
		    but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterNdUpdate(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Subtracts sparse updates to a variable reference.
		
		```python
		    # Scalar indices
		    ref[indices, ...] -= updates[...]
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] -= updates[i, ...]
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]
		```
		
		This operation outputs `ref` after the update is done.
		This makes it easier to chain operations that need to use the reset value.
		
		Duplicate entries are handled correctly: if multiple `indices` reference
		the same location, their (negated) contributions add.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/ScatterSub.png" alt>
		</div>
		
		Args:
		  ref: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A tensor of updated values to subtract from `ref`.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the subtraction will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterSub(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies sparse updates to a variable reference.
		
		This operation computes
		
		```python
		    # Scalar indices
		    ref[indices, ...] = updates[...]
		
		    # Vector indices (for each i)
		    ref[indices[i], ...] = updates[i, ...]
		
		    # High rank indices (for each i, ..., j)
		    ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]
		```
		
		This operation outputs `ref` after the update is done.
		This makes it easier to chain operations that need to use the reset value.
		
		If values in `ref` is to be updated more than once, because there are
		duplicate entries in `indices`, the order at which the updates happen
		for each value is undefined.
		
		Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape = []`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/ScatterUpdate.png" alt>
		</div>
		
		See also `tf.batch_scatter_update` and `tf.scatter_nd_update`.
		
		Args:
		  ref: A mutable `Tensor`. Should be from a `Variable` node.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor of indices into the first dimension of `ref`.
		  updates: A `Tensor`. Must have the same type as `ref`.
		    A tensor of updated values to store in `ref`.
		  use_locking: An optional `bool`. Defaults to `True`.
		    If True, the assignment will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function ScatterUpdate(ref:Dynamic, indices:Dynamic, updates:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes fingerprints of the input strings.
		
		Args:
		  input: A `Tensor` of type `string`.
		    vector of strings to compute fingerprints on.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function SdcaFprint(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for
		
		linear models with L1 + L2 regularization. As global optimization objective is
		strongly-convex, the optimizer optimizes the dual objective at each step. The
		optimizer applies each update one example at a time. Examples are sampled
		uniformly, and the optimizer is learning rate free and enjoys linear convergence
		rate.
		
		[Proximal Stochastic Dual Coordinate Ascent](http://arxiv.org/pdf/1211.2717v1.pdf).<br>
		Shai Shalev-Shwartz, Tong Zhang. 2012
		
		$$Loss Objective = \sum f_{i} (wx_{i}) + (l2 / 2) * |w|^2 + l1 * |w|$$
		
		[Adding vs. Averaging in Distributed Primal-Dual Optimization](http://arxiv.org/abs/1502.03508).<br>
		Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I. Jordan,
		Peter Richtarik, Martin Takac. 2015
		
		[Stochastic Dual Coordinate Ascent with Adaptive Probabilities](https://arxiv.org/abs/1502.08053).<br>
		Dominik Csiba, Zheng Qu, Peter Richtarik. 2015
		
		Args:
		  sparse_example_indices: A list of `Tensor` objects with type `int64`.
		    a list of vectors which contain example indices.
		  sparse_feature_indices: A list with the same length as `sparse_example_indices` of `Tensor` objects with type `int64`.
		    a list of vectors which contain feature indices.
		  sparse_feature_values: A list of `Tensor` objects with type `float32`.
		    a list of vectors which contains feature value
		    associated with each feature group.
		  dense_features: A list of `Tensor` objects with type `float32`.
		    a list of matrices which contains the dense feature values.
		  example_weights: A `Tensor` of type `float32`.
		    a vector which contains the weight associated with each
		    example.
		  example_labels: A `Tensor` of type `float32`.
		    a vector which contains the label/target associated with each
		    example.
		  sparse_indices: A list with the same length as `sparse_example_indices` of `Tensor` objects with type `int64`.
		    a list of vectors where each value is the indices which has
		    corresponding weights in sparse_weights. This field maybe omitted for the
		    dense approach.
		  sparse_weights: A list with the same length as `sparse_example_indices` of `Tensor` objects with type `float32`.
		    a list of vectors where each value is the weight associated with
		    a sparse feature group.
		  dense_weights: A list with the same length as `dense_features` of `Tensor` objects with type `float32`.
		    a list of vectors where the values are the weights associated
		    with a dense feature group.
		  example_state_data: A `Tensor` of type `float32`.
		    a list of vectors containing the example state data.
		  loss_type: A `string` from: `"logistic_loss", "squared_loss", "hinge_loss", "smooth_hinge_loss", "poisson_loss"`.
		    Type of the primal loss. Currently SdcaSolver supports logistic,
		    squared and hinge losses.
		  l1: A `float`. Symmetric l1 regularization strength.
		  l2: A `float`. Symmetric l2 regularization strength.
		  num_loss_partitions: An `int` that is `>= 1`.
		    Number of partitions of the global loss function.
		  num_inner_iterations: An `int` that is `>= 1`.
		    Number of iterations per mini-batch.
		  adaptative: An optional `bool`. Defaults to `True`.
		    Whether to use Adaptive SDCA for the inner loop.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (out_example_state_data, out_delta_sparse_weights, out_delta_dense_weights).
		
		  out_example_state_data: A `Tensor` of type `float32`.
		  out_delta_sparse_weights: A list with the same length as `sparse_example_indices` of `Tensor` objects with type `float32`.
		  out_delta_dense_weights: A list with the same length as `dense_features` of `Tensor` objects with type `float32`.
	**/
	static public function SdcaOptimizer(sparse_example_indices:Dynamic, sparse_feature_indices:Dynamic, sparse_feature_values:Dynamic, dense_features:Dynamic, example_weights:Dynamic, example_labels:Dynamic, sparse_indices:Dynamic, sparse_weights:Dynamic, dense_weights:Dynamic, example_state_data:Dynamic, loss_type:Dynamic, l1:Dynamic, l2:Dynamic, num_loss_partitions:Dynamic, num_inner_iterations:Dynamic, ?adaptative:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for
		
		linear models with L1 + L2 regularization. As global optimization objective is
		strongly-convex, the optimizer optimizes the dual objective at each step. The
		optimizer applies each update one example at a time. Examples are sampled
		uniformly, and the optimizer is learning rate free and enjoys linear convergence
		rate.
		
		[Proximal Stochastic Dual Coordinate Ascent](http://arxiv.org/pdf/1211.2717v1.pdf).<br>
		Shai Shalev-Shwartz, Tong Zhang. 2012
		
		$$Loss Objective = \sum f_{i} (wx_{i}) + (l2 / 2) * |w|^2 + l1 * |w|$$
		
		[Adding vs. Averaging in Distributed Primal-Dual Optimization](http://arxiv.org/abs/1502.03508).<br>
		Chenxin Ma, Virginia Smith, Martin Jaggi, Michael I. Jordan,
		Peter Richtarik, Martin Takac. 2015
		
		[Stochastic Dual Coordinate Ascent with Adaptive Probabilities](https://arxiv.org/abs/1502.08053).<br>
		Dominik Csiba, Zheng Qu, Peter Richtarik. 2015
		
		Args:
		  sparse_example_indices: A list of `Tensor` objects with type `int64`.
		    a list of vectors which contain example indices.
		  sparse_feature_indices: A list with the same length as `sparse_example_indices` of `Tensor` objects with type `int64`.
		    a list of vectors which contain feature indices.
		  sparse_feature_values: A list of `Tensor` objects with type `float32`.
		    a list of vectors which contains feature value
		    associated with each feature group.
		  dense_features: A list of `Tensor` objects with type `float32`.
		    a list of matrices which contains the dense feature values.
		  example_weights: A `Tensor` of type `float32`.
		    a vector which contains the weight associated with each
		    example.
		  example_labels: A `Tensor` of type `float32`.
		    a vector which contains the label/target associated with each
		    example.
		  sparse_indices: A list with the same length as `sparse_example_indices` of `Tensor` objects with type `int64`.
		    a list of vectors where each value is the indices which has
		    corresponding weights in sparse_weights. This field maybe omitted for the
		    dense approach.
		  sparse_weights: A list with the same length as `sparse_example_indices` of `Tensor` objects with type `float32`.
		    a list of vectors where each value is the weight associated with
		    a sparse feature group.
		  dense_weights: A list with the same length as `dense_features` of `Tensor` objects with type `float32`.
		    a list of vectors where the values are the weights associated
		    with a dense feature group.
		  example_state_data: A `Tensor` of type `float32`.
		    a list of vectors containing the example state data.
		  loss_type: A `string` from: `"logistic_loss", "squared_loss", "hinge_loss", "smooth_hinge_loss", "poisson_loss"`.
		    Type of the primal loss. Currently SdcaSolver supports logistic,
		    squared and hinge losses.
		  l1: A `float`. Symmetric l1 regularization strength.
		  l2: A `float`. Symmetric l2 regularization strength.
		  num_loss_partitions: An `int` that is `>= 1`.
		    Number of partitions of the global loss function.
		  num_inner_iterations: An `int` that is `>= 1`.
		    Number of iterations per mini-batch.
		  adaptive: An optional `bool`. Defaults to `True`.
		    Whether to use Adaptive SDCA for the inner loop.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (out_example_state_data, out_delta_sparse_weights, out_delta_dense_weights).
		
		  out_example_state_data: A `Tensor` of type `float32`.
		  out_delta_sparse_weights: A list with the same length as `sparse_example_indices` of `Tensor` objects with type `float32`.
		  out_delta_dense_weights: A list with the same length as `dense_features` of `Tensor` objects with type `float32`.
	**/
	static public function SdcaOptimizerV2(sparse_example_indices:Dynamic, sparse_feature_indices:Dynamic, sparse_feature_values:Dynamic, dense_features:Dynamic, example_weights:Dynamic, example_labels:Dynamic, sparse_indices:Dynamic, sparse_weights:Dynamic, dense_weights:Dynamic, example_state_data:Dynamic, loss_type:Dynamic, l1:Dynamic, l2:Dynamic, num_loss_partitions:Dynamic, num_inner_iterations:Dynamic, ?adaptive:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies L1 regularization shrink step on the parameters.
		
		Args:
		  weights: A list of `Tensor` objects with type mutable `float32`.
		    a list of vectors where each value is the weight associated with a
		    feature group.
		  l1: A `float`. Symmetric l1 regularization strength.
		  l2: A `float`.
		    Symmetric l2 regularization strength. Should be a positive float.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function SdcaShrinkL1(weights:Dynamic, l1:Dynamic, l2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the maximum along segments of a tensor.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		Computes a tensor such that
		\\(output_i = \max_j(data_j)\\) where `max` is over `j` such
		that `segment_ids[j] == i`.
		
		If the max is empty for a given segment ID `i`, `output[i] = 0`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/SegmentMax.png" alt>
		</div>
		
		For example:
		
		```
		c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])
		tf.segment_max(c, tf.constant([0, 0, 1]))
		# ==> [[4, 3, 3, 4],
		#      [5, 6, 7, 8]]
		```
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor whose size is equal to the size of `data`'s
		    first dimension.  Values should be sorted and can be repeated.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function SegmentMax(data:Dynamic, segment_ids:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the mean along segments of a tensor.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		Computes a tensor such that
		\\(output_i = \frac{\sum_j data_j}{N}\\) where `mean` is
		over `j` such that `segment_ids[j] == i` and `N` is the total number of
		values summed.
		
		If the mean is empty for a given segment ID `i`, `output[i] = 0`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/SegmentMean.png" alt>
		</div>
		
		For example:
		
		```
		c = tf.constant([[1.0,2,3,4], [4, 3, 2, 1], [5,6,7,8]])
		tf.segment_mean(c, tf.constant([0, 0, 1]))
		# ==> [[2.5, 2.5, 2.5, 2.5],
		#      [5, 6, 7, 8]]
		```
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor whose size is equal to the size of `data`'s
		    first dimension.  Values should be sorted and can be repeated.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function SegmentMean(data:Dynamic, segment_ids:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the minimum along segments of a tensor.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		Computes a tensor such that
		\\(output_i = \min_j(data_j)\\) where `min` is over `j` such
		that `segment_ids[j] == i`.
		
		If the min is empty for a given segment ID `i`, `output[i] = 0`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/SegmentMin.png" alt>
		</div>
		
		For example:
		
		```
		c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])
		tf.segment_min(c, tf.constant([0, 0, 1]))
		# ==> [[1, 2, 2, 1],
		#      [5, 6, 7, 8]]
		```
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor whose size is equal to the size of `data`'s
		    first dimension.  Values should be sorted and can be repeated.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function SegmentMin(data:Dynamic, segment_ids:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the product along segments of a tensor.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		Computes a tensor such that
		\\(output_i = \prod_j data_j\\) where the product is over `j` such
		that `segment_ids[j] == i`.
		
		If the product is empty for a given segment ID `i`, `output[i] = 1`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/SegmentProd.png" alt>
		</div>
		
		For example:
		
		```
		c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])
		tf.segment_prod(c, tf.constant([0, 0, 1]))
		# ==> [[4, 6, 6, 4],
		#      [5, 6, 7, 8]]
		```
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor whose size is equal to the size of `data`'s
		    first dimension.  Values should be sorted and can be repeated.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function SegmentProd(data:Dynamic, segment_ids:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the sum along segments of a tensor.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		Computes a tensor such that
		\\(output_i = \sum_j data_j\\) where sum is over `j` such
		that `segment_ids[j] == i`.
		
		If the sum is empty for a given segment ID `i`, `output[i] = 0`.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/SegmentSum.png" alt>
		</div>
		
		For example:
		
		```
		c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])
		tf.segment_sum(c, tf.constant([0, 0, 1]))
		# ==> [[5, 5, 5, 5],
		#      [5, 6, 7, 8]]
		```
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor whose size is equal to the size of `data`'s
		    first dimension.  Values should be sorted and can be repeated.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function SegmentSum(data:Dynamic, segment_ids:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Selects elements from `x` or `y`, depending on `condition`.
		
		The `x`, and `y` tensors must all have the same shape, and the
		output will also have that shape.
		
		The `condition` tensor must be a scalar if `x` and `y` are scalars.
		If `x` and `y` are vectors or higher rank, then `condition` must be either a
		scalar, a vector with size matching the first dimension of `x`, or must have
		the same shape as `x`.
		
		The `condition` tensor acts as a mask that chooses, based on the value at each
		element, whether the corresponding element / row in the output should be
		taken from `x` (if true) or `y` (if false).
		
		If `condition` is a vector and `x` and `y` are higher rank matrices, then
		it chooses which row (outer dimension) to copy from `x` and `y`.
		If `condition` has the same shape as `x` and `y`, then it chooses which
		element to copy from `x` and `y`.
		
		For example:
		
		```python
		# 'condition' tensor is [[True,  False]
		#                        [False, True]]
		# 't' is [[1, 2],
		#         [3, 4]]
		# 'e' is [[5, 6],
		#         [7, 8]]
		select(condition, t, e)  # => [[1, 6], [7, 4]]
		
		
		# 'condition' tensor is [True, False]
		# 't' is [[1, 2],
		#         [3, 4]]
		# 'e' is [[5, 6],
		#         [7, 8]]
		select(condition, t, e) ==> [[1, 2],
		                             [7, 8]]
		
		```
		
		Args:
		  condition: A `Tensor` of type `bool`.
		  x:  A `Tensor` which may have the same shape as `condition`.
		    If `condition` is rank 1, `x` may have higher rank,
		    but its first dimension must match the size of `condition`.
		  y:  A `Tensor` with the same type and shape as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `t`.
	**/
	static public function Select(condition:Dynamic, x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  condition: A `Tensor` of type `bool`.
		  t: A `Tensor`.
		  e: A `Tensor`. Must have the same type as `t`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `t`.
	**/
	static public function SelectV2(condition:Dynamic, t:Dynamic, e:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the Eigen Decomposition of a batch of square self-adjoint matrices.
		
		The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions
		form square matrices, with the same constraints as the single matrix
		SelfAdjointEig.
		
		The result is a [..., M+1, M] matrix with [..., 0,:] containing the
		eigenvalues, and subsequent [...,1:, :] containing the eigenvectors. The eigenvalues
		are sorted in non-decreasing order.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`.
		    Shape is `[..., M, M]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function SelfAdjointEig(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the eigen decomposition of one or more square self-adjoint matrices.
		
		Computes the eigenvalues and (optionally) eigenvectors of each inner matrix in
		`input` such that `input[..., :, :] = v[..., :, :] * diag(e[..., :])`. The eigenvalues
		are sorted in non-decreasing order.
		
		```python
		# a is a tensor.
		# e is a tensor of eigenvalues.
		# v is a tensor of eigenvectors.
		e, v = self_adjoint_eig(a)
		e = self_adjoint_eig(a, compute_v=False)
		```
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		    `Tensor` input of shape `[N, N]`.
		  compute_v: An optional `bool`. Defaults to `True`.
		    If `True` then eigenvectors will be computed and returned in `v`.
		    Otherwise, only the eigenvalues will be computed.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (e, v).
		
		  e: A `Tensor`. Has the same type as `input`.
		  v: A `Tensor`. Has the same type as `input`.
	**/
	static public function SelfAdjointEigV2(input:Dynamic, ?compute_v:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes scaled exponential linear: `scale * alpha * (exp(features) - 1)`
		
		if < 0, `scale * features` otherwise.
		
		To be used together with
		`initializer = tf.variance_scaling_initializer(factor=1.0, mode='FAN_IN')`.
		For correct dropout, use `tf.contrib.nn.alpha_dropout`.
		
		See [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `features`.
	**/
	static public function Selu(features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradients for the scaled exponential linear (Selu) operation.
		
		Args:
		  gradients: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    The backpropagated gradients to the corresponding Selu operation.
		  outputs: A `Tensor`. Must have the same type as `gradients`.
		    The outputs of the corresponding Selu operation.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `gradients`.
	**/
	static public function SeluGrad(gradients:Dynamic, outputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Sends the named tensor from send_device to recv_device.
		
		Args:
		  tensor: A `Tensor`. The tensor to send.
		  tensor_name: A `string`. The name of the tensor to send.
		  send_device: A `string`. The name of the device sending the tensor.
		  send_device_incarnation: An `int`. The current incarnation of send_device.
		  recv_device: A `string`. The name of the device receiving the tensor.
		  client_terminated: An optional `bool`. Defaults to `False`.
		    If set to true, this indicates that the node was added
		    to the graph as a result of a client-side feed or fetch of Tensor data,
		    in which case the corresponding send or recv is expected to be managed
		    locally by the caller.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function Send(tensor:Dynamic, tensor_name:Dynamic, send_device:Dynamic, send_device_incarnation:Dynamic, recv_device:Dynamic, ?client_terminated:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs gradient updates of embedding tables.
		
		Args:
		  inputs: A list of at least 1 `Tensor` objects with type `float32`.
		    A TensorList of gradients with which to update embedding tables.
		    This argument has the same length and shapes as the return value of
		    RecvTPUEmbeddingActivations, but contains gradients of the model's loss
		    with respect to the embedding activations. The embedding tables are updated
		    from these gradients via the optimizer specified in the TPU embedding
		    configuration given to tpu.initialize_system.
		  learning_rates: A list of `Tensor` objects with type `float32`.
		    A TensorList of float32 scalars, one for each dynamic learning
		    rate tag: see the comments in
		    //third_party/tensorflow/core/protobuf/tpu/optimization_parameters.proto.
		    Multiple tables can share the same dynamic learning rate tag as specified
		    in the configuration. If the learning rates for all tables are constant,
		    this list should be empty.
		  config: A `string`. Serialized TPUEmbeddingConfiguration proto.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function SendTPUEmbeddingGradients(inputs:Dynamic, learning_rates:Dynamic, config:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts the given `resource_handle` representing an iterator to a variant tensor.
		
		Args:
		  resource_handle: A `Tensor` of type `resource`.
		    A handle to an iterator resource.
		  external_state_policy: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SerializeIterator(resource_handle:Dynamic, ?external_state_policy:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Serialize an `N`-minibatch `SparseTensor` into an `[N, 3]` `Tensor` object.
		
		The `SparseTensor` must have rank `R` greater than 1, and the first dimension
		is treated as the minibatch dimension.  Elements of the `SparseTensor`
		must be sorted in increasing order of this first dimension.  The serialized
		`SparseTensor` objects going into each row of `serialized_sparse` will have
		rank `R-1`.
		
		The minibatch size `N` is extracted from `sparse_shape[0]`.
		
		Args:
		  sparse_indices: A `Tensor` of type `int64`.
		    2-D.  The `indices` of the minibatch `SparseTensor`.
		  sparse_values: A `Tensor`.
		    1-D.  The `values` of the minibatch `SparseTensor`.
		  sparse_shape: A `Tensor` of type `int64`.
		    1-D.  The `shape` of the minibatch `SparseTensor`.
		  out_type: An optional `tf.DType` from: `tf.string, tf.variant`. Defaults to `tf.string`.
		    The `dtype` to use for serialization; the supported types are `string`
		    (default) and `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `out_type`.
	**/
	static public function SerializeManySparse(sparse_indices:Dynamic, sparse_values:Dynamic, sparse_shape:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Serialize a `SparseTensor` into a `[3]` `Tensor` object.
		
		Args:
		  sparse_indices: A `Tensor` of type `int64`.
		    2-D.  The `indices` of the `SparseTensor`.
		  sparse_values: A `Tensor`. 1-D.  The `values` of the `SparseTensor`.
		  sparse_shape: A `Tensor` of type `int64`.
		    1-D.  The `shape` of the `SparseTensor`.
		  out_type: An optional `tf.DType` from: `tf.string, tf.variant`. Defaults to `tf.string`.
		    The `dtype` to use for serialization; the supported types are `string`
		    (default) and `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `out_type`.
	**/
	static public function SerializeSparse(sparse_indices:Dynamic, sparse_values:Dynamic, sparse_shape:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transforms a Tensor into a serialized TensorProto proto.
		
		Args:
		  tensor: A `Tensor`. A Tensor of type `T`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function SerializeTensor(tensor:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Number of unique elements along last dimension of input `set`.
		
		Input `set` is a `SparseTensor` represented by `set_indices`, `set_values`,
		and `set_shape`. The last dimension contains values in a set, duplicates are
		allowed but ignored.
		
		If `validate_indices` is `True`, this op validates the order and range of `set`
		indices.
		
		Args:
		  set_indices: A `Tensor` of type `int64`.
		    2D `Tensor`, indices of a `SparseTensor`.
		  set_values: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `string`.
		    1D `Tensor`, values of a `SparseTensor`.
		  set_shape: A `Tensor` of type `int64`.
		    1D `Tensor`, shape of a `SparseTensor`.
		  validate_indices: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function SetSize(set_indices:Dynamic, set_values:Dynamic, set_shape:Dynamic, ?validate_indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  stats_aggregator: A `Tensor` of type `resource`.
		  tag: A `Tensor` of type `string`.
		  counter_prefix: A `Tensor` of type `string`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SetStatsAggregatorDataset(input_dataset:Dynamic, stats_aggregator:Dynamic, tag:Dynamic, counter_prefix:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the shape of a tensor.
		
		This operation returns a 1-D integer tensor representing the shape of `input`.
		
		For example:
		
		```
		# 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
		shape(t) ==> [2, 2, 3]
		```
		
		Args:
		  input: A `Tensor`.
		  out_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `out_type`.
	**/
	static public function Shape(input:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns shape of tensors.
		
		This operation returns N 1-D integer tensors representing shape of `input[i]s`.
		
		Args:
		  input: A list of at least 1 `Tensor` objects with the same type.
		  out_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list with the same length as `input` of `Tensor` objects with type `out_type`.
	**/
	static public function ShapeN(input:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a `Dataset` that includes only 1/`num_shards` of this dataset.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  num_shards: A `Tensor` of type `int64`.
		    An integer representing the number of shards operating in parallel.
		  index: A `Tensor` of type `int64`.
		    An integer representing the current worker index.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  require_non_empty: An optional `bool`. Defaults to `False`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ShardDataset(input_dataset:Dynamic, num_shards:Dynamic, index:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?require_non_empty:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generate a sharded filename. The filename is printf formatted as
		
		   %s-%05d-of-%05d, basename, shard, num_shards.
		
		Args:
		  basename: A `Tensor` of type `string`.
		  shard: A `Tensor` of type `int32`.
		  num_shards: A `Tensor` of type `int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function ShardedFilename(basename:Dynamic, shard:Dynamic, num_shards:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generate a glob pattern matching all sharded file names.
		
		Args:
		  basename: A `Tensor` of type `string`.
		  num_shards: A `Tensor` of type `int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function ShardedFilespec(basename:Dynamic, num_shards:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that shuffles and repeats elements from `input_dataset`
		
		pseudorandomly.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  buffer_size: A `Tensor` of type `int64`.
		    The number of output elements to buffer in an iterator over
		    this dataset. Compare with the `min_after_dequeue` attr when creating a
		    `RandomShuffleQueue`.
		  seed: A `Tensor` of type `int64`.
		    A scalar seed for the random number generator. If either `seed` or
		    `seed2` is set to be non-zero, the random number generator is seeded
		    by the given seed.  Otherwise, a random seed is used.
		  seed2: A `Tensor` of type `int64`.
		    A second scalar seed to avoid seed collision.
		  count: A `Tensor` of type `int64`.
		    A scalar representing the number of times the underlying dataset
		    should be repeated. The default is `-1`, which results in infinite repetition.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  reshuffle_each_iteration: An optional `bool`. Defaults to `True`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ShuffleAndRepeatDataset(input_dataset:Dynamic, buffer_size:Dynamic, seed:Dynamic, seed2:Dynamic, count:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?reshuffle_each_iteration:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  buffer_size: A `Tensor` of type `int64`.
		  seed: A `Tensor` of type `int64`.
		  seed2: A `Tensor` of type `int64`.
		  count: A `Tensor` of type `int64`.
		  seed_generator: A `Tensor` of type `resource`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  reshuffle_each_iteration: An optional `bool`. Defaults to `True`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ShuffleAndRepeatDatasetV2(input_dataset:Dynamic, buffer_size:Dynamic, seed:Dynamic, seed2:Dynamic, count:Dynamic, seed_generator:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?reshuffle_each_iteration:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that shuffles elements from `input_dataset` pseudorandomly.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  buffer_size: A `Tensor` of type `int64`.
		    The number of output elements to buffer in an iterator over
		    this dataset. Compare with the `min_after_dequeue` attr when creating a
		    `RandomShuffleQueue`.
		  seed: A `Tensor` of type `int64`.
		    A scalar seed for the random number generator. If either `seed` or
		    `seed2` is set to be non-zero, the random number generator is seeded
		    by the given seed.  Otherwise, a random seed is used.
		  seed2: A `Tensor` of type `int64`.
		    A second scalar seed to avoid seed collision.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  reshuffle_each_iteration: An optional `bool`. Defaults to `True`.
		    If true, each iterator over this dataset will be given
		    a different pseudorandomly generated seed, based on a sequence seeded by the
		    `seed` and `seed2` inputs. If false, each iterator will be given the same
		    seed, and repeated iteration over this dataset will yield the exact same
		    sequence of results.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ShuffleDataset(input_dataset:Dynamic, buffer_size:Dynamic, seed:Dynamic, seed2:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?reshuffle_each_iteration:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  buffer_size: A `Tensor` of type `int64`.
		  seed_generator: A `Tensor` of type `resource`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ShuffleDatasetV2(input_dataset:Dynamic, buffer_size:Dynamic, seed_generator:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  buffer_size: A `Tensor` of type `int64`.
		  seed: A `Tensor` of type `int64`.
		  seed2: A `Tensor` of type `int64`.
		  seed_generator: A `Tensor` of type `resource`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  reshuffle_each_iteration: An optional `bool`. Defaults to `True`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ShuffleDatasetV3(input_dataset:Dynamic, buffer_size:Dynamic, seed:Dynamic, seed2:Dynamic, seed_generator:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?reshuffle_each_iteration:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Shuts down a running distributed TPU system.
		
		The op returns an error if no system is running.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function ShutdownDistributedTPU(?name:Dynamic):Dynamic;
	/**
		Computes sigmoid of `x` element-wise.
		
		Specifically, `y = 1 / (1 + exp(-x))`.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Sigmoid(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient of the sigmoid of `x` wrt its input.
		
		Specifically, `grad = dy * y * (1 - y)`, where `y = sigmoid(x)`, and
		`dy` is the corresponding input gradient.
		
		Args:
		  y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  dy: A `Tensor`. Must have the same type as `y`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `y`.
	**/
	static public function SigmoidGrad(y:Dynamic, dy:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns an element-wise indication of the sign of a number.
		
		`y = sign(x) = -1` if `x < 0`; 0 if `x == 0`; 1 if `x > 0`.
		
		For complex numbers, `y = sign(x) = x / |x|` if `x != 0`, otherwise `y = 0`.
		
		Example usage:
		>>> tf.math.sign([0., 2., -3.])
		<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 0.,  1., -1.], dtype=float32)>
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Sign(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes sine of x element-wise.
		
		  Given an input tensor, this function computes sine of every
		  element in the tensor. Input range is `(-inf, inf)` and
		  output range is `[-1,1]`.
		
		  ```python
		  x = tf.constant([-float("inf"), -9, -0.5, 1, 1.2, 200, 10, float("inf")])
		  tf.math.sin(x) ==> [nan -0.4121185 -0.47942555 0.84147096 0.9320391 -0.87329733 -0.54402107 nan]
		  ```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Sin(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes hyperbolic sine of x element-wise.
		
		  Given an input tensor, this function computes hyperbolic sine of every
		  element in the tensor. Input range is `[-inf,inf]` and output range
		  is `[-inf,inf]`.
		
		  ```python
		  x = tf.constant([-float("inf"), -9, -0.5, 1, 1.2, 2, 10, float("inf")])
		  tf.math.sinh(x) ==> [-inf -4.0515420e+03 -5.2109528e-01 1.1752012e+00 1.5094614e+00 3.6268604e+00 1.1013232e+04 inf]
		  ```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Sinh(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the size of a tensor.
		
		This operation returns an integer representing the number of elements in
		`input`.
		
		For example:
		
		```
		# 't' is [[[1, 1,, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]]
		size(t) ==> 12
		```
		
		Args:
		  input: A `Tensor`.
		  out_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `out_type`.
	**/
	static public function Size(input:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that skips `count` elements from the `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  count: A `Tensor` of type `int64`.
		    A scalar representing the number of elements from the `input_dataset`
		    that should be skipped.  If count is -1, skips everything.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SkipDataset(input_dataset:Dynamic, count:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  sleep_microseconds: A `Tensor` of type `int64`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SleepDataset(input_dataset:Dynamic, sleep_microseconds:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return a slice from 'input'.
		
		The output tensor is a tensor with dimensions described by 'size'
		whose values are extracted from 'input' starting at the offsets in
		'begin'.
		
		*Requirements*:
		  0 <= begin[i] <= begin[i] + size[i] <= Di  for i in [0, n)
		
		Args:
		  input: A `Tensor`.
		  begin: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    begin[i] specifies the offset into the 'i'th dimension of
		    'input' to slice from.
		  size: A `Tensor`. Must have the same type as `begin`.
		    size[i] specifies the number of elements of the 'i'th dimension
		    of 'input' to slice. If size[i] is -1, all remaining elements in dimension
		    i are included in the slice (i.e. this is equivalent to setting
		    size[i] = input.dim_size(i) - begin[i]).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Slice(input:Dynamic, begin:Dynamic, size:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that passes a sliding window over `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  window_size: A `Tensor` of type `int64`.
		    A scalar representing the number of elements in the
		    sliding window.
		  window_shift: A `Tensor` of type `int64`.
		    A scalar representing the steps moving the sliding window
		    forward in one iteration. It must be positive.
		  window_stride: A `Tensor` of type `int64`.
		    A scalar representing the stride of the input elements of the sliding window.
		    It must be positive.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SlidingWindowDataset(input_dataset:Dynamic, window_size:Dynamic, window_shift:Dynamic, window_stride:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a copy of the input tensor.
		
		Args:
		  input: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Snapshot(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that will write to / read from a snapshot.
		
		This dataset attempts to determine whether a valid snapshot exists at the
		`snapshot_path`, and reads from the snapshot in lieu of using `input_dataset`.
		If not, it will run the preprocessing pipeline as usual, and write out a
		snapshot of the data processed for future use.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  path: A `Tensor` of type `string`.
		    The path we should write snapshots to / read snapshots from.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  compression: An optional `string`. Defaults to `""`.
		  reader_path_prefix: An optional `string`. Defaults to `""`.
		  writer_path_prefix: An optional `string`. Defaults to `""`.
		  shard_size_bytes: An optional `int`. Defaults to `10737418240`.
		  pending_snapshot_expiry_seconds: An optional `int`. Defaults to `86400`.
		  num_reader_threads: An optional `int`. Defaults to `1`.
		  reader_buffer_size: An optional `int`. Defaults to `1`.
		  num_writer_threads: An optional `int`. Defaults to `1`.
		  writer_buffer_size: An optional `int`. Defaults to `1`.
		  shuffle_on_read: An optional `bool`. Defaults to `False`.
		  seed: An optional `int`. Defaults to `0`.
		  seed2: An optional `int`. Defaults to `0`.
		  mode: An optional `string`. Defaults to `"auto"`.
		  snapshot_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SnapshotDataset(input_dataset:Dynamic, path:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?compression:Dynamic, ?reader_path_prefix:Dynamic, ?writer_path_prefix:Dynamic, ?shard_size_bytes:Dynamic, ?pending_snapshot_expiry_seconds:Dynamic, ?num_reader_threads:Dynamic, ?reader_buffer_size:Dynamic, ?num_writer_threads:Dynamic, ?writer_buffer_size:Dynamic, ?shuffle_on_read:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?mode:Dynamic, ?snapshot_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  shard_dir: A `Tensor` of type `string`.
		  start_index: A `Tensor` of type `int64`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  version: An `int`.
		  compression: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SnapshotDatasetReader(shard_dir:Dynamic, start_index:Dynamic, output_types:Dynamic, output_shapes:Dynamic, version:Dynamic, ?compression:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that will write to / read from a snapshot.
		
		This dataset attempts to determine whether a valid snapshot exists at the
		`snapshot_path`, and reads from the snapshot in lieu of using `input_dataset`.
		If not, it will run the preprocessing pipeline as usual, and write out a
		snapshot of the data processed for future use.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		    A variant tensor representing the input dataset.
		  path: A `Tensor` of type `string`.
		    The path we should write snapshots to / read snapshots from.
		  reader_func_other_args: A list of `Tensor` objects.
		  shard_func_other_args: A list of `Tensor` objects.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  reader_func: A function decorated with @Defun.
		    Optional. A function to control how to read data from snapshot shards.
		  shard_func: A function decorated with @Defun.
		    Optional. A function to control how to shard data when writing a snapshot.
		  compression: An optional `string`. Defaults to `""`.
		    The type of compression to be applied to the saved snapshot files.
		  reader_prefix: An optional `string`. Defaults to `""`.
		  writer_prefix: An optional `string`. Defaults to `""`.
		  hash_valid: An optional `bool`. Defaults to `False`.
		  hash: An optional `int`. Defaults to `0`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SnapshotDatasetV2(input_dataset:Dynamic, path:Dynamic, reader_func_other_args:Dynamic, shard_func_other_args:Dynamic, output_types:Dynamic, output_shapes:Dynamic, reader_func:Dynamic, shard_func:Dynamic, ?compression:Dynamic, ?reader_prefix:Dynamic, ?writer_prefix:Dynamic, ?hash_valid:Dynamic, ?hash:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  inputs: A list of at least 1 `Tensor` objects with type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SnapshotNestedDatasetReader(inputs:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates points from the Sobol sequence.
		
		Creates a Sobol sequence with `num_results` samples. Each sample has dimension
		`dim`. Skips the first `skip` samples.
		
		Args:
		  dim: A `Tensor` of type `int32`.
		    Positive scalar `Tensor` representing each sample's dimension.
		  num_results: A `Tensor` of type `int32`.
		    Positive scalar `Tensor` of dtype int32. The number of Sobol points to return
		    in the output.
		  skip: A `Tensor` of type `int32`.
		    Positive scalar `Tensor` of dtype int32. The number of initial points of the
		    Sobol sequence to skip.
		  dtype: An optional `tf.DType` from: `tf.float32, tf.float64`. Defaults to `tf.float32`.
		    The type of the sample. One of: `float32` or `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function SobolSample(dim:Dynamic, num_results:Dynamic, skip:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes softmax activations.
		
		For each batch `i` and class `j` we have
		
		    $$softmax[i, j] = exp(logits[i, j]) / sum_j(exp(logits[i, j]))$$
		
		Args:
		  logits: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    2-D with shape `[batch_size, num_classes]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `logits`.
	**/
	static public function Softmax(logits:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes softmax cross entropy cost and gradients to backpropagate.
		
		Inputs are the logits, not probabilities.
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    batch_size x num_classes matrix
		  labels: A `Tensor`. Must have the same type as `features`.
		    batch_size x num_classes matrix
		    The caller must ensure that each batch of labels represents a valid
		    probability distribution.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (loss, backprop).
		
		  loss: A `Tensor`. Has the same type as `features`.
		  backprop: A `Tensor`. Has the same type as `features`.
	**/
	static public function SoftmaxCrossEntropyWithLogits(features:Dynamic, labels:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `features`.
	**/
	static public function Softplus(features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes softplus gradients for a softplus operation.
		
		Args:
		  gradients: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    The backpropagated gradients to the corresponding softplus operation.
		  features: A `Tensor`. Must have the same type as `gradients`.
		    The features passed as input to the corresponding softplus operation.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `gradients`.
	**/
	static public function SoftplusGrad(gradients:Dynamic, features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes softsign: `features / (abs(features) + 1)`.
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `features`.
	**/
	static public function Softsign(features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes softsign gradients for a softsign operation.
		
		Args:
		  gradients: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    The backpropagated gradients to the corresponding softsign operation.
		  features: A `Tensor`. Must have the same type as `gradients`.
		    The features passed as input to the corresponding softsign operation.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `gradients`.
	**/
	static public function SoftsignGrad(gradients:Dynamic, features:Dynamic, ?name:Dynamic):Dynamic;
	/**
		SpaceToBatch for 4-D tensors of type T.
		
		This is a legacy version of the more general SpaceToBatchND.
		
		Zero-pads and then rearranges (permutes) blocks of spatial data into batch.
		More specifically, this op outputs a copy of the input tensor where values from
		the `height` and `width` dimensions are moved to the `batch` dimension. After
		the zero-padding, both `height` and `width` of the input must be divisible by the
		block size.
		
		The attr `block_size` must be greater than one. It indicates the block size.
		
		  * Non-overlapping blocks of size `block_size x block size` in the height and
		    width dimensions are rearranged into the batch dimension at each location.
		  * The batch of the output tensor is `batch * block_size * block_size`.
		  * Both height_pad and width_pad must be divisible by block_size.
		
		The shape of the output will be:
		
		    [batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
		     depth]
		
		Some examples:
		
		(1) For the following input of shape `[1, 2, 2, 1]` and block_size of 2:
		
		```
		x = [[[[1], [2]], [[3], [4]]]]
		```
		
		The output tensor has shape `[4, 1, 1, 1]` and value:
		
		```
		[[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
		```
		
		(2) For the following input of shape `[1, 2, 2, 3]` and block_size of 2:
		
		```
		x = [[[[1, 2, 3], [4, 5, 6]],
		      [[7, 8, 9], [10, 11, 12]]]]
		```
		
		The output tensor has shape `[4, 1, 1, 3]` and value:
		
		```
		[[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]
		```
		
		(3) For the following input of shape `[1, 4, 4, 1]` and block_size of 2:
		
		```
		x = [[[[1],   [2],  [3],  [4]],
		      [[5],   [6],  [7],  [8]],
		      [[9],  [10], [11],  [12]],
		      [[13], [14], [15],  [16]]]]
		```
		
		The output tensor has shape `[4, 2, 2, 1]` and value:
		
		```
		x = [[[[1], [3]], [[9], [11]]],
		     [[[2], [4]], [[10], [12]]],
		     [[[5], [7]], [[13], [15]]],
		     [[[6], [8]], [[14], [16]]]]
		```
		
		(4) For the following input of shape `[2, 2, 4, 1]` and block_size of 2:
		
		```
		x = [[[[1],   [2],  [3],  [4]],
		      [[5],   [6],  [7],  [8]]],
		     [[[9],  [10], [11],  [12]],
		      [[13], [14], [15],  [16]]]]
		```
		
		The output tensor has shape `[8, 1, 2, 1]` and value:
		
		```
		x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],
		     [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]
		```
		
		Among others, this operation is useful for reducing atrous convolution into
		regular convolution.
		
		Args:
		  input: A `Tensor`. 4-D with shape `[batch, height, width, depth]`.
		  paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2-D tensor of non-negative integers with shape `[2, 2]`. It specifies
		      the padding of the input with zeros across the spatial dimensions as follows:
		
		          paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]
		
		      The effective spatial dimensions of the zero-padded input tensor will be:
		
		          height_pad = pad_top + height + pad_bottom
		          width_pad = pad_left + width + pad_right
		  block_size: An `int` that is `>= 2`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function SpaceToBatch(input:Dynamic, paddings:Dynamic, block_size:Dynamic, ?name:Dynamic):Dynamic;
	/**
		SpaceToBatch for N-D tensors of type T.
		
		This operation divides "spatial" dimensions `[1, ..., M]` of the input into a
		grid of blocks of shape `block_shape`, and interleaves these blocks with the
		"batch" dimension (0) such that in the output, the spatial dimensions
		`[1, ..., M]` correspond to the position within the grid, and the batch
		dimension combines both the position within a spatial block and the original
		batch position.  Prior to division into blocks, the spatial dimensions of the
		input are optionally zero padded according to `paddings`. See below for a
		precise description.
		
		This operation is equivalent to the following steps:
		
		1. Zero-pad the start and end of dimensions `[1, ..., M]` of the
		   input according to `paddings` to produce `padded` of shape `padded_shape`.
		
		2. Reshape `padded` to `reshaped_padded` of shape:
		
		     [batch] +
		     [padded_shape[1] / block_shape[0],
		       block_shape[0],
		      ...,
		      padded_shape[M] / block_shape[M-1],
		      block_shape[M-1]] +
		     remaining_shape
		
		3. Permute dimensions of `reshaped_padded` to produce
		   `permuted_reshaped_padded` of shape:
		
		     block_shape +
		     [batch] +
		     [padded_shape[1] / block_shape[0],
		      ...,
		      padded_shape[M] / block_shape[M-1]] +
		     remaining_shape
		
		4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the batch
		   dimension, producing an output tensor of shape:
		
		     [batch * prod(block_shape)] +
		     [padded_shape[1] / block_shape[0],
		      ...,
		      padded_shape[M] / block_shape[M-1]] +
		     remaining_shape
		
		Some examples:
		
		(1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and
		    `paddings = [[0, 0], [0, 0]]`:
		
		```
		x = [[[[1], [2]], [[3], [4]]]]
		```
		
		The output tensor has shape `[4, 1, 1, 1]` and value:
		
		```
		[[[[1]]], [[[2]]], [[[3]]], [[[4]]]]
		```
		
		(2) For the following input of shape `[1, 2, 2, 3]`, `block_shape = [2, 2]`, and
		    `paddings = [[0, 0], [0, 0]]`:
		
		```
		x = [[[[1, 2, 3], [4, 5, 6]],
		      [[7, 8, 9], [10, 11, 12]]]]
		```
		
		The output tensor has shape `[4, 1, 1, 3]` and value:
		
		```
		[[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]
		```
		
		(3) For the following input of shape `[1, 4, 4, 1]`, `block_shape = [2, 2]`, and
		    `paddings = [[0, 0], [0, 0]]`:
		
		```
		x = [[[[1],   [2],  [3],  [4]],
		      [[5],   [6],  [7],  [8]],
		      [[9],  [10], [11],  [12]],
		      [[13], [14], [15],  [16]]]]
		```
		
		The output tensor has shape `[4, 2, 2, 1]` and value:
		
		```
		x = [[[[1], [3]], [[9], [11]]],
		     [[[2], [4]], [[10], [12]]],
		     [[[5], [7]], [[13], [15]]],
		     [[[6], [8]], [[14], [16]]]]
		```
		
		(4) For the following input of shape `[2, 2, 4, 1]`, block_shape = `[2, 2]`, and
		    paddings = `[[0, 0], [2, 0]]`:
		
		```
		x = [[[[1],   [2],  [3],  [4]],
		      [[5],   [6],  [7],  [8]]],
		     [[[9],  [10], [11],  [12]],
		      [[13], [14], [15],  [16]]]]
		```
		
		The output tensor has shape `[8, 1, 3, 1]` and value:
		
		```
		x = [[[[0], [1], [3]]], [[[0], [9], [11]]],
		     [[[0], [2], [4]]], [[[0], [10], [12]]],
		     [[[0], [5], [7]]], [[[0], [13], [15]]],
		     [[[0], [6], [8]]], [[[0], [14], [16]]]]
		```
		
		Among others, this operation is useful for reducing atrous convolution into
		regular convolution.
		
		Args:
		  input: A `Tensor`.
		    N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,
		    where spatial_shape has `M` dimensions.
		  block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    1-D with shape `[M]`, all values must be >= 1.
		  paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2-D with shape `[M, 2]`, all values must be >= 0.
		      `paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension
		      `i + 1`, which corresponds to spatial dimension `i`.  It is required that
		      `block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function SpaceToBatchND(input:Dynamic, block_shape:Dynamic, paddings:Dynamic, ?name:Dynamic):Dynamic;
	/**
		SpaceToDepth for tensors of type T.
		
		Rearranges blocks of spatial data, into depth. More specifically,
		this op outputs a copy of the input tensor where values from the `height`
		and `width` dimensions are moved to the `depth` dimension.
		The attr `block_size` indicates the input block size.
		
		  * Non-overlapping blocks of size `block_size x block size` are rearranged
		    into depth at each location.
		  * The depth of the output tensor is `block_size * block_size * input_depth`.
		  * The Y, X coordinates within each block of the input become the high order
		    component of the output channel index.
		  * The input tensor's height and width must be divisible by block_size.
		
		The `data_format` attr specifies the layout of the input and output tensors
		with the following options:
		  "NHWC": `[ batch, height, width, channels ]`
		  "NCHW": `[ batch, channels, height, width ]`
		  "NCHW_VECT_C":
		      `qint8 [ batch, channels / 4, height, width, 4 ]`
		
		It is useful to consider the operation as transforming a 6-D Tensor.
		e.g. for data_format = NHWC,
		     Each element in the input tensor can be specified via 6 coordinates,
		     ordered by decreasing memory layout significance as:
		     n,oY,bY,oX,bX,iC  (where n=batch index, oX, oY means X or Y coordinates
		                        within the output image, bX, bY means coordinates
		                        within the input block, iC means input channels).
		     The output would be a transpose to the following layout:
		     n,oY,oX,bY,bX,iC
		
		This operation is useful for resizing the activations between convolutions
		(but keeping all data), e.g. instead of pooling. It is also useful for training
		purely convolutional models.
		
		For example, given an input of shape `[1, 2, 2, 1]`, data_format = "NHWC" and
		block_size = 2:
		
		```
		x = [[[[1], [2]],
		      [[3], [4]]]]
		```
		
		This operation will output a tensor of shape `[1, 1, 1, 4]`:
		
		```
		[[[[1, 2, 3, 4]]]]
		```
		
		Here, the input has a batch of 1 and each batch element has shape `[2, 2, 1]`,
		the corresponding output will have a single element (i.e. width and height are
		both 1) and will have a depth of 4 channels (1 * block_size * block_size).
		The output element shape is `[1, 1, 4]`.
		
		For an input tensor with larger depth, here of shape `[1, 2, 2, 3]`, e.g.
		
		```
		x = [[[[1, 2, 3], [4, 5, 6]],
		      [[7, 8, 9], [10, 11, 12]]]]
		```
		
		This operation, for block_size of 2, will return the following tensor of shape
		`[1, 1, 1, 12]`
		
		```
		[[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]
		```
		
		Similarly, for the following input of shape `[1 4 4 1]`, and a block size of 2:
		
		```
		x = [[[[1],   [2],  [5],  [6]],
		      [[3],   [4],  [7],  [8]],
		      [[9],  [10], [13],  [14]],
		      [[11], [12], [15],  [16]]]]
		```
		
		the operator will return the following tensor of shape `[1 2 2 4]`:
		
		```
		x = [[[[1, 2, 3, 4],
		       [5, 6, 7, 8]],
		      [[9, 10, 11, 12],
		       [13, 14, 15, 16]]]]
		```
		
		Args:
		  input: A `Tensor`.
		  block_size: An `int` that is `>= 2`. The size of the spatial block.
		  data_format: An optional `string` from: `"NHWC", "NCHW", "NCHW_VECT_C"`. Defaults to `"NHWC"`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function SpaceToDepth(input:Dynamic, block_size:Dynamic, ?data_format:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies a sparse gradient to a given accumulator.
		
		Does not add if local_step is smaller than the accumulator's
		global_step.
		
		Args:
		  handle: A `Tensor` of type mutable `string`. The handle to a accumulator.
		  local_step: A `Tensor` of type `int64`.
		    The local_step value at which the sparse gradient was computed.
		  gradient_indices: A `Tensor` of type `int64`.
		    Indices of the sparse gradient to be accumulated. Must be a
		    vector.
		  gradient_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Values are the non-zero slices of the gradient, and must have
		    the same first dimension as indices, i.e., the nnz represented by indices and
		    values must be consistent.
		  gradient_shape: A `Tensor` of type `int64`.
		    Shape of the sparse gradient to be accumulated.
		  has_known_shape: A `bool`.
		    Boolean indicating whether gradient_shape is unknown, in which
		    case the input is ignored during validation.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function SparseAccumulatorApplyGradient(handle:Dynamic, local_step:Dynamic, gradient_indices:Dynamic, gradient_values:Dynamic, gradient_shape:Dynamic, has_known_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Extracts the average sparse gradient in a SparseConditionalAccumulator.
		
		The op will blocks until sufficient (i.e., more than num_required)
		gradients have been accumulated. If the accumulator has already
		aggregated more than num_required gradients, it will return its
		average of the accumulated gradients.  Also automatically increments
		the recorded global_step in the accumulator by 1, and resets the
		aggregate to 0.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		    The handle to a SparseConditionalAccumulator.
		  num_required: A `Tensor` of type `int32`.
		    Number of gradients required before we return an aggregate.
		  dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
		    The data type of accumulated gradients. Needs to correspond to the type
		    of the accumulator.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (indices, values, shape).
		
		  indices: A `Tensor` of type `int64`.
		  values: A `Tensor` of type `dtype`.
		  shape: A `Tensor` of type `int64`.
	**/
	static public function SparseAccumulatorTakeGradient(handle:Dynamic, num_required:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adds two `SparseTensor` objects to produce another `SparseTensor`.
		
		The input `SparseTensor` objects' indices are assumed ordered in standard
		lexicographic order.  If this is not the case, before this step run
		`SparseReorder` to restore index ordering.
		
		By default, if two values sum to zero at some index, the output `SparseTensor`
		would still include that particular location in its index, storing a zero in the
		corresponding value slot.  To override this, callers can specify `thresh`,
		indicating that if the sum has a magnitude strictly smaller than `thresh`, its
		corresponding value and index would then not be included.  In particular,
		`thresh == 0` (default) means everything is kept and actual thresholding happens
		only for a positive value.
		
		In the following shapes, `nnz` is the count after taking `thresh` into account.
		
		Args:
		  a_indices: A `Tensor` of type `int64`.
		    2-D.  The `indices` of the first `SparseTensor`, size `[nnz, ndims]` Matrix.
		  a_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    1-D.  The `values` of the first `SparseTensor`, size `[nnz]` Vector.
		  a_shape: A `Tensor` of type `int64`.
		    1-D.  The `shape` of the first `SparseTensor`, size `[ndims]` Vector.
		  b_indices: A `Tensor` of type `int64`.
		    2-D.  The `indices` of the second `SparseTensor`, size `[nnz, ndims]` Matrix.
		  b_values: A `Tensor`. Must have the same type as `a_values`.
		    1-D.  The `values` of the second `SparseTensor`, size `[nnz]` Vector.
		  b_shape: A `Tensor` of type `int64`.
		    1-D.  The `shape` of the second `SparseTensor`, size `[ndims]` Vector.
		  thresh: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    0-D.  The magnitude threshold that determines if an output value/index
		    pair takes space.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sum_indices, sum_values, sum_shape).
		
		  sum_indices: A `Tensor` of type `int64`.
		  sum_values: A `Tensor`. Has the same type as `a_values`.
		  sum_shape: A `Tensor` of type `int64`.
	**/
	static public function SparseAdd(a_indices:Dynamic, a_values:Dynamic, a_shape:Dynamic, b_indices:Dynamic, b_values:Dynamic, b_shape:Dynamic, thresh:Dynamic, ?name:Dynamic):Dynamic;
	/**
		The gradient operator for the SparseAdd op.
		
		The SparseAdd op calculates A + B, where A, B, and the sum are all represented
		as `SparseTensor` objects.  This op takes in the upstream gradient w.r.t.
		non-empty values of the sum, and outputs the gradients w.r.t. the non-empty
		values of A and B.
		
		Args:
		  backprop_val_grad: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    1-D with shape `[nnz(sum)]`.  The gradient with respect to
		    the non-empty values of the sum.
		  a_indices: A `Tensor` of type `int64`.
		    2-D.  The `indices` of the `SparseTensor` A, size `[nnz(A), ndims]`.
		  b_indices: A `Tensor` of type `int64`.
		    2-D.  The `indices` of the `SparseTensor` B, size `[nnz(B), ndims]`.
		  sum_indices: A `Tensor` of type `int64`.
		    2-D.  The `indices` of the sum `SparseTensor`, size
		    `[nnz(sum), ndims]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (a_val_grad, b_val_grad).
		
		  a_val_grad: A `Tensor`. Has the same type as `backprop_val_grad`.
		  b_val_grad: A `Tensor`. Has the same type as `backprop_val_grad`.
	**/
	static public function SparseAddGrad(backprop_val_grad:Dynamic, a_indices:Dynamic, b_indices:Dynamic, sum_indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		var: Should be from a Variable().
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  accum_update: A mutable `Tensor`. Must have the same type as `var`.
		    : Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Learning rate. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `var`.
		    Decay factor. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `var`.
		    Constant factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var and accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function SparseApplyAdadelta(_var:Dynamic, accum:Dynamic, accum_update:Dynamic, lr:Dynamic, rho:Dynamic, epsilon:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update relevant entries in '*var' and '*accum' according to the adagrad scheme.
		
		That is for rows we have grad for, we update var and accum as follows:
		$$accum += grad * grad$$
		$$var -= lr * grad * (1 / sqrt(accum))$$
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Learning rate. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  update_slots: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function SparseApplyAdagrad(_var:Dynamic, accum:Dynamic, lr:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?update_slots:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update entries in '*var' and '*accum' according to the proximal adagrad scheme.
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  gradient_accumulator: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  gradient_squared_accumulator: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  lr: A `Tensor`. Must have the same type as `var`.
		    Learning rate. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `var`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `var`.
		    L2 regularization. Must be a scalar.
		  global_step: A `Tensor` of type `int64`.
		    Training step number. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var and accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function SparseApplyAdagradDA(_var:Dynamic, gradient_accumulator:Dynamic, gradient_squared_accumulator:Dynamic, grad:Dynamic, indices:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, global_step:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update relevant entries in '*var' and '*accum' according to the adagrad scheme.
		
		That is for rows we have grad for, we update var and accum as follows:
		$$accum += grad * grad$$
		$$var -= lr * grad * (1 / sqrt(accum))$$
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Learning rate. Must be a scalar.
		  epsilon: A `Tensor`. Must have the same type as `var`.
		    Constant factor. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  update_slots: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function SparseApplyAdagradV2(_var:Dynamic, accum:Dynamic, lr:Dynamic, epsilon:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?update_slots:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the centered RMSProp algorithm.
		
		The centered RMSProp algorithm uses an estimate of the centered second moment
		(i.e., the variance) for normalization, as opposed to regular RMSProp, which
		uses the (uncentered) second moment. This often helps with training, but is
		slightly more expensive in terms of computation and memory.
		
		Note that in dense implementation of this algorithm, mg, ms, and mom will
		update even if the grad is zero, but in this sparse implementation, mg, ms,
		and mom will not update in iterations during which the grad is zero.
		
		mean_square = decay * mean_square + (1-decay) * gradient ** 2
		mean_grad = decay * mean_grad + (1-decay) * gradient
		Delta = learning_rate * gradient / sqrt(mean_square + epsilon - mean_grad ** 2)
		
		$$ms <- rho * ms_{t-1} + (1-rho) * grad * grad$$
		$$mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)$$
		$$var <- var - mom$$
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  mg: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  ms: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  mom: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `var`.
		    Decay rate. Must be a scalar.
		  momentum: A `Tensor`. Must have the same type as `var`.
		  epsilon: A `Tensor`. Must have the same type as `var`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var, ms and mom.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, mg, ms, and mom tensors is
		    protected by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function SparseApplyCenteredRMSProp(_var:Dynamic, mg:Dynamic, ms:Dynamic, mom:Dynamic, lr:Dynamic, rho:Dynamic, momentum:Dynamic, epsilon:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update relevant entries in '*var' according to the Ftrl-proximal scheme.
		
		That is for rows we have grad for, we update var, accum and linear as follows:
		$$accum_new = accum + grad * grad$$
		$$linear += grad + (accum_{new}^{-lr_{power}} - accum^{-lr_{power}} / lr * var$$
		$$quadratic = 1.0 / (accum_{new}^{lr_{power}} * lr) + 2 * l2$$
		$$var = (sign(linear) * l1 - linear) / quadratic\ if\ |linear| > l1\ else\ 0.0$$
		$$accum = accum_{new}$$
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  linear: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `var`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `var`.
		    L2 regularization. Must be a scalar.
		  lr_power: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  multiply_linear_by_lr: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function SparseApplyFtrl(_var:Dynamic, accum:Dynamic, linear:Dynamic, grad:Dynamic, indices:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, lr_power:Dynamic, ?use_locking:Dynamic, ?multiply_linear_by_lr:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update relevant entries in '*var' according to the Ftrl-proximal scheme.
		
		That is for rows we have grad for, we update var, accum and linear as follows:
		grad_with_shrinkage = grad + 2 * l2_shrinkage * var
		accum_new = accum + grad * grad
		linear += grad_with_shrinkage -
		    (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var
		quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2
		var = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0
		accum = accum_new
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  linear: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `var`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `var`.
		    L2 shrinkage regularization. Must be a scalar.
		  l2_shrinkage: A `Tensor`. Must have the same type as `var`.
		  lr_power: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  multiply_linear_by_lr: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function SparseApplyFtrlV2(_var:Dynamic, accum:Dynamic, linear:Dynamic, grad:Dynamic, indices:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, l2_shrinkage:Dynamic, lr_power:Dynamic, ?use_locking:Dynamic, ?multiply_linear_by_lr:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update relevant entries in '*var' and '*accum' according to the momentum scheme.
		
		Set use_nesterov = True if you want to use Nesterov momentum.
		
		That is for rows we have grad for, we update var and accum as follows:
		
		$$accum = accum * momentum + grad$$
		$$var -= lr * accum$$
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Learning rate. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  momentum: A `Tensor`. Must have the same type as `var`.
		    Momentum. Must be a scalar.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var and accum tensors will be protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  use_nesterov: An optional `bool`. Defaults to `False`.
		    If `True`, the tensor passed to compute grad will be
		    var - lr * momentum * accum, so in the end, the var you get is actually
		    var - lr * momentum * accum.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function SparseApplyMomentum(_var:Dynamic, accum:Dynamic, lr:Dynamic, grad:Dynamic, indices:Dynamic, momentum:Dynamic, ?use_locking:Dynamic, ?use_nesterov:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Sparse update entries in '*var' and '*accum' according to FOBOS algorithm.
		
		That is for rows we have grad for, we update var and accum as follows:
		$$accum += grad * grad$$
		$$prox_v = var$$
		$$prox_v -= lr * grad * (1 / sqrt(accum))$$
		$$var = sign(prox_v)/(1+lr*l2) * max{|prox_v|-lr*l1,0}$$
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  accum: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Learning rate. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `var`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `var`.
		    L2 regularization. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, updating of the var and accum tensors will be protected by
		    a lock; otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function SparseApplyProximalAdagrad(_var:Dynamic, accum:Dynamic, lr:Dynamic, l1:Dynamic, l2:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Sparse update '*var' as FOBOS algorithm with fixed learning rate.
		
		That is for rows we have grad for, we update var as follows:
		$$prox_v = var - alpha * grad$$
		$$var = sign(prox_v)/(1+alpha*l2) * max{|prox_v|-alpha*l1,0}$$
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  alpha: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  l1: A `Tensor`. Must have the same type as `var`.
		    L1 regularization. Must be a scalar.
		  l2: A `Tensor`. Must have the same type as `var`.
		    L2 regularization. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var and accum.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If True, the subtraction will be protected by a lock;
		    otherwise the behavior is undefined, but may exhibit less contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function SparseApplyProximalGradientDescent(_var:Dynamic, alpha:Dynamic, l1:Dynamic, l2:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Update '*var' according to the RMSProp algorithm.
		
		Note that in dense implementation of this algorithm, ms and mom will
		update even if the grad is zero, but in this sparse implementation, ms
		and mom will not update in iterations during which the grad is zero.
		
		mean_square = decay * mean_square + (1-decay) * gradient ** 2
		Delta = learning_rate * gradient / sqrt(mean_square + epsilon)
		
		$$ms <- rho * ms_{t-1} + (1-rho) * grad * grad$$
		$$mom <- momentum * mom_{t-1} + lr * grad / sqrt(ms + epsilon)$$
		$$var <- var - mom$$
		
		Args:
		  var: A mutable `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    Should be from a Variable().
		  ms: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  mom: A mutable `Tensor`. Must have the same type as `var`.
		    Should be from a Variable().
		  lr: A `Tensor`. Must have the same type as `var`.
		    Scaling factor. Must be a scalar.
		  rho: A `Tensor`. Must have the same type as `var`.
		    Decay rate. Must be a scalar.
		  momentum: A `Tensor`. Must have the same type as `var`.
		  epsilon: A `Tensor`. Must have the same type as `var`.
		    Ridge term. Must be a scalar.
		  grad: A `Tensor`. Must have the same type as `var`. The gradient.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A vector of indices into the first dimension of var, ms and mom.
		  use_locking: An optional `bool`. Defaults to `False`.
		    If `True`, updating of the var, ms, and mom tensors is protected
		    by a lock; otherwise the behavior is undefined, but may exhibit less
		    contention.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `var`.
	**/
	static public function SparseApplyRMSProp(_var:Dynamic, ms:Dynamic, mom:Dynamic, lr:Dynamic, rho:Dynamic, momentum:Dynamic, epsilon:Dynamic, grad:Dynamic, indices:Dynamic, ?use_locking:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Counts the number of occurrences of each value in an integer array.
		
		Outputs a vector with length `size` and the same dtype as `weights`. If
		`weights` are empty, then index `i` stores the number of times the value `i` is
		counted in `arr`. If `weights` are non-empty, then index `i` stores the sum of
		the value in `weights` at each index where the corresponding value in `arr` is
		`i`.
		
		Values in `arr` outside of the range [0, size) are ignored.
		
		Args:
		  indices: A `Tensor` of type `int64`. 2D int64 `Tensor`.
		  values: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    1D int `Tensor`.
		  dense_shape: A `Tensor` of type `int64`. 1D int64 `Tensor`.
		  size: A `Tensor`. Must have the same type as `values`.
		    non-negative int scalar `Tensor`.
		  weights: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.
		    is an int32, int64, float32, or float64 `Tensor` with the same
		    shape as `input`, or a length-0 `Tensor`, in which case it acts as all weights
		    equal to 1.
		  binary_output: An optional `bool`. Defaults to `False`.
		    bool; Whether the kernel should count the appearance or number of occurrences.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `weights`.
	**/
	static public function SparseBincount(indices:Dynamic, values:Dynamic, dense_shape:Dynamic, size:Dynamic, weights:Dynamic, ?binary_output:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Concatenates a list of `SparseTensor` along the specified dimension.
		
		Concatenation is with respect to the dense versions of these sparse tensors.
		It is assumed that each input is a `SparseTensor` whose elements are ordered
		along increasing dimension number.
		
		All inputs' shapes must match, except for the concat dimension.  The
		`indices`, `values`, and `shapes` lists must have the same length.
		
		The output shape is identical to the inputs', except along the concat
		dimension, where it is the sum of the inputs' sizes along that dimension.
		
		The output elements will be resorted to preserve the sort order along
		increasing dimension number.
		
		This op runs in `O(M log M)` time, where `M` is the total number of non-empty
		values across all inputs. This is due to the need for an internal sort in
		order to concatenate efficiently across an arbitrary dimension.
		
		For example, if `concat_dim = 1` and the inputs are
		
		    sp_inputs[0]: shape = [2, 3]
		    [0, 2]: "a"
		    [1, 0]: "b"
		    [1, 1]: "c"
		
		    sp_inputs[1]: shape = [2, 4]
		    [0, 1]: "d"
		    [0, 2]: "e"
		
		then the output will be
		
		    shape = [2, 7]
		    [0, 2]: "a"
		    [0, 4]: "d"
		    [0, 5]: "e"
		    [1, 0]: "b"
		    [1, 1]: "c"
		
		Graphically this is equivalent to doing
		
		    [    a] concat [  d e  ] = [    a   d e  ]
		    [b c  ]        [       ]   [b c          ]
		
		Args:
		  indices: A list of at least 2 `Tensor` objects with type `int64`.
		    2-D.  Indices of each input `SparseTensor`.
		  values: A list with the same length as `indices` of `Tensor` objects with the same type.
		    1-D.  Non-empty values of each `SparseTensor`.
		  shapes: A list with the same length as `indices` of `Tensor` objects with type `int64`.
		    1-D.  Shapes of each `SparseTensor`.
		  concat_dim: An `int`.
		    Dimension to concatenate along. Must be in range [-rank, rank),
		    where rank is the number of dimensions in each input `SparseTensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, output_shape).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor`. Has the same type as `values`.
		  output_shape: A `Tensor` of type `int64`.
	**/
	static public function SparseConcat(indices:Dynamic, values:Dynamic, shapes:Dynamic, concat_dim:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A conditional accumulator for aggregating sparse gradients.
		
		The accumulator accepts gradients marked with local_step greater or
		equal to the most recent global_step known to the accumulator. The
		average can be extracted from the accumulator, provided sufficient
		gradients have been accumulated. Extracting the average automatically
		resets the aggregate to 0, and increments the global_step recorded by
		the accumulator.
		
		Args:
		  dtype: A `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.complex64, tf.int64, tf.qint8, tf.quint8, tf.qint32, tf.bfloat16, tf.uint16, tf.complex128, tf.half, tf.uint32, tf.uint64`.
		    The type of the value being accumulated.
		  shape: A `tf.TensorShape` or list of `ints`. The shape of the values.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this accumulator is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this accumulator will be shared under the given name
		    across multiple sessions.
		  reduction_type: An optional `string` from: `"MEAN", "SUM"`. Defaults to `"MEAN"`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function SparseConditionalAccumulator(dtype:Dynamic, shape:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?reduction_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Performs sparse-output bin counting for a sparse tensor input.
		
		  Counts the number of times each value occurs in the input.
		
		Args:
		  indices: A `Tensor` of type `int64`.
		    Tensor containing the indices of the sparse tensor to count.
		  values: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Tensor containing values of the sparse tensor to count.
		  dense_shape: A `Tensor` of type `int64`.
		    Tensor containing the dense shape of the sparse tensor to count.
		  weights: A `Tensor`. Must be one of the following types: `int32`, `int64`, `float32`, `float64`.
		    A Tensor of the same shape as indices containing per-index weight values.
		    May also be the empty tensor if no weights are used.
		  binary_output: A `bool`.
		    Whether to output the number of occurrences of each value or 1.
		  minlength: An optional `int` that is `>= -1`. Defaults to `-1`.
		    Minimum value to count. Can be set to -1 for no minimum.
		  maxlength: An optional `int` that is `>= -1`. Defaults to `-1`.
		    Maximum value to count. Can be set to -1 for no maximum.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, output_dense_shape).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor`. Has the same type as `weights`.
		  output_dense_shape: A `Tensor` of type `int64`.
	**/
	static public function SparseCountSparseOutput(indices:Dynamic, values:Dynamic, dense_shape:Dynamic, weights:Dynamic, binary_output:Dynamic, ?minlength:Dynamic, ?maxlength:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates sparse cross from a list of sparse and dense tensors.
		
		The op takes two lists, one of 2D `SparseTensor` and one of 2D `Tensor`, each
		representing features of one feature column. It outputs a 2D `SparseTensor` with
		the batchwise crosses of these features.
		
		For example, if the inputs are
		
		    inputs[0]: SparseTensor with shape = [2, 2]
		    [0, 0]: "a"
		    [1, 0]: "b"
		    [1, 1]: "c"
		
		    inputs[1]: SparseTensor with shape = [2, 1]
		    [0, 0]: "d"
		    [1, 0]: "e"
		
		    inputs[2]: Tensor [["f"], ["g"]]
		
		then the output will be
		
		    shape = [2, 2]
		    [0, 0]: "a_X_d_X_f"
		    [1, 0]: "b_X_e_X_g"
		    [1, 1]: "c_X_e_X_g"
		
		if hashed_output=true then the output will be
		
		    shape = [2, 2]
		    [0, 0]: FingerprintCat64(
		                Fingerprint64("f"), FingerprintCat64(
		                    Fingerprint64("d"), Fingerprint64("a")))
		    [1, 0]: FingerprintCat64(
		                Fingerprint64("g"), FingerprintCat64(
		                    Fingerprint64("e"), Fingerprint64("b")))
		    [1, 1]: FingerprintCat64(
		                Fingerprint64("g"), FingerprintCat64(
		                    Fingerprint64("e"), Fingerprint64("c")))
		
		Args:
		  indices: A list of `Tensor` objects with type `int64`.
		    2-D.  Indices of each input `SparseTensor`.
		  values: A list of `Tensor` objects with types from: `int64`, `string`.
		    1-D.   values of each `SparseTensor`.
		  shapes: A list with the same length as `indices` of `Tensor` objects with type `int64`.
		    1-D.   Shapes of each `SparseTensor`.
		  dense_inputs: A list of `Tensor` objects with types from: `int64`, `string`.
		    2-D.    Columns represented by dense `Tensor`.
		  hashed_output: A `bool`.
		    If true, returns the hash of the cross instead of the string.
		    This will allow us avoiding string manipulations.
		  num_buckets: An `int` that is `>= 0`. It is used if hashed_output is true.
		    output = hashed_value%num_buckets if num_buckets > 0 else hashed_value.
		  hash_key: An `int`.
		    Specify the hash_key that will be used by the `FingerprintCat64`
		    function to combine the crosses fingerprints.
		  out_type: A `tf.DType` from: `tf.int64, tf.string`.
		  internal_type: A `tf.DType` from: `tf.int64, tf.string`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, output_shape).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor` of type `out_type`.
		  output_shape: A `Tensor` of type `int64`.
	**/
	static public function SparseCross(indices:Dynamic, values:Dynamic, shapes:Dynamic, dense_inputs:Dynamic, hashed_output:Dynamic, num_buckets:Dynamic, hash_key:Dynamic, out_type:Dynamic, internal_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates sparse cross from a list of sparse and dense tensors.
		
		The op takes two lists, one of 2D `SparseTensor` and one of 2D `Tensor`, each
		representing features of one feature column. It outputs a 2D `SparseTensor` with
		the batchwise crosses of these features.
		
		For example, if the inputs are
		
		    inputs[0]: SparseTensor with shape = [2, 2]
		    [0, 0]: "a"
		    [1, 0]: "b"
		    [1, 1]: "c"
		
		    inputs[1]: SparseTensor with shape = [2, 1]
		    [0, 0]: "d"
		    [1, 0]: "e"
		
		    inputs[2]: Tensor [["f"], ["g"]]
		
		then the output will be
		
		    shape = [2, 2]
		    [0, 0]: "a_X_d_X_f"
		    [1, 0]: "b_X_e_X_g"
		    [1, 1]: "c_X_e_X_g"
		
		if hashed_output=true then the output will be
		
		    shape = [2, 2]
		    [0, 0]: FingerprintCat64(
		                Fingerprint64("f"), FingerprintCat64(
		                    Fingerprint64("d"), Fingerprint64("a")))
		    [1, 0]: FingerprintCat64(
		                Fingerprint64("g"), FingerprintCat64(
		                    Fingerprint64("e"), Fingerprint64("b")))
		    [1, 1]: FingerprintCat64(
		                Fingerprint64("g"), FingerprintCat64(
		                    Fingerprint64("e"), Fingerprint64("c")))
		
		Args:
		  indices: A list of `Tensor` objects with type `int64`.
		    2-D.  Indices of each input `SparseTensor`.
		  values: A list of `Tensor` objects with types from: `int64`, `string`.
		    1-D.   values of each `SparseTensor`.
		  shapes: A list with the same length as `indices` of `Tensor` objects with type `int64`.
		    1-D.   Shapes of each `SparseTensor`.
		  dense_inputs: A list of `Tensor` objects with types from: `int64`, `string`.
		    2-D.    Columns represented by dense `Tensor`.
		  num_buckets: A `Tensor` of type `int64`.
		    It is used if hashed_output is true.
		    output = hashed_value%num_buckets if num_buckets > 0 else hashed_value.
		  strong_hash: A `Tensor` of type `bool`.
		    boolean, if true, siphash with salt will be used instead of farmhash.
		  salt: A `Tensor` of type `int64`.
		    Specify the salt that will be used by the siphash function.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, output_shape).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor` of type `int64`.
		  output_shape: A `Tensor` of type `int64`.
	**/
	static public function SparseCrossHashed(indices:Dynamic, values:Dynamic, shapes:Dynamic, dense_inputs:Dynamic, num_buckets:Dynamic, strong_hash:Dynamic, salt:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates sparse cross from a list of sparse and dense tensors.
		
		The op takes two lists, one of 2D `SparseTensor` and one of 2D `Tensor`, each
		representing features of one feature column. It outputs a 2D `SparseTensor` with
		the batchwise crosses of these features.
		
		For example, if the inputs are
		
		    inputs[0]: SparseTensor with shape = [2, 2]
		    [0, 0]: "a"
		    [1, 0]: "b"
		    [1, 1]: "c"
		
		    inputs[1]: SparseTensor with shape = [2, 1]
		    [0, 0]: "d"
		    [1, 0]: "e"
		
		    inputs[2]: Tensor [["f"], ["g"]]
		
		then the output will be
		
		    shape = [2, 2]
		    [0, 0]: "a_X_d_X_f"
		    [1, 0]: "b_X_e_X_g"
		    [1, 1]: "c_X_e_X_g"
		
		if hashed_output=true then the output will be
		
		    shape = [2, 2]
		    [0, 0]: FingerprintCat64(
		                Fingerprint64("f"), FingerprintCat64(
		                    Fingerprint64("d"), Fingerprint64("a")))
		    [1, 0]: FingerprintCat64(
		                Fingerprint64("g"), FingerprintCat64(
		                    Fingerprint64("e"), Fingerprint64("b")))
		    [1, 1]: FingerprintCat64(
		                Fingerprint64("g"), FingerprintCat64(
		                    Fingerprint64("e"), Fingerprint64("c")))
		
		Args:
		  indices: A list of `Tensor` objects with type `int64`.
		    2-D.  Indices of each input `SparseTensor`.
		  values: A list of `Tensor` objects with types from: `int64`, `string`.
		    1-D.   values of each `SparseTensor`.
		  shapes: A list with the same length as `indices` of `Tensor` objects with type `int64`.
		    1-D.   Shapes of each `SparseTensor`.
		  dense_inputs: A list of `Tensor` objects with types from: `int64`, `string`.
		    2-D.    Columns represented by dense `Tensor`.
		  sep: A `Tensor` of type `string`.
		    string used when joining a list of string inputs, can be used as separator later.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, output_shape).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor` of type `string`.
		  output_shape: A `Tensor` of type `int64`.
	**/
	static public function SparseCrossV2(indices:Dynamic, values:Dynamic, shapes:Dynamic, dense_inputs:Dynamic, sep:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adds up a SparseTensor and a dense Tensor, using these special rules:
		
		(1) Broadcasts the dense side to have the same shape as the sparse side, if
		    eligible;
		(2) Then, only the dense values pointed to by the indices of the SparseTensor
		    participate in the cwise addition.
		
		By these rules, the result is a logical SparseTensor with exactly the same
		indices and shape, but possibly with different non-zero values.  The output of
		this Op is the resultant non-zero values.
		
		Args:
		  sp_indices: A `Tensor` of type `int64`.
		    2-D.  `N x R` matrix with the indices of non-empty values in a
		    SparseTensor, possibly not in canonical ordering.
		  sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    1-D.  `N` non-empty values corresponding to `sp_indices`.
		  sp_shape: A `Tensor` of type `int64`.
		    1-D.  Shape of the input SparseTensor.
		  dense: A `Tensor`. Must have the same type as `sp_values`.
		    `R`-D.  The dense Tensor operand.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `sp_values`.
	**/
	static public function SparseDenseCwiseAdd(sp_indices:Dynamic, sp_values:Dynamic, sp_shape:Dynamic, dense:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Component-wise divides a SparseTensor by a dense Tensor.
		
		*Limitation*: this Op only broadcasts the dense side to the sparse side, but not
		the other direction.
		
		Args:
		  sp_indices: A `Tensor` of type `int64`.
		    2-D.  `N x R` matrix with the indices of non-empty values in a
		    SparseTensor, possibly not in canonical ordering.
		  sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    1-D.  `N` non-empty values corresponding to `sp_indices`.
		  sp_shape: A `Tensor` of type `int64`.
		    1-D.  Shape of the input SparseTensor.
		  dense: A `Tensor`. Must have the same type as `sp_values`.
		    `R`-D.  The dense Tensor operand.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `sp_values`.
	**/
	static public function SparseDenseCwiseDiv(sp_indices:Dynamic, sp_values:Dynamic, sp_shape:Dynamic, dense:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Component-wise multiplies a SparseTensor by a dense Tensor.
		
		The output locations corresponding to the implicitly zero elements in the sparse
		tensor will be zero (i.e., will not take up storage space), regardless of the
		contents of the dense tensor (even if it's +/-INF and that INF*0 == NaN).
		
		*Limitation*: this Op only broadcasts the dense side to the sparse side, but not
		the other direction.
		
		Args:
		  sp_indices: A `Tensor` of type `int64`.
		    2-D.  `N x R` matrix with the indices of non-empty values in a
		    SparseTensor, possibly not in canonical ordering.
		  sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    1-D.  `N` non-empty values corresponding to `sp_indices`.
		  sp_shape: A `Tensor` of type `int64`.
		    1-D.  Shape of the input SparseTensor.
		  dense: A `Tensor`. Must have the same type as `sp_values`.
		    `R`-D.  The dense Tensor operand.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `sp_values`.
	**/
	static public function SparseDenseCwiseMul(sp_indices:Dynamic, sp_values:Dynamic, sp_shape:Dynamic, dense:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Fills empty rows in the input 2-D `SparseTensor` with a default value.
		
		The input `SparseTensor` is represented via the tuple of inputs
		(`indices`, `values`, `dense_shape`).  The output `SparseTensor` has the
		same `dense_shape` but with indices `output_indices` and values
		`output_values`.
		
		This op inserts a single entry for every row that doesn't have any values.
		The index is created as `[row, 0, ..., 0]` and the inserted value
		is `default_value`.
		
		For example, suppose `sp_input` has shape `[5, 6]` and non-empty values:
		
		    [0, 1]: a
		    [0, 3]: b
		    [2, 0]: c
		    [3, 1]: d
		
		Rows 1 and 4 are empty, so the output will be of shape `[5, 6]` with values:
		
		    [0, 1]: a
		    [0, 3]: b
		    [1, 0]: default_value
		    [2, 0]: c
		    [3, 1]: d
		    [4, 0]: default_value
		
		The output `SparseTensor` will be in row-major order and will have the
		same shape as the input.
		
		This op also returns an indicator vector shaped `[dense_shape[0]]` such that
		
		    empty_row_indicator[i] = True iff row i was an empty row.
		
		And a reverse index map vector shaped `[indices.shape[0]]` that is used during
		backpropagation,
		
		    reverse_index_map[j] = out_j s.t. indices[j, :] == output_indices[out_j, :]
		
		Args:
		  indices: A `Tensor` of type `int64`.
		    2-D. the indices of the sparse tensor.
		  values: A `Tensor`. 1-D. the values of the sparse tensor.
		  dense_shape: A `Tensor` of type `int64`.
		    1-D. the shape of the sparse tensor.
		  default_value: A `Tensor`. Must have the same type as `values`.
		    0-D. default value to insert into location `[row, 0, ..., 0]`
		      for rows missing from the input sparse tensor.
		    output indices: 2-D. the indices of the filled sparse tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, empty_row_indicator, reverse_index_map).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor`. Has the same type as `values`.
		  empty_row_indicator: A `Tensor` of type `bool`.
		  reverse_index_map: A `Tensor` of type `int64`.
	**/
	static public function SparseFillEmptyRows(indices:Dynamic, values:Dynamic, dense_shape:Dynamic, default_value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		The gradient of SparseFillEmptyRows.
		
		Takes vectors reverse_index_map, shaped `[N]`, and grad_values,
		shaped `[N_full]`, where `N_full >= N` and copies data into either
		`d_values` or `d_default_value`.  Here `d_values` is shaped `[N]` and
		`d_default_value` is a scalar.
		
		  d_values[j] = grad_values[reverse_index_map[j]]
		  d_default_value = sum_{k : 0 .. N_full - 1} (
		     grad_values[k] * 1{k not in reverse_index_map})
		
		Args:
		  reverse_index_map: A `Tensor` of type `int64`.
		    1-D.  The reverse index map from SparseFillEmptyRows.
		  grad_values: A `Tensor`. 1-D.  The gradients from backprop.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (d_values, d_default_value).
		
		  d_values: A `Tensor`. Has the same type as `grad_values`.
		  d_default_value: A `Tensor`. Has the same type as `grad_values`.
	**/
	static public function SparseFillEmptyRowsGrad(reverse_index_map:Dynamic, grad_values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Multiply matrix "a" by matrix "b".
		
		The inputs must be two-dimensional matrices and the inner dimension of "a" must
		match the outer dimension of "b". Both "a" and "b" must be `Tensor`s not
		`SparseTensor`s.  This op is optimized for the case where at least one of "a" or
		"b" is sparse, in the sense that they have a large proportion of zero values.
		The breakeven for using this versus a dense matrix multiply on one platform was
		30% zero values in the sparse matrix.
		
		The gradient computation of this operation will only take advantage of sparsity
		in the input gradient when that gradient comes from a Relu.
		
		Args:
		  a: A `Tensor`. Must be one of the following types: `float32`, `bfloat16`.
		  b: A `Tensor`. Must be one of the following types: `float32`, `bfloat16`.
		  transpose_a: An optional `bool`. Defaults to `False`.
		  transpose_b: An optional `bool`. Defaults to `False`.
		  a_is_sparse: An optional `bool`. Defaults to `False`.
		  b_is_sparse: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function SparseMatMul(a:Dynamic, b:Dynamic, ?transpose_a:Dynamic, ?transpose_b:Dynamic, ?a_is_sparse:Dynamic, ?b_is_sparse:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Sparse addition of two CSR matrices, C = alpha * A + beta * B.
		
		The gradients of SparseMatrixAdd outputs with respect to alpha and beta are not
		currently defined (TensorFlow will return zeros for these entries).
		
		Args:
		  a: A `Tensor` of type `variant`. A CSRSparseMatrix.
		  b: A `Tensor` of type `variant`. A CSRSparseMatrix.
		  alpha: A `Tensor`. Must be one of the following types: `float32`, `float64`, `complex64`, `complex128`.
		    A constant scalar.
		  beta: A `Tensor`. Must have the same type as `alpha`. A constant scalar.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SparseMatrixAdd(a:Dynamic, b:Dynamic, alpha:Dynamic, beta:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Matrix-multiplies a sparse matrix with a dense matrix.
		
		Returns a dense matrix.
		For inputs A and B, where A is CSR and B is dense; this op returns a dense C;
		
		If transpose_output is false, returns:
		```
		  C = A . B
		```
		
		If transpose_output is `true`, returns:
		```
		  C = transpose(A . B) = transpose(B) . transpose(A)
		```
		where the transposition is performed along the two innermost (matrix)
		dimensions.
		
		If conjugate_output is `true`, returns:
		```
		  C = conjugate(A . B) = conjugate(A) . conjugate(B)
		```
		
		If both conjugate_output and transpose_output are `true`, returns:
		```
		  C = conjugate(transpose(A . B)) = conjugate(transpose(B)) .
		                                    conjugate(transpose(A))
		```
		
		Args:
		  a: A `Tensor` of type `variant`. A CSRSparseMatrix.
		  b: A `Tensor`. A dense tensor.
		  transpose_a: An optional `bool`. Defaults to `False`.
		    Indicates whether `a` should be transposed.
		  transpose_b: An optional `bool`. Defaults to `False`.
		    Indicates whether `b` should be transposed.
		  adjoint_a: An optional `bool`. Defaults to `False`.
		    Indicates whether `a` should be conjugate-transposed.
		  adjoint_b: An optional `bool`. Defaults to `False`.
		    Indicates whether `b` should be conjugate-transposed.
		  transpose_output: An optional `bool`. Defaults to `False`.
		    Transposes the product of `a` and `b`.
		  conjugate_output: An optional `bool`. Defaults to `False`.
		    Conjugates the product of `a` and `b`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `b`.
	**/
	static public function SparseMatrixMatMul(a:Dynamic, b:Dynamic, ?transpose_a:Dynamic, ?transpose_b:Dynamic, ?adjoint_a:Dynamic, ?adjoint_b:Dynamic, ?transpose_output:Dynamic, ?conjugate_output:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Element-wise multiplication of a sparse matrix with a dense tensor.
		
		Returns a sparse matrix.
		
		The dense tensor `b` may be either a scalar; otherwise `a` must be a rank-3
		`SparseMatrix`; in this case `b` must be shaped `[batch_size, 1, 1]` and the
		multiply operation broadcasts.
		
		**NOTE** even if `b` is zero, the sparsity structure of the output does not
		change.
		
		Args:
		  a: A `Tensor` of type `variant`. A CSRSparseMatrix.
		  b: A `Tensor`. A dense tensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SparseMatrixMul(a:Dynamic, b:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the number of nonzeroes of `sparse_matrix`.
		
		Args:
		  sparse_matrix: A `Tensor` of type `variant`. A CSRSparseMatrix.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function SparseMatrixNNZ(sparse_matrix:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the Approximate Minimum Degree (AMD) ordering of `input`.
		
		Computes the Approximate Minimum Degree (AMD) ordering for a sparse matrix.
		
		The returned permutation may be used to permute the rows and columns of the
		given sparse matrix. This typically results in permuted sparse matrix's sparse
		Cholesky (or other decompositions) in having fewer zero fill-in compared to
		decomposition of the original matrix.
		
		The input sparse matrix may have rank 2 or rank 3. The output Tensor,
		representing would then have rank 1 or 2 respectively, with the same batch
		shape as the input.
		
		Each component of the input sparse matrix must represent a square symmetric
		matrix; only the lower triangular part of the matrix is read. The values of the
		sparse matrix does not affect the returned permutation, only the sparsity
		pattern of the sparse matrix is used. Hence, a single AMD ordering may be
		reused for the Cholesky decompositions of sparse matrices with the same sparsity
		pattern but with possibly different values.
		
		Each batch component of the output permutation represents a permutation of `N`
		elements, where the input sparse matrix components each have `N` rows. That is,
		the component contains each of the integers `{0, .. N-1}` exactly once. The
		`i`th element represents the row index that the `i`th row maps to.
		
		Usage example:
		
		```python
		    from tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops
		
		    a_indices = np.array([[0, 0], [1, 1], [2, 1], [2, 2], [3, 3]])
		    a_values = np.array([1.0, 2.0, 1.0, 3.0, 4.0], np.float32)
		    a_dense_shape = [4, 4]
		
		    with tf.Session() as sess:
		      # Define (COO format) SparseTensor over Numpy array.
		      a_st = tf.sparse.SparseTensor(a_indices, a_values, a_dense_shape)
		
		      # Convert SparseTensors to CSR SparseMatrix.
		      a_sm = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(
		          a_st.indices, a_st.values, a_st.dense_shape)
		
		      # Obtain the AMD Ordering for the CSR SparseMatrix.
		      ordering_amd = sparse_csr_matrix_ops.sparse_matrix_ordering_amd(sparse_matrix)
		
		      ordering_amd_value = sess.run(ordering_amd)
		```
		
		`ordering_amd_value` stores the AMD ordering: `[1 2 3 0]`.
		
		input: A `CSRSparseMatrix`.
		
		Args:
		  input: A `Tensor` of type `variant`. A `CSRSparseMatrix`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function SparseMatrixOrderingAMD(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Calculates the softmax of a CSRSparseMatrix.
		
		Calculate the softmax of the innermost dimensions of a SparseMatrix.
		
		Missing values are treated as `-inf` (i.e., logits of zero probability); and
		the output has the same sparsity structure as the input (though missing values
		in the output may now be treated as having probability zero).
		
		Args:
		  logits: A `Tensor` of type `variant`. A CSRSparseMatrix.
		  type: A `tf.DType` from: `tf.float32, tf.float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SparseMatrixSoftmax(logits:Dynamic, type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Calculates the gradient of the SparseMatrixSoftmax op.
		
		Args:
		  softmax: A `Tensor` of type `variant`. A CSRSparseMatrix.
		  grad_softmax: A `Tensor` of type `variant`. The gradient of `softmax`.
		  type: A `tf.DType` from: `tf.float32, tf.float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SparseMatrixSoftmaxGrad(softmax:Dynamic, grad_softmax:Dynamic, type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the sparse Cholesky decomposition of `input`.
		
		Computes the Sparse Cholesky decomposition of a sparse matrix, with the given
		fill-in reducing permutation.
		
		The input sparse matrix and the fill-in reducing permutation `permutation` must
		have compatible shapes. If the sparse matrix has rank 3; with the batch
		dimension `B`, then the `permutation` must be of rank 2; with the same batch
		dimension `B`. There is no support for broadcasting.
		
		Furthermore, each component vector of `permutation` must be of length `N`,
		containing each of the integers {0, 1, ..., N - 1} exactly once, where `N` is
		the number of rows of each component of the sparse matrix.
		
		Each component of the input sparse matrix must represent a symmetric positive
		definite (SPD) matrix; although only the lower triangular part of the matrix is
		read. If any individual component is not SPD, then an InvalidArgument error is
		thrown.
		
		The returned sparse matrix has the same dense shape as the input sparse matrix.
		For each component `A` of the input sparse matrix, the corresponding output
		sparse matrix represents `L`, the lower triangular Cholesky factor satisfying
		the following identity:
		
		```
		  A = L * Lt
		```
		
		where Lt denotes the transpose of L (or its conjugate transpose, if `type` is
		`complex64` or `complex128`).
		
		The `type` parameter denotes the type of the matrix elements. The supported
		types are: `float32`, `float64`, `complex64` and `complex128`.
		
		Usage example:
		
		```python
		    from tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops
		
		    a_indices = np.array([[0, 0], [1, 1], [2, 1], [2, 2], [3, 3]])
		    a_values = np.array([1.0, 2.0, 1.0, 3.0, 4.0], np.float32)
		    a_dense_shape = [4, 4]
		
		    with tf.Session() as sess:
		      # Define (COO format) SparseTensor over Numpy array.
		      a_st = tf.sparse.SparseTensor(a_indices, a_values, a_dense_shape)
		
		      # Convert SparseTensors to CSR SparseMatrix.
		      a_sm = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(
		          a_st.indices, a_st.values, a_st.dense_shape)
		
		      # Obtain the Sparse Cholesky factor using AMD Ordering for reducing zero
		      # fill-in (number of structural non-zeros in the sparse Cholesky factor).
		      ordering_amd = sparse_csr_matrix_ops.sparse_matrix_ordering_amd(sparse_matrix)
		      cholesky_sparse_matrices = (
		          sparse_csr_matrix_ops.sparse_matrix_sparse_cholesky(
		              sparse_matrix, ordering_amd, type=tf.float32))
		
		      # Convert the CSRSparseMatrix Cholesky factor to a dense Tensor
		      dense_cholesky = sparse_csr_matrix_ops.csr_sparse_matrix_to_dense(
		          cholesky_sparse_matrices, tf.float32)
		
		      # Evaluate the dense Tensor value.
		      dense_cholesky_value = sess.run(dense_cholesky)
		```
		
		`dense_cholesky_value` stores the dense Cholesky factor:
		
		```
		    [[  1.  0.    0.    0.]
		     [  0.  1.41  0.    0.]
		     [  0.  0.70  1.58  0.]
		     [  0.  0.    0.    2.]]
		```
		
		
		input: A `CSRSparseMatrix`.
		permutation: A `Tensor`.
		type: The type of `input`.
		
		Args:
		  input: A `Tensor` of type `variant`. A `CSRSparseMatrix`.
		  permutation: A `Tensor` of type `int32`.
		    A fill-in reducing permutation matrix.
		  type: A `tf.DType` from: `tf.float32, tf.float64, tf.complex64, tf.complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SparseMatrixSparseCholesky(input:Dynamic, permutation:Dynamic, type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Sparse-matrix-multiplies two CSR matrices `a` and `b`.
		
		Performs a matrix multiplication of a sparse matrix `a` with a sparse matrix
		`b`; returns a sparse matrix `a * b`, unless either `a` or `b` is transposed or
		adjointed.
		
		Each matrix may be transposed or adjointed (conjugated and transposed)
		according to the Boolean parameters `transpose_a`, `adjoint_a`, `transpose_b`
		and `adjoint_b`. At most one of `transpose_a` or `adjoint_a` may be True.
		Similarly, at most one of `transpose_b` or `adjoint_b` may be True.
		
		The inputs must have compatible shapes. That is, the inner dimension of `a`
		must be equal to the outer dimension of `b`. This requirement is adjusted
		according to whether either `a` or `b` is transposed or adjointed.
		
		The `type` parameter denotes the type of the matrix elements. Both `a` and `b`
		must have the same type. The supported types are: `float32`, `float64`,
		`complex64` and `complex128`.
		
		Both `a` and `b` must have the same rank. Broadcasting is not supported. If they
		have rank 3, each batch of 2D CSRSparseMatrices within `a` and `b` must have the
		same dense shape.
		
		The sparse matrix product may have numeric (non-structural) zeros.
		TODO(anudhyan): Consider adding a boolean attribute to control whether to prune
		zeros.
		
		Usage example:
		
		```python
		    from tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops
		
		    a_indices = np.array([[0, 0], [2, 3], [2, 4], [3, 0]])
		    a_values = np.array([1.0, 5.0, -1.0, -2.0], np.float32)
		    a_dense_shape = [4, 5]
		
		    b_indices = np.array([[0, 0], [3, 0], [3, 1]])
		    b_values = np.array([2.0, 7.0, 8.0], np.float32)
		    b_dense_shape = [5, 3]
		
		    with tf.Session() as sess:
		      # Define (COO format) Sparse Tensors over Numpy arrays
		      a_st = tf.sparse.SparseTensor(a_indices, a_values, a_dense_shape)
		      b_st = tf.sparse.SparseTensor(b_indices, b_values, b_dense_shape)
		
		      # Convert SparseTensors to CSR SparseMatrix
		      a_sm = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(
		          a_st.indices, a_st.values, a_st.dense_shape)
		      b_sm = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(
		          b_st.indices, b_st.values, b_st.dense_shape)
		
		      # Compute the CSR SparseMatrix matrix multiplication
		      c_sm = sparse_csr_matrix_ops.sparse_matrix_sparse_mat_mul(
		          a=a_sm, b=b_sm, type=tf.float32)
		
		      # Convert the CSR SparseMatrix product to a dense Tensor
		      c_sm_dense = sparse_csr_matrix_ops.csr_sparse_matrix_to_dense(
		          c_sm, tf.float32)
		      # Evaluate the dense Tensor value
		      c_sm_dense_value = sess.run(c_sm_dense)
		```
		
		`c_sm_dense_value` stores the dense matrix product:
		
		```
		    [[  2.   0.   0.]
		     [  0.   0.   0.]
		     [ 35.  40.   0.]
		     [ -4.   0.   0.]]
		```
		
		a: A `CSRSparseMatrix`.
		b: A `CSRSparseMatrix` with the same type and rank as `a`.
		type: The type of both `a` and `b`.
		transpose_a: If True, `a` transposed before multiplication.
		transpose_b: If True, `b` transposed before multiplication.
		adjoint_a: If True, `a` adjointed before multiplication.
		adjoint_b: If True, `b` adjointed before multiplication.
		
		Args:
		  a: A `Tensor` of type `variant`. A CSRSparseMatrix.
		  b: A `Tensor` of type `variant`. A CSRSparseMatrix.
		  type: A `tf.DType` from: `tf.float32, tf.float64, tf.complex64, tf.complex128`.
		  transpose_a: An optional `bool`. Defaults to `False`.
		    Indicates whether `a` should be transposed.
		  transpose_b: An optional `bool`. Defaults to `False`.
		    Indicates whether `b` should be transposed.
		  adjoint_a: An optional `bool`. Defaults to `False`.
		    Indicates whether `a` should be conjugate-transposed.
		  adjoint_b: An optional `bool`. Defaults to `False`.
		    Indicates whether `b` should be conjugate-transposed.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SparseMatrixSparseMatMul(a:Dynamic, b:Dynamic, type:Dynamic, ?transpose_a:Dynamic, ?transpose_b:Dynamic, ?adjoint_a:Dynamic, ?adjoint_b:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transposes the inner (matrix) dimensions of a CSRSparseMatrix.
		
		Transposes the inner (matrix) dimensions of a SparseMatrix and optionally
		conjugates its values.
		
		Args:
		  input: A `Tensor` of type `variant`. A CSRSparseMatrix.
		  type: A `tf.DType` from: `tf.float32, tf.float64, tf.complex64, tf.complex128`.
		  conjugate: An optional `bool`. Defaults to `False`.
		    Indicates whether `input` should be conjugated.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SparseMatrixTranspose(input:Dynamic, type:Dynamic, ?conjugate:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates an all-zeros CSRSparseMatrix with shape `dense_shape`.
		
		Args:
		  dense_shape: A `Tensor` of type `int64`. The desired matrix shape.
		  type: A `tf.DType` from: `tf.float32, tf.float64, tf.complex64, tf.complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SparseMatrixZeros(dense_shape:Dynamic, type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the max of elements across dimensions of a SparseTensor.
		
		This Op takes a SparseTensor and is the sparse counterpart to
		`tf.reduce_max()`.  In particular, this Op also returns a dense `Tensor`
		instead of a sparse one.
		
		Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`reduction_axes`. If `keep_dims` is true, the reduced dimensions are retained
		with length 1.
		
		If `reduction_axes` has no entries, all dimensions are reduced, and a tensor
		with a single element is returned.  Additionally, the axes can be negative,
		which are interpreted according to the indexing rules in Python.
		
		Args:
		  input_indices: A `Tensor` of type `int64`.
		    2-D.  `N x R` matrix with the indices of non-empty values in a
		    SparseTensor, possibly not in canonical ordering.
		  input_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    1-D.  `N` non-empty values corresponding to `input_indices`.
		  input_shape: A `Tensor` of type `int64`.
		    1-D.  Shape of the input SparseTensor.
		  reduction_axes: A `Tensor` of type `int32`.
		    1-D.  Length-`K` vector containing the reduction axes.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input_values`.
	**/
	static public function SparseReduceMax(input_indices:Dynamic, input_values:Dynamic, input_shape:Dynamic, reduction_axes:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the max of elements across dimensions of a SparseTensor.
		
		This Op takes a SparseTensor and is the sparse counterpart to
		`tf.reduce_max()`.  In contrast to SparseReduceMax, this Op returns a
		SparseTensor.
		
		Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`reduction_axes`. If `keep_dims` is true, the reduced dimensions are retained
		with length 1.
		
		If `reduction_axes` has no entries, all dimensions are reduced, and a tensor
		with a single element is returned.  Additionally, the axes can be negative,
		which are interpreted according to the indexing rules in Python.
		
		Args:
		  input_indices: A `Tensor` of type `int64`.
		    2-D.  `N x R` matrix with the indices of non-empty values in a
		    SparseTensor, possibly not in canonical ordering.
		  input_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    1-D.  `N` non-empty values corresponding to `input_indices`.
		  input_shape: A `Tensor` of type `int64`.
		    1-D.  Shape of the input SparseTensor.
		  reduction_axes: A `Tensor` of type `int32`.
		    1-D.  Length-`K` vector containing the reduction axes.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, output_shape).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor`. Has the same type as `input_values`.
		  output_shape: A `Tensor` of type `int64`.
	**/
	static public function SparseReduceMaxSparse(input_indices:Dynamic, input_values:Dynamic, input_shape:Dynamic, reduction_axes:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the sum of elements across dimensions of a SparseTensor.
		
		This Op takes a SparseTensor and is the sparse counterpart to
		`tf.reduce_sum()`.  In particular, this Op also returns a dense `Tensor`
		instead of a sparse one.
		
		Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`reduction_axes`. If `keep_dims` is true, the reduced dimensions are retained
		with length 1.
		
		If `reduction_axes` has no entries, all dimensions are reduced, and a tensor
		with a single element is returned.  Additionally, the axes can be negative,
		which are interpreted according to the indexing rules in Python.
		
		Args:
		  input_indices: A `Tensor` of type `int64`.
		    2-D.  `N x R` matrix with the indices of non-empty values in a
		    SparseTensor, possibly not in canonical ordering.
		  input_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    1-D.  `N` non-empty values corresponding to `input_indices`.
		  input_shape: A `Tensor` of type `int64`.
		    1-D.  Shape of the input SparseTensor.
		  reduction_axes: A `Tensor` of type `int32`.
		    1-D.  Length-`K` vector containing the reduction axes.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input_values`.
	**/
	static public function SparseReduceSum(input_indices:Dynamic, input_values:Dynamic, input_shape:Dynamic, reduction_axes:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the sum of elements across dimensions of a SparseTensor.
		
		This Op takes a SparseTensor and is the sparse counterpart to
		`tf.reduce_sum()`.  In contrast to SparseReduceSum, this Op returns a
		SparseTensor.
		
		Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`reduction_axes`. If `keep_dims` is true, the reduced dimensions are retained
		with length 1.
		
		If `reduction_axes` has no entries, all dimensions are reduced, and a tensor
		with a single element is returned.  Additionally, the axes can be negative,
		which are interpreted according to the indexing rules in Python.
		
		Args:
		  input_indices: A `Tensor` of type `int64`.
		    2-D.  `N x R` matrix with the indices of non-empty values in a
		    SparseTensor, possibly not in canonical ordering.
		  input_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    1-D.  `N` non-empty values corresponding to `input_indices`.
		  input_shape: A `Tensor` of type `int64`.
		    1-D.  Shape of the input SparseTensor.
		  reduction_axes: A `Tensor` of type `int32`.
		    1-D.  Length-`K` vector containing the reduction axes.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, output_shape).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor`. Has the same type as `input_values`.
		  output_shape: A `Tensor` of type `int64`.
	**/
	static public function SparseReduceSumSparse(input_indices:Dynamic, input_values:Dynamic, input_shape:Dynamic, reduction_axes:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reorders a SparseTensor into the canonical, row-major ordering.
		
		Note that by convention, all sparse ops preserve the canonical ordering along
		increasing dimension number. The only time ordering can be violated is during
		manual manipulation of the indices and values vectors to add entries.
		
		Reordering does not affect the shape of the SparseTensor.
		
		If the tensor has rank `R` and `N` non-empty values, `input_indices` has
		shape `[N, R]`, input_values has length `N`, and input_shape has length `R`.
		
		Args:
		  input_indices: A `Tensor` of type `int64`.
		    2-D.  `N x R` matrix with the indices of non-empty values in a
		    SparseTensor, possibly not in canonical ordering.
		  input_values: A `Tensor`.
		    1-D.  `N` non-empty values corresponding to `input_indices`.
		  input_shape: A `Tensor` of type `int64`.
		    1-D.  Shape of the input SparseTensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor`. Has the same type as `input_values`.
	**/
	static public function SparseReorder(input_indices:Dynamic, input_values:Dynamic, input_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reshapes a SparseTensor to represent values in a new dense shape.
		
		This operation has the same semantics as reshape on the represented dense
		tensor.  The `input_indices` are recomputed based on the requested `new_shape`.
		
		If one component of `new_shape` is the special value -1, the size of that
		dimension is computed so that the total dense size remains constant.  At
		most one component of `new_shape` can be -1.  The number of dense elements
		implied by `new_shape` must be the same as the number of dense elements
		originally implied by `input_shape`.
		
		Reshaping does not affect the order of values in the SparseTensor.
		
		If the input tensor has rank `R_in` and `N` non-empty values, and `new_shape`
		has length `R_out`, then `input_indices` has shape `[N, R_in]`,
		`input_shape` has length `R_in`, `output_indices` has shape `[N, R_out]`, and
		`output_shape` has length `R_out`.
		
		Args:
		  input_indices: A `Tensor` of type `int64`.
		    2-D.  `N x R_in` matrix with the indices of non-empty values in a
		    SparseTensor.
		  input_shape: A `Tensor` of type `int64`.
		    1-D.  `R_in` vector with the input SparseTensor's dense shape.
		  new_shape: A `Tensor` of type `int64`.
		    1-D.  `R_out` vector with the requested new dense shape.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_shape).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_shape: A `Tensor` of type `int64`.
	**/
	static public function SparseReshape(input_indices:Dynamic, input_shape:Dynamic, new_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the mean along sparse segments of a tensor.
		
		See `tf.sparse.segment_sum` for usage examples.
		
		Like `SegmentMean`, but `segment_ids` can have rank less than `data`'s first
		dimension, selecting a subset of dimension 0, specified by `indices`.
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Has same rank as `segment_ids`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Values should be sorted and can be repeated.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function SparseSegmentMean(data:Dynamic, indices:Dynamic, segment_ids:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradients for SparseSegmentMean.
		
		Returns tensor "output" with same shape as grad, except for dimension 0 whose
		value is output_dim0.
		
		Args:
		  grad: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		    gradient propagated to the SparseSegmentMean op.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    indices passed to the corresponding SparseSegmentMean op.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    segment_ids passed to the corresponding SparseSegmentMean op.
		  output_dim0: A `Tensor` of type `int32`.
		    dimension 0 of "data" passed to SparseSegmentMean op.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `grad`.
	**/
	static public function SparseSegmentMeanGrad(grad:Dynamic, indices:Dynamic, segment_ids:Dynamic, output_dim0:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the mean along sparse segments of a tensor.
		
		Like `SparseSegmentMean`, but allows missing ids in `segment_ids`. If an id is
		missing, the `output` tensor at that position will be zeroed.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Has same rank as `segment_ids`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Values should be sorted and can be repeated.
		  num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Should equal the number of distinct segment IDs.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function SparseSegmentMeanWithNumSegments(data:Dynamic, indices:Dynamic, segment_ids:Dynamic, num_segments:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the sum along sparse segments of a tensor divided by the sqrt of N.
		
		N is the size of the segment being reduced.
		
		See `tf.sparse.segment_sum` for usage examples.
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Has same rank as `segment_ids`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Values should be sorted and can be repeated.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function SparseSegmentSqrtN(data:Dynamic, indices:Dynamic, segment_ids:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradients for SparseSegmentSqrtN.
		
		Returns tensor "output" with same shape as grad, except for dimension 0 whose
		value is output_dim0.
		
		Args:
		  grad: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		    gradient propagated to the SparseSegmentSqrtN op.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    indices passed to the corresponding SparseSegmentSqrtN op.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    segment_ids passed to the corresponding SparseSegmentSqrtN op.
		  output_dim0: A `Tensor` of type `int32`.
		    dimension 0 of "data" passed to SparseSegmentSqrtN op.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `grad`.
	**/
	static public function SparseSegmentSqrtNGrad(grad:Dynamic, indices:Dynamic, segment_ids:Dynamic, output_dim0:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the sum along sparse segments of a tensor divided by the sqrt of N.
		
		N is the size of the segment being reduced.
		
		Like `SparseSegmentSqrtN`, but allows missing ids in `segment_ids`. If an id is
		missing, the `output` tensor at that position will be zeroed.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Has same rank as `segment_ids`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Values should be sorted and can be repeated.
		  num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Should equal the number of distinct segment IDs.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function SparseSegmentSqrtNWithNumSegments(data:Dynamic, indices:Dynamic, segment_ids:Dynamic, num_segments:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the sum along sparse segments of a tensor.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		Like `SegmentSum`, but `segment_ids` can have rank less than `data`'s first
		dimension, selecting a subset of dimension 0, specified by `indices`.
		
		For example:
		
		```python
		c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])
		
		# Select two rows, one segment.
		tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0]))
		# => [[0 0 0 0]]
		
		# Select two rows, two segment.
		tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 1]))
		# => [[ 1  2  3  4]
		#     [-1 -2 -3 -4]]
		
		# Select all rows, two segments.
		tf.sparse_segment_sum(c, tf.constant([0, 1, 2]), tf.constant([0, 0, 1]))
		# => [[0 0 0 0]
		#     [5 6 7 8]]
		
		# Which is equivalent to:
		tf.segment_sum(c, tf.constant([0, 0, 1]))
		```
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Has same rank as `segment_ids`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Values should be sorted and can be repeated.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function SparseSegmentSum(data:Dynamic, indices:Dynamic, segment_ids:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes gradients for SparseSegmentSum.
		
		Returns tensor "output" with same shape as grad, except for dimension 0 whose
		value is output_dim0.
		
		Args:
		  grad: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		    gradient propagated to the SparseSegmentSum op.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    indices passed to the corresponding SparseSegmentSum op.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    segment_ids passed to the corresponding SparseSegmentSum op.
		  output_dim0: A `Tensor` of type `int32`.
		    dimension 0 of "data" passed to SparseSegmentSum op.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `grad`.
	**/
	static public function SparseSegmentSumGrad(grad:Dynamic, indices:Dynamic, segment_ids:Dynamic, output_dim0:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the sum along sparse segments of a tensor.
		
		Like `SparseSegmentSum`, but allows missing ids in `segment_ids`. If an id is
		missing, the `output` tensor at that position will be zeroed.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/sparse#Segmentation)
		for an explanation of segments.
		
		For example:
		
		```python
		c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])
		
		tf.sparse_segment_sum_with_num_segments(
		    c, tf.constant([0, 1]), tf.constant([0, 0]), num_segments=3)
		# => [[0 0 0 0]
		#     [0 0 0 0]
		#     [0 0 0 0]]
		
		tf.sparse_segment_sum_with_num_segments(c,
		                                        tf.constant([0, 1]),
		                                        tf.constant([0, 2],
		                                        num_segments=4))
		# => [[ 1  2  3  4]
		#     [ 0  0  0  0]
		#     [-1 -2 -3 -4]
		#     [ 0  0  0  0]]
		```
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Has same rank as `segment_ids`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1-D tensor. Values should be sorted and can be repeated.
		  num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Should equal the number of distinct segment IDs.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function SparseSegmentSumWithNumSegments(data:Dynamic, indices:Dynamic, segment_ids:Dynamic, num_segments:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Slice a `SparseTensor` based on the `start` and `size`.
		
		For example, if the input is
		
		    input_tensor = shape = [2, 7]
		    [    a   d e  ]
		    [b c          ]
		
		Graphically the output tensors are:
		
		    sparse_slice([0, 0], [2, 4]) = shape = [2, 4]
		    [    a  ]
		    [b c    ]
		
		    sparse_slice([0, 4], [2, 3]) = shape = [2, 3]
		    [ d e  ]
		    [      ]
		
		Args:
		  indices: A `Tensor` of type `int64`.
		    2-D tensor represents the indices of the sparse tensor.
		  values: A `Tensor`. 1-D tensor represents the values of the sparse tensor.
		  shape: A `Tensor` of type `int64`.
		    1-D. tensor represents the shape of the sparse tensor.
		  start: A `Tensor` of type `int64`.
		    1-D. tensor represents the start of the slice.
		  size: A `Tensor` of type `int64`.
		    1-D. tensor represents the size of the slice.
		    output indices: A list of 1-D tensors represents the indices of the output
		    sparse tensors.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, output_shape).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor`. Has the same type as `values`.
		  output_shape: A `Tensor` of type `int64`.
	**/
	static public function SparseSlice(indices:Dynamic, values:Dynamic, shape:Dynamic, start:Dynamic, size:Dynamic, ?name:Dynamic):Dynamic;
	/**
		The gradient operator for the SparseSlice op.
		
		This op takes in the upstream gradient w.r.t. non-empty values of
		the sliced `SparseTensor`, and outputs the gradients w.r.t.
		the non-empty values of input `SparseTensor`.
		
		Args:
		  backprop_val_grad: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    1-D. The gradient with respect to
		    the non-empty values of the sliced `SparseTensor`.
		  input_indices: A `Tensor` of type `int64`.
		    2-D.  The `indices` of the input `SparseTensor`.
		  input_start: A `Tensor` of type `int64`.
		    1-D. tensor represents the start of the slice.
		  output_indices: A `Tensor` of type `int64`.
		    2-D.  The `indices` of the sliced `SparseTensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `backprop_val_grad`.
	**/
	static public function SparseSliceGrad(backprop_val_grad:Dynamic, input_indices:Dynamic, input_start:Dynamic, output_indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies softmax to a batched N-D `SparseTensor`.
		
		The inputs represent an N-D SparseTensor  with logical shape `[..., B, C]`
		(where `N >= 2`), and with indices sorted in the canonical lexicographic order.
		
		This op is equivalent to applying the normal `tf.nn.softmax()` to each innermost
		logical submatrix with shape `[B, C]`, but with the catch that *the implicitly
		zero elements do not participate*.  Specifically, the algorithm is equivalent
		to the following:
		
		  (1) Applies `tf.nn.softmax()` to a densified view of each innermost submatrix
		      with shape `[B, C]`, along the size-C dimension;
		  (2) Masks out the original implicitly-zero locations;
		  (3) Renormalizes the remaining elements.
		
		Hence, the `SparseTensor` result has exactly the same non-zero indices and
		shape.
		
		Args:
		  sp_indices: A `Tensor` of type `int64`.
		    2-D.  `NNZ x R` matrix with the indices of non-empty values in a
		    SparseTensor, in canonical ordering.
		  sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		    1-D.  `NNZ` non-empty values corresponding to `sp_indices`.
		  sp_shape: A `Tensor` of type `int64`.
		    1-D.  Shape of the input SparseTensor.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `sp_values`.
	**/
	static public function SparseSoftmax(sp_indices:Dynamic, sp_values:Dynamic, sp_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes softmax cross entropy cost and gradients to backpropagate.
		
		Unlike `SoftmaxCrossEntropyWithLogits`, this operation does not accept
		a matrix of label probabilities, but rather a single label per row
		of features.  This label is considered to have probability 1.0 for the
		given row.
		
		Inputs are the logits, not probabilities.
		
		Args:
		  features: A `Tensor`. Must be one of the following types: `half`, `bfloat16`, `float32`, `float64`.
		    batch_size x num_classes matrix
		  labels: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    batch_size vector with values in [0, num_classes).
		    This is the label for the given minibatch entry.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (loss, backprop).
		
		  loss: A `Tensor`. Has the same type as `features`.
		  backprop: A `Tensor`. Has the same type as `features`.
	**/
	static public function SparseSoftmaxCrossEntropyWithLogits(features:Dynamic, labels:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the element-wise max of two SparseTensors.
		
		Assumes the two SparseTensors have the same shape, i.e., no broadcasting.
		
		Args:
		  a_indices: A `Tensor` of type `int64`.
		    2-D.  `N x R` matrix with the indices of non-empty values in a
		    SparseTensor, in the canonical lexicographic ordering.
		  a_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    1-D.  `N` non-empty values corresponding to `a_indices`.
		  a_shape: A `Tensor` of type `int64`.
		    1-D.  Shape of the input SparseTensor.
		  b_indices: A `Tensor` of type `int64`.
		    counterpart to `a_indices` for the other operand.
		  b_values: A `Tensor`. Must have the same type as `a_values`.
		    counterpart to `a_values` for the other operand; must be of the same dtype.
		  b_shape: A `Tensor` of type `int64`.
		    counterpart to `a_shape` for the other operand; the two shapes must be equal.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor`. Has the same type as `a_values`.
	**/
	static public function SparseSparseMaximum(a_indices:Dynamic, a_values:Dynamic, a_shape:Dynamic, b_indices:Dynamic, b_values:Dynamic, b_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the element-wise min of two SparseTensors.
		
		Assumes the two SparseTensors have the same shape, i.e., no broadcasting.
		
		Args:
		  a_indices: A `Tensor` of type `int64`.
		    2-D.  `N x R` matrix with the indices of non-empty values in a
		    SparseTensor, in the canonical lexicographic ordering.
		  a_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    1-D.  `N` non-empty values corresponding to `a_indices`.
		  a_shape: A `Tensor` of type `int64`.
		    1-D.  Shape of the input SparseTensor.
		  b_indices: A `Tensor` of type `int64`.
		    counterpart to `a_indices` for the other operand.
		  b_values: A `Tensor`. Must have the same type as `a_values`.
		    counterpart to `a_values` for the other operand; must be of the same dtype.
		  b_shape: A `Tensor` of type `int64`.
		    counterpart to `a_shape` for the other operand; the two shapes must be equal.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values).
		
		  output_indices: A `Tensor` of type `int64`.
		  output_values: A `Tensor`. Has the same type as `a_values`.
	**/
	static public function SparseSparseMinimum(a_indices:Dynamic, a_values:Dynamic, a_shape:Dynamic, b_indices:Dynamic, b_values:Dynamic, b_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Split a `SparseTensor` into `num_split` tensors along one dimension.
		
		If the `shape[split_dim]` is not an integer multiple of `num_split`. Slices
		`[0 : shape[split_dim] % num_split]` gets one extra dimension.
		For example, if `split_dim = 1` and `num_split = 2` and the input is
		
		    input_tensor = shape = [2, 7]
		    [    a   d e  ]
		    [b c          ]
		
		Graphically the output tensors are:
		
		    output_tensor[0] = shape = [2, 4]
		    [    a  ]
		    [b c    ]
		
		    output_tensor[1] = shape = [2, 3]
		    [ d e  ]
		    [      ]
		
		Args:
		  split_dim: A `Tensor` of type `int64`.
		    0-D.  The dimension along which to split.  Must be in the range
		    `[0, rank(shape))`.
		  indices: A `Tensor` of type `int64`.
		    2-D tensor represents the indices of the sparse tensor.
		  values: A `Tensor`. 1-D tensor represents the values of the sparse tensor.
		  shape: A `Tensor` of type `int64`.
		    1-D. tensor represents the shape of the sparse tensor.
		    output indices: A list of 1-D tensors represents the indices of the output
		    sparse tensors.
		  num_split: An `int` that is `>= 1`. The number of ways to split.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_indices, output_values, output_shape).
		
		  output_indices: A list of `num_split` `Tensor` objects with type `int64`.
		  output_values: A list of `num_split` `Tensor` objects with the same type as `values`.
		  output_shape: A list of `num_split` `Tensor` objects with type `int64`.
	**/
	static public function SparseSplit(split_dim:Dynamic, indices:Dynamic, values:Dynamic, shape:Dynamic, num_split:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adds up a `SparseTensor` and a dense `Tensor`, producing a dense `Tensor`.
		
		This Op does not require `a_indices` be sorted in standard lexicographic order.
		
		Args:
		  a_indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2-D.  The `indices` of the `SparseTensor`, with shape `[nnz, ndims]`.
		  a_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    1-D.  The `values` of the `SparseTensor`, with shape `[nnz]`.
		  a_shape: A `Tensor`. Must have the same type as `a_indices`.
		    1-D.  The `shape` of the `SparseTensor`, with shape `[ndims]`.
		  b: A `Tensor`. Must have the same type as `a_values`.
		    `ndims`-D Tensor.  With shape `a_shape`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `a_values`.
	**/
	static public function SparseTensorDenseAdd(a_indices:Dynamic, a_values:Dynamic, a_shape:Dynamic, b:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Multiply SparseTensor (of rank 2) "A" by dense matrix "B".
		
		No validity checking is performed on the indices of A.  However, the following
		input format is recommended for optimal behavior:
		
		if adjoint_a == false:
		  A should be sorted in lexicographically increasing order.  Use SparseReorder
		  if you're not sure.
		if adjoint_a == true:
		  A should be sorted in order of increasing dimension 1 (i.e., "column major"
		  order instead of "row major" order).
		
		Args:
		  a_indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2-D.  The `indices` of the `SparseTensor`, size `[nnz, 2]` Matrix.
		  a_values: A `Tensor`.
		    1-D.  The `values` of the `SparseTensor`, size `[nnz]` Vector.
		  a_shape: A `Tensor` of type `int64`.
		    1-D.  The `shape` of the `SparseTensor`, size `[2]` Vector.
		  b: A `Tensor`. Must have the same type as `a_values`.
		    2-D.  A dense Matrix.
		  adjoint_a: An optional `bool`. Defaults to `False`.
		    Use the adjoint of A in the matrix multiply.  If A is complex, this
		    is transpose(conj(A)).  Otherwise it's transpose(A).
		  adjoint_b: An optional `bool`. Defaults to `False`.
		    Use the adjoint of B in the matrix multiply.  If B is complex, this
		    is transpose(conj(B)).  Otherwise it's transpose(B).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `a_values`.
	**/
	static public function SparseTensorDenseMatMul(a_indices:Dynamic, a_values:Dynamic, a_shape:Dynamic, b:Dynamic, ?adjoint_a:Dynamic, ?adjoint_b:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that splits a SparseTensor into elements row-wise.
		
		Args:
		  indices: A `Tensor` of type `int64`.
		  values: A `Tensor`.
		  dense_shape: A `Tensor` of type `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SparseTensorSliceDataset(indices:Dynamic, values:Dynamic, dense_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts a SparseTensor to a (possibly batched) CSRSparseMatrix.
		
		Args:
		  indices: A `Tensor` of type `int64`. SparseTensor indices.
		  values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `complex64`, `complex128`.
		    SparseTensor values.
		  dense_shape: A `Tensor` of type `int64`. SparseTensor dense shape.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SparseTensorToCSRSparseMatrix(indices:Dynamic, values:Dynamic, dense_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts a sparse representation into a dense tensor.
		
		Builds an array `dense` with shape `output_shape` such that
		
		```
		# If sparse_indices is scalar
		dense[i] = (i == sparse_indices ? sparse_values : default_value)
		
		# If sparse_indices is a vector, then for each i
		dense[sparse_indices[i]] = sparse_values[i]
		
		# If sparse_indices is an n by d matrix, then for each i in [0, n)
		dense[sparse_indices[i][0], ..., sparse_indices[i][d-1]] = sparse_values[i]
		```
		
		All other values in `dense` are set to `default_value`.  If `sparse_values` is a
		scalar, all sparse indices are set to this single value.
		
		Indices should be sorted in lexicographic order, and indices must not
		contain any repeats. If `validate_indices` is true, these properties
		are checked during execution.
		
		Args:
		  sparse_indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    0-D, 1-D, or 2-D.  `sparse_indices[i]` contains the complete
		    index where `sparse_values[i]` will be placed.
		  output_shape: A `Tensor`. Must have the same type as `sparse_indices`.
		    1-D.  Shape of the dense output tensor.
		  sparse_values: A `Tensor`.
		    1-D.  Values corresponding to each row of `sparse_indices`,
		    or a scalar value to be used for all sparse indices.
		  default_value: A `Tensor`. Must have the same type as `sparse_values`.
		    Scalar value to set for indices not specified in
		    `sparse_indices`.
		  validate_indices: An optional `bool`. Defaults to `True`.
		    If true, indices are checked to make sure they are sorted in
		    lexicographic order and that there are no repeats.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `sparse_values`.
	**/
	static public function SparseToDense(sparse_indices:Dynamic, output_shape:Dynamic, sparse_values:Dynamic, default_value:Dynamic, ?validate_indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies set operation along last dimension of 2 `SparseTensor` inputs.
		
		See SetOperationOp::SetOperationFromContext for values of `set_operation`.
		
		If `validate_indices` is `True`, `SparseToSparseSetOperation` validates the
		order and range of `set1` and `set2` indices.
		
		Input `set1` is a `SparseTensor` represented by `set1_indices`, `set1_values`,
		and `set1_shape`. For `set1` ranked `n`, 1st `n-1` dimensions must be the same
		as `set2`. Dimension `n` contains values in a set, duplicates are allowed but
		ignored.
		
		Input `set2` is a `SparseTensor` represented by `set2_indices`, `set2_values`,
		and `set2_shape`. For `set2` ranked `n`, 1st `n-1` dimensions must be the same
		as `set1`. Dimension `n` contains values in a set, duplicates are allowed but
		ignored.
		
		If `validate_indices` is `True`, this op validates the order and range of `set1`
		and `set2` indices.
		
		Output `result` is a `SparseTensor` represented by `result_indices`,
		`result_values`, and `result_shape`. For `set1` and `set2` ranked `n`, this
		has rank `n` and the same 1st `n-1` dimensions as `set1` and `set2`. The `nth`
		dimension contains the result of `set_operation` applied to the corresponding
		`[0...n-1]` dimension of `set`.
		
		Args:
		  set1_indices: A `Tensor` of type `int64`.
		    2D `Tensor`, indices of a `SparseTensor`. Must be in row-major
		    order.
		  set1_values: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `string`.
		    1D `Tensor`, values of a `SparseTensor`. Must be in row-major
		    order.
		  set1_shape: A `Tensor` of type `int64`.
		    1D `Tensor`, shape of a `SparseTensor`. `set1_shape[0...n-1]` must
		    be the same as `set2_shape[0...n-1]`, `set1_shape[n]` is the
		    max set size across `0...n-1` dimensions.
		  set2_indices: A `Tensor` of type `int64`.
		    2D `Tensor`, indices of a `SparseTensor`. Must be in row-major
		    order.
		  set2_values: A `Tensor`. Must have the same type as `set1_values`.
		    1D `Tensor`, values of a `SparseTensor`. Must be in row-major
		    order.
		  set2_shape: A `Tensor` of type `int64`.
		    1D `Tensor`, shape of a `SparseTensor`. `set2_shape[0...n-1]` must
		    be the same as `set1_shape[0...n-1]`, `set2_shape[n]` is the
		    max set size across `0...n-1` dimensions.
		  set_operation: A `string`.
		  validate_indices: An optional `bool`. Defaults to `True`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (result_indices, result_values, result_shape).
		
		  result_indices: A `Tensor` of type `int64`.
		  result_values: A `Tensor`. Has the same type as `set1_values`.
		  result_shape: A `Tensor` of type `int64`.
	**/
	static public function SparseToSparseSetOperation(set1_indices:Dynamic, set1_values:Dynamic, set1_shape:Dynamic, set2_indices:Dynamic, set2_values:Dynamic, set2_shape:Dynamic, set_operation:Dynamic, ?validate_indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Spence(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Splits a tensor into `num_split` tensors along one dimension.
		
		Args:
		  axis: A `Tensor` of type `int32`.
		    0-D.  The dimension along which to split.  Must be in the range
		    `[-rank(value), rank(value))`.
		  value: A `Tensor`. The tensor to split.
		  num_split: An `int` that is `>= 1`.
		    The number of ways to split.  Must evenly divide
		    `value.shape[split_dim]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `num_split` `Tensor` objects with the same type as `value`.
	**/
	static public function Split(axis:Dynamic, value:Dynamic, num_split:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Splits a tensor into `num_split` tensors along one dimension.
		
		Args:
		  value: A `Tensor`. The tensor to split.
		  size_splits: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    list containing the sizes of each output tensor along the split
		    dimension. Must sum to the dimension of value along split_dim.
		    Can contain one -1 indicating that dimension is to be inferred.
		  axis: A `Tensor` of type `int32`.
		    0-D.  The dimension along which to split.  Must be in the range
		    `[-rank(value), rank(value))`.
		  num_split: An `int` that is `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `num_split` `Tensor` objects with the same type as `value`.
	**/
	static public function SplitV(value:Dynamic, size_splits:Dynamic, axis:Dynamic, num_split:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that executes a SQL query and emits rows of the result set.
		
		Args:
		  driver_name: A `Tensor` of type `string`.
		    The database type. Currently, the only supported type is 'sqlite'.
		  data_source_name: A `Tensor` of type `string`.
		    A connection string to connect to the database.
		  query: A `Tensor` of type `string`. A SQL query to execute.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function SqlDataset(driver_name:Dynamic, data_source_name:Dynamic, query:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes square root of x element-wise.
		
		I.e., \\(y = \sqrt{x} = x^{1/2}\\).
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Sqrt(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient for the sqrt of `x` wrt its input.
		
		Specifically, `grad = dy * 0.5 / y`, where `y = sqrt(x)`, and `dy`
		is the corresponding input gradient.
		
		Args:
		  y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  dy: A `Tensor`. Must have the same type as `y`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `y`.
	**/
	static public function SqrtGrad(y:Dynamic, dy:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes square of x element-wise.
		
		I.e., \\(y = x * x = x^2\\).
		
		>>> tf.math.square([-2., 0., 3.])
		<tf.Tensor: shape=(3,), dtype=float32, numpy=array([4., 0., 9.], dtype=float32)>
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Square(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns conj(x - y)(x - y) element-wise.
		
		*NOTE*: `math.squared_difference` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function SquaredDifference(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Removes dimensions of size 1 from the shape of a tensor.
		
		Given a tensor `input`, this operation returns a tensor of the same type with
		all dimensions of size 1 removed. If you don't want to remove all size 1
		dimensions, you can remove specific size 1 dimensions by specifying
		`axis`.
		
		For example:
		
		```
		# 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
		shape(squeeze(t)) ==> [2, 3]
		```
		
		Or, to remove specific size 1 dimensions:
		
		```
		# 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
		shape(squeeze(t, [2, 4])) ==> [1, 2, 3, 1]
		```
		
		Args:
		  input: A `Tensor`. The `input` to squeeze.
		  axis: An optional list of `ints`. Defaults to `[]`.
		    If specified, only squeezes the dimensions listed. The dimension
		    index starts at 0. It is an error to squeeze a dimension that is not 1. Must
		    be in the range `[-rank(input), rank(input))`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Squeeze(input:Dynamic, ?axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated, use StackV2.
		
		Args:
		  elem_type: A `tf.DType`.
		  stack_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function Stack(elem_type:Dynamic, ?stack_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated, use StackCloseV2.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function StackClose(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Delete the stack from its resource container.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a stack.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function StackCloseV2(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated, use StackPopV2.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  elem_type: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `elem_type`.
	**/
	static public function StackPop(handle:Dynamic, elem_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Pop the element at the top of the stack.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a stack.
		  elem_type: A `tf.DType`. The type of the elem that is popped.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `elem_type`.
	**/
	static public function StackPopV2(handle:Dynamic, elem_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated, use StackPushV2.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  elem: A `Tensor`.
		  swap_memory: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `elem`.
	**/
	static public function StackPush(handle:Dynamic, elem:Dynamic, ?swap_memory:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Push an element onto the stack.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a stack.
		  elem: A `Tensor`. The tensor to be pushed onto the stack.
		  swap_memory: An optional `bool`. Defaults to `False`.
		    Swap `elem` to CPU. Default to false.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `elem`.
	**/
	static public function StackPushV2(handle:Dynamic, elem:Dynamic, ?swap_memory:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A stack that produces elements in first-in last-out order.
		
		Args:
		  max_size: A `Tensor` of type `int32`.
		    The maximum size of the stack if non-negative. If negative, the stack
		    size is unlimited.
		  elem_type: A `tf.DType`. The type of the elements on the stack.
		  stack_name: An optional `string`. Defaults to `""`.
		    Overrides the name used for the temporary stack resource. Default
		    value is the name of the 'Stack' op (which is guaranteed unique).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function StackV2(max_size:Dynamic, elem_type:Dynamic, ?stack_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Stage values similar to a lightweight Enqueue.
		
		The basic functionality of this Op is similar to a queue with many
		fewer capabilities and options.  This Op is optimized for performance.
		
		Args:
		  values: A list of `Tensor` objects. a list of tensors
		    dtypes A list of data types that inserted values should adhere to.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		    Maximum number of elements in the Staging Area. If > 0, inserts
		    on the container will block when the capacity is reached.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		    The maximum number of bytes allowed for Tensors in the Staging Area.
		    If > 0, inserts will block until sufficient space is available.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this queue is placed in the given container. Otherwise,
		    a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    It is necessary to match this name to the matching Unstage Op.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function Stage(values:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op removes all elements in the underlying container.
		
		Args:
		  dtypes: A list of `tf.DTypes`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function StageClear(dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op peeks at the values at the specified index.  If the
		
		underlying container does not contain sufficient elements
		this op will block until it does.   This Op is optimized for
		performance.
		
		Args:
		  index: A `Tensor` of type `int32`.
		  dtypes: A list of `tf.DTypes` that has length `>= 1`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `dtypes`.
	**/
	static public function StagePeek(index:Dynamic, dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op returns the number of elements in the underlying container.
		
		Args:
		  dtypes: A list of `tf.DTypes`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function StageSize(dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		returns `f(inputs)`, where `f`'s body is placed and partitioned.
		
		Args:
		  args: A list of `Tensor` objects. A list of input tensors.
		  Tout: A list of `tf.DTypes`. A list of output types.
		  f: A function decorated with @Defun.
		          A function that takes 'args', a list of tensors, and returns 'output',
		          another list of tensors. Input and output types are specified by 'Tin'
		          and 'Tout'. The function body of f will be placed and partitioned across
		          devices, setting this op apart from the regular Call op. This op is
		          stateful.
		  config: An optional `string`. Defaults to `""`.
		  config_proto: An optional `string`. Defaults to `""`.
		  executor_type: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function StatefulPartitionedCall(args:Dynamic, Tout:Dynamic, f:Dynamic, ?config:Dynamic, ?config_proto:Dynamic, ?executor_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		  algorithm: A `Tensor` of type `int64`.
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  counts: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `int32`, `int64`.
		  probs: A `Tensor`. Must have the same type as `counts`.
		  dtype: An optional `tf.DType` from: `tf.half, tf.float32, tf.float64, tf.int32, tf.int64`. Defaults to `tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatefulRandomBinomial(resource:Dynamic, algorithm:Dynamic, shape:Dynamic, counts:Dynamic, probs:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random values from a normal distribution. This op is deprecated in favor of op 'StatefulStandardNormalV2'
		
		The generated values will have mean 0 and standard deviation 1.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    The handle of the resource variable that stores the state of the RNG.
		  shape: A `Tensor`. The shape of the output tensor.
		  dtype: An optional `tf.DType`. Defaults to `tf.float32`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatefulStandardNormal(resource:Dynamic, shape:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random values from a normal distribution.
		
		The generated values will have mean 0 and standard deviation 1.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    The handle of the resource variable that stores the state of the RNG.
		  algorithm: A `Tensor` of type `int64`. The RNG algorithm.
		  shape: A `Tensor`. The shape of the output tensor.
		  dtype: An optional `tf.DType`. Defaults to `tf.float32`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatefulStandardNormalV2(resource:Dynamic, algorithm:Dynamic, shape:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random values from a truncated normal distribution.
		
		The generated values follow a normal distribution with mean 0 and standard
		deviation 1, except that values whose magnitude is more than 2 standard
		deviations from the mean are dropped and re-picked.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    The handle of the resource variable that stores the state of the RNG.
		  algorithm: A `Tensor` of type `int64`. The RNG algorithm.
		  shape: A `Tensor`. The shape of the output tensor.
		  dtype: An optional `tf.DType`. Defaults to `tf.float32`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatefulTruncatedNormal(resource:Dynamic, algorithm:Dynamic, shape:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random values from a uniform distribution.
		
		The generated values follow a uniform distribution in the range `[0, 1)`. The
		lower bound 0 is included in the range, while the upper bound 1 is excluded.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    The handle of the resource variable that stores the state of the RNG.
		  algorithm: A `Tensor` of type `int64`. The RNG algorithm.
		  shape: A `Tensor`. The shape of the output tensor.
		  dtype: An optional `tf.DType`. Defaults to `tf.float32`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatefulUniform(resource:Dynamic, algorithm:Dynamic, shape:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random integers from a uniform distribution.
		
		The generated values are uniform integers covering the whole range of `dtype`.
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    The handle of the resource variable that stores the state of the RNG.
		  algorithm: A `Tensor` of type `int64`. The RNG algorithm.
		  shape: A `Tensor`. The shape of the output tensor.
		  dtype: An optional `tf.DType`. Defaults to `tf.uint64`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatefulUniformFullInt(resource:Dynamic, algorithm:Dynamic, shape:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random integers from a uniform distribution.
		
		The generated values are uniform integers in the range `[minval, maxval)`.
		The lower bound `minval` is included in the range, while the upper bound
		`maxval` is excluded.
		
		The random integers are slightly biased unless `maxval - minval` is an exact
		power of two.  The bias is small for values of `maxval - minval` significantly
		smaller than the range of the output (either `2^32` or `2^64`).
		
		Args:
		  resource: A `Tensor` of type `resource`.
		    The handle of the resource variable that stores the state of the RNG.
		  algorithm: A `Tensor` of type `int64`. The RNG algorithm.
		  shape: A `Tensor`. The shape of the output tensor.
		  minval: A `Tensor`. Minimum value (inclusive, scalar).
		  maxval: A `Tensor`. Must have the same type as `minval`.
		    Maximum value (exclusive, scalar).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `minval`.
	**/
	static public function StatefulUniformInt(resource:Dynamic, algorithm:Dynamic, shape:Dynamic, minval:Dynamic, maxval:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An n-way switch statement which calls a single branch function.
		
		    An n-way switch statement, implementing the following:
		    ```
		    switch (branch_index) {
		      case 0:
		        output = branches[0](input);
		        break;
		      case 1:
		        output = branches[1](input);
		        break;
		      ...
		      case [[nbranches-1]]:
		      default:
		        output = branches[nbranches-1](input);
		        break;
		    }
		    ```
		
		    This should only be used when the none of branches has stateful ops.
		
		Args:
		  branch_index: A `Tensor` of type `int32`.
		    The branch selector, an int32 Tensor.
		  input: A list of `Tensor` objects.
		    A list of input tensors passed to the branch function.
		  Tout: A list of `tf.DTypes`. A list of output types.
		  branches: A list of functions decorated with @Defun that has length `>= 1`.
		          A list of functions each of which takes 'inputs' and returns a list of
		          tensors, whose types are the same as what every other branch returns.
		  output_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function StatelessCase(branch_index:Dynamic, input:Dynamic, Tout:Dynamic, branches:Dynamic, ?output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		output = cond ? then_branch(input) : else_branch(input)
		
		Args:
		  cond: A `Tensor`.
		          A Tensor. If the tensor is a scalar of non-boolean type, the
		          scalar is converted to a boolean according to the
		          following rule: if the scalar is a numerical value, non-zero means
		          `True` and zero means False; if the scalar is a string, non-empty
		          means `True` and empty means `False`. If the tensor is not a scalar,
		          being empty means False and being non-empty means True.
		
		          This should only be used when the if then/else body functions do not
		          have stateful ops.
		  input: A list of `Tensor` objects. A list of input tensors.
		  Tout: A list of `tf.DTypes`. A list of output types.
		  then_branch: A function decorated with @Defun.
		          A function that takes 'inputs' and returns a list of tensors, whose
		          types are the same as what else_branch returns.
		  else_branch: A function decorated with @Defun.
		        A function that takes 'inputs' and returns a list of tensors, whose
		        types are the same as what then_branch returns.
		  output_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function StatelessIf(cond:Dynamic, input:Dynamic, Tout:Dynamic, then_branch:Dynamic, else_branch:Dynamic, ?output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Draws samples from a multinomial distribution.
		
		Args:
		  logits: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    2-D Tensor with shape `[batch_size, num_classes]`.  Each slice `[i, :]`
		    represents the unnormalized log probabilities for all classes.
		  num_samples: A `Tensor` of type `int32`.
		    0-D.  Number of independent samples to draw for each row slice.
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2 seeds (shape [2]).
		  output_dtype: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `output_dtype`.
	**/
	static public function StatelessMultinomial(logits:Dynamic, num_samples:Dynamic, seed:Dynamic, ?output_dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2 seeds (shape [2]).
		  means: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		    The mean parameter of each batch.
		  stddevs: A `Tensor`. Must have the same type as `means`.
		    The standard deviation parameter of each batch. Must be greater than 0.
		  minvals: A `Tensor`. Must have the same type as `means`.
		    The minimum cutoff. May be -infinity.
		  maxvals: A `Tensor`. Must have the same type as `means`.
		    The maximum cutoff. May be +infinity, and must be more than the minval
		    for each batch.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `means`.
	**/
	static public function StatelessParameterizedTruncatedNormal(shape:Dynamic, seed:Dynamic, means:Dynamic, stddevs:Dynamic, minvals:Dynamic, maxvals:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom random numbers from a binomial distribution.
		
		Outputs random values from a binomial distribution.
		
		The outputs are a deterministic function of `shape`, `seed`, `counts`, and `probs`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2 seeds (shape [2]).
		  counts: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `int32`, `int64`.
		    The counts of the binomial distribution. Must be broadcastable with `probs`,
		    and broadcastable with the rightmost dimensions of `shape`.
		  probs: A `Tensor`. Must have the same type as `counts`.
		    The probability of success for the binomial distribution. Must be broadcastable
		    with `counts` and broadcastable with the rightmost dimensions of `shape`.
		  dtype: An optional `tf.DType` from: `tf.half, tf.float32, tf.float64, tf.int32, tf.int64`. Defaults to `tf.int64`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatelessRandomBinomial(shape:Dynamic, seed:Dynamic, counts:Dynamic, probs:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom random numbers from a gamma distribution.
		
		Outputs random values from a gamma distribution.
		
		The outputs are a deterministic function of `shape`, `seed`, and `alpha`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2 seeds (shape [2]).
		  alpha: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.
		    The concentration of the gamma distribution. Shape must match the rightmost
		    dimensions of `shape`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `alpha`.
	**/
	static public function StatelessRandomGammaV2(shape:Dynamic, seed:Dynamic, alpha:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Picks the best counter-based RNG algorithm based on device.
		
		This op picks the best counter-based RNG algorithm based on device.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function StatelessRandomGetAlg(?name:Dynamic):Dynamic;
	/**
		Scrambles seed into key and counter, using the best algorithm based on device.
		
		This op scrambles a shape-[2] seed into a key and a counter, both needed by counter-based RNG algorithms. The scrambing uses the best algorithm based on device. The scrambling is opaque but approximately satisfies the property that different seed results in different key/counter pair (which will in turn result in different random numbers).
		
		Args:
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2 seeds (shape [2]).
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (key, counter).
		
		  key: A `Tensor` of type `uint64`.
		  counter: A `Tensor` of type `uint64`.
	**/
	static public function StatelessRandomGetKeyCounter(seed:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Picks the best algorithm based on device, and scrambles seed into key and counter.
		
		This op picks the best counter-based RNG algorithm based on device, and scrambles a shape-[2] seed into a key and a counter, both needed by the counter-based algorithm. The scrambling is opaque but approximately satisfies the property that different seed results in different key/counter pair (which will in turn result in different random numbers).
		
		Args:
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2 seeds (shape [2]).
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (key, counter, alg).
		
		  key: A `Tensor` of type `uint64`.
		  counter: A `Tensor` of type `uint64`.
		  alg: A `Tensor` of type `int32`.
	**/
	static public function StatelessRandomGetKeyCounterAlg(seed:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom values from a normal distribution.
		
		The generated values will have mean 0 and standard deviation 1.
		
		The outputs are a deterministic function of `shape` and `seed`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2 seeds (shape [2]).
		  dtype: An optional `tf.DType` from: `tf.half, tf.bfloat16, tf.float32, tf.float64`. Defaults to `tf.float32`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatelessRandomNormal(shape:Dynamic, seed:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom values from a normal distribution.
		
		The generated values will have mean 0 and standard deviation 1.
		
		The outputs are a deterministic function of `shape`, `key`, `counter` and `alg`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  key: A `Tensor` of type `uint64`.
		    Key for the counter-based RNG algorithm (shape uint64[1]).
		  counter: A `Tensor` of type `uint64`.
		    Initial counter for the counter-based RNG algorithm (shape uint64[2] or uint64[1] depending on the algorithm). If a larger vector is given, only the needed portion on the left (i.e. [:N]) will be used.
		  alg: A `Tensor` of type `int32`. The RNG algorithm (shape int32[]).
		  dtype: An optional `tf.DType` from: `tf.half, tf.bfloat16, tf.float32, tf.float64`. Defaults to `tf.float32`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatelessRandomNormalV2(shape:Dynamic, key:Dynamic, counter:Dynamic, alg:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom random numbers from a Poisson distribution.
		
		Outputs random values from a Poisson distribution.
		
		The outputs are a deterministic function of `shape`, `seed`, and `lam`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2 seeds (shape [2]).
		  lam: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `int32`, `int64`.
		    The rate of the Poisson distribution. Shape must match the rightmost dimensions
		    of `shape`.
		  dtype: A `tf.DType` from: `tf.half, tf.float32, tf.float64, tf.int32, tf.int64`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatelessRandomPoisson(shape:Dynamic, seed:Dynamic, lam:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom random values from a uniform distribution.
		
		The generated values follow a uniform distribution in the range `[0, 1)`. The
		lower bound 0 is included in the range, while the upper bound 1 is excluded.
		
		The outputs are a deterministic function of `shape` and `seed`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2 seeds (shape [2]).
		  dtype: An optional `tf.DType` from: `tf.half, tf.bfloat16, tf.float32, tf.float64`. Defaults to `tf.float32`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatelessRandomUniform(shape:Dynamic, seed:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom random integers from a uniform distribution.
		
		The generated values are uniform integers covering the whole range of `dtype`.
		
		The outputs are a deterministic function of `shape` and `seed`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`, `uint32`, `uint64`.
		    2 seeds (shape [2]).
		  dtype: An optional `tf.DType` from: `tf.int32, tf.int64, tf.uint32, tf.uint64`. Defaults to `tf.uint64`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatelessRandomUniformFullInt(shape:Dynamic, seed:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom random integers from a uniform distribution.
		
		The generated values are uniform integers covering the whole range of `dtype`.
		
		The outputs are a deterministic function of `shape`, `key`, `counter` and `alg`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  key: A `Tensor` of type `uint64`.
		    Key for the counter-based RNG algorithm (shape uint64[1]).
		  counter: A `Tensor` of type `uint64`.
		    Initial counter for the counter-based RNG algorithm (shape uint64[2] or uint64[1] depending on the algorithm). If a larger vector is given, only the needed portion on the left (i.e. [:N]) will be used.
		  alg: A `Tensor` of type `int32`. The RNG algorithm (shape int32[]).
		  dtype: An optional `tf.DType` from: `tf.int32, tf.int64, tf.uint32, tf.uint64`. Defaults to `tf.uint64`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatelessRandomUniformFullIntV2(shape:Dynamic, key:Dynamic, counter:Dynamic, alg:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom random integers from a uniform distribution.
		
		The generated values follow a uniform distribution in the range `[minval, maxval)`.
		
		The outputs are a deterministic function of `shape`, `seed`, `minval`, and `maxval`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2 seeds (shape [2]).
		  minval: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Minimum value (inclusive, scalar).
		  maxval: A `Tensor`. Must have the same type as `minval`.
		    Maximum value (exclusive, scalar).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `minval`.
	**/
	static public function StatelessRandomUniformInt(shape:Dynamic, seed:Dynamic, minval:Dynamic, maxval:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom random integers from a uniform distribution.
		
		The generated values follow a uniform distribution in the range `[minval, maxval)`.
		
		The outputs are a deterministic function of `shape`, `key`, `counter`, `alg`, `minval` and `maxval`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  key: A `Tensor` of type `uint64`.
		    Key for the counter-based RNG algorithm (shape uint64[1]).
		  counter: A `Tensor` of type `uint64`.
		    Initial counter for the counter-based RNG algorithm (shape uint64[2] or uint64[1] depending on the algorithm). If a larger vector is given, only the needed portion on the left (i.e. [:N]) will be used.
		  alg: A `Tensor` of type `int32`. The RNG algorithm (shape int32[]).
		  minval: A `Tensor`. Must be one of the following types: `int32`, `int64`, `uint32`, `uint64`.
		    Minimum value (inclusive, scalar).
		  maxval: A `Tensor`. Must have the same type as `minval`.
		    Maximum value (exclusive, scalar).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `minval`.
	**/
	static public function StatelessRandomUniformIntV2(shape:Dynamic, key:Dynamic, counter:Dynamic, alg:Dynamic, minval:Dynamic, maxval:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom random values from a uniform distribution.
		
		The generated values follow a uniform distribution in the range `[0, 1)`. The
		lower bound 0 is included in the range, while the upper bound 1 is excluded.
		
		The outputs are a deterministic function of `shape`, `key`, `counter` and `alg`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  key: A `Tensor` of type `uint64`.
		    Key for the counter-based RNG algorithm (shape uint64[1]).
		  counter: A `Tensor` of type `uint64`.
		    Initial counter for the counter-based RNG algorithm (shape uint64[2] or uint64[1] depending on the algorithm). If a larger vector is given, only the needed portion on the left (i.e. [:N]) will be used.
		  alg: A `Tensor` of type `int32`. The RNG algorithm (shape int32[]).
		  dtype: An optional `tf.DType` from: `tf.half, tf.bfloat16, tf.float32, tf.float64`. Defaults to `tf.float32`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatelessRandomUniformV2(shape:Dynamic, key:Dynamic, counter:Dynamic, alg:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generate a randomly distorted bounding box for an image deterministically.
		
		Bounding box annotations are often supplied in addition to ground-truth labels
		in image recognition or object localization tasks. A common technique for
		training such a system is to randomly distort an image while preserving its
		content, i.e. *data augmentation*. This Op, given the same `seed`,
		deterministically outputs a randomly distorted localization of an object, i.e.
		bounding box, given an `image_size`, `bounding_boxes` and a series of
		constraints.
		
		The output of this Op is a single bounding box that may be used to crop the
		original image. The output is returned as 3 tensors: `begin`, `size` and
		`bboxes`. The first 2 tensors can be fed directly into `tf.slice` to crop the
		image. The latter may be supplied to `tf.image.draw_bounding_boxes` to visualize
		what the bounding box looks like.
		
		Bounding boxes are supplied and returned as `[y_min, x_min, y_max, x_max]`. The
		bounding box coordinates are floats in `[0.0, 1.0]` relative to the width and
		the height of the underlying image.
		
		The output of this Op is guaranteed to be the same given the same `seed` and is
		independent of how many times the function is called, and independent of global
		seed settings (e.g. `tf.random.set_seed`).
		
		Example usage:
		
		>>> image = np.array([[[1], [2], [3]], [[4], [5], [6]], [[7], [8], [9]]])
		>>> bbox = tf.constant(
		...   [0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])
		>>> seed = (1, 2)
		>>> # Generate a single distorted bounding box.
		>>> bbox_begin, bbox_size, bbox_draw = (
		...   tf.image.stateless_sample_distorted_bounding_box(
		...     tf.shape(image), bounding_boxes=bbox, seed=seed))
		>>> # Employ the bounding box to distort the image.
		>>> tf.slice(image, bbox_begin, bbox_size)
		<tf.Tensor: shape=(2, 2, 1), dtype=int64, numpy=
		array([[[1],
		        [2]],
		       [[4],
		        [5]]])>
		>>> # Draw the bounding box in an image summary.
		>>> colors = np.array([[1.0, 0.0, 0.0], [0.0, 0.0, 1.0]])
		>>> tf.image.draw_bounding_boxes(
		...   tf.expand_dims(tf.cast(image, tf.float32),0), bbox_draw, colors)
		<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=
		array([[[[1.],
		         [1.],
		         [3.]],
		        [[1.],
		         [1.],
		         [6.]],
		        [[7.],
		         [8.],
		         [9.]]]], dtype=float32)>
		
		Note that if no bounding box information is available, setting
		`use_image_if_no_bounding_boxes = true` will assume there is a single implicit
		bounding box covering the whole image. If `use_image_if_no_bounding_boxes` is
		false and no bounding boxes are supplied, an error is raised.
		
		Args:
		  image_size: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `int16`, `int32`, `int64`.
		    1-D, containing `[height, width, channels]`.
		  bounding_boxes: A `Tensor` of type `float32`.
		    3-D with shape `[batch, N, 4]` describing the N bounding boxes
		    associated with the image.
		  min_object_covered: A `Tensor` of type `float32`.
		    The cropped area of the image must contain at least this
		    fraction of any bounding box supplied. The value of this parameter should be
		    non-negative. In the case of 0, the cropped area does not need to overlap
		    any of the bounding boxes supplied.
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    1-D with shape `[2]`. The seed to the random number generator. Must have dtype
		    `int32` or `int64`. (When using XLA, only `int32` is allowed.)
		  aspect_ratio_range: An optional list of `floats`. Defaults to `[0.75, 1.33]`.
		    The cropped area of the image must have an aspect ratio =
		    width / height within this range.
		  area_range: An optional list of `floats`. Defaults to `[0.05, 1]`.
		    The cropped area of the image must contain a fraction of the
		    supplied image within this range.
		  max_attempts: An optional `int`. Defaults to `100`.
		    Number of attempts at generating a cropped region of the image
		    of the specified constraints. After `max_attempts` failures, return the entire
		    image.
		  use_image_if_no_bounding_boxes: An optional `bool`. Defaults to `False`.
		    Controls behavior if no bounding boxes supplied.
		    If true, assume an implicit bounding box covering the whole input. If false,
		    raise an error.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (begin, size, bboxes).
		
		  begin: A `Tensor`. Has the same type as `image_size`.
		  size: A `Tensor`. Has the same type as `image_size`.
		  bboxes: A `Tensor` of type `float32`.
	**/
	static public function StatelessSampleDistortedBoundingBox(image_size:Dynamic, bounding_boxes:Dynamic, min_object_covered:Dynamic, seed:Dynamic, ?aspect_ratio_range:Dynamic, ?area_range:Dynamic, ?max_attempts:Dynamic, ?use_image_if_no_bounding_boxes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom values from a truncated normal distribution.
		
		The generated values follow a normal distribution with mean 0 and standard
		deviation 1, except that values whose magnitude is more than 2 standard
		deviations from the mean are dropped and re-picked.
		
		The outputs are a deterministic function of `shape` and `seed`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  seed: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    2 seeds (shape [2]).
		  dtype: An optional `tf.DType` from: `tf.half, tf.bfloat16, tf.float32, tf.float64`. Defaults to `tf.float32`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatelessTruncatedNormal(shape:Dynamic, seed:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs deterministic pseudorandom values from a truncated normal distribution.
		
		The generated values follow a normal distribution with mean 0 and standard
		deviation 1, except that values whose magnitude is more than 2 standard
		deviations from the mean are dropped and re-picked.
		
		The outputs are a deterministic function of `shape`, `key`, `counter` and `alg`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  key: A `Tensor` of type `uint64`.
		    Key for the counter-based RNG algorithm (shape uint64[1]).
		  counter: A `Tensor` of type `uint64`.
		    Initial counter for the counter-based RNG algorithm (shape uint64[2] or uint64[1] depending on the algorithm). If a larger vector is given, only the needed portion on the left (i.e. [:N]) will be used.
		  alg: A `Tensor` of type `int32`. The RNG algorithm (shape int32[]).
		  dtype: An optional `tf.DType` from: `tf.half, tf.bfloat16, tf.float32, tf.float64`. Defaults to `tf.float32`.
		    The type of the output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function StatelessTruncatedNormalV2(shape:Dynamic, key:Dynamic, counter:Dynamic, alg:Dynamic, ?dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		output = input; While (Cond(output)) { output = Body(output) }
		
		Args:
		  input: A list of `Tensor` objects.
		    A list of input tensors whose types are T.
		  cond: A function decorated with @Defun.
		          A function takes 'input' and returns a tensor.  If the tensor is
		          a scalar of non-boolean, the scalar is converted to a boolean
		          according to the following rule: if the scalar is a numerical
		          value, non-zero means True and zero means False; if the scalar is
		          a string, non-empty means True and empty means False. If the
		          tensor is not a scalar, non-emptiness means True and False
		          otherwise.
		
		          This should only be used when the while condition and body functions
		          do not have stateful ops.
		  body: A function decorated with @Defun.
		          A function that takes a list of tensors and returns another
		          list of tensors. Both lists have the same types as specified
		          by T.
		  output_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		  parallel_iterations: An optional `int`. Defaults to `10`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects. Has the same type as `input`.
	**/
	static public function StatelessWhile(input:Dynamic, cond:Dynamic, body:Dynamic, ?output_shapes:Dynamic, ?parallel_iterations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Check if the input matches the regex pattern.
		
		The input is a string tensor of any shape. The pattern is the
		regular expression to be matched with every element of the input tensor.
		The boolean values (True or False) of the output tensor indicate
		if the input matches the regex pattern provided.
		
		The pattern follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)
		
		Args:
		  input: A `Tensor` of type `string`.
		    A string tensor of the text to be processed.
		  pattern: A `string`. The regular expression to match the input.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function StaticRegexFullMatch(input:Dynamic, pattern:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Replaces the match of pattern in input with rewrite.
		
		It follows the re2 syntax (https://github.com/google/re2/wiki/Syntax)
		
		Args:
		  input: A `Tensor` of type `string`. The text to be processed.
		  pattern: A `string`. The regular expression to match the input.
		  rewrite: A `string`. The rewrite to be applied to the matched expression.
		  replace_global: An optional `bool`. Defaults to `True`.
		    If True, the replacement is global, otherwise the replacement
		    is done only on the first match.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function StaticRegexReplace(input:Dynamic, pattern:Dynamic, rewrite:Dynamic, ?replace_global:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a statistics manager resource.
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function StatsAggregatorHandle(?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function StatsAggregatorHandleV2(?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Set a summary_writer_interface to record statistics using given stats_aggregator.
		
		Args:
		  stats_aggregator: A `Tensor` of type `resource`.
		  summary: A `Tensor` of type `resource`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function StatsAggregatorSetSummaryWriter(stats_aggregator:Dynamic, summary:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Produces a summary of any statistics recorded by the given statistics manager.
		
		Args:
		  iterator: A `Tensor` of type `resource`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function StatsAggregatorSummary(iterator:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Stops gradient computation.
		
		When executed in a graph, this op outputs its input tensor as-is.
		
		When building ops to compute gradients, this op prevents the contribution of
		its inputs to be taken into account.  Normally, the gradient generator adds ops
		to a graph to compute the derivatives of a specified 'loss' by recursively
		finding out inputs that contributed to its computation.  If you insert this op
		in the graph it inputs are masked from the gradient generator.  They are not
		taken into account for computing gradients.
		
		This is useful any time you want to compute a value with TensorFlow but need
		to pretend that the value was a constant. For example, the softmax function
		for a vector x can be written as
		
		```python
		
		  def softmax(x):
		    numerator = tf.exp(x)
		    denominator = tf.reduce_sum(numerator)
		    return numerator / denominator
		```
		
		This however is susceptible to overflow if the values in x are large. An
		alternative more stable way is to subtract the maximum of x from each of the
		values.
		
		```python
		
		  def stable_softmax(x):
		    z = x - tf.reduce_max(x)
		    numerator = tf.exp(z)
		    denominator = tf.reduce_sum(numerator)
		    return numerator / denominator
		```
		
		However, when we backprop through the softmax to x, we dont want to backprop
		through the `tf.reduce_max(x)` (if the max values are not unique then the
		gradient could flow to the wrong input) calculation and treat that as a
		constant. Therefore, we should write this out as
		
		```python
		
		  def stable_softmax(x):
		    z = x - tf.stop_gradient(tf.reduce_max(x))
		    numerator = tf.exp(z)
		    denominator = tf.reduce_sum(numerator)
		    return numerator / denominator
		```
		
		Some other examples include:
		
		*  The *EM* algorithm where the *M-step* should not involve backpropagation
		   through the output of the *E-step*.
		*  Contrastive divergence training of Boltzmann machines where, when
		   differentiating the energy function, the training must not backpropagate
		   through the graph that generated the samples from the model.
		*  Adversarial training, where no backprop should happen through the adversarial
		   example generation process.
		
		Args:
		  input: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function StopGradient(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return a strided slice from `input`.
		
		Note, most python users will want to use the Python `Tensor.__getitem__`
		or `Variable.__getitem__` rather than this op directly.
		
		The goal of this op is to produce a new tensor with a subset of
		the elements from the `n` dimensional `input` tensor. The subset is chosen using
		a sequence of `m` sparse range specifications encoded into the arguments
		of this function. Note, in some cases
		`m` could be equal to `n`, but this need not be the case. Each
		range specification entry can be one of the following:
		
		- An ellipsis (...). Ellipses are used to imply zero or more
		  dimensions of full-dimension selection and are produced using
		  `ellipsis_mask`. For example, `foo[...]` is the identity slice.
		
		- A new axis. This is used to insert a new shape=1 dimension and is
		  produced using `new_axis_mask`. For example, `foo[:, ...]` where
		  `foo` is shape `(3, 4)` produces a `(1, 3, 4)` tensor.
		
		
		- A range `begin:end:stride`. This is used to specify how much to choose from
		  a given dimension. `stride` can be any integer but 0.  `begin` is an integer
		  which represents the index of the first value to select while `end` represents
		  the index of the last value to select. The number of values selected in each
		  dimension is `end - begin` if `stride > 0` and `begin - end` if `stride < 0`.
		  `begin` and `end` can be negative where `-1` is the last element, `-2` is
		  the second to last. `begin_mask` controls whether to replace the explicitly
		  given `begin` with an implicit effective value of `0` if `stride > 0` and
		  `-1` if `stride < 0`. `end_mask` is analogous but produces the number
		  required to create the largest open interval. For example, given a shape
		  `(3,)` tensor `foo[:]`, the effective `begin` and `end` are `0` and `3`. Do
		  not assume this is equivalent to `foo[0:-1]` which has an effective `begin`
		  and `end` of `0` and `2`. Another example is `foo[-2::-1]` which reverses the
		  first dimension of a tensor while dropping the last two (in the original
		  order elements). For example `foo = [1,2,3,4]; foo[-2::-1]` is `[4,3]`.
		
		- A single index. This is used to keep only elements that have a given
		  index. For example (`foo[2, :]` on a shape `(5,6)` tensor produces a
		  shape `(6,)` tensor. This is encoded in `begin` and `end` and
		  `shrink_axis_mask`.
		
		Each conceptual range specification is encoded in the op's argument. This
		encoding is best understand by considering a non-trivial example. In
		particular,
		`foo[1, 2:4, None, ..., :-3:-1, :]` will be encoded as
		
		```
		begin = [1, 2, x, x, 0, x] # x denotes don't care (usually 0)
		end = [2, 4, x, x, -3, x]
		strides = [1, 1, x, x, -1, 1]
		begin_mask = 1<<4 | 1<<5 = 48
		end_mask = 1<<5 = 32
		ellipsis_mask = 1<<3 = 8
		new_axis_mask = 1<<2 = 4
		shrink_axis_mask = 1<<0 = 1
		```
		
		In this case if `foo.shape` is (5, 5, 5, 5, 5, 5) the final shape of
		the slice becomes (2, 1, 5, 5, 2, 5).
		Let us walk step by step through each argument specification.
		
		1.  The first argument in the example slice is turned into `begin = 1` and
		`end = begin + 1 = 2`. To disambiguate from the original spec `2:4` we
		also set the appropriate bit in `shrink_axis_mask`.
		
		2. `2:4` is contributes 2, 4, 1 to begin, end, and stride. All masks have
		zero bits contributed.
		
		3. None is a synonym for `tf.newaxis`. This means insert a dimension of size 1
		dimension in the final shape. Dummy values are contributed to begin,
		end and stride, while the new_axis_mask bit is set.
		
		4. `...` grab the full ranges from as many dimensions as needed to
		fully specify a slice for every dimension of the input shape.
		
		5. `:-3:-1` shows the use of negative indices. A negative index `i` associated
		with a dimension that has shape `s` is converted to a positive index
		`s + i`. So `-1` becomes `s-1` (i.e. the last element). This conversion
		is done internally so begin, end and strides receive x, -3, and -1.
		The appropriate begin_mask bit is set to indicate the start range is the
		full range (ignoring the x).
		
		6. `:` indicates that the entire contents of the corresponding dimension
		is selected. This is equivalent to `::` or `0::1`. begin, end, and strides
		receive 0, 0, and 1, respectively. The appropriate bits in `begin_mask` and
		`end_mask` are also set.
		
		*Requirements*:
		  `0 != strides[i] for i in [0, m)`
		  `ellipsis_mask must be a power of two (only one ellipsis)`
		
		Args:
		  input: A `Tensor`.
		  begin: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    `begin[k]` specifies the offset into the `k`th range specification.
		    The exact dimension this corresponds to will be determined by context.
		    Out-of-bounds values will be silently clamped. If the `k`th bit of
		    `begin_mask` then `begin[k]` is ignored and the full range of the
		    appropriate dimension is used instead. Negative values causes indexing
		    to start from the highest element e.g. If `foo==[1,2,3]` then `foo[-1]==3`.
		  end: A `Tensor`. Must have the same type as `begin`.
		    `end[i]` is like `begin` with the exception that `end_mask` is
		    used to determine full ranges.
		  strides: A `Tensor`. Must have the same type as `begin`.
		    `strides[i]` specifies the increment in the `i`th specification
		    after extracting a given element. Negative indices will reverse
		    the original order. Out or range values are
		    clamped to `[0,dim[i]) if slice[i]>0` or `[-1,dim[i]-1] if slice[i] < 0`
		  begin_mask: An optional `int`. Defaults to `0`.
		    a bitmask where a bit i being 1 means to ignore the begin
		    value and instead use the largest interval possible. At runtime
		    begin[i] will be replaced with `[0, n-1)` if `stride[i] > 0` or
		    `[-1, n-1]` if `stride[i] < 0`
		  end_mask: An optional `int`. Defaults to `0`. analogous to `begin_mask`
		  ellipsis_mask: An optional `int`. Defaults to `0`.
		    a bitmask where bit `i` being 1 means the `i`th
		    position is actually an ellipsis. One bit at most can be 1.
		    If `ellipsis_mask == 0`, then an implicit ellipsis mask of `1 << (m+1)`
		    is provided. This means that `foo[3:5] == foo[3:5, ...]`. An ellipsis
		    implicitly creates as many range specifications as necessary to fully
		    specify the sliced range for every dimension. For example for a 4-dimensional
		    tensor `foo` the slice `foo[2, ..., 5:8]` implies `foo[2, :, :, 5:8]`.
		  new_axis_mask: An optional `int`. Defaults to `0`.
		    a bitmask where bit `i` being 1 means the `i`th
		    specification creates a new shape 1 dimension. For example
		    `foo[:4, tf.newaxis, :2]` would produce a shape `(4, 1, 2)` tensor.
		  shrink_axis_mask: An optional `int`. Defaults to `0`.
		    a bitmask where bit `i` implies that the `i`th
		    specification should shrink the dimensionality. begin and end
		    must imply a slice of size 1 in the dimension. For example in
		    python one might do `foo[:, 3, :]` which would result in
		    `shrink_axis_mask` being 2.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function StridedSlice(input:Dynamic, begin:Dynamic, end:Dynamic, strides:Dynamic, ?begin_mask:Dynamic, ?end_mask:Dynamic, ?ellipsis_mask:Dynamic, ?new_axis_mask:Dynamic, ?shrink_axis_mask:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Assign `value` to the sliced l-value reference of `ref`.
		
		The values of `value` are assigned to the positions in the variable
		`ref` that are selected by the slice parameters. The slice parameters
		`begin`, `end`, `strides`, etc. work exactly as in `StridedSlice`.
		
		NOTE this op currently does not support broadcasting and so `value`'s
		shape must be exactly the shape produced by the slice of `ref`.
		
		Args:
		  ref: A mutable `Tensor`.
		  begin: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  end: A `Tensor`. Must have the same type as `begin`.
		  strides: A `Tensor`. Must have the same type as `begin`.
		  value: A `Tensor`. Must have the same type as `ref`.
		  begin_mask: An optional `int`. Defaults to `0`.
		  end_mask: An optional `int`. Defaults to `0`.
		  ellipsis_mask: An optional `int`. Defaults to `0`.
		  new_axis_mask: An optional `int`. Defaults to `0`.
		  shrink_axis_mask: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor`. Has the same type as `ref`.
	**/
	static public function StridedSliceAssign(ref:Dynamic, begin:Dynamic, end:Dynamic, strides:Dynamic, value:Dynamic, ?begin_mask:Dynamic, ?end_mask:Dynamic, ?ellipsis_mask:Dynamic, ?new_axis_mask:Dynamic, ?shrink_axis_mask:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the gradient of `StridedSlice`.
		
		Since `StridedSlice` cuts out pieces of its `input` which is size
		`shape`, its gradient will have the same shape (which is passed here
		as `shape`). The gradient will be zero in any element that the slice
		does not select.
		
		Arguments are the same as StridedSliceGrad with the exception that
		`dy` is the input gradient to be propagated and `shape` is the
		shape of `StridedSlice`'s `input`.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  begin: A `Tensor`. Must have the same type as `shape`.
		  end: A `Tensor`. Must have the same type as `shape`.
		  strides: A `Tensor`. Must have the same type as `shape`.
		  dy: A `Tensor`.
		  begin_mask: An optional `int`. Defaults to `0`.
		  end_mask: An optional `int`. Defaults to `0`.
		  ellipsis_mask: An optional `int`. Defaults to `0`.
		  new_axis_mask: An optional `int`. Defaults to `0`.
		  shrink_axis_mask: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `dy`.
	**/
	static public function StridedSliceGrad(shape:Dynamic, begin:Dynamic, end:Dynamic, strides:Dynamic, dy:Dynamic, ?begin_mask:Dynamic, ?end_mask:Dynamic, ?ellipsis_mask:Dynamic, ?new_axis_mask:Dynamic, ?shrink_axis_mask:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Formats a string template using a list of tensors.
		
		Formats a string template using a list of tensors, pretty-printing tensor summaries.
		
		Args:
		  inputs: A list of `Tensor` objects.
		    The list of tensors to format into the placeholder string.
		  template: An optional `string`. Defaults to `"%s"`.
		    A string, the template to format tensor summaries into.
		  placeholder: An optional `string`. Defaults to `"%s"`.
		    A string, at each placeholder in the template a subsequent tensor summary will be inserted.
		  summarize: An optional `int`. Defaults to `3`.
		    When formatting the tensor summaries print the first and last summarize entries of each tensor dimension.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function StringFormat(inputs:Dynamic, ?template:Dynamic, ?placeholder:Dynamic, ?summarize:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Joins the strings in the given list of string tensors into one tensor;
		
		with the given separator (default is an empty separator).
		
		Examples:
		
		>>> s = ["hello", "world", "tensorflow"]
		>>> tf.strings.join(s, " ")
		<tf.Tensor: shape=(), dtype=string, numpy=b'hello world tensorflow'>
		
		Args:
		  inputs: A list of at least 1 `Tensor` objects with type `string`.
		    A list of string tensors.  The tensors must all have the same shape,
		    or be scalars.  Scalars may be mixed in; these will be broadcast to the shape
		    of non-scalar inputs.
		  separator: An optional `string`. Defaults to `""`.
		    string, an optional join separator.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function StringJoin(inputs:Dynamic, ?separator:Dynamic, ?name:Dynamic):Dynamic;
	/**
		String lengths of `input`.
		
		Computes the length of each string given in the input tensor.
		
		>>> strings = tf.constant(['Hello','TensorFlow', '\U0001F642'])
		>>> tf.strings.length(strings).numpy() # default counts bytes
		array([ 5, 10, 4], dtype=int32)
		>>> tf.strings.length(strings, unit="UTF8_CHAR").numpy()
		array([ 5, 10, 1], dtype=int32)
		
		Args:
		  input: A `Tensor` of type `string`.
		    The strings for which to compute the length for each element.
		  unit: An optional `string` from: `"BYTE", "UTF8_CHAR"`. Defaults to `"BYTE"`.
		    The unit that is counted to compute string length.  One of: `"BYTE"` (for
		    the number of bytes in each string) or `"UTF8_CHAR"` (for the number of UTF-8
		    encoded Unicode code points in each string).  Results are undefined
		    if `unit=UTF8_CHAR` and the `input` strings do not contain structurally
		    valid UTF-8.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function StringLength(input:Dynamic, ?unit:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts all uppercase characters into their respective lowercase replacements.
		
		Example:
		
		>>> tf.strings.lower("CamelCase string and ALL CAPS")
		<tf.Tensor: shape=(), dtype=string, numpy=b'camelcase string and all caps'>
		
		Args:
		  input: A `Tensor` of type `string`. The input to be lower-cased.
		  encoding: An optional `string`. Defaults to `""`.
		    Character encoding of `input`. Allowed values are '' and 'utf-8'.
		    Value '' is interpreted as ASCII.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function StringLower(input:Dynamic, ?encoding:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates ngrams from ragged string data.
		
		This op accepts a ragged tensor with 1 ragged dimension containing only
		strings and outputs a ragged tensor with 1 ragged dimension containing ngrams
		of that string, joined along the innermost axis.
		
		Args:
		  data: A `Tensor` of type `string`.
		    The values tensor of the ragged string tensor to make ngrams out of. Must be a
		    1D string tensor.
		  data_splits: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The splits tensor of the ragged string tensor to make ngrams out of.
		  separator: A `string`.
		    The string to append between elements of the token. Use "" for no separator.
		  ngram_widths: A list of `ints`. The sizes of the ngrams to create.
		  left_pad: A `string`.
		    The string to use to pad the left side of the ngram sequence. Only used if
		    pad_width != 0.
		  right_pad: A `string`.
		    The string to use to pad the right side of the ngram sequence. Only used if
		    pad_width != 0.
		  pad_width: An `int`.
		    The number of padding elements to add to each side of each
		    sequence. Note that padding will never be greater than 'ngram_widths'-1
		    regardless of this value. If `pad_width=-1`, then add `max(ngram_widths)-1`
		    elements.
		  preserve_short_sequences: A `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (ngrams, ngrams_splits).
		
		  ngrams: A `Tensor` of type `string`.
		  ngrams_splits: A `Tensor`. Has the same type as `data_splits`.
	**/
	static public function StringNGrams(data:Dynamic, data_splits:Dynamic, separator:Dynamic, ngram_widths:Dynamic, left_pad:Dynamic, right_pad:Dynamic, pad_width:Dynamic, preserve_short_sequences:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Split elements of `input` based on `delimiter` into a `SparseTensor`.
		
		Let N be the size of source (typically N will be the batch size). Split each
		element of `input` based on `delimiter` and return a `SparseTensor`
		containing the splitted tokens. Empty tokens are ignored.
		
		`delimiter` can be empty, or a string of split characters. If `delimiter` is an
		 empty string, each element of `input` is split into individual single-byte
		 character strings, including splitting of UTF-8 multibyte sequences. Otherwise
		 every character of `delimiter` is a potential split point.
		
		For example:
		  N = 2, input[0] is 'hello world' and input[1] is 'a b c', then the output
		  will be
		
		  indices = [0, 0;
		             0, 1;
		             1, 0;
		             1, 1;
		             1, 2]
		  shape = [2, 3]
		  values = ['hello', 'world', 'a', 'b', 'c']
		
		Args:
		  input: A `Tensor` of type `string`. 1-D. Strings to split.
		  delimiter: A `Tensor` of type `string`.
		    0-D. Delimiter characters (bytes), or empty string.
		  skip_empty: An optional `bool`. Defaults to `True`.
		    A `bool`. If `True`, skip the empty strings from the result.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (indices, values, shape).
		
		  indices: A `Tensor` of type `int64`.
		  values: A `Tensor` of type `string`.
		  shape: A `Tensor` of type `int64`.
	**/
	static public function StringSplit(input:Dynamic, delimiter:Dynamic, ?skip_empty:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Split elements of `source` based on `sep` into a `SparseTensor`.
		
		Let N be the size of source (typically N will be the batch size). Split each
		element of `source` based on `sep` and return a `SparseTensor`
		containing the split tokens. Empty tokens are ignored.
		
		For example, N = 2, source[0] is 'hello world' and source[1] is 'a b c',
		then the output will be
		```
		st.indices = [0, 0;
		              0, 1;
		              1, 0;
		              1, 1;
		              1, 2]
		st.shape = [2, 3]
		st.values = ['hello', 'world', 'a', 'b', 'c']
		```
		
		If `sep` is given, consecutive delimiters are not grouped together and are
		deemed to delimit empty strings. For example, source of `"1<>2<><>3"` and
		sep of `"<>"` returns `["1", "2", "", "3"]`. If `sep` is None or an empty
		string, consecutive whitespace are regarded as a single separator, and the
		result will contain no empty strings at the startor end if the string has
		leading or trailing whitespace.
		
		Note that the above mentioned behavior matches python's str.split.
		
		Args:
		  input: A `Tensor` of type `string`.
		    `1-D` string `Tensor`, the strings to split.
		  sep: A `Tensor` of type `string`.
		    `0-D` string `Tensor`, the delimiter character.
		  maxsplit: An optional `int`. Defaults to `-1`.
		    An `int`. If `maxsplit > 0`, limit of the split of the result.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (indices, values, shape).
		
		  indices: A `Tensor` of type `int64`.
		  values: A `Tensor` of type `string`.
		  shape: A `Tensor` of type `int64`.
	**/
	static public function StringSplitV2(input:Dynamic, sep:Dynamic, ?maxsplit:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Strip leading and trailing whitespaces from the Tensor.
		
		Examples:
		
		>>> tf.strings.strip(["\nTensorFlow", "     The python library    "]).numpy()
		array([b'TensorFlow', b'The python library'], dtype=object)
		
		Args:
		  input: A `Tensor` of type `string`. A string `Tensor` of any shape.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function StringStrip(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts each string in the input Tensor to its hash mod by a number of buckets.
		
		The hash function is deterministic on the content of the string within the
		process.
		
		Note that the hash function may change from time to time.
		This functionality will be deprecated and it's recommended to use
		`tf.string_to_hash_bucket_fast()` or `tf.string_to_hash_bucket_strong()`.
		
		Args:
		  string_tensor: A `Tensor` of type `string`.
		  num_buckets: An `int` that is `>= 1`. The number of buckets.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function StringToHashBucket(string_tensor:Dynamic, num_buckets:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts each string in the input Tensor to its hash mod by a number of buckets.
		
		The hash function is deterministic on the content of the string within the
		process and will never change. However, it is not suitable for cryptography.
		This function may be used when CPU time is scarce and inputs are trusted or
		unimportant. There is a risk of adversaries constructing inputs that all hash
		to the same bucket. To prevent this problem, use a strong hash function with
		`tf.string_to_hash_bucket_strong`.
		
		Examples:
		
		>>> tf.strings.to_hash_bucket_fast(["Hello", "TensorFlow", "2.x"], 3).numpy()
		array([0, 2, 2])
		
		Args:
		  input: A `Tensor` of type `string`. The strings to assign a hash bucket.
		  num_buckets: An `int` that is `>= 1`. The number of buckets.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function StringToHashBucketFast(input:Dynamic, num_buckets:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts each string in the input Tensor to its hash mod by a number of buckets.
		
		The hash function is deterministic on the content of the string within the
		process. The hash function is a keyed hash function, where attribute `key`
		defines the key of the hash function. `key` is an array of 2 elements.
		
		A strong hash is important when inputs may be malicious, e.g. URLs with
		additional components. Adversaries could try to make their inputs hash to the
		same bucket for a denial-of-service attack or to skew the results. A strong
		hash can be used to make it difficult to find inputs with a skewed hash value
		distribution over buckets. This requires that the hash function is
		seeded by a high-entropy (random) "key" unknown to the adversary.
		
		The additional robustness comes at a cost of roughly 4x higher compute
		time than `tf.string_to_hash_bucket_fast`.
		
		Examples:
		
		>>> tf.strings.to_hash_bucket_strong(["Hello", "TF"], 3, [1, 2]).numpy()
		array([2, 0])
		
		Args:
		  input: A `Tensor` of type `string`. The strings to assign a hash bucket.
		  num_buckets: An `int` that is `>= 1`. The number of buckets.
		  key: A list of `ints`.
		    The key used to seed the hash function, passed as a list of two uint64
		    elements.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function StringToHashBucketStrong(input:Dynamic, num_buckets:Dynamic, key:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts each string in the input Tensor to the specified numeric type.
		
		(Note that int32 overflow results in an error while float overflow
		results in a rounded value.)
		
		Example:
		
		>>> strings = ["5.0", "3.0", "7.0"]
		>>> tf.strings.to_number(strings)
		<tf.Tensor: shape=(3,), dtype=float32, numpy=array([5., 3., 7.], dtype=float32)>
		
		Args:
		  string_tensor: A `Tensor` of type `string`.
		  out_type: An optional `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.int64`. Defaults to `tf.float32`.
		    The numeric type to interpret each string in `string_tensor` as.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `out_type`.
	**/
	static public function StringToNumber(string_tensor:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts all lowercase characters into their respective uppercase replacements.
		
		Example:
		
		>>> tf.strings.upper("CamelCase string and ALL CAPS")
		<tf.Tensor: shape=(), dtype=string, numpy=b'CAMELCASE STRING AND ALL CAPS'>
		
		Args:
		  input: A `Tensor` of type `string`. The input to be upper-cased.
		  encoding: An optional `string`. Defaults to `""`.
		    Character encoding of `input`. Allowed values are '' and 'utf-8'.
		    Value '' is interpreted as ASCII.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function StringUpper(input:Dynamic, ?encoding:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x - y element-wise.
		
		*NOTE*: `tf.subtract` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Both input and output have a range `(-inf, inf)`.
		
		Example usages below.
		
		Subtract operation between an array and a scalar:
		
		>>> x = [1, 2, 3, 4, 5]
		>>> y = 1
		>>> tf.subtract(x, y)
		<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>
		>>> tf.subtract(y, x)
		<tf.Tensor: shape=(5,), dtype=int32,
		numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>
		
		Note that binary `-` operator can be used instead:
		
		>>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])
		>>> y = tf.convert_to_tensor(1)
		>>> x - y
		<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>
		
		Subtract operation between an array and a tensor of same shape:
		
		>>> x = [1, 2, 3, 4, 5]
		>>> y = tf.constant([5, 4, 3, 2, 1])
		>>> tf.subtract(y, x)
		<tf.Tensor: shape=(5,), dtype=int32,
		numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>
		
		**Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a
		non-tensor, the non-tensor input will adopt (or get casted to) the data type
		of the tensor input. This can potentially cause unwanted overflow or underflow
		conversion.
		
		For example,
		
		>>> x = tf.constant([1, 2], dtype=tf.int8)
		>>> y = [2**8 + 1, 2**8 + 2]
		>>> tf.subtract(x, y)
		<tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>
		
		When subtracting two input values of different shapes, `tf.subtract` follows the
		[general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)
		. The two input array shapes are compared element-wise. Starting with the
		trailing dimensions, the two dimensions either have to be equal or one of them
		needs to be `1`.
		
		For example,
		
		>>> x = np.ones(6).reshape(2, 3, 1)
		>>> y = np.ones(6).reshape(2, 1, 3)
		>>> tf.subtract(x, y)
		<tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=
		array([[[0., 0., 0.],
		        [0., 0., 0.],
		        [0., 0., 0.]],
		       [[0., 0., 0.],
		        [0., 0., 0.],
		        [0., 0., 0.]]])>
		
		Example with inputs of different dimensions:
		
		>>> x = np.ones(6).reshape(2, 3, 1)
		>>> y = np.ones(6).reshape(1, 6)
		>>> tf.subtract(x, y)
		<tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=
		array([[[0., 0., 0., 0., 0., 0.],
		        [0., 0., 0., 0., 0., 0.],
		        [0., 0., 0., 0., 0., 0.]],
		       [[0., 0., 0., 0., 0., 0.],
		        [0., 0., 0., 0., 0., 0.],
		        [0., 0., 0., 0., 0., 0.]]])>
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Sub(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Return substrings from `Tensor` of strings.
		
		For each string in the input `Tensor`, creates a substring starting at index
		`pos` with a total length of `len`.
		
		If `len` defines a substring that would extend beyond the length of the input
		string, or if `len` is negative, then as many characters as possible are used.
		
		A negative `pos` indicates distance within the string backwards from the end.
		
		If `pos` specifies an index which is out of range for any of the input strings,
		then an `InvalidArgumentError` is thrown.
		
		`pos` and `len` must have the same shape, otherwise a `ValueError` is thrown on
		Op creation.
		
		*NOTE*: `Substr` supports broadcasting up to two dimensions. More about
		broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		---
		
		Examples
		
		Using scalar `pos` and `len`:
		
		```python
		input = [b'Hello', b'World']
		position = 1
		length = 3
		
		output = [b'ell', b'orl']
		```
		
		Using `pos` and `len` with same shape as `input`:
		
		```python
		input = [[b'ten', b'eleven', b'twelve'],
		         [b'thirteen', b'fourteen', b'fifteen'],
		         [b'sixteen', b'seventeen', b'eighteen']]
		position = [[1, 2, 3],
		            [1, 2, 3],
		            [1, 2, 3]]
		length =   [[2, 3, 4],
		            [4, 3, 2],
		            [5, 5, 5]]
		
		output = [[b'en', b'eve', b'lve'],
		          [b'hirt', b'urt', b'te'],
		          [b'ixtee', b'vente', b'hteen']]
		```
		
		Broadcasting `pos` and `len` onto `input`:
		
		```
		input = [[b'ten', b'eleven', b'twelve'],
		         [b'thirteen', b'fourteen', b'fifteen'],
		         [b'sixteen', b'seventeen', b'eighteen'],
		         [b'nineteen', b'twenty', b'twentyone']]
		position = [1, 2, 3]
		length =   [1, 2, 3]
		
		output = [[b'e', b'ev', b'lve'],
		          [b'h', b'ur', b'tee'],
		          [b'i', b've', b'hte'],
		          [b'i', b'en', b'nty']]
		```
		
		Broadcasting `input` onto `pos` and `len`:
		
		```
		input = b'thirteen'
		position = [1, 5, 7]
		length =   [3, 2, 1]
		
		output = [b'hir', b'ee', b'n']
		```
		
		Raises:
		
		  * `ValueError`: If the first argument cannot be converted to a
		     Tensor of `dtype string`.
		  * `InvalidArgumentError`: If indices are out of range.
		  * `ValueError`: If `pos` and `len` are not the same shape.
		
		Args:
		  input: A `Tensor` of type `string`. Tensor of strings
		  pos: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Scalar defining the position of first character in each substring
		  len: A `Tensor`. Must have the same type as `pos`.
		    Scalar defining the number of characters to include in each substring
		  unit: An optional `string` from: `"BYTE", "UTF8_CHAR"`. Defaults to `"BYTE"`.
		    The unit that is used to create the substring.  One of: `"BYTE"` (for
		    defining position and length by bytes) or `"UTF8_CHAR"` (for the UTF-8
		    encoded Unicode code points).  The default is `"BYTE"`. Results are undefined if
		    `unit=UTF8_CHAR` and the `input` strings do not contain structurally valid
		    UTF-8.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function Substr(input:Dynamic, pos:Dynamic, len:Dynamic, ?unit:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the sum of elements across dimensions of a tensor.
		
		Reduces `input` along the dimensions given in `axis`. Unless
		`keep_dims` is true, the rank of the tensor is reduced by 1 for each entry in
		`axis`. If `keep_dims` is true, the reduced dimensions are
		retained with length 1.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		    The tensor to reduce.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The dimensions to reduce. Must be in the range
		    `[-rank(input), rank(input))`.
		  keep_dims: An optional `bool`. Defaults to `False`.
		    If true, retain reduced dimensions with length 1.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Sum(input:Dynamic, axis:Dynamic, ?keep_dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  shared_name: An optional `string`. Defaults to `""`.
		  container: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function SummaryWriter(?shared_name:Dynamic, ?container:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the singular value decompositions of one or more matrices.
		
		Computes the SVD of each inner matrix in `input` such that
		`input[..., :, :] = u[..., :, :] * diag(s[..., :, :]) * transpose(v[..., :, :])`
		
		```python
		# a is a tensor containing a batch of matrices.
		# s is a tensor of singular values for each matrix.
		# u is the tensor containing the left singular vectors for each matrix.
		# v is the tensor containing the right singular vectors for each matrix.
		s, u, v = svd(a)
		s, _, _ = svd(a, compute_uv=False)
		```
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.
		    A tensor of shape `[..., M, N]` whose inner-most 2 dimensions
		    form matrices of size `[M, N]`. Let `P` be the minimum of `M` and `N`.
		  compute_uv: An optional `bool`. Defaults to `True`.
		    If true, left and right singular vectors will be
		    computed and returned in `u` and `v`, respectively.
		    If false, `u` and `v` are not set and should never referenced.
		  full_matrices: An optional `bool`. Defaults to `False`.
		    If true, compute full-sized `u` and `v`. If false
		    (the default), compute only the leading `P` singular vectors.
		    Ignored if `compute_uv` is `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (s, u, v).
		
		  s: A `Tensor`. Has the same type as `input`.
		  u: A `Tensor`. Has the same type as `input`.
		  v: A `Tensor`. Has the same type as `input`.
	**/
	static public function Svd(input:Dynamic, ?compute_uv:Dynamic, ?full_matrices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Forwards `data` to the output port determined by `pred`.
		
		If `pred` is true, the `data` input is forwarded to `output_true`. Otherwise,
		the data goes to `output_false`.
		
		See also `RefSwitch` and `Merge`.
		
		Args:
		  data: A `Tensor`. The tensor to be forwarded to the appropriate output.
		  pred: A `Tensor` of type `bool`.
		    A scalar that specifies which output port will receive data.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_false, output_true).
		
		  output_false: A `Tensor`. Has the same type as `data`.
		  output_true: A `Tensor`. Has the same type as `data`.
	**/
	static public function Switch(data:Dynamic, pred:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient function for function f via backpropagation.
		
		Args:
		  input: A list of `Tensor` objects. a list of input tensors of size N + M;
		  Tout: A list of `tf.DTypes` that has length `>= 1`.
		    the type list for the input list.
		  f: A function decorated with @Defun.
		    The function we want to compute the gradient for.
		
		    The function 'f' must be a numerical function which takes N inputs and
		    produces M outputs. Its gradient function 'g', which is computed by
		    this SymbolicGradient op is a function taking N + M inputs and
		    produces N outputs.
		
		    I.e. if we have
		       (y1, y2, ..., y_M) = f(x1, x2, ..., x_N),
		    then, g is
		       (dL/dx1, dL/dx2, ..., dL/dx_N) = g(x1, x2, ..., x_N,
		                                         dL/dy1, dL/dy2, ..., dL/dy_M),
		
		    where L is a scalar-value function of (x1, x2, ..., xN) (e.g., the
		    loss function). dL/dx_i is the partial derivative of L with respect
		    to x_i.
		
		    (Needs some math expert to say the comment above better.)
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function SymbolicGradient(input:Dynamic, Tout:Dynamic, f:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that emits the records from one or more TFRecord files.
		
		Args:
		  filenames: A `Tensor` of type `string`.
		    A scalar or vector containing the name(s) of the file(s) to be
		    read.
		  compression_type: A `Tensor` of type `string`.
		    A scalar containing either (i) the empty string (no
		    compression), (ii) "ZLIB", or (iii) "GZIP".
		  buffer_size: A `Tensor` of type `int64`.
		    A scalar representing the number of bytes to buffer. A value of
		    0 means no buffering will be performed.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TFRecordDataset(filenames:Dynamic, compression_type:Dynamic, buffer_size:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A Reader that outputs the records from a TensorFlow Records file.
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  compression_type: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function TFRecordReader(?container:Dynamic, ?shared_name:Dynamic, ?compression_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A Reader that outputs the records from a TensorFlow Records file.
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  compression_type: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function TFRecordReaderV2(?container:Dynamic, ?shared_name:Dynamic, ?compression_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the result of a TPU compilation.
		
		This operation returns the result of a TPU compilation as a serialized
		CompilationResultProto, which holds a status and an error message if an error
		occurred during compilation.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function TPUCompilationResult(?name:Dynamic):Dynamic;
	/**
		An op enabling differentiation of TPU Embeddings.
		
		This op simply returns its first input, which is assumed to have been sliced
		from the Tensors returned by TPUEmbeddingDequeueActivations. The presence of
		this op, and its first argument being a trainable Variable, enables automatic
		differentiation of graphs containing embeddings via the TPU Embedding Python
		libraries.
		
		Args:
		  embedding_variable: A `Tensor` of type `float32`.
		    A trainable variable, enabling optimizers to find this op.
		  sliced_activations: A `Tensor` of type `float32`.
		    The embedding activations Tensor to return.
		  table_id: An `int` that is `>= 0`.
		    The id of the table in the embedding layer configuration from which
		    these activations were computed.
		  lookup_id: An `int` that is `>= 0`.
		    Identifier of the set of embedding indices which produced these
		    activations.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function TPUEmbeddingActivations(embedding_variable:Dynamic, sliced_activations:Dynamic, table_id:Dynamic, lookup_id:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A TPU core selector Op.
		
		This Op produces a set of TPU cores (for warm-up) or a single TPU core
		(for regular inference) to execute the TPU program on. The output is
		consumed by TPUPartitionedCall.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function TPUOrdinalSelector(?name:Dynamic):Dynamic;
	/**
		Calls a function placed on a specified TPU device.
		
		Args:
		  args: A list of `Tensor` objects. The arguments to the function.
		  device_ordinal: A `Tensor` of type `int32`.
		    The TPU device ordinal to run the function on.
		  Tout: A list of `tf.DTypes`. The types of the outputs of the function.
		  f: A function decorated with @Defun. The function to call.
		  autotuner_thresh: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `Tout`.
	**/
	static public function TPUPartitionedCall(args:Dynamic, device_ordinal:Dynamic, Tout:Dynamic, f:Dynamic, ?autotuner_thresh:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Metadata indicating how the TPU computation should be replicated.
		
		This operation holds the metadata common to operations of a `tpu.replicate()` computation subgraph.
		
		Args:
		  num_replicas: An `int` that is `>= 0`.
		    Number of replicas of the computation
		  num_cores_per_replica: An optional `int`. Defaults to `1`.
		    Number of cores per replica. Used for model parallelism.
		  topology: An optional `string`. Defaults to `""`.
		    TopologyProto indicating the topology of the TPU pod slice.
		  use_tpu: An optional `bool`. Defaults to `True`.
		    Whether to place the computation on the TPU.
		  device_assignment: An optional list of `ints`. Defaults to `[]`.
		    The assignment of devices for the computation.
		  computation_shape: An optional list of `ints`. Defaults to `[]`.
		    DEPRECATED. Use num_cores_per_replica instead.
		  host_compute_core: An optional list of `strings`. Defaults to `[]`.
		  padding_map: An optional list of `strings`. Defaults to `[]`.
		  step_marker_location: An optional `string`. Defaults to `"STEP_MARK_AT_ENTRY"`.
		  allow_soft_placement: An optional `bool`. Defaults to `False`.
		  use_spmd_for_xla_partitioning: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function TPUReplicateMetadata(num_replicas:Dynamic, ?num_cores_per_replica:Dynamic, ?topology:Dynamic, ?use_tpu:Dynamic, ?device_assignment:Dynamic, ?computation_shape:Dynamic, ?host_compute_core:Dynamic, ?padding_map:Dynamic, ?step_marker_location:Dynamic, ?allow_soft_placement:Dynamic, ?use_spmd_for_xla_partitioning:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Connects N inputs to an N-way replicated TPU computation.
		
		This operation holds a replicated input to a `tpu.replicate()` computation subgraph.
		Each replicated input has the same shape and type alongside the output.
		
		For example:
		```
		%a = "tf.opA"()
		%b = "tf.opB"()
		%replicated_input = "tf.TPUReplicatedInput"(%a, %b)
		%computation = "tf.Computation"(%replicated_input)
		```
		The above computation has a replicated input of two replicas.
		
		Args:
		  inputs: A list of at least 1 `Tensor` objects with the same type.
		  is_mirrored_variable: An optional `bool`. Defaults to `False`.
		  index: An optional `int`. Defaults to `-1`.
		  is_packed: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `inputs`.
	**/
	static public function TPUReplicatedInput(inputs:Dynamic, ?is_mirrored_variable:Dynamic, ?index:Dynamic, ?is_packed:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Connects N outputs from an N-way replicated TPU computation.
		
		This operation holds a replicated output from a `tpu.replicate()` computation subgraph.
		Each replicated output has the same shape and type alongside the input.
		
		For example:
		```
		%computation = "tf.Computation"()
		%replicated_output:2 = "tf.TPUReplicatedOutput"(%computation)
		```
		The above computation has a replicated output of two replicas.
		
		Args:
		  input: A `Tensor`.
		  num_replicas: An `int` that is `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `num_replicas` `Tensor` objects with the same type as `input`.
	**/
	static public function TPUReplicatedOutput(input:Dynamic, num_replicas:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that contains `count` elements from the `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  count: A `Tensor` of type `int64`.
		    A scalar representing the number of elements from the `input_dataset`
		    that should be taken. A value of `-1` indicates that all of `input_dataset`
		    is taken.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TakeDataset(input_dataset:Dynamic, count:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Read `SparseTensors` from a `SparseTensorsMap` and concatenate them.
		
		The input `sparse_handles` must be an `int64` matrix of shape `[N, 1]` where
		`N` is the minibatch size and the rows correspond to the output handles of
		`AddSparseToTensorsMap` or `AddManySparseToTensorsMap`.  The ranks of the
		original `SparseTensor` objects that went into the given input ops must all
		match.  When the final `SparseTensor` is created, it has rank one
		higher than the ranks of the incoming `SparseTensor` objects
		(they have been concatenated along a new row dimension on the left).
		
		The output `SparseTensor` object's shape values for all dimensions but the
		first are the max across the input `SparseTensor` objects' shape values
		for the corresponding dimensions.  Its first shape value is `N`, the minibatch
		size.
		
		The input `SparseTensor` objects' indices are assumed ordered in
		standard lexicographic order.  If this is not the case, after this
		step run `SparseReorder` to restore index ordering.
		
		For example, if the handles represent an input, which is a `[2, 3]` matrix
		representing two original `SparseTensor` objects:
		
		```
		    index = [ 0]
		            [10]
		            [20]
		    values = [1, 2, 3]
		    shape = [50]
		```
		
		and
		
		```
		    index = [ 2]
		            [10]
		    values = [4, 5]
		    shape = [30]
		```
		
		then the final `SparseTensor` will be:
		
		```
		    index = [0  0]
		            [0 10]
		            [0 20]
		            [1  2]
		            [1 10]
		    values = [1, 2, 3, 4, 5]
		    shape = [2 50]
		```
		
		Args:
		  sparse_handles: A `Tensor` of type `int64`.
		    1-D, The `N` serialized `SparseTensor` objects.
		    Shape: `[N]`.
		  dtype: A `tf.DType`.
		    The `dtype` of the `SparseTensor` objects stored in the
		    `SparseTensorsMap`.
		  container: An optional `string`. Defaults to `""`.
		    The container name for the `SparseTensorsMap` read by this op.
		  shared_name: An optional `string`. Defaults to `""`.
		    The shared name for the `SparseTensorsMap` read by this op.
		    It should not be blank; rather the `shared_name` or unique Operation name
		    of the Op that created the original `SparseTensorsMap` should be used.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sparse_indices, sparse_values, sparse_shape).
		
		  sparse_indices: A `Tensor` of type `int64`.
		  sparse_values: A `Tensor` of type `dtype`.
		  sparse_shape: A `Tensor` of type `int64`.
	**/
	static public function TakeManySparseFromTensorsMap(sparse_handles:Dynamic, dtype:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that stops iteration when predicate` is false.
		
		The `predicate` function must return a scalar boolean and accept the
		following arguments:
		
		* One tensor for each component of an element of `input_dataset`.
		* One tensor for each value in `other_arguments`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  other_arguments: A list of `Tensor` objects.
		    A list of tensors, typically values that were captured when
		    building a closure for `predicate`.
		  predicate: A function decorated with @Defun.
		    A function returning a scalar boolean.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TakeWhileDataset(input_dataset:Dynamic, other_arguments:Dynamic, predicate:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes tan of x element-wise.
		
		  Given an input tensor, this function computes tangent of every
		  element in the tensor. Input range is `(-inf, inf)` and
		  output range is `(-inf, inf)`. If input lies outside the boundary, `nan`
		  is returned.
		
		  ```python
		  x = tf.constant([-float("inf"), -9, -0.5, 1, 1.2, 200, 10000, float("inf")])
		  tf.math.tan(x) ==> [nan 0.45231566 -0.5463025 1.5574077 2.572152 -1.7925274 0.32097113 nan]
		  ```
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Tan(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes hyperbolic tangent of `x` element-wise.
		
		  Given an input tensor, this function computes hyperbolic tangent of every
		  element in the tensor. Input range is `[-inf, inf]` and
		  output range is `[-1,1]`.
		
		  >>> x = tf.constant([-float("inf"), -5, -0.5, 1, 1.2, 2, 3, float("inf")])
		  >>> tf.math.tanh(x)
		  <tf.Tensor: shape=(8,), dtype=float32, numpy=
		  array([-1.        , -0.99990916, -0.46211717,  0.7615942 ,  0.8336547 ,
		          0.9640276 ,  0.9950547 ,  1.        ], dtype=float32)>
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Tanh(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the gradient for the tanh of `x` wrt its input.
		
		Specifically, `grad = dy * (1 - y*y)`, where `y = tanh(x)`, and `dy`
		is the corresponding input gradient.
		
		Args:
		  y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.
		  dy: A `Tensor`. Must have the same type as `y`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `y`.
	**/
	static public function TanhGrad(y:Dynamic, dy:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a tensor that may be mutated, but only persists within a single step.
		
		This is an experimental op for internal use only and it is possible to use this
		op in unsafe ways.  DO NOT USE unless you fully understand the risks.
		
		It is the caller's responsibility to ensure that 'ref' is eventually passed to a
		matching 'DestroyTemporaryVariable' op after all other uses have completed.
		
		Outputs a ref to the tensor state so it may be read or modified.
		
		  E.g.
		      var = state_ops._temporary_variable([1, 2], types.float_)
		      var_name = var.op.name
		      var = state_ops.assign(var, [[4.0, 5.0]])
		      var = state_ops.assign_add(var, [[6.0, 7.0]])
		      final = state_ops._destroy_temporary_variable(var, var_name=var_name)
		
		Args:
		  shape: A `tf.TensorShape` or list of `ints`.
		    The shape of the variable tensor.
		  dtype: A `tf.DType`. The type of elements in the variable tensor.
		  var_name: An optional `string`. Defaults to `""`.
		    Overrides the name used for the temporary variable resource. Default
		    value is the name of the 'TemporaryVariable' op (which is guaranteed unique).
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor` of type `dtype`.
	**/
	static public function TemporaryVariable(shape:Dynamic, dtype:Dynamic, ?var_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  size: A `Tensor` of type `int32`.
		  dtype: A `tf.DType`.
		  dynamic_size: An optional `bool`. Defaults to `False`.
		  clear_after_read: An optional `bool`. Defaults to `True`.
		  tensor_array_name: An optional `string`. Defaults to `""`.
		  element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function TensorArray(size:Dynamic, dtype:Dynamic, ?dynamic_size:Dynamic, ?clear_after_read:Dynamic, ?tensor_array_name:Dynamic, ?element_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function TensorArrayClose(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Use TensorArrayCloseV3
		
		Args:
		  handle: A `Tensor` of type `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function TensorArrayCloseV2(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Delete the TensorArray from its resource container.
		
		This enables the user to close and release the resource in the middle
		of a step/run.
		
		Args:
		  handle: A `Tensor` of type `resource`.
		    The handle to a TensorArray (output of TensorArray or TensorArrayGrad).
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function TensorArrayCloseV3(handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  flow_in: A `Tensor` of type `float32`.
		  dtype: A `tf.DType`.
		  element_shape_except0: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (value, lengths).
		
		  value: A `Tensor` of type `dtype`.
		  lengths: A `Tensor` of type `int64`.
	**/
	static public function TensorArrayConcat(handle:Dynamic, flow_in:Dynamic, dtype:Dynamic, ?element_shape_except0:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Use TensorArrayConcatV3
		
		Args:
		  handle: A `Tensor` of type `string`.
		  flow_in: A `Tensor` of type `float32`.
		  dtype: A `tf.DType`.
		  element_shape_except0: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (value, lengths).
		
		  value: A `Tensor` of type `dtype`.
		  lengths: A `Tensor` of type `int64`.
	**/
	static public function TensorArrayConcatV2(handle:Dynamic, flow_in:Dynamic, dtype:Dynamic, ?element_shape_except0:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Concat the elements from the TensorArray into value `value`.
		
		Takes `T` elements of shapes
		
		  ```
		  (n0 x d0 x d1 x ...), (n1 x d0 x d1 x ...), ..., (n(T-1) x d0 x d1 x ...)
		  ```
		
		and concatenates them into a Tensor of shape:
		
		  ```(n0 + n1 + ... + n(T-1) x d0 x d1 x ...)```
		
		All elements must have the same shape (excepting the first dimension).
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a TensorArray.
		  flow_in: A `Tensor` of type `float32`.
		    A float scalar that enforces proper chaining of operations.
		  dtype: A `tf.DType`. The type of the elem that is returned.
		  element_shape_except0: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		    The expected shape of an element, if known,
		    excluding the first dimension. Used to validate the shapes of
		    TensorArray elements. If this shape is not fully specified, concatenating
		    zero-size TensorArrays is an error.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (value, lengths).
		
		  value: A `Tensor` of type `dtype`.
		  lengths: A `Tensor` of type `int64`.
	**/
	static public function TensorArrayConcatV3(handle:Dynamic, flow_in:Dynamic, dtype:Dynamic, ?element_shape_except0:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  indices: A `Tensor` of type `int32`.
		  flow_in: A `Tensor` of type `float32`.
		  dtype: A `tf.DType`.
		  element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function TensorArrayGather(handle:Dynamic, indices:Dynamic, flow_in:Dynamic, dtype:Dynamic, ?element_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Use TensorArrayGatherV3
		
		Args:
		  handle: A `Tensor` of type `string`.
		  indices: A `Tensor` of type `int32`.
		  flow_in: A `Tensor` of type `float32`.
		  dtype: A `tf.DType`.
		  element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function TensorArrayGatherV2(handle:Dynamic, indices:Dynamic, flow_in:Dynamic, dtype:Dynamic, ?element_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gather specific elements from the TensorArray into output `value`.
		
		All elements selected by `indices` must have the same shape.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a TensorArray.
		  indices: A `Tensor` of type `int32`.
		    The locations in the TensorArray from which to read tensor elements.
		  flow_in: A `Tensor` of type `float32`.
		    A float scalar that enforces proper chaining of operations.
		  dtype: A `tf.DType`. The type of the elem that is returned.
		  element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		    The expected shape of an element, if known. Used to
		    validate the shapes of TensorArray elements. If this shape is not
		    fully specified, gathering zero-size TensorArrays is an error.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function TensorArrayGatherV3(handle:Dynamic, indices:Dynamic, flow_in:Dynamic, dtype:Dynamic, ?element_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type `string`.
		  flow_in: A `Tensor` of type `float32`.
		  source: A `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function TensorArrayGrad(handle:Dynamic, flow_in:Dynamic, source:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Use TensorArrayGradV3
		
		Args:
		  handle: A `Tensor` of type `string`.
		  flow_in: A `Tensor` of type `float32`.
		  source: A `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function TensorArrayGradV2(handle:Dynamic, flow_in:Dynamic, source:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a TensorArray for storing the gradients of values in the given handle.
		
		If the given TensorArray gradient already exists, returns a reference to it.
		
		Locks the size of the original TensorArray by disabling its dynamic size flag.
		
		**A note about the input flow_in:**
		
		The handle flow_in forces the execution of the gradient lookup to occur
		only after certain other operations have occurred.  For example, when
		the forward TensorArray is dynamically sized, writes to this TensorArray
		may resize the object.  The gradient TensorArray is statically sized based
		on the size of the forward TensorArray when this operation executes.
		Furthermore, the size of the forward TensorArray is frozen by this call.
		As a result, the flow is used to ensure that the call to generate the gradient
		TensorArray only happens after all writes are executed.
		
		In the case of dynamically sized TensorArrays, gradient computation should
		only be performed on read operations that have themselves been chained via
		flow to occur only after all writes have executed. That way the final size
		of the forward TensorArray is known when this operation is called.
		
		**A note about the source attribute:**
		
		TensorArray gradient calls use an accumulator TensorArray object.  If
		multiple gradients are calculated and run in the same session, the multiple
		gradient nodes may accidentally flow through the same accumulator TensorArray.
		This double counts and generally breaks the TensorArray gradient flow.
		
		The solution is to identify which gradient call this particular
		TensorArray gradient is being called in.  This is performed by identifying
		a unique string (e.g. "gradients", "gradients_1", ...) from the input
		gradient Tensor's name.  This string is used as a suffix when creating
		the TensorArray gradient object here (the attribute `source`).
		
		The attribute `source` is added as a suffix to the forward TensorArray's
		name when performing the creation / lookup, so that each separate gradient
		calculation gets its own TensorArray accumulator.
		
		Args:
		  handle: A `Tensor` of type `resource`.
		    The handle to the forward TensorArray.
		  flow_in: A `Tensor` of type `float32`.
		    A float scalar that enforces proper chaining of operations.
		  source: A `string`.
		    The gradient source string, used to decide which gradient TensorArray
		    to return.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (grad_handle, flow_out).
		
		  grad_handle: A `Tensor` of type `resource`.
		  flow_out: A `Tensor` of type `float32`.
	**/
	static public function TensorArrayGradV3(handle:Dynamic, flow_in:Dynamic, source:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a TensorArray for storing multiple gradients of values in the given handle.
		
		Similar to TensorArrayGradV3. However it creates an accumulator with an
		expanded shape compared to the input TensorArray whose gradient is being
		computed. This enables multiple gradients for the same TensorArray to be
		calculated using the same accumulator.
		
		Args:
		  handle: A `Tensor` of type `resource`.
		    The handle to the forward TensorArray.
		  flow_in: A `Tensor` of type `float32`.
		    A float scalar that enforces proper chaining of operations.
		  shape_to_prepend: A `Tensor` of type `int32`.
		    An int32 vector representing a shape. Elements in the gradient accumulator will
		    have shape which is this shape_to_prepend value concatenated with shape of the
		    elements in the TensorArray corresponding to the input handle.
		  source: A `string`.
		    The gradient source string, used to decide which gradient TensorArray
		    to return.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (grad_handle, flow_out).
		
		  grad_handle: A `Tensor` of type `resource`.
		  flow_out: A `Tensor` of type `float32`.
	**/
	static public function TensorArrayGradWithShape(handle:Dynamic, flow_in:Dynamic, shape_to_prepend:Dynamic, source:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  flow_in: A `Tensor` of type `float32`.
		  dtype: A `tf.DType`.
		  element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function TensorArrayPack(handle:Dynamic, flow_in:Dynamic, dtype:Dynamic, ?element_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  index: A `Tensor` of type `int32`.
		  flow_in: A `Tensor` of type `float32`.
		  dtype: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function TensorArrayRead(handle:Dynamic, index:Dynamic, flow_in:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Use TensorArrayReadV3
		
		Args:
		  handle: A `Tensor` of type `string`.
		  index: A `Tensor` of type `int32`.
		  flow_in: A `Tensor` of type `float32`.
		  dtype: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function TensorArrayReadV2(handle:Dynamic, index:Dynamic, flow_in:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Read an element from the TensorArray into output `value`.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a TensorArray.
		  index: A `Tensor` of type `int32`.
		  flow_in: A `Tensor` of type `float32`.
		    A float scalar that enforces proper chaining of operations.
		  dtype: A `tf.DType`. The type of the elem that is returned.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function TensorArrayReadV3(handle:Dynamic, index:Dynamic, flow_in:Dynamic, dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  indices: A `Tensor` of type `int32`.
		  value: A `Tensor`.
		  flow_in: A `Tensor` of type `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function TensorArrayScatter(handle:Dynamic, indices:Dynamic, value:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Use TensorArrayScatterV3
		
		Args:
		  handle: A `Tensor` of type `string`.
		  indices: A `Tensor` of type `int32`.
		  value: A `Tensor`.
		  flow_in: A `Tensor` of type `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function TensorArrayScatterV2(handle:Dynamic, indices:Dynamic, value:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Scatter the data from the input value into specific TensorArray elements.
		
		`indices` must be a vector, its length must match the first dim of `value`.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a TensorArray.
		  indices: A `Tensor` of type `int32`.
		    The locations at which to write the tensor elements.
		  value: A `Tensor`. The concatenated tensor to write to the TensorArray.
		  flow_in: A `Tensor` of type `float32`.
		    A float scalar that enforces proper chaining of operations.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function TensorArrayScatterV3(handle:Dynamic, indices:Dynamic, value:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  flow_in: A `Tensor` of type `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function TensorArraySize(handle:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Use TensorArraySizeV3
		
		Args:
		  handle: A `Tensor` of type `string`.
		  flow_in: A `Tensor` of type `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function TensorArraySizeV2(handle:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Get the current size of the TensorArray.
		
		Args:
		  handle: A `Tensor` of type `resource`.
		    The handle to a TensorArray (output of TensorArray or TensorArrayGrad).
		  flow_in: A `Tensor` of type `float32`.
		    A float scalar that enforces proper chaining of operations.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function TensorArraySizeV3(handle:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  value: A `Tensor`.
		  lengths: A `Tensor` of type `int64`.
		  flow_in: A `Tensor` of type `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function TensorArraySplit(handle:Dynamic, value:Dynamic, lengths:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Use TensorArraySplitV3
		
		Args:
		  handle: A `Tensor` of type `string`.
		  value: A `Tensor`.
		  lengths: A `Tensor` of type `int64`.
		  flow_in: A `Tensor` of type `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function TensorArraySplitV2(handle:Dynamic, value:Dynamic, lengths:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Split the data from the input value into TensorArray elements.
		
		Assuming that `lengths` takes on values
		
		  ```(n0, n1, ..., n(T-1))```
		
		and that `value` has shape
		
		  ```(n0 + n1 + ... + n(T-1) x d0 x d1 x ...)```,
		
		this splits values into a TensorArray with T tensors.
		
		TensorArray index t will be the subtensor of values with starting position
		
		  ```(n0 + n1 + ... + n(t-1), 0, 0, ...)```
		
		and having size
		
		  ```nt x d0 x d1 x ...```
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a TensorArray.
		  value: A `Tensor`. The concatenated tensor to write to the TensorArray.
		  lengths: A `Tensor` of type `int64`.
		    The vector of lengths, how to split the rows of value into the
		    TensorArray.
		  flow_in: A `Tensor` of type `float32`.
		    A float scalar that enforces proper chaining of operations.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function TensorArraySplitV3(handle:Dynamic, value:Dynamic, lengths:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  value: A `Tensor`.
		  flow_in: A `Tensor` of type `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function TensorArrayUnpack(handle:Dynamic, value:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Use TensorArrayV3
		
		Args:
		  size: A `Tensor` of type `int32`.
		  dtype: A `tf.DType`.
		  element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		  dynamic_size: An optional `bool`. Defaults to `False`.
		  clear_after_read: An optional `bool`. Defaults to `True`.
		  tensor_array_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function TensorArrayV2(size:Dynamic, dtype:Dynamic, ?element_shape:Dynamic, ?dynamic_size:Dynamic, ?clear_after_read:Dynamic, ?tensor_array_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		An array of Tensors of given size.
		
		Write data via Write and read via Read or Pack.
		
		Args:
		  size: A `Tensor` of type `int32`. The size of the array.
		  dtype: A `tf.DType`. The type of the elements on the tensor_array.
		  element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		    The expected shape of an element, if known. Used to
		    validate the shapes of TensorArray elements. If this shape is not
		    fully specified, gathering zero-size TensorArrays is an error.
		  dynamic_size: An optional `bool`. Defaults to `False`.
		    A boolean that determines whether writes to the TensorArray
		    are allowed to grow the size.  By default, this is not allowed.
		  clear_after_read: An optional `bool`. Defaults to `True`.
		    If true (default), Tensors in the TensorArray are cleared
		    after being read.  This disables multiple read semantics but allows early
		    release of memory.
		  identical_element_shapes: An optional `bool`. Defaults to `False`.
		    If true (default is false), then all
		    elements in the TensorArray will be expected to have identical shapes.
		    This allows certain behaviors, like dynamically checking for
		    consistent shapes on write, and being able to fill in properly
		    shaped zero tensors on stack -- even if the element_shape attribute
		    is not fully defined.
		  tensor_array_name: An optional `string`. Defaults to `""`.
		    Overrides the name used for the temporary tensor_array
		    resource. Default value is the name of the 'TensorArray' op (which
		    is guaranteed unique).
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (handle, flow).
		
		  handle: A `Tensor` of type `resource`.
		  flow: A `Tensor` of type `float32`.
	**/
	static public function TensorArrayV3(size:Dynamic, dtype:Dynamic, ?element_shape:Dynamic, ?dynamic_size:Dynamic, ?clear_after_read:Dynamic, ?identical_element_shapes:Dynamic, ?tensor_array_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  handle: A `Tensor` of type mutable `string`.
		  index: A `Tensor` of type `int32`.
		  value: A `Tensor`.
		  flow_in: A `Tensor` of type `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function TensorArrayWrite(handle:Dynamic, index:Dynamic, value:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Deprecated. Use TensorArrayGradV3
		
		Args:
		  handle: A `Tensor` of type `string`.
		  index: A `Tensor` of type `int32`.
		  value: A `Tensor`.
		  flow_in: A `Tensor` of type `float32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function TensorArrayWriteV2(handle:Dynamic, index:Dynamic, value:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Push an element onto the tensor_array.
		
		Args:
		  handle: A `Tensor` of type `resource`. The handle to a TensorArray.
		  index: A `Tensor` of type `int32`.
		    The position to write to inside the TensorArray.
		  value: A `Tensor`. The tensor to write to the TensorArray.
		  flow_in: A `Tensor` of type `float32`.
		    A float scalar that enforces proper chaining of operations.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float32`.
	**/
	static public function TensorArrayWriteV3(handle:Dynamic, index:Dynamic, value:Dynamic, flow_in:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that emits `components` as a tuple of tensors once.
		
		Args:
		  components: A list of `Tensor` objects.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorDataset(components:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Concats all tensors in the list along the 0th dimension.
		
		Requires that all tensors have the same shape except the first dimension.
		
		input_handle: The input list.
		tensor: The concated result.
		lengths: Output tensor containing sizes of the 0th dimension of tensors in the list, used for computing the gradient.
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  element_dtype: A `tf.DType`.
		  element_shape: An optional `tf.TensorShape` or list of `ints`. Defaults to `None`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (tensor, lengths).
		
		  tensor: A `Tensor` of type `element_dtype`.
		  lengths: A `Tensor` of type `int64`.
	**/
	static public function TensorListConcat(input_handle:Dynamic, element_dtype:Dynamic, ?element_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_a: A `Tensor` of type `variant`.
		  input_b: A `Tensor` of type `variant`.
		  element_dtype: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorListConcatLists(input_a:Dynamic, input_b:Dynamic, element_dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Concats all tensors in the list along the 0th dimension.
		
		Requires that all tensors have the same shape except the first dimension.
		
		input_handle: The input list.
		element_shape: The shape of the uninitialized elements in the list. If the first
		  dimension is not -1, it is assumed that all list elements have the same
		  leading dim.
		leading_dims: The list of leading dims of uninitialized list elements. Used if
		  the leading dim of input_handle.element_shape or the element_shape input arg
		  is not already set.
		tensor: The concated result.
		lengths: Output tensor containing sizes of the 0th dimension of tensors in the list, used for computing the gradient.
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  element_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  leading_dims: A `Tensor` of type `int64`.
		  element_dtype: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (tensor, lengths).
		
		  tensor: A `Tensor` of type `element_dtype`.
		  lengths: A `Tensor` of type `int64`.
	**/
	static public function TensorListConcatV2(input_handle:Dynamic, element_shape:Dynamic, leading_dims:Dynamic, element_dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		The shape of the elements of the given list, as a tensor.
		
		  input_handle: the list
		  element_shape: the shape of elements of the list
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  shape_type: A `tf.DType` from: `tf.int32, tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `shape_type`.
	**/
	static public function TensorListElementShape(input_handle:Dynamic, shape_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a TensorList which, when stacked, has the value of `tensor`.
		
		Each tensor in the result list corresponds to one row of the input tensor.
		
		tensor: The input tensor.
		output_handle: The list.
		
		Args:
		  tensor: A `Tensor`.
		  element_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorListFromTensor(tensor:Dynamic, element_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a Tensor by indexing into the TensorList.
		
		Each row in the produced Tensor corresponds to the element in the TensorList
		specified by the given index (see `tf.gather`).
		
		input_handle: The input tensor list.
		indices: The indices used to index into the list.
		values: The tensor.
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  indices: A `Tensor` of type `int32`.
		  element_shape: A `Tensor` of type `int32`.
		  element_dtype: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `element_dtype`.
	**/
	static public function TensorListGather(input_handle:Dynamic, indices:Dynamic, element_shape:Dynamic, element_dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the item in the list with the given index.
		
		input_handle: the list
		index: the position in the list from which an element will be retrieved
		item: the element at that position
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  index: A `Tensor` of type `int32`.
		  element_shape: A `Tensor` of type `int32`.
		  element_dtype: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `element_dtype`.
	**/
	static public function TensorListGetItem(input_handle:Dynamic, index:Dynamic, element_shape:Dynamic, element_dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the number of tensors in the input tensor list.
		
		input_handle: the input list
		length: the number of tensors in the list
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function TensorListLength(input_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the last element of the input list as well as a list with all but that element.
		
		Fails if the list is empty.
		
		input_handle: the input list
		tensor: the withdrawn last element of the list
		element_dtype: the type of elements in the list
		element_shape: the shape of the output tensor
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  element_shape: A `Tensor` of type `int32`.
		  element_dtype: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (output_handle, tensor).
		
		  output_handle: A `Tensor` of type `variant`.
		  tensor: A `Tensor` of type `element_dtype`.
	**/
	static public function TensorListPopBack(input_handle:Dynamic, element_shape:Dynamic, element_dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a list which has the passed-in `Tensor` as last element and the other elements of the given list in `input_handle`.
		
		tensor: The tensor to put on the list.
		input_handle: The old list.
		output_handle: A list with the elements of the old list followed by tensor.
		element_dtype: the type of elements in the list.
		element_shape: a shape compatible with that of elements in the list.
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  tensor: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorListPushBack(input_handle:Dynamic, tensor:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_handles: A `Tensor` of type `variant`.
		  tensor: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorListPushBackBatch(input_handles:Dynamic, tensor:Dynamic, ?name:Dynamic):Dynamic;
	/**
		List of the given size with empty elements.
		
		element_shape: the shape of the future elements of the list
		num_elements: the number of elements to reserve
		handle: the output list
		element_dtype: the desired type of elements in the list.
		
		Args:
		  element_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  num_elements: A `Tensor` of type `int32`.
		  element_dtype: A `tf.DType`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorListReserve(element_shape:Dynamic, num_elements:Dynamic, element_dtype:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Resizes the list.
		
		
		input_handle: the input list
		size: size of the output list
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  size: A `Tensor` of type `int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorListResize(input_handle:Dynamic, size:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a TensorList by indexing into a Tensor.
		
		Each member of the TensorList corresponds to one row of the input tensor,
		specified by the given index (see `tf.gather`).
		
		tensor: The input tensor.
		indices: The indices used to index into the list.
		element_shape: The shape of the elements in the list (can be less specified than
		  the shape of the tensor).
		output_handle: The TensorList.
		
		Args:
		  tensor: A `Tensor`.
		  indices: A `Tensor` of type `int32`.
		  element_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorListScatter(tensor:Dynamic, indices:Dynamic, element_shape:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Scatters tensor at indices in an input list.
		
		Each member of the TensorList corresponds to one row of the input tensor,
		specified by the given index (see `tf.gather`).
		
		input_handle: The list to scatter into.
		tensor: The input tensor.
		indices: The indices used to index into the list.
		output_handle: The TensorList.
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  tensor: A `Tensor`.
		  indices: A `Tensor` of type `int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorListScatterIntoExistingList(input_handle:Dynamic, tensor:Dynamic, indices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a TensorList by indexing into a Tensor.
		
		Each member of the TensorList corresponds to one row of the input tensor,
		specified by the given index (see `tf.gather`).
		
		tensor: The input tensor.
		indices: The indices used to index into the list.
		element_shape: The shape of the elements in the list (can be less specified than
		  the shape of the tensor).
		num_elements: The size of the output list. Must be large enough to accommodate
		  the largest index in indices. If -1, the list is just large enough to include
		  the largest index in indices.
		output_handle: The TensorList.
		
		Args:
		  tensor: A `Tensor`.
		  indices: A `Tensor` of type `int32`.
		  element_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  num_elements: A `Tensor` of type `int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorListScatterV2(tensor:Dynamic, indices:Dynamic, element_shape:Dynamic, num_elements:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Sets the index-th position of the list to contain the given tensor.
		
		input_handle: the list
		index: the position in the list to which the tensor will be assigned
		item: the element to be assigned to that position
		output_handle: the new list, with the element in the proper position
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  index: A `Tensor` of type `int32`.
		  item: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorListSetItem(input_handle:Dynamic, index:Dynamic, item:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Splits a tensor into a list.
		
		list[i] corresponds to lengths[i] tensors from the input tensor.
		The tensor must have rank at least 1 and contain exactly sum(lengths) elements.
		
		tensor: The input tensor.
		element_shape: A shape compatible with that of elements in the tensor.
		lengths: Vector of sizes of the 0th dimension of tensors in the list.
		output_handle: The list.
		
		Args:
		  tensor: A `Tensor`.
		  element_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  lengths: A `Tensor` of type `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorListSplit(tensor:Dynamic, element_shape:Dynamic, lengths:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Stacks all tensors in the list.
		
		Requires that all tensors have the same shape.
		
		input_handle: the input list
		tensor: the gathered result
		num_elements: optional. If not -1, the number of elements in the list.
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  element_shape: A `Tensor` of type `int32`.
		  element_dtype: A `tf.DType`.
		  num_elements: An optional `int`. Defaults to `-1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `element_dtype`.
	**/
	static public function TensorListStack(input_handle:Dynamic, element_shape:Dynamic, element_dtype:Dynamic, ?num_elements:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Adds sparse `updates` to an existing tensor according to `indices`.
		
		This operation creates a new tensor by adding sparse `updates` to the passed
		in `tensor`.
		This operation is very similar to `tf.compat.v1.scatter_nd_add`, except that the updates
		are added onto an existing tensor (as opposed to a variable). If the memory
		for the existing tensor cannot be re-used, a copy is made and updated.
		
		`indices` is an integer tensor containing indices into a new tensor of shape
		`tensor.shape`.  The last dimension of `indices` can be at most the rank of
		`tensor.shape`:
		
		    indices.shape[-1] <= tensor.shape.rank
		
		The last dimension of `indices` corresponds to indices into elements
		(if `indices.shape[-1] = tensor.shape.rank`) or slices
		(if `indices.shape[-1] < tensor.shape.rank`) along dimension
		`indices.shape[-1]` of `tensor.shape`.  `updates` is a tensor with shape
		
		    indices.shape[:-1] + tensor.shape[indices.shape[-1]:]
		
		The simplest form of tensor_scatter_add is to add individual elements to a
		tensor by index. For example, say we want to add 4 elements in a rank-1
		tensor with 8 elements.
		
		In Python, this scatter add operation would look like this:
		
		```python
		    indices = tf.constant([[4], [3], [1], [7]])
		    updates = tf.constant([9, 10, 11, 12])
		    tensor = tf.ones([8], dtype=tf.int32)
		    updated = tf.tensor_scatter_nd_add(tensor, indices, updates)
		    print(updated)
		```
		
		The resulting tensor would look like this:
		
		    [1, 12, 1, 11, 10, 1, 1, 13]
		
		We can also, insert entire slices of a higher rank tensor all at once. For
		example, if we wanted to insert two slices in the first dimension of a
		rank-3 tensor with two matrices of new values.
		
		In Python, this scatter add operation would look like this:
		
		```python
		    indices = tf.constant([[0], [2]])
		    updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],
		                            [7, 7, 7, 7], [8, 8, 8, 8]],
		                           [[5, 5, 5, 5], [6, 6, 6, 6],
		                            [7, 7, 7, 7], [8, 8, 8, 8]]])
		    tensor = tf.ones([4, 4, 4],dtype=tf.int32)
		    updated = tf.tensor_scatter_nd_add(tensor, indices, updates)
		    print(updated)
		```
		
		The resulting tensor would look like this:
		
		    [[[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],
		     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],
		     [[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],
		     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]
		
		Note that on CPU, if an out of bound index is found, an error is returned.
		On GPU, if an out of bound index is found, the index is ignored.
		
		Args:
		  tensor: A `Tensor`. Tensor to copy/update.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Index tensor.
		  updates: A `Tensor`. Must have the same type as `tensor`.
		    Updates to scatter into output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `tensor`.
	**/
	static public function TensorScatterAdd(tensor:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  tensor: A `Tensor`. Tensor to update.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Index tensor.
		  updates: A `Tensor`. Must have the same type as `tensor`.
		    Updates to scatter into output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `tensor`.
	**/
	static public function TensorScatterMax(tensor:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  tensor: A `Tensor`. Tensor to update.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Index tensor.
		  updates: A `Tensor`. Must have the same type as `tensor`.
		    Updates to scatter into output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `tensor`.
	**/
	static public function TensorScatterMin(tensor:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Subtracts sparse `updates` from an existing tensor according to `indices`.
		
		This operation creates a new tensor by subtracting sparse `updates` from the
		passed in `tensor`.
		This operation is very similar to `tf.scatter_nd_sub`, except that the updates
		are subtracted from an existing tensor (as opposed to a variable). If the memory
		for the existing tensor cannot be re-used, a copy is made and updated.
		
		`indices` is an integer tensor containing indices into a new tensor of shape
		`shape`.  The last dimension of `indices` can be at most the rank of `shape`:
		
		    indices.shape[-1] <= shape.rank
		
		The last dimension of `indices` corresponds to indices into elements
		(if `indices.shape[-1] = shape.rank`) or slices
		(if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of
		`shape`.  `updates` is a tensor with shape
		
		    indices.shape[:-1] + shape[indices.shape[-1]:]
		
		The simplest form of tensor_scatter_sub is to subtract individual elements
		from a tensor by index. For example, say we want to insert 4 scattered elements
		in a rank-1 tensor with 8 elements.
		
		In Python, this scatter subtract operation would look like this:
		
		```python
		    indices = tf.constant([[4], [3], [1], [7]])
		    updates = tf.constant([9, 10, 11, 12])
		    tensor = tf.ones([8], dtype=tf.int32)
		    updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)
		    print(updated)
		```
		
		The resulting tensor would look like this:
		
		    [1, -10, 1, -9, -8, 1, 1, -11]
		
		We can also, insert entire slices of a higher rank tensor all at once. For
		example, if we wanted to insert two slices in the first dimension of a
		rank-3 tensor with two matrices of new values.
		
		In Python, this scatter add operation would look like this:
		
		```python
		    indices = tf.constant([[0], [2]])
		    updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],
		                            [7, 7, 7, 7], [8, 8, 8, 8]],
		                           [[5, 5, 5, 5], [6, 6, 6, 6],
		                            [7, 7, 7, 7], [8, 8, 8, 8]]])
		    tensor = tf.ones([4, 4, 4],dtype=tf.int32)
		    updated = tf.tensor_scatter_nd_sub(tensor, indices, updates)
		    print(updated)
		```
		
		The resulting tensor would look like this:
		
		    [[[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],
		     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],
		     [[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],
		     [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]
		
		Note that on CPU, if an out of bound index is found, an error is returned.
		On GPU, if an out of bound index is found, the index is ignored.
		
		Args:
		  tensor: A `Tensor`. Tensor to copy/update.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Index tensor.
		  updates: A `Tensor`. Must have the same type as `tensor`.
		    Updates to scatter into output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `tensor`.
	**/
	static public function TensorScatterSub(tensor:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Scatter `updates` into an existing tensor according to `indices`.
		
		This operation creates a new tensor by applying sparse `updates` to the passed
		in `tensor`.
		This operation is very similar to `tf.scatter_nd`, except that the updates are
		scattered onto an existing tensor (as opposed to a zero-tensor). If the memory
		for the existing tensor cannot be re-used, a copy is made and updated.
		
		If `indices` contains duplicates, then we pick the last update for the index.
		
		If an out of bound index is found on CPU, an error is returned.
		
		**WARNING**: There are some GPU specific semantics for this operation.
		- If an out of bound index is found, the index is ignored.
		- The order in which updates are applied is nondeterministic, so the output
		will be nondeterministic if `indices` contains duplicates.
		
		`indices` is an integer tensor containing indices into a new tensor of shape
		`shape`.
		
		* `indices` must have at least 2 axes: `(num_updates, index_depth)`.
		* The last axis of `indices` is how deep to index into `tensor` so  this index
		  depth must be less than the rank of `tensor`: `indices.shape[-1] <= tensor.ndim`
		
		if `indices.shape[-1] = tensor.rank` this Op indexes and updates scalar elements.
		if `indices.shape[-1] < tensor.rank` it indexes and updates slices of the input
		`tensor`.
		
		Each `update` has a rank of `tensor.rank - indices.shape[-1]`.
		The overall shape of `updates` is:
		
		```
		indices.shape[:-1] + tensor.shape[indices.shape[-1]:]
		```
		
		For usage examples see the python [tf.tensor_scatter_nd_update](
		https://www.tensorflow.org/api_docs/python/tf/tensor_scatter_nd_update) function
		
		Args:
		  tensor: A `Tensor`. Tensor to copy/update.
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    Index tensor.
		  updates: A `Tensor`. Must have the same type as `tensor`.
		    Updates to scatter into output.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `tensor`.
	**/
	static public function TensorScatterUpdate(tensor:Dynamic, indices:Dynamic, updates:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that emits each dim-0 slice of `components` once.
		
		Args:
		  components: A list of `Tensor` objects.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  is_files: An optional `bool`. Defaults to `False`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TensorSliceDataset(components:Dynamic, output_shapes:Dynamic, ?is_files:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Assign `value` to the sliced l-value reference of `input`.
		
		The values of `value` are assigned to the positions in the tensor `input` that
		are selected by the slice parameters. The slice parameters `begin` `end`
		`strides` etc. work exactly as in `StridedSlice`.
		
		NOTE this op currently does not support broadcasting and so `value`'s shape
		must be exactly the shape produced by the slice of `input`.
		
		Args:
		  input: A `Tensor`.
		  begin: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  end: A `Tensor`. Must have the same type as `begin`.
		  strides: A `Tensor`. Must have the same type as `begin`.
		  value: A `Tensor`. Must have the same type as `input`.
		  begin_mask: An optional `int`. Defaults to `0`.
		  end_mask: An optional `int`. Defaults to `0`.
		  ellipsis_mask: An optional `int`. Defaults to `0`.
		  new_axis_mask: An optional `int`. Defaults to `0`.
		  shrink_axis_mask: An optional `int`. Defaults to `0`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function TensorStridedSliceUpdate(input:Dynamic, begin:Dynamic, end:Dynamic, strides:Dynamic, value:Dynamic, ?begin_mask:Dynamic, ?end_mask:Dynamic, ?ellipsis_mask:Dynamic, ?new_axis_mask:Dynamic, ?shrink_axis_mask:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs a `Summary` protocol buffer with a tensor.
		
		This op is being phased out in favor of TensorSummaryV2, which lets callers pass
		a tag as well as a serialized SummaryMetadata proto string that contains
		plugin-specific data. We will keep this op to maintain backwards compatibility.
		
		Args:
		  tensor: A `Tensor`. A tensor to serialize.
		  description: An optional `string`. Defaults to `""`.
		    A json-encoded SummaryDescription proto.
		  labels: An optional list of `strings`. Defaults to `[]`.
		    An unused list of strings.
		  display_name: An optional `string`. Defaults to `""`. An unused string.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function TensorSummary(tensor:Dynamic, ?description:Dynamic, ?labels:Dynamic, ?display_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs a `Summary` protocol buffer with a tensor and per-plugin data.
		
		Args:
		  tag: A `Tensor` of type `string`.
		    A string attached to this summary. Used for organization in TensorBoard.
		  tensor: A `Tensor`. A tensor to serialize.
		  serialized_summary_metadata: A `Tensor` of type `string`.
		    A serialized SummaryMetadata proto. Contains plugin
		    data.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function TensorSummaryV2(tag:Dynamic, tensor:Dynamic, serialized_summary_metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that emits the lines of one or more text files.
		
		Args:
		  filenames: A `Tensor` of type `string`.
		    A scalar or a vector containing the name(s) of the file(s) to be
		    read.
		  compression_type: A `Tensor` of type `string`.
		    A scalar containing either (i) the empty string (no
		    compression), (ii) "ZLIB", or (iii) "GZIP".
		  buffer_size: A `Tensor` of type `int64`.
		    A scalar containing the number of bytes to buffer.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function TextLineDataset(filenames:Dynamic, compression_type:Dynamic, buffer_size:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A Reader that outputs the lines of a file delimited by '\n'.
		
		Args:
		  skip_header_lines: An optional `int`. Defaults to `0`.
		    Number of lines to skip from the beginning of every file.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function TextLineReader(?skip_header_lines:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A Reader that outputs the lines of a file delimited by '\n'.
		
		Args:
		  skip_header_lines: An optional `int`. Defaults to `0`.
		    Number of lines to skip from the beginning of every file.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function TextLineReaderV2(?skip_header_lines:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that uses a custom thread pool to compute `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  thread_pool: A `Tensor` of type `resource`.
		    A resource produced by the ThreadPoolHandle op.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ThreadPoolDataset(input_dataset:Dynamic, thread_pool:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that uses a custom thread pool to compute `input_dataset`.
		
		Args:
		  num_threads: An `int`. The number of threads in the thread pool.
		  display_name: A `string`.
		    A human-readable name for the threads that may be visible in some
		    visualizations.
		    threadpool.
		  max_intra_op_parallelism: An optional `int`. Defaults to `1`.
		    The maximum degree of parallelism to use within operations that execute on this
		    threadpool.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function ThreadPoolHandle(num_threads:Dynamic, display_name:Dynamic, ?max_intra_op_parallelism:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates labels for candidate sampling with a learned unigram distribution.
		
		See explanations of candidate sampling and the data formats at
		go/candidate-sampling.
		
		For each batch, this op picks a single set of sampled candidate labels.
		
		The advantages of sampling candidates per-batch are simplicity and the
		possibility of efficient dense matrix multiplication. The disadvantage is that
		the sampled candidates must be chosen independently of the context and of the
		true labels.
		
		Args:
		  true_classes: A `Tensor` of type `int64`.
		    A batch_size * num_true matrix, in which each row contains the
		    IDs of the num_true target_classes in the corresponding original label.
		  num_true: An `int` that is `>= 1`. Number of true labels per context.
		  num_sampled: An `int` that is `>= 1`.
		    Number of candidates to randomly sample.
		  unique: A `bool`.
		    If unique is true, we sample with rejection, so that all sampled
		    candidates in a batch are unique. This requires some approximation to
		    estimate the post-rejection sampling probabilities.
		  range_max: An `int` that is `>= 1`.
		    The sampler will sample integers from the interval [0, range_max).
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    An second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sampled_candidates, true_expected_count, sampled_expected_count).
		
		  sampled_candidates: A `Tensor` of type `int64`.
		  true_expected_count: A `Tensor` of type `float32`.
		  sampled_expected_count: A `Tensor` of type `float32`.
	**/
	static public function ThreadUnsafeUnigramCandidateSampler(true_classes:Dynamic, num_true:Dynamic, num_sampled:Dynamic, unique:Dynamic, range_max:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Constructs a tensor by tiling a given tensor.
		
		This operation creates a new tensor by replicating `input` `multiples` times.
		The output tensor's i'th dimension has `input.dims(i) * multiples[i]` elements,
		and the values of `input` are replicated `multiples[i]` times along the 'i'th
		dimension. For example, tiling `[a b c d]` by `[2]` produces
		`[a b c d a b c d]`.
		
		>>> a = tf.constant([[1,2,3],[4,5,6]], tf.int32)
		>>> b = tf.constant([1,2], tf.int32)
		>>> tf.tile(a, b)
		<tf.Tensor: shape=(2, 6), dtype=int32, numpy=
		array([[1, 2, 3, 1, 2, 3],
		       [4, 5, 6, 4, 5, 6]], dtype=int32)>
		>>> c = tf.constant([2,1], tf.int32)
		>>> tf.tile(a, c)
		<tf.Tensor: shape=(4, 3), dtype=int32, numpy=
		array([[1, 2, 3],
		       [4, 5, 6],
		       [1, 2, 3],
		       [4, 5, 6]], dtype=int32)>
		>>> d = tf.constant([2,2], tf.int32)
		>>> tf.tile(a, d)
		<tf.Tensor: shape=(4, 6), dtype=int32, numpy=
		array([[1, 2, 3, 1, 2, 3],
		       [4, 5, 6, 4, 5, 6],
		       [1, 2, 3, 1, 2, 3],
		       [4, 5, 6, 4, 5, 6]], dtype=int32)>
		
		Args:
		  input: A `Tensor`. 1-D or higher.
		  multiples: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    1-D. Length must be the same as the number of dimensions in `input`
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function Tile(input:Dynamic, multiples:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the gradient of `Tile`.
		
		Since `Tile` takes an input and repeats the input `multiples` times
		along each dimension, `TileGrad` takes in `multiples` and aggregates
		each repeated tile of `input` into `output`.
		
		Args:
		  input: A `Tensor`.
		  multiples: A `Tensor` of type `int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `input`.
	**/
	static public function TileGrad(input:Dynamic, multiples:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Provides the time since epoch in seconds.
		
		Returns the timestamp as a `float64` for seconds since the Unix epoch.
		
		Note: the timestamp is computed when the op is executed, not when it is added
		to the graph.
		
		Args:
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `float64`.
	**/
	static public function Timestamp(?name:Dynamic):Dynamic;
	/**
		Converts a tensor to a scalar predicate.
		
		Converts a tensor to a scalar predicate with the following rules:
		
		- For 0D tensors, truthiness is determined by comparing against a "zero"
		  value. For numerical types it is the obvious zero. For strings it is the
		  empty string.
		
		- For >0D tensors, truthiness is determined by looking at the number of
		  elements. If has zero elements, then the result is false. Otherwise the
		  result is true.
		
		This matches the behavior of If and While for determining if a tensor counts
		as true/false for a branch condition.
		
		Args:
		  input: A `Tensor`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function ToBool(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Finds values and indices of the `k` largest elements for the last dimension.
		
		If the input is a vector (rank-1), finds the `k` largest entries in the vector
		and outputs their values and indices as vectors.  Thus `values[j]` is the
		`j`-th largest entry in `input`, and its index is `indices[j]`.
		
		For matrices (resp. higher rank input), computes the top `k` entries in each
		row (resp. vector along the last dimension).  Thus,
		
		    values.shape = indices.shape = input.shape[:-1] + [k]
		
		If two elements are equal, the lower-index element appears first.
		
		If `k` varies dynamically, use `TopKV2` below.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    1-D or higher with last dimension at least `k`.
		  k: An `int` that is `>= 0`.
		    Number of top elements to look for along the last dimension (along each
		    row for matrices).
		  sorted: An optional `bool`. Defaults to `True`.
		    If true the resulting `k` elements will be sorted by the values in
		    descending order.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (values, indices).
		
		  values: A `Tensor`. Has the same type as `input`.
		  indices: A `Tensor` of type `int32`.
	**/
	static public function TopK(input:Dynamic, k:Dynamic, ?sorted:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Finds values and indices of the `k` largest elements for the last dimension.
		
		If the input is a vector (rank-1), finds the `k` largest entries in the vector
		and outputs their values and indices as vectors.  Thus `values[j]` is the
		`j`-th largest entry in `input`, and its index is `indices[j]`.
		
		For matrices (resp. higher rank input), computes the top `k` entries in each
		row (resp. vector along the last dimension).  Thus,
		
		    values.shape = indices.shape = input.shape[:-1] + [k]
		
		If two elements are equal, the lower-index element appears first.
		
		Args:
		  input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		    1-D or higher with last dimension at least `k`.
		  k: A `Tensor` of type `int32`.
		    0-D.  Number of top elements to look for along the last dimension (along each
		    row for matrices).
		  sorted: An optional `bool`. Defaults to `True`.
		    If true the resulting `k` elements will be sorted by the values in
		    descending order.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (values, indices).
		
		  values: A `Tensor`. Has the same type as `input`.
		  indices: A `Tensor` of type `int32`.
	**/
	static public function TopKV2(input:Dynamic, k:Dynamic, ?sorted:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Shuffle dimensions of x according to a permutation.
		
		The output `y` has the same rank as `x`. The shapes of `x` and `y` satisfy:
		  `y.shape[i] == x.shape[perm[i]] for i in [0, 1, ..., rank(x) - 1]`
		
		Args:
		  x: A `Tensor`.
		  perm: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Transpose(x:Dynamic, perm:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Calculate product with tridiagonal matrix.
		
		Calculates product of two matrices, where left matrix is a tridiagonal matrix.
		
		Args:
		  superdiag: A `Tensor`. Must be one of the following types: `float64`, `float32`, `complex64`, `complex128`.
		    Tensor of shape `[..., 1, M]`, representing superdiagonals of
		    tri-diagonal matrices to the left of multiplication. Last element is ignored.
		  maindiag: A `Tensor`. Must have the same type as `superdiag`.
		    Tensor of shape `[..., 1, M]`, representing main diagonals of tri-diagonal
		    matrices to the left of multiplication.
		  subdiag: A `Tensor`. Must have the same type as `superdiag`.
		    Tensor of shape `[..., 1, M]`, representing subdiagonals of tri-diagonal
		    matrices to the left of multiplication. First element is ignored.
		  rhs: A `Tensor`. Must have the same type as `superdiag`.
		    Tensor of shape `[..., M, N]`, representing MxN matrices to the right of
		    multiplication.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `superdiag`.
	**/
	static public function TridiagonalMatMul(superdiag:Dynamic, maindiag:Dynamic, subdiag:Dynamic, rhs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Solves tridiagonal systems of equations.
		
		  Solves tridiagonal systems of equations.
		  Supports batch dimensions and multiple right-hand sides per each left-hand
		  side.
		  On CPU, solution is computed via Gaussian elimination with or without partial
		  pivoting, depending on `partial_pivoting` attribute. On GPU, Nvidia's cuSPARSE
		  library is used: https://docs.nvidia.com/cuda/cusparse/index.html#gtsv
		  Partial pivoting is not yet supported by XLA backends.
		
		Args:
		  diagonals: A `Tensor`. Must be one of the following types: `float64`, `float32`, `complex64`, `complex128`.
		    Tensor of shape `[..., 3, M]` whose innermost 2 dimensions represent the
		    tridiagonal matrices with three rows being the superdiagonal, diagonals, and
		    subdiagonals, in order. The last element of the superdiagonal and the first
		    element of the subdiagonal is ignored.
		  rhs: A `Tensor`. Must have the same type as `diagonals`.
		    Tensor of shape `[..., M, K]`, representing K right-hand sides per each
		    left-hand side.
		  partial_pivoting: An optional `bool`. Defaults to `True`.
		    Whether to apply partial pivoting. Partial pivoting makes the procedure more
		    stable, but slower.
		  perturb_singular: An optional `bool`. Defaults to `False`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `diagonals`.
	**/
	static public function TridiagonalSolve(diagonals:Dynamic, rhs:Dynamic, ?partial_pivoting:Dynamic, ?perturb_singular:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns x / y element-wise for integer types.
		
		Truncation designates that negative numbers will round fractional quantities
		toward zero. I.e. -7 / 5 = -1. This matches C semantics but it is different
		than Python semantics. See `FloorDiv` for a division function that matches
		Python Semantics.
		
		*NOTE*: `truncatediv` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `uint32`, `uint64`, `int64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function TruncateDiv(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns element-wise remainder of division. This emulates C semantics in that
		
		the result here is consistent with a truncating divide. E.g. `truncate(x / y) *
		y + truncate_mod(x, y) = x`.
		
		*NOTE*: `truncatemod` supports broadcasting. More about broadcasting
		[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function TruncateMod(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Outputs random values from a truncated normal distribution.
		
		The generated values follow a normal distribution with mean 0 and standard
		deviation 1, except that values whose magnitude is more than 2 standard
		deviations from the mean are dropped and re-picked.
		
		Args:
		  shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    The shape of the output tensor.
		  dtype: A `tf.DType` from: `tf.half, tf.bfloat16, tf.float32, tf.float64`.
		    The type of the output.
		  seed: An optional `int`. Defaults to `0`.
		    If either `seed` or `seed2` are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    A second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `dtype`.
	**/
	static public function TruncatedNormal(shape:Dynamic, dtype:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Reverses the operation of Batch for a single output Tensor.
		
		An instance of Unbatch either receives an empty batched_tensor, in which case it
		asynchronously waits until the values become available from a concurrently
		running instance of Unbatch with the same container and shared_name, or receives
		a non-empty batched_tensor in which case it finalizes all other concurrently
		running instances and outputs its own element from the batch.
		
		batched_tensor: The possibly transformed output of Batch. The size of the first
		 dimension should remain unchanged by the transformations for the operation to
		 work.
		batch_index: The matching batch_index obtained from Batch.
		id: The id scalar emitted by Batch.
		unbatched_tensor: The Tensor corresponding to this execution.
		timeout_micros: Maximum amount of time (in microseconds) to wait to receive the
		 batched input tensor associated with a given invocation of the op.
		container: Container to control resource sharing.
		shared_name: Instances of Unbatch with the same container and shared_name are
		 assumed to possibly belong to the same batch. If left empty, the op name will
		 be used as the shared name.
		
		Args:
		  batched_tensor: A `Tensor`.
		  batch_index: A `Tensor` of type `int64`.
		  id: A `Tensor` of type `int64`.
		  timeout_micros: An `int`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `batched_tensor`.
	**/
	static public function Unbatch(batched_tensor:Dynamic, batch_index:Dynamic, id:Dynamic, timeout_micros:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A dataset that splits the elements of its input into multiple elements.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function UnbatchDataset(input_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Gradient of Unbatch.
		
		Acts like Batch but using the given batch_index index of batching things as they
		become available. This ensures that the gradients are propagated back in the
		same session which did the forward pass.
		
		original_input: The input to the Unbatch operation this is the gradient of.
		batch_index: The batch_index given to the Unbatch operation this is the gradient
		of.
		grad: The downstream gradient.
		id: The id scalar emitted by Batch.
		batched_grad: The return value, either an empty tensor or the batched gradient.
		container: Container to control resource sharing.
		shared_name: Instances of UnbatchGrad with the same container and shared_name
		 are assumed to possibly belong to the same batch. If left empty, the op name
		 will be used as the shared name.
		
		Args:
		  original_input: A `Tensor`.
		  batch_index: A `Tensor` of type `int64`.
		  grad: A `Tensor`. Must have the same type as `original_input`.
		  id: A `Tensor` of type `int64`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `original_input`.
	**/
	static public function UnbatchGrad(original_input:Dynamic, batch_index:Dynamic, grad:Dynamic, id:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Uncompresses a compressed dataset element.
		
		Args:
		  compressed: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `output_types`.
	**/
	static public function UncompressElement(compressed:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decodes each string in `input` into a sequence of Unicode code points.
		
		The character codepoints for all strings are returned using a single vector
		`char_values`, with strings expanded to characters in row-major order.
		
		The `row_splits` tensor indicates where the codepoints for
		each input string begin and end within the `char_values` tensor.
		In particular, the values for the `i`th
		string (in row-major order) are stored in the slice
		`[row_splits[i]:row_splits[i+1]]`. Thus:
		
		* `char_values[row_splits[i]+j]` is the Unicode codepoint for the `j`th
		  character in the `i`th string (in row-major order).
		* `row_splits[i+1] - row_splits[i]` is the number of characters in the `i`th
		  string (in row-major order).
		
		Args:
		  input: A `Tensor` of type `string`.
		    The text to be decoded. Can have any shape. Note that the output is flattened
		    to a vector of char values.
		  input_encoding: A `string`.
		    Text encoding of the input strings. This is any of the encodings supported
		    by ICU ucnv algorithmic converters. Examples: `"UTF-16", "US ASCII", "UTF-8"`.
		  errors: An optional `string` from: `"strict", "replace", "ignore"`. Defaults to `"replace"`.
		    Error handling policy when there is invalid formatting found in the input.
		    The value of 'strict' will cause the operation to produce a InvalidArgument
		    error on any invalid input formatting. A value of 'replace' (the default) will
		    cause the operation to replace any invalid formatting in the input with the
		    `replacement_char` codepoint. A value of 'ignore' will cause the operation to
		    skip any invalid formatting in the input and produce no corresponding output
		    character.
		  replacement_char: An optional `int`. Defaults to `65533`.
		    The replacement character codepoint to be used in place of any invalid
		    formatting in the input when `errors='replace'`. Any valid unicode codepoint may
		    be used. The default value is the default unicode replacement character is
		    0xFFFD or U+65533.)
		  replace_control_characters: An optional `bool`. Defaults to `False`.
		    Whether to replace the C0 control characters (00-1F) with the
		    `replacement_char`. Default is false.
		  Tsplits: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (row_splits, char_values).
		
		  row_splits: A `Tensor` of type `Tsplits`.
		  char_values: A `Tensor` of type `int32`.
	**/
	static public function UnicodeDecode(input:Dynamic, input_encoding:Dynamic, ?errors:Dynamic, ?replacement_char:Dynamic, ?replace_control_characters:Dynamic, ?Tsplits:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Decodes each string in `input` into a sequence of Unicode code points.
		
		The character codepoints for all strings are returned using a single vector
		`char_values`, with strings expanded to characters in row-major order.
		Similarly, the character start byte offsets are returned using a single vector
		`char_to_byte_starts`, with strings expanded in row-major order.
		
		The `row_splits` tensor indicates where the codepoints and start offsets for
		each input string begin and end within the `char_values` and
		`char_to_byte_starts` tensors.  In particular, the values for the `i`th
		string (in row-major order) are stored in the slice
		`[row_splits[i]:row_splits[i+1]]`. Thus:
		
		* `char_values[row_splits[i]+j]` is the Unicode codepoint for the `j`th
		  character in the `i`th string (in row-major order).
		* `char_to_bytes_starts[row_splits[i]+j]` is the start byte offset for the `j`th
		  character in the `i`th string (in row-major order).
		* `row_splits[i+1] - row_splits[i]` is the number of characters in the `i`th
		  string (in row-major order).
		
		Args:
		  input: A `Tensor` of type `string`.
		    The text to be decoded. Can have any shape. Note that the output is flattened
		    to a vector of char values.
		  input_encoding: A `string`.
		    Text encoding of the input strings. This is any of the encodings supported
		    by ICU ucnv algorithmic converters. Examples: `"UTF-16", "US ASCII", "UTF-8"`.
		  errors: An optional `string` from: `"strict", "replace", "ignore"`. Defaults to `"replace"`.
		    Error handling policy when there is invalid formatting found in the input.
		    The value of 'strict' will cause the operation to produce a InvalidArgument
		    error on any invalid input formatting. A value of 'replace' (the default) will
		    cause the operation to replace any invalid formatting in the input with the
		    `replacement_char` codepoint. A value of 'ignore' will cause the operation to
		    skip any invalid formatting in the input and produce no corresponding output
		    character.
		  replacement_char: An optional `int`. Defaults to `65533`.
		    The replacement character codepoint to be used in place of any invalid
		    formatting in the input when `errors='replace'`. Any valid unicode codepoint may
		    be used. The default value is the default unicode replacement character is
		    0xFFFD or U+65533.)
		  replace_control_characters: An optional `bool`. Defaults to `False`.
		    Whether to replace the C0 control characters (00-1F) with the
		    `replacement_char`. Default is false.
		  Tsplits: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (row_splits, char_values, char_to_byte_starts).
		
		  row_splits: A `Tensor` of type `Tsplits`.
		  char_values: A `Tensor` of type `int32`.
		  char_to_byte_starts: A `Tensor` of type `int64`.
	**/
	static public function UnicodeDecodeWithOffsets(input:Dynamic, input_encoding:Dynamic, ?errors:Dynamic, ?replacement_char:Dynamic, ?replace_control_characters:Dynamic, ?Tsplits:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Encode a tensor of ints into unicode strings.
		
		Returns a vector of strings, where `output[i]` is constructed by encoding the
		Unicode codepoints in `input_values[input_splits[i]:input_splits[i+1]]`
		using `output_encoding`.
		
		---
		
		Example:
		
		```
		input_values = [72, 101, 108, 108, 111, 87, 111, 114, 108, 100]
		input_splits = [0, 5, 10]
		output_encoding = 'UTF-8'
		
		output = ['Hello', 'World']
		```
		
		Args:
		  input_values: A `Tensor` of type `int32`.
		    A 1D tensor containing the unicode codepoints that should be encoded.
		  input_splits: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A 1D tensor specifying how the unicode codepoints should be split into strings.
		    In particular, `output[i]` is constructed by encoding the codepoints in the
		    slice `input_values[input_splits[i]:input_splits[i+1]]`.
		  output_encoding: A `string` from: `"UTF-8", "UTF-16-BE", "UTF-32-BE"`.
		    Unicode encoding of the output strings. Valid encodings are: `"UTF-8",
		    "UTF-16-BE", and "UTF-32-BE"`.
		  errors: An optional `string` from: `"ignore", "replace", "strict"`. Defaults to `"replace"`.
		    Error handling policy when there is invalid formatting found in the input.
		    The value of 'strict' will cause the operation to produce a InvalidArgument
		    error on any invalid input formatting. A value of 'replace' (the default) will
		    cause the operation to replace any invalid formatting in the input with the
		    `replacement_char` codepoint. A value of 'ignore' will cause the operation to
		    skip any invalid formatting in the input and produce no corresponding output
		    character.
		  replacement_char: An optional `int`. Defaults to `65533`.
		    The replacement character codepoint to be used in place of any invalid
		    formatting in the input when `errors='replace'`. Any valid unicode codepoint may
		    be used. The default value is the default unicode replacement character is
		    0xFFFD (U+65533).
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function UnicodeEncode(input_values:Dynamic, input_splits:Dynamic, output_encoding:Dynamic, ?errors:Dynamic, ?replacement_char:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Determine the script codes of a given tensor of Unicode integer code points.
		
		This operation converts Unicode code points to script codes corresponding to
		each code point. Script codes correspond to International Components for
		Unicode (ICU) UScriptCode values.
		
		See
		[ICU project docs](http://icu-project.org/apiref/icu4c/uscript_8h.html)
		for more details on script codes.
		
		For an example, see the unicode strings guide on [unicode scripts]
		(https://www.tensorflow.org/tutorials/load_data/unicode#representing_unicode).
		
		Returns -1 (USCRIPT_INVALID_CODE) for invalid codepoints. Output shape will
		match input shape.
		
		Examples:
		
		>>> tf.strings.unicode_script([1, 31, 38])
		<tf.Tensor: shape=(3,), dtype=int32, numpy=array([0, 0, 0], dtype=int32)>
		
		Args:
		  input: A `Tensor` of type `int32`. A Tensor of int32 Unicode code points.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int32`.
	**/
	static public function UnicodeScript(input:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Transcode the input text from a source encoding to a destination encoding.
		
		The input is a string tensor of any shape. The output is a string tensor of
		the same shape containing the transcoded strings. Output strings are always
		valid unicode. If the input contains invalid encoding positions, the
		`errors` attribute sets the policy for how to deal with them. If the default
		error-handling policy is used, invalid formatting will be substituted in the
		output by the `replacement_char`. If the errors policy is to `ignore`, any
		invalid encoding positions in the input are skipped and not included in the
		output. If it set to `strict` then any invalid formatting will result in an
		InvalidArgument error.
		
		This operation can be used with `output_encoding = input_encoding` to enforce
		correct formatting for inputs even if they are already in the desired encoding.
		
		If the input is prefixed by a Byte Order Mark needed to determine encoding
		(e.g. if the encoding is UTF-16 and the BOM indicates big-endian), then that
		BOM will be consumed and not emitted into the output. If the input encoding
		is marked with an explicit endianness (e.g. UTF-16-BE), then the BOM is
		interpreted as a non-breaking-space and is preserved in the output (including
		always for UTF-8).
		
		The end result is that if the input is marked as an explicit endianness the
		transcoding is faithful to all codepoints in the source. If it is not marked
		with an explicit endianness, the BOM is not considered part of the string itself
		but as metadata, and so is not preserved in the output.
		
		Examples:
		
		>>> tf.strings.unicode_transcode(["Hello", "TensorFlow", "2.x"], "UTF-8", "UTF-16-BE")
		<tf.Tensor: shape=(3,), dtype=string, numpy=
		array([b'\x00H\x00e\x00l\x00l\x00o',
		       b'\x00T\x00e\x00n\x00s\x00o\x00r\x00F\x00l\x00o\x00w',
		       b'\x002\x00.\x00x'], dtype=object)>
		>>> tf.strings.unicode_transcode(["A", "B", "C"], "US ASCII", "UTF-8").numpy()
		array([b'A', b'B', b'C'], dtype=object)
		
		Args:
		  input: A `Tensor` of type `string`.
		    The text to be processed. Can have any shape.
		  input_encoding: A `string`.
		    Text encoding of the input strings. This is any of the encodings supported
		    by ICU ucnv algorithmic converters. Examples: `"UTF-16", "US ASCII", "UTF-8"`.
		  output_encoding: A `string` from: `"UTF-8", "UTF-16-BE", "UTF-32-BE"`.
		    The unicode encoding to use in the output. Must be one of
		    `"UTF-8", "UTF-16-BE", "UTF-32-BE"`. Multi-byte encodings will be big-endian.
		  errors: An optional `string` from: `"strict", "replace", "ignore"`. Defaults to `"replace"`.
		    Error handling policy when there is invalid formatting found in the input.
		    The value of 'strict' will cause the operation to produce a InvalidArgument
		    error on any invalid input formatting. A value of 'replace' (the default) will
		    cause the operation to replace any invalid formatting in the input with the
		    `replacement_char` codepoint. A value of 'ignore' will cause the operation to
		    skip any invalid formatting in the input and produce no corresponding output
		    character.
		  replacement_char: An optional `int`. Defaults to `65533`.
		    The replacement character codepoint to be used in place of any invalid
		    formatting in the input when `errors='replace'`. Any valid unicode codepoint may
		    be used. The default value is the default unicode replacement character is
		    0xFFFD or U+65533.)
		
		    Note that for UTF-8, passing a replacement character expressible in 1 byte, such
		    as ' ', will preserve string alignment to the source since invalid bytes will be
		    replaced with a 1-byte replacement. For UTF-16-BE and UTF-16-LE, any 1 or 2 byte
		    replacement character will preserve byte alignment to the source.
		  replace_control_characters: An optional `bool`. Defaults to `False`.
		    Whether to replace the C0 control characters (00-1F) with the
		    `replacement_char`. Default is false.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function UnicodeTranscode(input:Dynamic, input_encoding:Dynamic, output_encoding:Dynamic, ?errors:Dynamic, ?replacement_char:Dynamic, ?replace_control_characters:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Generates labels for candidate sampling with a uniform distribution.
		
		See explanations of candidate sampling and the data formats at
		go/candidate-sampling.
		
		For each batch, this op picks a single set of sampled candidate labels.
		
		The advantages of sampling candidates per-batch are simplicity and the
		possibility of efficient dense matrix multiplication. The disadvantage is that
		the sampled candidates must be chosen independently of the context and of the
		true labels.
		
		Args:
		  true_classes: A `Tensor` of type `int64`.
		    A batch_size * num_true matrix, in which each row contains the
		    IDs of the num_true target_classes in the corresponding original label.
		  num_true: An `int` that is `>= 1`. Number of true labels per context.
		  num_sampled: An `int` that is `>= 1`.
		    Number of candidates to randomly sample.
		  unique: A `bool`.
		    If unique is true, we sample with rejection, so that all sampled
		    candidates in a batch are unique. This requires some approximation to
		    estimate the post-rejection sampling probabilities.
		  range_max: An `int` that is `>= 1`.
		    The sampler will sample integers from the interval [0, range_max).
		  seed: An optional `int`. Defaults to `0`.
		    If either seed or seed2 are set to be non-zero, the random number
		    generator is seeded by the given seed.  Otherwise, it is seeded by a
		    random seed.
		  seed2: An optional `int`. Defaults to `0`.
		    An second seed to avoid seed collision.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (sampled_candidates, true_expected_count, sampled_expected_count).
		
		  sampled_candidates: A `Tensor` of type `int64`.
		  true_expected_count: A `Tensor` of type `float32`.
		  sampled_expected_count: A `Tensor` of type `float32`.
	**/
	static public function UniformCandidateSampler(true_classes:Dynamic, num_true:Dynamic, num_sampled:Dynamic, unique:Dynamic, range_max:Dynamic, ?seed:Dynamic, ?seed2:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Finds unique elements in a 1-D tensor.
		
		This operation returns a tensor `y` containing all of the unique elements of `x`
		sorted in the same order that they occur in `x`; `x` does not need to be sorted.
		This operation also returns a tensor `idx` the same size as `x` that contains
		the index of each value of `x` in the unique output `y`. In other words:
		
		`y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`
		
		Examples:
		
		```
		# tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
		y, idx = unique(x)
		y ==> [1, 2, 4, 7, 8]
		idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]
		```
		
		```
		# tensor 'x' is [4, 5, 1, 2, 3, 3, 4, 5]
		y, idx = unique(x)
		y ==> [4, 5, 1, 2, 3]
		idx ==> [0, 1, 2, 3, 4, 4, 0, 1]
		```
		
		Args:
		  x: A `Tensor`. 1-D.
		  out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (y, idx).
		
		  y: A `Tensor`. Has the same type as `x`.
		  idx: A `Tensor` of type `out_idx`.
	**/
	static public function Unique(x:Dynamic, ?out_idx:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that contains the unique elements of `input_dataset`.
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function UniqueDataset(input_dataset:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Finds unique elements along an axis of a tensor.
		
		This operation either returns a tensor `y` containing unique elements
		along the `axis` of a tensor. The returned unique elements is sorted
		in the same order as they occur along `axis` in `x`.
		This operation also returns a tensor `idx` that is the same size as
		the number of the elements in `x` along the `axis` dimension. It
		contains the index in the unique output `y`.
		In other words, for an `1-D` tensor `x` with `axis = None:
		
		`y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`
		
		For example:
		
		```
		# tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
		y, idx = unique(x)
		y ==> [1, 2, 4, 7, 8]
		idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]
		```
		
		For an `2-D` tensor `x` with `axis = 0`:
		
		```
		# tensor 'x' is [[1, 0, 0],
		#                [1, 0, 0],
		#                [2, 0, 0]]
		y, idx = unique(x, axis=0)
		y ==> [[1, 0, 0],
		       [2, 0, 0]]
		idx ==> [0, 0, 1]
		```
		
		For an `2-D` tensor `x` with `axis = 1`:
		
		```
		# tensor 'x' is [[1, 0, 0],
		#                [1, 0, 0],
		#                [2, 0, 0]]
		y, idx = unique(x, axis=1)
		y ==> [[1, 0],
		       [1, 0],
		       [2, 0]]
		idx ==> [0, 1, 1]
		```
		
		Args:
		  x: A `Tensor`. A `Tensor`.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A `Tensor` of type `int32` (default: None). The axis of the Tensor to
		    find the unique elements.
		  out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (y, idx).
		
		  y: A `Tensor`. Has the same type as `x`.
		  idx: A `Tensor` of type `out_idx`.
	**/
	static public function UniqueV2(x:Dynamic, axis:Dynamic, ?out_idx:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Finds unique elements in a 1-D tensor.
		
		This operation returns a tensor `y` containing all of the unique elements of `x`
		sorted in the same order that they occur in `x`. This operation also returns a
		tensor `idx` the same size as `x` that contains the index of each value of `x`
		in the unique output `y`. Finally, it returns a third tensor `count` that
		contains the count of each element of `y` in `x`. In other words:
		
		`y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`
		
		For example:
		
		```
		# tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]
		y, idx, count = unique_with_counts(x)
		y ==> [1, 2, 4, 7, 8]
		idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]
		count ==> [2, 1, 3, 1, 2]
		```
		
		Args:
		  x: A `Tensor`. 1-D.
		  out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (y, idx, count).
		
		  y: A `Tensor`. Has the same type as `x`.
		  idx: A `Tensor` of type `out_idx`.
		  count: A `Tensor` of type `out_idx`.
	**/
	static public function UniqueWithCounts(x:Dynamic, ?out_idx:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Finds unique elements along an axis of a tensor.
		
		This operation either returns a tensor `y` containing unique elements
		along the `axis` of a tensor. The returned unique elements is sorted
		in the same order as they occur along `axis` in `x`.
		This operation also returns a tensor `idx` and a tensor `count`
		that are the same size as the number of the elements in `x` along the
		`axis` dimension. The `idx` contains the index in the unique output `y`
		and the `count` contains the count in the unique output `y`.
		In other words, for an `1-D` tensor `x` with `axis = None:
		
		`y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`
		
		For example:
		
		```
		x = tf.constant([1, 1, 2, 4, 4, 4, 7, 8, 8])
		y, idx, count = UniqueWithCountsV2(x, axis = [0])
		y ==> [1, 2, 4, 7, 8]
		idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]
		count ==> [2, 1, 3, 1, 2]
		```
		
		For a `2-D` tensor `x` with `axis = 0`:
		
		```
		x = tf.constant([[1, 0, 0],
		                [1, 0, 0],
		                [2, 0, 0]])
		y, idx, count = UniqueWithCountsV2(x, axis=[0])
		y ==> [[1, 0, 0],
		       [2, 0, 0]]
		idx ==> [0, 0, 1]
		count ==> [2, 1]
		```
		
		For a `2-D` tensor `x` with `axis = 1`:
		
		```
		x = tf.constant([[1, 0, 0],
		                [1, 0, 0],
		                [2, 0, 0]])
		y, idx, count = UniqueWithCountsV2(x, axis=[1])
		y ==> [[1, 0],
		       [1, 0],
		       [2, 0]]
		idx ==> [0, 1, 1]
		count ==> [1, 2]
		```
		
		Args:
		  x: A `Tensor`. A `Tensor`.
		  axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A `Tensor` of type `int32` (default: None). The axis of the Tensor to
		    find the unique elements.
		  out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A tuple of `Tensor` objects (y, idx, count).
		
		  y: A `Tensor`. Has the same type as `x`.
		  idx: A `Tensor` of type `out_idx`.
		  count: A `Tensor` of type `out_idx`.
	**/
	static public function UniqueWithCountsV2(x:Dynamic, axis:Dynamic, ?out_idx:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Unpacks a given dimension of a rank-`R` tensor into `num` rank-`(R-1)` tensors.
		
		Unpacks `num` tensors from `value` by chipping it along the `axis` dimension.
		For example, given a tensor of shape `(A, B, C, D)`;
		
		If `axis == 0` then the i'th tensor in `output` is the slice `value[i, :, :, :]`
		  and each tensor in `output` will have shape `(B, C, D)`. (Note that the
		  dimension unpacked along is gone, unlike `split`).
		
		If `axis == 1` then the i'th tensor in `output` is the slice `value[:, i, :, :]`
		  and each tensor in `output` will have shape `(A, C, D)`.
		Etc.
		
		This is the opposite of `pack`.
		
		Args:
		  value: A `Tensor`.
		    1-D or higher, with `axis` dimension size equal to `num`.
		  num: An `int` that is `>= 0`.
		  axis: An optional `int`. Defaults to `0`.
		    Dimension along which to unpack.  Negative values wrap around, so the
		    valid range is `[-R, R)`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `num` `Tensor` objects with the same type as `value`.
	**/
	static public function Unpack(value:Dynamic, num:Dynamic, ?axis:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Converts an array of flat indices into a tuple of coordinate arrays.
		
		
		Example:
		
		```
		y = tf.unravel_index(indices=[2, 5, 7], dims=[3, 3])
		# 'dims' represent a hypothetical (3, 3) tensor of indices:
		# [[0, 1, *2*],
		#  [3, 4, *5*],
		#  [6, *7*, 8]]
		# For each entry from 'indices', this operation returns
		# its coordinates (marked with '*'), such as
		# 2 ==> (0, 2)
		# 5 ==> (1, 2)
		# 7 ==> (2, 1)
		y ==> [[0, 1, 2], [2, 2, 1]]
		```
		
		@compatibility(numpy)
		Equivalent to np.unravel_index
		@end_compatibility
		
		Args:
		  indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    An 0-D or 1-D `int` Tensor whose elements are indices into the
		    flattened version of an array of dimensions dims.
		  dims: A `Tensor`. Must have the same type as `indices`.
		    An 1-D `int` Tensor. The shape of the array to use for unraveling
		    indices.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `indices`.
	**/
	static public function UnravelIndex(indices:Dynamic, dims:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Joins the elements of `inputs` based on `segment_ids`.
		
		Computes the string join along segments of a tensor.
		Given `segment_ids` with rank `N` and `data` with rank `N+M`:
		
		    `output[i, k1...kM] = strings.join([data[j1...jN, k1...kM])`
		
		where the join is over all [j1...jN] such that segment_ids[j1...jN] = i.
		Strings are joined in row-major order.
		
		For example:
		
		```python
		inputs = [['Y', 'q', 'c'], ['Y', '6', '6'], ['p', 'G', 'a']]
		output_array = string_ops.unsorted_segment_join(inputs=inputs,
		                                                segment_ids=[1, 0, 1],
		                                                num_segments=2,
		                                                separator=':'))
		# output_array ==> [['Y', '6', '6'], ['Y:p', 'q:G', 'c:a']]
		
		
		inputs = ['this', 'is', 'a', 'test']
		output_array = string_ops.unsorted_segment_join(inputs=inputs,
		                                                segment_ids=[0, 0, 0, 0],
		                                                num_segments=1,
		                                                separator=':'))
		# output_array ==> ['this:is:a:test']
		```
		
		Args:
		  inputs: A `Tensor` of type `string`. The input to be joined.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor whose shape is a prefix of data.shape.  Negative segment ids are not
		    supported.
		  num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A scalar.
		  separator: An optional `string`. Defaults to `""`.
		    The separator to use when joining.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function UnsortedSegmentJoin(inputs:Dynamic, segment_ids:Dynamic, num_segments:Dynamic, ?separator:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the maximum along segments of a tensor.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		This operator is similar to the unsorted segment sum operator found
		[(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).
		Instead of computing the sum over segments, it computes the maximum such that:
		
		\\(output_i = \max_{j...} data[j...]\\) where max is over tuples `j...` such
		that `segment_ids[j...] == i`.
		
		If the maximum is empty for a given segment ID `i`, it outputs the smallest
		possible value for the specific numeric type,
		`output[i] = numeric_limits<T>::lowest()`.
		
		If the given segment ID `i` is negative, then the corresponding value is
		dropped, and will not be included in the result.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/UnsortedSegmentMax.png" alt>
		</div>
		
		For example:
		
		``` python
		c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])
		tf.unsorted_segment_max(c, tf.constant([0, 1, 0]), num_segments=2)
		# ==> [[ 4,  3, 3, 4],
		#       [5,  6, 7, 8]]
		```
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor whose shape is a prefix of `data.shape`.
		  num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function UnsortedSegmentMax(data:Dynamic, segment_ids:Dynamic, num_segments:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the minimum along segments of a tensor.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		This operator is similar to the unsorted segment sum operator found
		[(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).
		Instead of computing the sum over segments, it computes the minimum such that:
		
		\\(output_i = \min_{j...} data_[j...]\\) where min is over tuples `j...` such
		that `segment_ids[j...] == i`.
		
		If the minimum is empty for a given segment ID `i`, it outputs the largest
		possible value for the specific numeric type,
		`output[i] = numeric_limits<T>::max()`.
		
		For example:
		
		``` python
		c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])
		tf.unsorted_segment_min(c, tf.constant([0, 1, 0]), num_segments=2)
		# ==> [[ 1,  2, 2, 1],
		#       [5,  6, 7, 8]]
		```
		
		If the given segment ID `i` is negative, then the corresponding value is
		dropped, and will not be included in the result.
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor whose shape is a prefix of `data.shape`.
		  num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function UnsortedSegmentMin(data:Dynamic, segment_ids:Dynamic, num_segments:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the product along segments of a tensor.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		This operator is similar to the unsorted segment sum operator found
		[(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).
		Instead of computing the sum over segments, it computes the product of all
		entries belonging to a segment such that:
		
		\\(output_i = \prod_{j...} data[j...]\\) where the product is over tuples
		`j...` such that `segment_ids[j...] == i`.
		
		For example:
		
		``` python
		c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])
		tf.unsorted_segment_prod(c, tf.constant([0, 1, 0]), num_segments=2)
		# ==> [[ 4,  6, 6, 4],
		#       [5,  6, 7, 8]]
		```
		
		If there is no entry for a given segment ID `i`, it outputs 1.
		
		If the given segment ID `i` is negative, then the corresponding value is
		dropped, and will not be included in the result.
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor whose shape is a prefix of `data.shape`.
		  num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function UnsortedSegmentProd(data:Dynamic, segment_ids:Dynamic, num_segments:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Computes the sum along segments of a tensor.
		
		Read
		[the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)
		for an explanation of segments.
		
		Computes a tensor such that
		\\(output[i] = \sum_{j...} data[j...]\\) where the sum is over tuples `j...` such
		that `segment_ids[j...] == i`.  Unlike `SegmentSum`, `segment_ids`
		need not be sorted and need not cover all values in the full
		range of valid values.
		
		If the sum is empty for a given segment ID `i`, `output[i] = 0`.
		If the given segment ID `i` is negative, the value is dropped and will not be
		added to the sum of the segment.
		
		`num_segments` should equal the number of distinct segment IDs.
		
		<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
		<img style="width:100%" src="https://www.tensorflow.org/images/UnsortedSegmentSum.png" alt>
		</div>
		
		``` python
		c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])
		tf.math.unsorted_segment_sum(c, tf.constant([0, 1, 0]), num_segments=2)
		# ==> [[ 5, 5, 5, 5],
		#       [5, 6, 7, 8]]
		```
		
		Args:
		  data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.
		  segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		    A tensor whose shape is a prefix of `data.shape`.
		  num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `data`.
	**/
	static public function UnsortedSegmentSum(data:Dynamic, segment_ids:Dynamic, num_segments:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Op is similar to a lightweight Dequeue.
		
		The basic functionality is similar to dequeue with many fewer
		capabilities and options.  This Op is optimized for performance.
		
		Args:
		  dtypes: A list of `tf.DTypes` that has length `>= 1`.
		  capacity: An optional `int` that is `>= 0`. Defaults to `0`.
		  memory_limit: An optional `int` that is `>= 0`. Defaults to `0`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects of type `dtypes`.
	**/
	static public function Unstage(dtypes:Dynamic, ?capacity:Dynamic, ?memory_limit:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function UnwrapDatasetVariant(input_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Applies upper_bound(sorted_search_values, values) along each row.
		
		Each set of rows with the same index in (sorted_inputs, values) is treated
		independently.  The resulting row is the equivalent of calling
		`np.searchsorted(sorted_inputs, values, side='right')`.
		
		The result is not a global index to the entire
		`Tensor`, but rather just the index in the last dimension.
		
		A 2-D example:
		  sorted_sequence = [[0, 3, 9, 9, 10],
		                     [1, 2, 3, 4, 5]]
		  values = [[2, 4, 9],
		            [0, 2, 6]]
		
		  result = UpperBound(sorted_sequence, values)
		
		  result == [[1, 2, 4],
		             [0, 2, 5]]
		
		Args:
		  sorted_inputs: A `Tensor`. 2-D Tensor where each row is ordered.
		  values: A `Tensor`. Must have the same type as `sorted_inputs`.
		    2-D Tensor with the same numbers of rows as `sorted_search_values`. Contains
		    the values that will be searched for in `sorted_search_values`.
		  out_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `out_type`.
	**/
	static public function UpperBound(sorted_inputs:Dynamic, values:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a handle to a Variable resource.
		
		Args:
		  dtype: A `tf.DType`. the type of this variable. Must agree with the dtypes
		    of all ops using this variable.
		  shape: A `tf.TensorShape` or list of `ints`.
		    The (possibly partially specified) shape of this variable.
		  container: An optional `string`. Defaults to `""`.
		    the container this variable is placed in.
		  shared_name: An optional `string`. Defaults to `""`.
		    the name by which this variable is referred to.
		  allowed_devices: An optional list of `strings`. Defaults to `[]`.
		    DEPRECATED. The allowed devices containing the resource variable. Set when the
		    output ResourceHandle represents a per-replica/partitioned resource variable.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function VarHandleOp(dtype:Dynamic, shape:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?allowed_devices:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Checks whether a resource handle-based variable has been initialized.
		
		Args:
		  resource: A `Tensor` of type `resource`. the input resource handle.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `bool`.
	**/
	static public function VarIsInitializedOp(resource:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Use VariableV2 instead.
		
		Args:
		  shape: A `tf.TensorShape` or list of `ints`.
		  dtype: A `tf.DType`.
		  container: An optional `string`. Defaults to `""`.
		  shared_name: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor` of type `dtype`.
	**/
	static public function Variable(shape:Dynamic, dtype:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns the shape of the variable pointed to by `resource`.
		
		This operation returns a 1-D integer tensor representing the shape of `input`.
		
		For example:
		
		```
		# 't' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]
		shape(t) ==> [2, 2, 3]
		```
		
		Args:
		  input: A `Tensor` of type `resource`.
		  out_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `out_type`.
	**/
	static public function VariableShape(input:Dynamic, ?out_type:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Holds state in the form of a tensor that persists across steps.
		
		Outputs a ref to the tensor state so it may be read or modified.
		TODO(zhifengc/mrry): Adds a pointer to a more detail document
		about sharing states in tensorflow.
		
		Args:
		  shape: A `tf.TensorShape` or list of `ints`.
		    The shape of the variable tensor.
		  dtype: A `tf.DType`. The type of elements in the variable tensor.
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this variable is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this variable is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  name: A name for the operation (optional).
		
		Returns:
		  A mutable `Tensor` of type `dtype`.
	**/
	static public function VariableV2(shape:Dynamic, dtype:Dynamic, ?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns locations of nonzero / true values in a tensor.
		
		This operation returns the coordinates of true elements in `condition`. The
		coordinates are returned in a 2-D tensor where the first dimension (rows)
		represents the number of true elements, and the second dimension (columns)
		represents the coordinates of the true elements. Keep in mind, the shape of
		the output tensor can vary depending on how many true values there are in
		`condition`. Indices are output in row-major order.
		
		For example:
		
		```
		# 'input' tensor is [[True, False]
		#                    [True, False]]
		# 'input' has two true values, so output has two coordinates.
		# 'input' has rank of 2, so coordinates have two indices.
		where(input) ==> [[0, 0],
		                  [1, 0]]
		
		# `condition` tensor is [[[True, False]
		#                     [True, False]]
		#                    [[False, True]
		#                     [False, True]]
		#                    [[False, False]
		#                     [False, True]]]
		# 'input' has 5 true values, so output has 5 coordinates.
		# 'input' has rank of 3, so coordinates have three indices.
		where(input) ==> [[0, 0, 0],
		                  [0, 1, 0],
		                  [1, 0, 1],
		                  [1, 1, 1],
		                  [2, 1, 1]]
		
		# `condition` tensor is [[[1.5,  0.0]
		#                     [-0.5, 0.0]]
		#                    [[0.0,  0.25]
		#                     [0.0,  0.75]]
		#                    [[0.0,  0.0]
		#                     [0.0,  0.01]]]
		# 'input' has 5 nonzero values, so output has 5 coordinates.
		# 'input' has rank of 3, so coordinates have three indices.
		where(input) ==> [[0, 0, 0],
		                  [0, 1, 0],
		                  [1, 0, 1],
		                  [1, 1, 1],
		                  [2, 1, 1]]
		
		# `condition` tensor is [[[1.5 + 0.0j, 0.0  + 0.0j]
		#                     [0.0 + 0.5j, 0.0  + 0.0j]]
		#                    [[0.0 + 0.0j, 0.25 + 1.5j]
		#                     [0.0 + 0.0j, 0.75 + 0.0j]]
		#                    [[0.0 + 0.0j, 0.0  + 0.0j]
		#                     [0.0 + 0.0j, 0.01 + 0.0j]]]
		# 'input' has 5 nonzero magnitude values, so output has 5 coordinates.
		# 'input' has rank of 3, so coordinates have three indices.
		where(input) ==> [[0, 0, 0],
		                  [0, 1, 0],
		                  [1, 0, 1],
		                  [1, 1, 1],
		                  [2, 1, 1]]
		```
		
		Args:
		  condition: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`, `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `int64`.
	**/
	static public function Where(condition:Dynamic, ?name:Dynamic):Dynamic;
	/**
		output = input; While (Cond(output)) { output = Body(output) }
		
		Args:
		  input: A list of `Tensor` objects.
		    A list of input tensors whose types are T.
		  cond: A function decorated with @Defun.
		          A function takes 'input' and returns a tensor.  If the tensor is
		          a scalar of non-boolean, the scalar is converted to a boolean
		          according to the following rule: if the scalar is a numerical
		          value, non-zero means True and zero means False; if the scalar is
		          a string, non-empty means True and empty means False. If the
		          tensor is not a scalar, non-emptiness means True and False
		          otherwise.
		  body: A function decorated with @Defun.
		          A function that takes a list of tensors and returns another
		          list of tensors. Both lists have the same types as specified
		          by T.
		  output_shapes: An optional list of shapes (each a `tf.TensorShape` or list of `ints`). Defaults to `[]`.
		  parallel_iterations: An optional `int`. Defaults to `10`.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `Tensor` objects. Has the same type as `input`.
	**/
	static public function While(input:Dynamic, cond:Dynamic, body:Dynamic, ?output_shapes:Dynamic, ?parallel_iterations:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A Reader that outputs the entire contents of a file as a value.
		
		To use, enqueue filenames in a Queue.  The output of ReaderRead will
		be a filename (key) and the contents of that file (value).
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type mutable `string`.
	**/
	static public function WholeFileReader(?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		A Reader that outputs the entire contents of a file as a value.
		
		To use, enqueue filenames in a Queue.  The output of ReaderRead will
		be a filename (key) and the contents of that file (value).
		
		Args:
		  container: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is placed in the given container.
		    Otherwise, a default container is used.
		  shared_name: An optional `string`. Defaults to `""`.
		    If non-empty, this reader is named in the given bucket
		    with this shared_name. Otherwise, the node name is used instead.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `resource`.
	**/
	static public function WholeFileReaderV2(?container:Dynamic, ?shared_name:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Combines (nests of) input elements into a dataset of (nests of) windows.
		
		A "window" is a finite dataset of flat elements of size `size` (or possibly
		fewer if there are not enough input elements to fill the window and
		`drop_remainder` evaluates to false).
		
		The `shift` argument determines the number of input elements by which
		the window moves on each iteration.  The first element in the `k`th window
		will be element
		
		```
		1 + (k-1) * shift
		```
		
		of the input dataset. In particular, the first element of the first window
		will always be the first element of the input dataset.  
		
		If the `stride` parameter is greater than 1, then each window will skip
		`(stride - 1)` input elements between each element that appears in the
		window. Output windows will still contain `size` elements regardless of
		the value of `stride`.
		
		The `stride` argument determines the stride of the input elements, and the
		`shift` argument determines the shift of the window.
		
		For example, letting `{...}` to represent a Dataset:
		
		- `tf.data.Dataset.range(7).window(2)` produces
		  `{{0, 1}, {2, 3}, {4, 5}, {6}}`
		- `tf.data.Dataset.range(7).window(3, 2, 1, True)` produces
		  `{{0, 1, 2}, {2, 3, 4}, {4, 5, 6}}`
		- `tf.data.Dataset.range(7).window(3, 1, 2, True)` produces
		  `{{0, 2, 4}, {1, 3, 5}, {2, 4, 6}}`
		
		Note that when the `window` transformation is applied to a dataset of
		nested elements, it produces a dataset of nested windows.
		
		For example:
		
		- `tf.data.Dataset.from_tensor_slices((range(4), range(4))).window(2)`
		  produces `{({0, 1}, {0, 1}), ({2, 3}, {2, 3})}`
		- `tf.data.Dataset.from_tensor_slices({"a": range(4)}).window(2)`
		  produces `{{"a": {0, 1}}, {"a": {2, 3}}}`
		
		Args:
		  input_dataset: A `Tensor` of type `variant`.
		  size: A `Tensor` of type `int64`.
		    An integer scalar, representing the number of elements
		    of the input dataset to combine into a window. Must be positive.
		  shift: A `Tensor` of type `int64`.
		    An integer scalar, representing the number of input elements
		    by which the window moves in each iteration.  Defaults to `size`.
		    Must be positive.
		  stride: A `Tensor` of type `int64`.
		    An integer scalar, representing the stride of the input elements
		    in the sliding window. Must be positive. The default value of 1 means
		    "retain every input element".
		  drop_remainder: A `Tensor` of type `bool`.
		    A Boolean scalar, representing whether the last window should be
		    dropped if its size is smaller than `window_size`.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function WindowDataset(input_dataset:Dynamic, size:Dynamic, shift:Dynamic, stride:Dynamic, drop_remainder:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  inputs: A list of `Tensor` objects.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function WindowOp(inputs:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Worker heartbeat op.
		
		Heartbeats may be sent periodically to indicate the coordinator is still active,
		to retrieve the current worker status and to expedite shutdown when necessary.
		
		Args:
		  request: A `Tensor` of type `string`.
		    A string tensor containing a serialized WorkerHeartbeatRequest
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `string`.
	**/
	static public function WorkerHeartbeat(request:Dynamic, ?name:Dynamic):Dynamic;
	/**
		TODO: add doc.
		
		Args:
		  input_handle: A `Tensor` of type `variant`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function WrapDatasetVariant(input_handle:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Writes an audio summary.
		
		Writes encoded audio summary `tensor` at `step` with `tag` using summary `writer`.
		`sample_rate` is the audio sample rate is Hz.
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  step: A `Tensor` of type `int64`.
		  tag: A `Tensor` of type `string`.
		  tensor: A `Tensor` of type `float32`.
		  sample_rate: A `Tensor` of type `float32`.
		  max_outputs: An optional `int` that is `>= 1`. Defaults to `3`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function WriteAudioSummary(writer:Dynamic, step:Dynamic, tag:Dynamic, tensor:Dynamic, sample_rate:Dynamic, ?max_outputs:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Writes contents to the file at input filename. Creates file and recursively
		
		creates directory if not existing.
		
		Args:
		  filename: A `Tensor` of type `string`.
		    scalar. The name of the file to which we write the contents.
		  contents: A `Tensor` of type `string`.
		    scalar. The content to be written to the output file.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function WriteFile(filename:Dynamic, contents:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Writes a graph summary.
		
		Writes TensorFlow graph `tensor` at `step` using summary `writer`.
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  step: A `Tensor` of type `int64`.
		  tensor: A `Tensor` of type `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function WriteGraphSummary(writer:Dynamic, step:Dynamic, tensor:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Writes a histogram summary.
		
		Writes histogram `values` at `step` with `tag` using summary `writer`.
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  step: A `Tensor` of type `int64`.
		  tag: A `Tensor` of type `string`.
		  values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`, `bool`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function WriteHistogramSummary(writer:Dynamic, step:Dynamic, tag:Dynamic, values:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Writes an image summary.
		
		Writes image `tensor` at `step` with `tag` using summary `writer`.
		`tensor` is image with shape [height, width, channels].
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  step: A `Tensor` of type `int64`.
		  tag: A `Tensor` of type `string`.
		  tensor: A `Tensor`. Must be one of the following types: `uint8`, `float64`, `float32`, `half`.
		  bad_color: A `Tensor` of type `uint8`.
		  max_images: An optional `int` that is `>= 1`. Defaults to `3`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function WriteImageSummary(writer:Dynamic, step:Dynamic, tag:Dynamic, tensor:Dynamic, bad_color:Dynamic, ?max_images:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Writes a serialized proto summary.
		
		Writes `tensor`, a serialized proto at `step` using summary `writer`.
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  step: A `Tensor` of type `int64`.
		  tensor: A `Tensor` of type `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function WriteRawProtoSummary(writer:Dynamic, step:Dynamic, tensor:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Writes a scalar summary.
		
		Writes scalar `value` at `step` with `tag` using summary `writer`.
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  step: A `Tensor` of type `int64`.
		  tag: A `Tensor` of type `string`.
		  value: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function WriteScalarSummary(writer:Dynamic, step:Dynamic, tag:Dynamic, value:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Writes a tensor summary.
		
		Writes `tensor` at `step` with `tag` using summary `writer`.
		
		Args:
		  writer: A `Tensor` of type `resource`.
		  step: A `Tensor` of type `int64`.
		  tensor: A `Tensor`.
		  tag: A `Tensor` of type `string`.
		  summary_metadata: A `Tensor` of type `string`.
		  name: A name for the operation (optional).
		
		Returns:
		  The created Operation.
	**/
	static public function WriteSummary(writer:Dynamic, step:Dynamic, tensor:Dynamic, tag:Dynamic, summary_metadata:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns 0 if x == 0, and x / y otherwise, elementwise.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Xdivy(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Concats input tensor across all dimensions.
		
		An op which merges slices the input tensor based on the given num_splits
		attribute, strips paddings optionally, and returns the merged tensor without
		paddings.
		
		This op may be generated via the TPU bridge.
		
		For example, with `input` tensor:
		```
		[[0, 1],
		 [4, 5]]
		[[2, 3],
		 [6, 7]]
		[[8, 9],
		 [12, 13]]
		[[10, 11],
		 [14, 15]]
		```
		`num_splits`:
		```
		[2, 2]
		```
		and `paddings`:
		```
		[1, 1]
		```
		the expected `outputs` is:
		```
		[[0, 1, 2],
		 [4, 5, 6],
		 [8, 9, 10]]
		```
		
		Args:
		  inputs: A list of at least 1 `Tensor` objects with the same type.
		    Input tensor slices in row-major order to merge across all dimensions. All
		    inputs must have the same shape.
		      }
		      out_arg {
		        name: "output"
		        description: <<END
		    Output tensor formed from merging input slices based on num_concats defined.
		  num_concats: A list of `ints`. Number of ways to merge per dimension.
		  paddings: An optional list of `ints`. Defaults to `[]`.
		    Optional list of right paddings per dimension to strip from the final merged
		    tensor. These paddings must not exceed the dimension size of the merged result
		    prior to stripping paddings.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `inputs`.
	**/
	static public function XlaConcatND(inputs:Dynamic, num_concats:Dynamic, ?paddings:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Splits input tensor across all dimensions.
		
		An op which slices the input tensor based on the given num_splits attribute,
		pads slices optionally, and returned the slices. Slices are returned in
		row-major order.
		
		This op may be generated via the TPU bridge.
		
		For example, with `input` tensor:
		```
		[[0, 1, 2],
		 [3, 4, 5],
		 [6, 7, 8]]
		```
		`num_splits`:
		```
		[2, 2]
		```
		and `paddings`:
		```
		[1, 1]
		```
		the expected `outputs` is:
		```
		[[0, 1],
		 [3, 4]]
		[[2, 0],
		 [5, 0]]
		[[6, 7],
		 [0, 0]]
		[[8, 0],
		 [0, 0]]
		```
		
		Args:
		  input: A `Tensor`. Input tensor to split across all dimensions.
		      }
		      out_arg {
		        name: "outputs"
		        description: <<END
		    Output slices based on input and num_splits defined, in row-major order.
		  N: An `int` that is `>= 1`.
		  num_splits: A list of `ints`.
		    Number of ways to split per dimension. Shape dimensions must be evenly
		    divisible.
		  paddings: An optional list of `ints`. Defaults to `[]`.
		    Optional list of right paddings per dimension of input tensor to apply before
		    splitting. This can be used to make a dimension evenly divisible.
		  name: A name for the operation (optional).
		
		Returns:
		  A list of `N` `Tensor` objects with the same type as `input`.
	**/
	static public function XlaSplitND(input:Dynamic, N:Dynamic, num_splits:Dynamic, ?paddings:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns 0 if x == 0, and x * log1p(y) otherwise, elementwise.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Xlog1py(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns 0 if x == 0, and x * log(y) otherwise, elementwise.
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.
		  y: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Xlogy(x:Dynamic, y:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Returns a tensor of zeros with the same shape and type as x.
		
		Args:
		  x: A `Tensor`. a tensor of type T.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function ZerosLike(x:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Compute the Hurwitz zeta function \\(\zeta(x, q)\\).
		
		The Hurwitz zeta function is defined as:
		
		
		\\(\zeta(x, q) = \sum_{n=0}^{\infty} (q + n)^{-x}\\)
		
		Args:
		  x: A `Tensor`. Must be one of the following types: `float32`, `float64`.
		  q: A `Tensor`. Must have the same type as `x`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor`. Has the same type as `x`.
	**/
	static public function Zeta(x:Dynamic, q:Dynamic, ?name:Dynamic):Dynamic;
	/**
		Creates a dataset that zips together `input_datasets`.
		
		The elements of the resulting dataset are created by zipping corresponding
		elements from each of the input datasets.
		
		The size of the resulting dataset will match the size of the smallest input
		dataset, and no error will be raised if input datasets have different sizes.
		
		Args:
		  input_datasets: A list of at least 1 `Tensor` objects with type `variant`.
		    List of `N` variant Tensors representing datasets to be zipped together.
		  output_types: A list of `tf.DTypes` that has length `>= 1`.
		  output_shapes: A list of shapes (each a `tf.TensorShape` or list of `ints`) that has length `>= 1`.
		  metadata: An optional `string`. Defaults to `""`.
		  name: A name for the operation (optional).
		
		Returns:
		  A `Tensor` of type `variant`.
	**/
	static public function ZipDataset(input_datasets:Dynamic, output_types:Dynamic, output_shapes:Dynamic, ?metadata:Dynamic, ?name:Dynamic):Dynamic;
	static public var __builtins__ : Dynamic;
	static public var __cached__ : Dynamic;
	static public var __doc__ : Dynamic;
	static public var __file__ : Dynamic;
	static public var __loader__ : Dynamic;
	static public var __name__ : Dynamic;
	static public var __package__ : Dynamic;
	static public var __path__ : Dynamic;
	static public var __spec__ : Dynamic;
}